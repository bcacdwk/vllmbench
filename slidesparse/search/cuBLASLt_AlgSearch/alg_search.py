#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# SPDX-License-Identifier: Apache-2.0
"""
cuBLASLt ç®—æ³•ç¦»çº¿æœç´¢

æ¶æ„è¯´æ˜ï¼š
=========
- Python ç«¯ï¼šè´Ÿè´£å¤–å±‚ NK å¾ªç¯ã€å‚æ•°è§£æã€GPU æ£€æµ‹ã€æ•°æ®ç”Ÿæˆã€ç»“æœè½ç›˜
- C++ ç«¯ï¼šè´Ÿè´£å†…å±‚ M å¾ªç¯ã€ç®—æ³•æšä¸¾ã€cuBLASLt API è°ƒç”¨ã€ç²¾ç¡®è®¡æ—¶

å›ºå®š Layout:
- T/N + Col/Col + Col (æƒé‡ W åœ¨å·¦)
- W[N,K]^T_col * A[K,M]_col = C[N,M]_col

è¿è¡Œç¤ºä¾‹:
    python3 alg_search.py --dtype int8 --outdtype bf16 --model BitNet-2B4T
    python3 alg_search.py --dtype fp8e4m3 --outdtype bf16 --model BitNet-2B4T
    python3 alg_search.py --dtype int8 --outdtype bf16 --model /path/to/model
"""

import argparse
import base64
import ctypes
import datetime
import json
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

import torch
import numpy as np

# æ·»åŠ  search ç›®å½•åˆ°è·¯å¾„
SCRIPT_DIR = Path(__file__).parent.absolute()
SEARCH_DIR = SCRIPT_DIR.parent
sys.path.insert(0, str(SEARCH_DIR))

from utils import (
    # ç¡¬ä»¶ä¿¡æ¯
    hw_info,
    normalize_dtype,
    # ç¼–è¯‘ä¸åŠ è½½
    ensure_cublaslt_loaded,
    # æ¨¡å‹ NK å·¥å…·
    get_nk_list_auto,
    build_model_name_with_dtype,
    # è¾“å‡ºå‘½å
    build_output_dir_name,
    build_result_filename,
    # å…ƒæ•°æ®
    build_search_meta,
    build_csv_header_lines,
    # dtype æ£€æµ‹
    SUPPORTED_DTYPES,
    SUPPORTED_OUTDTYPES,
    # é»˜è®¤é…ç½®
    default_m_list,
)


# =============================================================================
# CUDA æ‰©å±•ç¼–è¯‘ä¸åŠ è½½
# =============================================================================

def build_cuda_extension(
    source_file: Path,
    build_dir: Path,
    force: bool = False,
    verbose: bool = True,
) -> Path:
    """
    ä½¿ç”¨ nvcc ç›´æ¥ç¼–è¯‘ CUDA æ‰©å±•ä¸º .so æ–‡ä»¶ã€‚
    
    Returns:
        ç¼–è¯‘ç”Ÿæˆçš„ .so æ–‡ä»¶è·¯å¾„
    """
    build_dir.mkdir(parents=True, exist_ok=True)
    
    so_name = f"alg_search_cublaslt_{hw_info.gpu_name}_{hw_info.cc_tag}.so"
    so_path = build_dir / so_name
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç¼–è¯‘
    if so_path.exists() and not force:
        if source_file.stat().st_mtime <= so_path.stat().st_mtime:
            if verbose:
                print(f"âœ“ Using existing: {so_path.name}")
            return so_path
    
    if verbose:
        print(f"ğŸ”¨ Building {so_name}...")
    
    # CUDA è·¯å¾„
    import os
    cuda_home = os.environ.get('CUDA_HOME', '/usr/local/cuda')
    nvcc = Path(cuda_home) / 'bin' / 'nvcc'
    
    # ç¼–è¯‘å‘½ä»¤
    cmd = [
        str(nvcc),
        '-std=c++17', '-O3', '-Xcompiler', '-fPIC', '--shared',
        f'-gencode=arch=compute_{hw_info.cc_major}{hw_info.cc_minor},'
        f'code=sm_{hw_info.cc_major}{hw_info.cc_minor}',
        f'-I{cuda_home}/include',
        str(source_file),
        '-L/usr/lib/x86_64-linux-gnu',
        '-lcublasLt', '-lcublas', '-lcuda',
        '-o', str(so_path),
    ]
    
    if verbose:
        print(f"Command: {' '.join(cmd)}")
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode != 0:
        error_msg = result.stderr or result.stdout
        raise RuntimeError(f"ç¼–è¯‘å¤±è´¥:\n{error_msg}")
    
    if verbose:
        print(f"âœ“ Built: {so_path.name}")
    
    return so_path


def load_extension(so_path: Path) -> ctypes.CDLL:
    """
    åŠ è½½ç¼–è¯‘å¥½çš„ CUDA æ‰©å±•ã€‚
    """
    # ç¡®ä¿ cuBLASLt åº“å·²åŠ è½½
    ensure_cublaslt_loaded()
    
    # åŠ è½½æ‰©å±•
    lib = ctypes.CDLL(str(so_path), mode=ctypes.RTLD_GLOBAL)
    
    # è®¾ç½®å‡½æ•°ç­¾å
    lib.cublaslt_search_single_m.argtypes = [
        ctypes.c_void_p,   # W_ptr
        ctypes.c_void_p,   # A_ptr
        ctypes.c_void_p,   # C_ptr
        ctypes.c_int64,    # N
        ctypes.c_int64,    # K
        ctypes.c_int64,    # M
        ctypes.c_char_p,   # dtype
        ctypes.c_char_p,   # outdtype
        ctypes.c_int,      # warmup
        ctypes.c_int,      # repeat
        ctypes.c_int,      # topk
        ctypes.POINTER(ctypes.c_int),        # out_alg_ids
        ctypes.POINTER(ctypes.c_float),      # out_lat_us
        ctypes.POINTER(ctypes.c_float),      # out_tops
        ctypes.POINTER(ctypes.c_int64),      # out_workspace
        ctypes.POINTER(ctypes.c_float),      # out_waves_count
        ctypes.POINTER(ctypes.c_uint8),      # out_algo_data
        ctypes.POINTER(ctypes.c_uint8),      # out_valid
        ctypes.POINTER(ctypes.c_int),        # out_num_valid
        ctypes.POINTER(ctypes.c_int),        # out_alg_count
        ctypes.c_void_p,   # stream
    ]
    lib.cublaslt_search_single_m.restype = ctypes.c_int
    
    lib.cublaslt_alg_search_is_available.argtypes = []
    lib.cublaslt_alg_search_is_available.restype = ctypes.c_int
    
    lib.cublaslt_alg_search_get_last_error.argtypes = []
    lib.cublaslt_alg_search_get_last_error.restype = ctypes.c_char_p
    
    lib.cublaslt_alg_search_get_alignment.argtypes = [ctypes.c_char_p]
    lib.cublaslt_alg_search_get_alignment.restype = ctypes.c_int
    
    return lib


# =============================================================================
# æ•°æ®å‡†å¤‡
# =============================================================================

def quantize_int8(x: torch.Tensor) -> Tuple[torch.Tensor, float]:
    """å°† BF16/FP16 å¼ é‡é‡åŒ–åˆ° INT8"""
    abs_max = x.abs().max().item()
    scale = 127.0 / abs_max if abs_max > 0 else 1.0
    q = (x * scale).round().clamp(-128, 127).to(torch.int8)
    return q, scale


def to_fp8_e4m3(x: torch.Tensor) -> torch.Tensor:
    """è½¬æ¢ä¸º FP8E4M3"""
    return x.to(torch.float8_e4m3fn)


def prepare_data(
    W_bf16: torch.Tensor,
    A_bf16: torch.Tensor,
    dtype: str,
) -> Tuple[torch.Tensor, torch.Tensor]:
    """å‡†å¤‡é‡åŒ–åçš„æ•°æ®"""
    if dtype == "int8":
        W_q, _ = quantize_int8(W_bf16)
        A_q, _ = quantize_int8(A_bf16)
    elif dtype == "fp8e4m3":
        W_q = to_fp8_e4m3(W_bf16)
        A_q = to_fp8_e4m3(A_bf16)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {dtype}")
    
    return W_q, A_q


# =============================================================================
# æœç´¢æ ¸å¿ƒ
# =============================================================================

def search_single_nk(
    lib: ctypes.CDLL,
    N: int, K: int, M: int,
    W_q: torch.Tensor,
    A_q: torch.Tensor,
    dtype: str,
    outdtype: str,
    warmup: int,
    repeat: int,
    topk: int = 3,
) -> Dict[str, Any]:
    """
    æœç´¢å•ä¸ª (N, K, M) ç»„åˆçš„æœ€ä½³ç®—æ³•ã€‚
    """
    # åˆ†é…è¾“å‡ºç¼“å†²
    C_torch_dtype = torch.float32 if outdtype == "fp32" else torch.bfloat16
    C_out = torch.zeros(M, N, dtype=C_torch_dtype, device=W_q.device)
    
    # åˆ†é…è¾“å‡ºæ•°ç»„
    out_alg_ids = (ctypes.c_int * topk)()
    out_lat_us = (ctypes.c_float * topk)()
    out_tops = (ctypes.c_float * topk)()
    out_workspace = (ctypes.c_int64 * topk)()
    out_waves_count = (ctypes.c_float * topk)()
    out_algo_data = (ctypes.c_uint8 * (topk * 64))()
    out_valid = (ctypes.c_uint8 * topk)()
    out_num_valid = ctypes.c_int(0)
    out_alg_count = ctypes.c_int(0)
    
    # è°ƒç”¨ C å‡½æ•°
    ret = lib.cublaslt_search_single_m(
        W_q.data_ptr(),
        A_q.data_ptr(),
        C_out.data_ptr(),
        N, K, M,
        dtype.encode(),
        outdtype.encode(),
        warmup,
        repeat,
        topk,
        out_alg_ids,
        out_lat_us,
        out_tops,
        out_workspace,
        out_waves_count,
        out_algo_data,
        out_valid,
        ctypes.byref(out_num_valid),
        ctypes.byref(out_alg_count),
        None,  # ä½¿ç”¨é»˜è®¤ stream
    )
    
    if ret != 0:
        error = lib.cublaslt_alg_search_get_last_error()
        raise RuntimeError(f"æœç´¢å¤±è´¥: {error.decode() if error else 'unknown error'}")
    
    # è½¬æ¢ç»“æœ
    results = []
    for i in range(topk):
        if out_valid[i]:
            algo_bytes = bytes(out_algo_data[i*64:(i+1)*64])
            results.append({
                "alg_id": out_alg_ids[i],
                "lat_us": out_lat_us[i],
                "tops": out_tops[i],
                "workspace": out_workspace[i],
                "waves_count": out_waves_count[i],
                "algo_data": algo_bytes,
            })
    
    return {
        "results": results,
        "num_valid": out_num_valid.value,
        "alg_count": out_alg_count.value,
    }


def run_search(
    lib: ctypes.CDLL,
    dtype: str,
    outdtype: str,
    nk_list: List[Tuple[int, int]],
    m_list: List[int],
    warmup: int,
    repeat: int,
    topk: int = 3,
    verbose: bool = True,
) -> Dict:
    """
    è¿è¡Œå®Œæ•´çš„ç®—æ³•æœç´¢ã€‚
    """
    layout = "TNCCcol"
    results = []
    max_M = max(m_list)
    total_nk = len(nk_list)
    
    max_alg_count = 0
    
    for nk_id, (N, K) in enumerate(nk_list):
        if verbose:
            print(f"    NK {nk_id+1}/{total_nk}: ({N}, {K})", flush=True)
        
        # ç”Ÿæˆéšæœºæ•°æ®
        W = torch.randn(N, K, device="cuda", dtype=torch.bfloat16)
        A = torch.randn(max_M, K, device="cuda", dtype=torch.bfloat16)
        
        # é‡åŒ–
        W_q, A_q = prepare_data(W, A, dtype)
        
        nk_results = {
            "nk_id": nk_id,
            "N": N,
            "K": K,
            "m_results": {},
        }
        
        for M in m_list:
            # åˆ‡ç‰‡
            A_slice = A_q[:M].contiguous()
            
            out = search_single_nk(
                lib, N, K, M,
                W_q, A_slice,
                dtype, outdtype,
                warmup, repeat, topk,
            )
            
            nk_results["m_results"][M] = out
            
            if out["alg_count"] > max_alg_count:
                max_alg_count = out["alg_count"]
        
        if verbose:
            first_m = m_list[0]
            first_result = nk_results["m_results"][first_m]
            print(f"      â†’ å¯å‘å¼è¿”å›: {first_result['alg_count']} ç®—æ³•, æœ‰æ•ˆ: {first_result['num_valid']}")
        
        results.append(nk_results)
        
        # é‡Šæ”¾
        del W, A, W_q, A_q
    
    torch.cuda.empty_cache()
    
    return {
        "dtype": dtype,
        "outdtype": outdtype,
        "results": results,
        "M_list": m_list,
        "NK_list": nk_list,
        "max_alg_count": max_alg_count,
    }


# =============================================================================
# ç»“æœä¿å­˜
# =============================================================================

def save_outputs(
    out_dir: Path,
    model_name: str,
    dtype: str,
    outdtype: str,
    search_ret: Dict,
    warmup: int,
    repeat: int,
    verify: bool,
) -> Path:
    """
    ä¿å­˜æœç´¢ç»“æœåˆ° CSV å’Œ JSON æ–‡ä»¶ã€‚
    """
    layout = "TNCCcol"
    
    subdir_name = build_output_dir_name(model_name, dtype, outdtype)
    subdir = out_dir / subdir_name
    subdir.mkdir(parents=True, exist_ok=True)
    
    csv_path = subdir / build_result_filename("alg_search_bench", model_name, "csv")
    json_path = subdir / build_result_filename("alg_search_LUT", model_name, "json")
    
    alg_count = search_ret.get("max_alg_count", 0)
    config_count = alg_count  # cuBLASLt æ²¡æœ‰ split-k
    
    # === CSV ç”Ÿæˆ ===
    header_lines = build_csv_header_lines(
        model_name=model_name,
        dtype=dtype,
        outdtype=outdtype,
        warmup=warmup,
        repeat=repeat,
        verify=verify,
        m_list=search_ret["M_list"],
        nk_list=search_ret["NK_list"],
        layout=layout,
        alg_count=alg_count,
        config_count=config_count,
    )
    
    # CSV æ•°æ®åˆ—
    csv_lines = list(header_lines)
    csv_lines.append("M,N,K,alg_count,config_count,tops1,lat_us1,id1,ws1,waves1,tops2,lat_us2,id2,ws2,waves2,tops3,lat_us3,id3,ws3,waves3")
    
    csv_rows = []  # [(M, nk_idx, line), ...]
    
    for nk_idx, nk_res in enumerate(search_ret["results"]):
        N, K = nk_res["N"], nk_res["K"]
        
        for M in search_ret["M_list"]:
            m_res = nk_res["m_results"].get(M, {})
            results = m_res.get("results", [])
            
            values = [str(M), str(N), str(K), str(m_res.get("alg_count", 0)), str(m_res.get("alg_count", 0))]
            
            for k in range(3):
                if k < len(results):
                    r = results[k]
                    values.extend([
                        f"{r['tops']:.6f}",
                        f"{r['lat_us']:.3f}",
                        str(r['alg_id']),
                        str(r['workspace']),
                        f"{r['waves_count']:.4f}",
                    ])
                else:
                    values.extend(["", "", "", "", ""])
            
            csv_rows.append((M, nk_idx, ",".join(values)))
    
    csv_rows.sort(key=lambda x: (x[0], x[1]))
    for _, _, line in csv_rows:
        csv_lines.append(line)
    
    csv_path.write_text("\n".join(csv_lines))
    
    # === JSON ç”Ÿæˆ ===
    meta = build_search_meta(
        dtype=dtype,
        outdtype=outdtype,
        warmup=warmup,
        repeat=repeat,
        verify=verify,
        m_list=search_ret["M_list"],
        nk_list=search_ret["NK_list"],
        model_name=model_name,
        layout=layout,
        alg_count=alg_count,
        config_count=config_count,
    )
    
    nk_entries = {}
    for nk_res in search_ret["results"]:
        N, K = nk_res["N"], nk_res["K"]
        nk_key = f"({N},{K})"
        
        m_thresholds = []
        alg_by_m = {}
        
        for M in search_ret["M_list"]:
            m_res = nk_res["m_results"].get(M, {})
            results = m_res.get("results", [])
            
            if results:
                m_thresholds.append(M)
                top3_b64 = []
                for r in results[:3]:
                    if "algo_data" in r:
                        algo_b64 = base64.b64encode(r["algo_data"]).decode('ascii')
                        top3_b64.append(algo_b64)
                alg_by_m[str(M)] = top3_b64
        
        nk_entries[nk_key] = {
            "m_thresholds": m_thresholds,
            "alg_by_m": alg_by_m,
        }
    
    json_payload = {
        "meta": meta,
        "nk_entries": nk_entries,
    }
    json_path.write_text(json.dumps(json_payload, indent=2, ensure_ascii=False))
    
    print(f"å·²ç”Ÿæˆ: {csv_path}")
    print(f"å·²ç”Ÿæˆ: {json_path}")
    
    return subdir


# =============================================================================
# ä¸»æµç¨‹
# =============================================================================

def parse_args():
    p = argparse.ArgumentParser(description="cuBLASLt ç®—æ³•ç¦»çº¿æœç´¢")
    p.add_argument("--dtype", default="int8", choices=SUPPORTED_DTYPES, help="è¾“å…¥æ•°æ®ç±»å‹")
    p.add_argument("--outdtype", default="bf16", choices=SUPPORTED_OUTDTYPES, help="è¾“å‡ºæ•°æ®ç±»å‹")
    p.add_argument("--model", default="BitNet-2B4T", help="æ¨¡å‹åç§°æˆ–è·¯å¾„")
    p.add_argument("--warmup", type=int, default=25)
    p.add_argument("--repeat", type=int, default=100)
    p.add_argument("--verify", action="store_true", help="å¼€å¯æ­£ç¡®æ€§æ ¡éªŒ")
    p.add_argument("--compile", action="store_true", help="å¼ºåˆ¶é‡æ–°ç¼–è¯‘ CUDA æ‰©å±•")
    p.add_argument("--out_dir", default=None, help="è¾“å‡ºç›®å½•")
    p.add_argument("--m_list", type=str, default=None, help="M åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼Œå¦‚ 16,128,512,2048,16384")
    return p.parse_args()


def main():
    args = parse_args()
    
    if not torch.cuda.is_available():
        raise RuntimeError("éœ€è¦ CUDA ç¯å¢ƒ")
    
    # æ„å»ºæ¨¡å‹åç§°
    dtype_suffix = normalize_dtype(args.dtype)
    model_name = build_model_name_with_dtype(args.model.split('/')[-1], args.dtype)
    
    # === æ˜¾ç¤ºé…ç½®ä¿¡æ¯ ===
    print("=" * 60)
    print("cuBLASLt ç®—æ³•ç¦»çº¿æœç´¢")
    print("=" * 60)
    print(f"GPU: {hw_info.gpu_full_name} ({hw_info.cc_tag}, {hw_info.arch_name})")
    print(f"æ¨¡å‹: {model_name}")
    print(f"å‚æ•°: dtype={args.dtype}, outdtype={args.outdtype}, warmup={args.warmup}, repeat={args.repeat}")
    print()
    
    # è¾“å‡ºç›®å½•
    out_dir = Path(args.out_dir) if args.out_dir else Path("./alg_search_results")
    
    # ç¼–è¯‘ CUDA æ‰©å±•
    print("[1/4] ç¼–è¯‘ CUDA æ‰©å±•...")
    src_path = SCRIPT_DIR / "alg_search_cublaslt.cu"
    build_dir = SCRIPT_DIR / "build"
    so_path = build_cuda_extension(src_path, build_dir, force=args.compile)
    
    print("[2/4] åŠ è½½ CUDA æ‰©å±•...")
    lib = load_extension(so_path)
    
    if not lib.cublaslt_alg_search_is_available():
        raise RuntimeError("cuBLASLt ä¸å¯ç”¨")
    print("âœ“ cuBLASLt å¯ç”¨")
    
    # è·å– NK åˆ—è¡¨
    nk_list = get_nk_list_auto(args.model, with_names=False)
    
    # è·å– M åˆ—è¡¨
    if args.m_list:
        m_list = [int(x.strip()) for x in args.m_list.split(",")]
    else:
        m_list = default_m_list()
    
    print()
    print(f"[3/4] å¼€å§‹ç®—æ³•æœç´¢...")
    print(f"      NK ç»„åˆ: {len(nk_list)} ä¸ª, M åˆ—è¡¨: {m_list}")
    print()
    
    ret = run_search(
        lib,
        args.dtype,
        args.outdtype,
        nk_list,
        m_list,
        args.warmup,
        args.repeat,
        topk=3,
        verbose=True,
    )
    
    saved_dir = save_outputs(
        out_dir,
        model_name,
        args.dtype,
        args.outdtype,
        ret,
        args.warmup,
        args.repeat,
        args.verify,
    )
    
    print()
    print(f"[4/4] å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°:")
    print(f"      - {saved_dir}")
    print("=" * 60)


if __name__ == "__main__":
    main()
