# Auto-generated by autotune_autogen_quant_only.py
# Target: RTX5080 (cc120)
# Design: Per-row kernel (grid = M), Unified FP8/INT8
# DO NOT EDIT

import torch
import triton
import triton.language as tl

# Tensor Cache for output allocation

_fp8_out_cache: dict = {}
_fp8_scale_cache: dict = {}
_int8_out_cache: dict = {}
_int8_scale_cache: dict = {}


def _get_cached_fp8_tensors(M_padded: int, K_padded: int, device: torch.device):
    """Get or create cached FP8 output tensors."""
    key = (M_padded, K_padded, device.index if device.index is not None else 0)
    if key not in _fp8_out_cache:
        _fp8_out_cache[key] = torch.empty(M_padded, K_padded, dtype=torch.float8_e4m3fn, device=device)
        _fp8_scale_cache[key] = torch.empty(M_padded, dtype=torch.float32, device=device)
    # Must zero/fill every call since kernel only writes valid M rows
    out, scale = _fp8_out_cache[key], _fp8_scale_cache[key]
    out.zero_()
    scale.fill_(1.0)
    return out, scale


def _get_cached_int8_tensors(M_padded: int, K_padded: int, device: torch.device):
    """Get or create cached INT8 output tensors."""
    key = (M_padded, K_padded, device.index if device.index is not None else 0)
    if key not in _int8_out_cache:
        _int8_out_cache[key] = torch.empty(M_padded, K_padded, dtype=torch.int8, device=device)
        _int8_scale_cache[key] = torch.empty(M_padded, dtype=torch.float32, device=device)
    # Must zero/fill every call since kernel only writes valid M rows
    out, scale = _int8_out_cache[key], _int8_scale_cache[key]
    out.zero_()
    scale.fill_(1.0)
    return out, scale


def _get_config(M: int, K: int) -> tuple:
    """Returns (BLOCK_K, num_warps, num_stages)"""
    if K == 2560:
        if M <= 16:
            return 8192, 16, 2
        elif M <= 128:
            return 4096, 4, 4
        elif M <= 1024:
            return 4096, 1, 2
        else:
            return 4096, 1, 3
    elif K == 6912:
        if M <= 16:
            return 8192, 8, 1
        elif M <= 128:
            return 8192, 8, 3
        elif M <= 1024:
            return 8192, 16, 1
        elif M <= 4096:
            return 8192, 16, 3
        else:
            return 8192, 16, 1
    # Default fallback
    if K <= 4096:
        return 4096, 8, 2
    return 8192, 8, 2


# =============================================================================
# FP8 Kernel
# =============================================================================

@triton.jit
def _quant_only_fp8_kernel(
    x_ptr, out_ptr, scale_ptr,
    M, K: tl.constexpr,
    stride_xm, stride_om,
    BLOCK_K: tl.constexpr,
):
    """Per-token FP8 quantization kernel - one program per row"""
    row = tl.program_id(0)
    
    FP8_MAX: tl.constexpr = 448.0
    MIN_SCALE: tl.constexpr = 1.0 / (448.0 * 512.0)
    
    x_row_ptr = x_ptr + row * stride_xm
    out_row_ptr = out_ptr + row * stride_om
    
    # Pass 1: 计算 absmax
    absmax = tl.zeros((), dtype=tl.float32)
    
    for k_start in range(0, K, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        mask_k = offs_k < K
        x_val = tl.load(x_row_ptr + offs_k, mask=mask_k, other=0.0).to(tl.float32)
        absmax = tl.maximum(absmax, tl.max(tl.abs(x_val)))
    
    # 计算 scale
    absmax = tl.maximum(absmax, 1e-12)
    scale = tl.maximum(absmax / FP8_MAX, MIN_SCALE)
    inv_scale = FP8_MAX / absmax
    
    tl.store(scale_ptr + row, scale)
    
    # Pass 2: 量化
    for k_start in range(0, K, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        mask_k = offs_k < K
        x_val = tl.load(x_row_ptr + offs_k, mask=mask_k, other=0.0).to(tl.float32)
        y_val = tl.clamp(x_val * inv_scale, -FP8_MAX, FP8_MAX)
        tl.store(out_row_ptr + offs_k, y_val.to(tl.float8e4nv), mask=mask_k)


def quant_only_fp8_triton(
    x: torch.Tensor,
) -> tuple[torch.Tensor, torch.Tensor]:

    assert x.is_cuda and x.is_contiguous()
    M, K = x.shape
    
    # Padding: K -> 32 aligned, M -> 16 aligned
    K_padded = ((K + 31) // 32) * 32
    M_padded = ((M + 15) // 16) * 16
    
    out, scale = _get_cached_fp8_tensors(M_padded, K_padded, x.device)
    
    BLOCK_K, num_warps, num_stages = _get_config(M, K)
    
    # Per-row: grid = (M,) - 只处理有效的 M 行
    _quant_only_fp8_kernel[(M,)](
        x, out, scale,
        M, K,
        x.stride(0), K_padded,  # output stride 使用 K_padded
        BLOCK_K=BLOCK_K,
        num_warps=num_warps,
        num_stages=num_stages,
    )
    return out, scale


# =============================================================================
# INT8 Kernel
# =============================================================================

@triton.jit
def _quant_only_int8_kernel(
    x_ptr, out_ptr, scale_ptr,
    M, K: tl.constexpr,
    stride_xm, stride_om,
    BLOCK_K: tl.constexpr,
):
    """Per-token INT8 quantization kernel - one program per row"""
    row = tl.program_id(0)
    
    INT8_MAX: tl.constexpr = 127.0
    MIN_SCALE: tl.constexpr = 1.0 / (127.0 * 512.0)
    
    x_row_ptr = x_ptr + row * stride_xm
    out_row_ptr = out_ptr + row * stride_om
    
    # Pass 1: 计算 absmax
    absmax = tl.zeros((), dtype=tl.float32)
    
    for k_start in range(0, K, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        mask_k = offs_k < K
        x_val = tl.load(x_row_ptr + offs_k, mask=mask_k, other=0.0).to(tl.float32)
        absmax = tl.maximum(absmax, tl.max(tl.abs(x_val)))
    
    # 计算 scale
    absmax = tl.maximum(absmax, 1e-12)
    scale = tl.maximum(absmax / INT8_MAX, MIN_SCALE)
    inv_scale = INT8_MAX / absmax
    
    tl.store(scale_ptr + row, scale)
    
    # Pass 2: 量化
    for k_start in range(0, K, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        mask_k = offs_k < K
        x_val = tl.load(x_row_ptr + offs_k, mask=mask_k, other=0.0).to(tl.float32)
        y_val = tl.clamp(tl.extra.cuda.libdevice.rint(x_val * inv_scale), -128.0, 127.0)
        tl.store(out_row_ptr + offs_k, y_val.to(tl.int8), mask=mask_k)


def quant_only_int8_triton(
    x: torch.Tensor,
) -> tuple[torch.Tensor, torch.Tensor]:

    assert x.is_cuda and x.is_contiguous()
    M, K = x.shape
    
    # Padding: K -> 32 aligned, M -> 16 aligned
    K_padded = ((K + 31) // 32) * 32
    M_padded = ((M + 15) // 16) * 16
    
    out, scale = _get_cached_int8_tensors(M_padded, K_padded, x.device)
    
    BLOCK_K, num_warps, num_stages = _get_config(M, K)
    
    # Per-row: grid = (M,) - 只处理有效的 M 行
    _quant_only_int8_kernel[(M,)](
        x, out, scale,
        M, K,
        x.stride(0), K_padded,  # output stride 使用 K_padded
        BLOCK_K=BLOCK_K,
        num_warps=num_warps,
        num_stages=num_stages,
    )
    return out, scale


__all__ = ['quant_only_fp8_triton', 'quant_only_int8_triton', '_get_config']
