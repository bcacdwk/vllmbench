#!/usr/bin/env python3
# SPDX-License-Identifier: Apache-2.0
"""
SlideSparse CSRC ç¼–è¯‘å·¥å…·åº“

æœ¬æ¨¡å—æä¾› CUDA æ‰©å±•ç¼–è¯‘ç›¸å…³çš„é€šç”¨å·¥å…·å‡½æ•°ã€‚

æ³¨æ„ï¼šæ–‡ä»¶åã€ç¡¬ä»¶ä¿¡æ¯ç­‰åŠŸèƒ½è¯·ä½¿ç”¨é¡¶å±‚ slidesparse.utils æ¨¡å—ã€‚

ä¸»è¦åŠŸèƒ½
========
1. NVCC æ¶æ„æ ‡å¿—ç”Ÿæˆ
2. CUDA æ‰©å±•ç¼–è¯‘å™¨ï¼ˆæ”¯æŒ cuBLASLt, cuSPARSELt ç­‰ï¼‰
3. ç¼–è¯‘äº§ç‰©æ¸…ç†
4. Triton Autotune é…ç½®

ä½¿ç”¨ç¤ºä¾‹
========
>>> from slidesparse.csrc.utils import build_cuda_extension, get_nvcc_arch_flags
>>>
>>> # ç¼–è¯‘ cuBLASLt æ‰©å±•
>>> so_path = build_cuda_extension(
...     name="cublaslt_gemm",
...     source_file=Path("cublaslt_gemm.cu"),
...     build_dir=Path("build"),
...     extra_ldflags=["-lcublasLt", "-lcublas"],
... )
"""

import os
import sys
import shutil
from pathlib import Path
from typing import List, Optional, Callable

import torch
from torch.utils.cpp_extension import load


# =============================================================================
# NVCC æ¶æ„æ ‡å¿—
# =============================================================================

# æ”¯æŒçš„ GPU æ¶æ„åˆ—è¡¨
SUPPORTED_ARCHITECTURES = [
    ("80", "sm_80"),   # Ampere (A100, A10, A30)
    ("86", "sm_86"),   # Ampere (RTX 30xx)
    ("89", "sm_89"),   # Ada Lovelace (RTX 40xx)
    ("90", "sm_90"),   # Hopper (H100, H200)
    ("100", "sm_100"), # Blackwell (B100, B200)
    ("120", "sm_120"), # Blackwell (RTX 50xx, GB10)
]


def get_nvcc_arch_flags(
    min_compute: int = 80,
    max_compute: int = 120,
) -> List[str]:
    """
    ç”Ÿæˆ nvcc æ¶æ„ç¼–è¯‘é€‰é¡¹
    
    æ”¯æŒä» SM 80 (Ampere) åˆ° SM 120 (Blackwell)
    
    Args:
        min_compute: æœ€å°æ”¯æŒçš„ compute capability (é»˜è®¤ 80)
        max_compute: æœ€å¤§æ”¯æŒçš„ compute capability (é»˜è®¤ 120)
        
    Returns:
        nvcc -gencode æ ‡å¿—åˆ—è¡¨
        
    Example:
        >>> get_nvcc_arch_flags()
        ['-gencode=arch=compute_80,code=sm_80', ...]
    """
    flags = []
    for compute, sm in SUPPORTED_ARCHITECTURES:
        cc = int(compute)
        if min_compute <= cc <= max_compute:
            flags.append(f"-gencode=arch=compute_{compute},code={sm}")
    return flags


def get_current_arch_flag() -> str:
    """
    è·å–å½“å‰ GPU æ¶æ„çš„ nvcc ç¼–è¯‘æ ‡å¿—
    
    Returns:
        å•ä¸ª -gencode æ ‡å¿—ï¼Œé’ˆå¯¹å½“å‰ GPU
        
    Raises:
        RuntimeError: CUDA ä¸å¯ç”¨
    """
    if not torch.cuda.is_available():
        raise RuntimeError("CUDA not available")
    prop = torch.cuda.get_device_properties(0)
    compute = f"{prop.major}{prop.minor}"
    return f"-gencode=arch=compute_{compute},code=sm_{compute}"


# =============================================================================
# CUDA æ‰©å±•ç¼–è¯‘å™¨
# =============================================================================

# é»˜è®¤ç¼–è¯‘é€‰é¡¹
DEFAULT_CFLAGS = ['-O3', '-std=c++17']

DEFAULT_CUDA_CFLAGS = [
    '-O3',
    '-std=c++17',
    '--expt-relaxed-constexpr',
    '--expt-extended-lambda',
    '-U__CUDA_NO_HALF_OPERATORS__',
    '-U__CUDA_NO_HALF_CONVERSIONS__',
    '-U__CUDA_NO_BFLOAT16_CONVERSIONS__',
]


def should_rebuild(so_path: Path, source_paths: List[Path]) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°ç¼–è¯‘
    
    å¦‚æœ .so ä¸å­˜åœ¨æˆ–æ¯”ä»»ä¸€æºæ–‡ä»¶æ—§ï¼Œè¿”å› True
    
    Args:
        so_path: .so æ–‡ä»¶è·¯å¾„
        source_paths: æºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        
    Returns:
        æ˜¯å¦éœ€è¦é‡æ–°ç¼–è¯‘
    """
    if not so_path.exists():
        return True
    
    so_mtime = so_path.stat().st_mtime
    for src in source_paths:
        if src.exists() and src.stat().st_mtime > so_mtime:
            return True
    return False


def clean_build_artifacts(build_dir: Path, keep_extensions: List[str] = None):
    """
    æ¸…ç†ç¼–è¯‘ä¸­é—´æ–‡ä»¶
    
    é»˜è®¤ä¿ç•™ .so å’Œ .py æ–‡ä»¶ï¼Œåˆ é™¤å…¶ä»–æ‰€æœ‰å†…å®¹ã€‚
    
    Args:
        build_dir: æ„å»ºç›®å½•
        keep_extensions: è¦ä¿ç•™çš„æ–‡ä»¶æ‰©å±•ååˆ—è¡¨ï¼ˆé»˜è®¤ ['.so', '.py']ï¼‰
    """
    if keep_extensions is None:
        keep_extensions = ['.so', '.py']
    
    if not build_dir.exists():
        return
    
    for item in build_dir.iterdir():
        # ä¿ç•™æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶
        if item.suffix in keep_extensions:
            continue
        
        # åˆ é™¤å…¶ä»–æ–‡ä»¶å’Œç›®å½•
        if item.is_dir():
            shutil.rmtree(item)
        else:
            item.unlink()


def build_cuda_extension(
    name: str,
    source_file: Path,
    build_dir: Path,
    *,
    extra_cflags: List[str] = None,
    extra_cuda_cflags: List[str] = None,
    extra_ldflags: List[str] = None,
    extra_include_paths: List[str] = None,
    force: bool = False,
    verbose: bool = True,
    clean_after_build: bool = True,
) -> Path:
    """
    ç¼–è¯‘ CUDA æ‰©å±•çš„é€šç”¨å‡½æ•°
    
    æ”¯æŒç¼–è¯‘ cuBLASLt, cuSPARSELt ç­‰ CUDA æ‰©å±•ã€‚
    
    Args:
        name: æ‰©å±•åç§°ï¼ˆä¸å« .so åç¼€ï¼‰
        source_file: æºæ–‡ä»¶è·¯å¾„ (.cu æˆ– .cpp)
        build_dir: æ„å»ºç›®å½•
        extra_cflags: é¢å¤–çš„ C++ ç¼–è¯‘æ ‡å¿—
        extra_cuda_cflags: é¢å¤–çš„ CUDA ç¼–è¯‘æ ‡å¿—
        extra_ldflags: é¢å¤–çš„é“¾æ¥æ ‡å¿—ï¼ˆå¦‚ -lcublasLtï¼‰
        extra_include_paths: é¢å¤–çš„å¤´æ–‡ä»¶æœç´¢è·¯å¾„
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç¼–è¯‘
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
        clean_after_build: ç¼–è¯‘åæ˜¯å¦æ¸…ç†ä¸­é—´æ–‡ä»¶
        
    Returns:
        ç¼–è¯‘ç”Ÿæˆçš„ .so æ–‡ä»¶è·¯å¾„
        
    Raises:
        FileNotFoundError: æºæ–‡ä»¶ä¸å­˜åœ¨
        RuntimeError: ç¼–è¯‘å¤±è´¥
        
    Example:
        >>> so_path = build_cuda_extension(
        ...     name="cublaslt_gemm_H100_cc90_FP8E4M3_py312_cu124_x86_64",
        ...     source_file=Path("cublaslt_gemm.cu"),
        ...     build_dir=Path("build"),
        ...     extra_ldflags=["-lcublasLt", "-lcublas", "-lcuda"],
        ... )
    """
    # éªŒè¯æºæ–‡ä»¶
    if not source_file.exists():
        raise FileNotFoundError(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file}")
    
    # ç¡®ä¿ build ç›®å½•å­˜åœ¨
    build_dir.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾å·²å­˜åœ¨çš„ .so
    so_pattern = f"{name}*.so"
    existing_sos = list(build_dir.glob(so_pattern))
    
    if existing_sos and not force:
        so_path = existing_sos[0]
        if not should_rebuild(so_path, [source_file]):
            if verbose:
                print(f"âœ“ Using existing: {so_path.name}")
            return so_path
        elif verbose:
            print(f"âš  Source changed, rebuilding...")
    
    if verbose:
        print(f"ğŸ”¨ Building {name}...")
    
    # CUDA è·¯å¾„
    cuda_home = os.environ.get('CUDA_HOME', '/usr/local/cuda')
    
    # åˆå¹¶ç¼–è¯‘é€‰é¡¹
    cflags = DEFAULT_CFLAGS + (extra_cflags or [])
    cuda_cflags = DEFAULT_CUDA_CFLAGS + get_nvcc_arch_flags() + (extra_cuda_cflags or [])
    ldflags = extra_ldflags or []
    include_paths = [os.path.join(cuda_home, 'include')] + (extra_include_paths or [])
    
    # ç¼–è¯‘
    try:
        load(
            name=name,
            sources=[str(source_file)],
            extra_cflags=cflags,
            extra_cuda_cflags=cuda_cflags,
            extra_ldflags=ldflags,
            extra_include_paths=include_paths,
            build_directory=str(build_dir),
            verbose=verbose,
        )
    except Exception as e:
        raise RuntimeError(f"ç¼–è¯‘å¤±è´¥: {e}") from e
    
    # æŸ¥æ‰¾ç”Ÿæˆçš„ .so
    new_sos = list(build_dir.glob(so_pattern))
    if not new_sos:
        raise RuntimeError(f"ç¼–è¯‘å®Œæˆä½†æœªæ‰¾åˆ° .so æ–‡ä»¶: {so_pattern}")
    
    so_path = new_sos[0]
    
    if verbose:
        print(f"âœ“ Built: {so_path.name}")
    
    # æ¸…ç†ä¸­é—´æ–‡ä»¶
    if clean_after_build:
        if verbose:
            print(f"ğŸ§¹ Cleaning build artifacts...")
        clean_build_artifacts(build_dir)
    
    return so_path


# =============================================================================
# ç‰¹å®šæ‰©å±•çš„é“¾æ¥åº“é…ç½®
# =============================================================================

# cuBLASLt æ‰©å±•æ‰€éœ€çš„é“¾æ¥åº“
CUBLASLT_LDFLAGS = ['-lcublasLt', '-lcublas', '-lcuda']

# cuSPARSELt æ‰©å±•æ‰€éœ€çš„é“¾æ¥åº“
CUSPARSELT_LDFLAGS = ['-lcusparseLt', '-lcusparse', '-lcuda']


def get_gemm_ldflags(backend: str) -> List[str]:
    """
    è·å– GEMM åç«¯æ‰€éœ€çš„é“¾æ¥åº“æ ‡å¿—
    
    Args:
        backend: åç«¯åç§° ("cublaslt" æˆ– "cusparselt")
        
    Returns:
        é“¾æ¥åº“æ ‡å¿—åˆ—è¡¨
        
    Raises:
        ValueError: æœªçŸ¥çš„åç«¯
    """
    if backend.lower() == "cublaslt":
        return CUBLASLT_LDFLAGS.copy()
    elif backend.lower() == "cusparselt":
        return CUSPARSELT_LDFLAGS.copy()
    else:
        raise ValueError(f"æœªçŸ¥çš„ GEMM åç«¯: {backend}")


# =============================================================================
# Triton Autotune é…ç½®
# =============================================================================

def get_dequant_autotune_configs():
    """
    è·å– dequant+bias kernel çš„ Triton autotune é…ç½®
    
    è¦†ç›–: SM80(A100), SM89(4090), SM90(H100), SM100(B200), SM120(5080)
    
    å› ä¸º M æ˜¯çµæ´»å¯å˜çš„batchsize æ­¤å¤„ç›¸å½“äºæ˜¯æœç´¢ R[M,N] = A[M,K] * W[N,K] ä¸­çš„ [M,N]
    
    Returns:
        triton.Config å¯¹è±¡åˆ—è¡¨
    """
    import triton
    
    return [
        # =====================================================================
        # Tier 1: Proven Winners (A100 validated)
        # =====================================================================
        # Small M King (M=1~128): 32x32
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=4, num_stages=4),
        # Medium M King (M=256~8192): 64x32
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32}, num_warps=4, num_stages=4),
        # Large M King (M=12288+): 128x64
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64}, num_warps=8, num_stages=4),

        # =====================================================================
        # Tier 2: Basic kernel heuristics
        # =====================================================================
        # Small M, N<=4096: (32, 64, 4)
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=4, num_stages=4),
        # Small M, N>4096: (32, 128, 4)
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=4, num_stages=4),
        # Medium M, N<=4096: (64, 64, 4)
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=4, num_stages=4),
        # Medium M, N>4096: (64, 128, 8)
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128}, num_warps=8, num_stages=4),
        # Large M, N>4096: (128, 128, 8)
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128}, num_warps=8, num_stages=4),

        # =====================================================================
        # Tier 3: Read/Write bias exploration
        # =====================================================================
        # Write Heavy (tall blocks): 128x32
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 32}, num_warps=8, num_stages=4),
        # Read Heavy (wide blocks): 64x128 with lower warps
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 128}, num_warps=4, num_stages=4),
        # Balanced high warp: 64x64 w=8
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=8, num_stages=4),
        # Low warp large block
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 64}, num_warps=4, num_stages=4),

        # =====================================================================
        # Tier 4: H100/Blackwell exploration (SM90/100/120)
        # =====================================================================
        # Super Wide: 256x64
        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64}, num_warps=16, num_stages=3),
        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 64}, num_warps=8, num_stages=3),
        # Super Tall: 64x256
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 256}, num_warps=16, num_stages=3),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 256}, num_warps=8, num_stages=3),
        # Super Square: 128x128 high warp
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128}, num_warps=16, num_stages=3),
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128}, num_warps=16, num_stages=4),
        # Wide variants for large N
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 256}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 256}, num_warps=8, num_stages=4),
        # Extreme Wide: 256x32
        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 32}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 256, 'BLOCK_N': 32}, num_warps=8, num_stages=4),

        # =====================================================================
        # Tier 5: Small M + Large N special cases
        # =====================================================================
        # 32x128 with various warps
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=2, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 128}, num_warps=8, num_stages=3),
        # 32x64 with high warps
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=8, num_stages=4),
        # 32x64 with low warps
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=2, num_stages=3),

        # =====================================================================
        # Tier 6: Tiny M = 16 special cases
        # =====================================================================
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 64}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 64}, num_warps=2, num_stages=3),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 64}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 64}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 128}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 128}, num_warps=2, num_stages=3),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 128}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 128}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 32}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 32}, num_warps=2, num_stages=3),
        # Very wide for large N
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 256}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 16, 'BLOCK_N': 256}, num_warps=4, num_stages=3),
    ]


def get_quant_autotune_configs():
    """
    è·å– quant (per-row quantization) kernel çš„ Triton autotune é…ç½®
    
    è¦†ç›–: SM80(A100), SM89(4090), SM90(H100), SM100(B200), SM120(5080)
    
    å› ä¸º M æ˜¯çµæ´»å¯å˜çš„batchsize æ­¤å¤„ç›¸å½“äºæ˜¯æœç´¢ R[M,N] = A[M,K] * W[N,K] ä¸­çš„ [M,K]

    - BLOCK_K æ˜¯ä¸»è¦çš„å—å¤§å°å‚æ•°ï¼Œæ§åˆ¶æ¯æ¬¡å¾ªç¯å¤„ç†çš„å…ƒç´ æ•°
    - M è™½ç„¶ä¸åœ¨ kernel å—å‚æ•°ä¸­ï¼Œä½†å½±å“æœ€ä½³ num_warps/num_stages
    - autotune key = ['M', 'K']
    
    BLOCK_K é€‰æ‹©åŸåˆ™ï¼š
    - å¿…é¡»æ˜¯ 2 çš„å¹‚æ¬¡
    - å…¸å‹å€¼ï¼š512, 1024, 2048, 4096, 8192
    - K=2560 â†’ BLOCK_K=2048/4096 (1-2 æ¬¡å¾ªç¯)
    - K=6912 â†’ BLOCK_K=4096/8192 (1-2 æ¬¡å¾ªç¯)
    
    num_warps é€‰æ‹©åŸåˆ™ï¼š
    - å° Mï¼ˆ1-64ï¼‰ï¼š1-4 warps
    - ä¸­ Mï¼ˆ64-4096ï¼‰ï¼š4-8 warps
    - å¤§ Mï¼ˆ4096+ï¼‰ï¼š8-32 warps
    
    Returns:
        triton.Config å¯¹è±¡åˆ—è¡¨
    """
    import triton
    
    return [
        # =====================================================================
        # Tier 1: å° BLOCK_K (é€‚åˆå° K æˆ–éœ€è¦ä½å¯„å­˜å™¨å‹åŠ›)
        # =====================================================================
        triton.Config({'BLOCK_K': 512}, num_warps=1, num_stages=1),
        triton.Config({'BLOCK_K': 512}, num_warps=1, num_stages=2),
        triton.Config({'BLOCK_K': 512}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_K': 512}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_K': 512}, num_warps=4, num_stages=3),
        
        # =====================================================================
        # Tier 2: ä¸­ç­‰ BLOCK_K (K <= 2048 çš„é»˜è®¤é€‰æ‹©)
        # =====================================================================
        triton.Config({'BLOCK_K': 1024}, num_warps=1, num_stages=1),
        triton.Config({'BLOCK_K': 1024}, num_warps=1, num_stages=2),
        triton.Config({'BLOCK_K': 1024}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_K': 1024}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_K': 1024}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 1024}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_K': 1024}, num_warps=8, num_stages=3),
        
        # =====================================================================
        # Tier 3: å¤§ BLOCK_K (K=2560-4096 çš„é»˜è®¤é€‰æ‹©)
        # =====================================================================
        triton.Config({'BLOCK_K': 2048}, num_warps=1, num_stages=1),
        triton.Config({'BLOCK_K': 2048}, num_warps=1, num_stages=2),
        triton.Config({'BLOCK_K': 2048}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_K': 2048}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_K': 2048}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 2048}, num_warps=4, num_stages=4),
        triton.Config({'BLOCK_K': 2048}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_K': 2048}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_K': 2048}, num_warps=8, num_stages=4),
        triton.Config({'BLOCK_K': 2048}, num_warps=16, num_stages=2),
        triton.Config({'BLOCK_K': 2048}, num_warps=16, num_stages=3),
        
        # =====================================================================
        # Tier 4: è¶…å¤§ BLOCK_K (K=4096-8192 çš„é»˜è®¤é€‰æ‹©)
        # =====================================================================
        triton.Config({'BLOCK_K': 4096}, num_warps=1, num_stages=1),
        triton.Config({'BLOCK_K': 4096}, num_warps=1, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=2, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 4096}, num_warps=4, num_stages=4),
        triton.Config({'BLOCK_K': 4096}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_K': 4096}, num_warps=8, num_stages=4),
        triton.Config({'BLOCK_K': 4096}, num_warps=16, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=16, num_stages=3),
        triton.Config({'BLOCK_K': 4096}, num_warps=16, num_stages=4),
        triton.Config({'BLOCK_K': 4096}, num_warps=32, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=32, num_stages=3),
        
        # =====================================================================
        # Tier 5: æå¤§ BLOCK_K (K > 6000 çš„é€‰æ‹©ï¼Œå¦‚ K=6912)
        # =====================================================================
        triton.Config({'BLOCK_K': 8192}, num_warps=1, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=2, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=4, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_K': 8192}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 8192}, num_warps=4, num_stages=4),
        triton.Config({'BLOCK_K': 8192}, num_warps=8, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=8, num_stages=2),
        triton.Config({'BLOCK_K': 8192}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_K': 8192}, num_warps=16, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=16, num_stages=2),
        triton.Config({'BLOCK_K': 8192}, num_warps=16, num_stages=3),
        triton.Config({'BLOCK_K': 8192}, num_warps=32, num_stages=1),
        triton.Config({'BLOCK_K': 8192}, num_warps=32, num_stages=2),
        triton.Config({'BLOCK_K': 8192}, num_warps=32, num_stages=3),
        
        # =====================================================================
        # Tier 6: è¾¹ç•Œæ¢ç´¢ - å° M ç‰¹æ®Šä¼˜åŒ–
        # =====================================================================
        # å° M (1-16) éœ€è¦ä½ num_warps
        triton.Config({'BLOCK_K': 2048}, num_warps=1, num_stages=3),
        triton.Config({'BLOCK_K': 2048}, num_warps=1, num_stages=4),
        triton.Config({'BLOCK_K': 4096}, num_warps=1, num_stages=3),
        triton.Config({'BLOCK_K': 4096}, num_warps=1, num_stages=4),
        
        # =====================================================================
        # Tier 7: è¾¹ç•Œæ¢ç´¢ - å¤§ M ç‰¹æ®Šä¼˜åŒ–  
        # =====================================================================
        # å¤§ M (16384+) éœ€è¦é«˜ num_warps
        triton.Config({'BLOCK_K': 2048}, num_warps=32, num_stages=2),
        triton.Config({'BLOCK_K': 4096}, num_warps=32, num_stages=4),
        triton.Config({'BLOCK_K': 8192}, num_warps=32, num_stages=4),
    ]


def get_quant_or_dequant_autotune_configs():
    """
    è·å– quant/dequant é€šç”¨çš„ Triton autotune é…ç½®
    
    è¿™æ˜¯æ—§ç‰ˆ 2D tiled kernel çš„é…ç½®ï¼ˆBLOCK_M x BLOCK_N/BLOCK_Kï¼‰
    å¯¹äºæ–°ç‰ˆ per-row kernelï¼Œè¯·ä½¿ç”¨ get_quant_autotune_configs()
    
    Returns:
        triton.Config å¯¹è±¡åˆ—è¡¨ï¼ˆç­‰åŒäº get_dequant_autotune_configsï¼‰
    """
    return get_dequant_autotune_configs()



# =============================================================================
# å¯¼å‡º
# =============================================================================

__all__ = [
    # NVCC æ¶æ„æ ‡å¿—
    'SUPPORTED_ARCHITECTURES',
    'get_nvcc_arch_flags',
    'get_current_arch_flag',
    # CUDA ç¼–è¯‘
    'DEFAULT_CFLAGS',
    'DEFAULT_CUDA_CFLAGS',
    'should_rebuild',
    'clean_build_artifacts',
    'build_cuda_extension',
    # GEMM é“¾æ¥åº“
    'CUBLASLT_LDFLAGS',
    'CUSPARSELT_LDFLAGS',
    'get_gemm_ldflags',
    # Triton é…ç½®
    'get_dequant_autotune_configs',
    'get_quant_autotune_configs',
    'get_quant_or_dequant_autotune_configs',
]
