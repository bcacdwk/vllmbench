======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 18:56:21
======================================================================

Hardware:
  GPU: NVIDIA GeForce RTX 4090 (cc89)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_185621.log
[INFO] è·³è¿‡ Task 1: cuBLASLt Model æµ‹è¯•

======================================================================
TASK 2: cuBLASLt Square æµ‹è¯•
Started: 2026-01-27 18:56:21
======================================================================


------------------------------------------------------------
  cuBLASLt Square æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model square

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 18:57:15.513287943 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 18:58:10.483427126 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 18:58:23.547157493 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 18:59:02.927456491 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 18:59:03.153263673 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square æµ‹è¯•å®Œæˆ (162.5s)

----------------------------------------------------------------------
TASK 2: cuBLASLt Square æµ‹è¯• - SUCCESS
Duration: 162.5 seconds (2.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 18:59:03
======================================================================


------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/cusparselt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/build/cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
âœ“ Built: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 18:59:46.670164468 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:00:19.875244737 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:00:52.493609548 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:01:25.139103222 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:01:51.390092456 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:02:24.688234567 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:02:57.463316508 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:03:32.869266049 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:03:50.227374355 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:04:10.435674899 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:04:30.607744539 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:04:53.597692057 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:05:12.773093193 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:05:33.086877108 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:05:55.130711161 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:06:16.969139698 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:06:18.050589038 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 é«˜ç¨€ç–å®Œæˆ (435.1s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:06:51.031975797 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:07:24.349403050 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:07:57.099414082 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:08:32.502983868 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:08:59.474183330 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:09:30.472510406 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:10:05.943096787 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:10:38.582590136 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:10:57.074269748 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:11:15.995647022 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:11:37.561609435 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:12:01.351179121 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:12:21.269340909 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:12:43.791489388 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:13:03.796538700 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:13:27.442509984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:13:28.047849324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 é«˜ç¨€ç–å®Œæˆ (430.6s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:14:06.973190087 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:14:48.154525489 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:15:32.057878122 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:16:17.925037086 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:16:48.002162589 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:17:30.216885179 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:18:17.083706627 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:19:02.261534227 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:19:25.406282727 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:19:52.315808332 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:20:18.370881942 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:20:45.223045005 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:21:09.907370749 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:21:34.160275793 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:21:59.671649612 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:22:26.416266185 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:22:27.512264238 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 é«˜ç¨€ç–å®Œæˆ (538.6s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:23:09.764762159 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:23:55.251919330 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:24:44.545140871 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:25:31.006162652 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:26:07.401388172 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:26:48.595569603 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:27:35.332422163 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:28:21.601044783 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:28:42.840481152 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:29:09.996466423 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:29:37.086184588 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:30:06.527745991 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:30:27.772580254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:30:54.796760782 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:31:23.994301791 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:31:50.099226213 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:31:52.191913832 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 é«˜ç¨€ç–å®Œæˆ (564.6s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:33:01.396970271 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:34:21.591778827 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:35:51.752117933 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:37:27.735718374 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:38:32.579870261 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:39:51.877094435 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:41:18.305103857 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:42:55.642153356 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:43:28.799678837 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:44:09.055228783 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:44:48.240729626 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 19:45:31.257344257 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:46:07.587809896 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:46:49.407764689 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:47:31.344095646 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 19:48:15.119644317 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:48:17.663037930 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 é«˜ç¨€ç–å®Œæˆ (985.1s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:49:31.638748714 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:50:51.547869888 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:52:24.406726028 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 19:54:01.589288003 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:55:09.981107697 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:56:30.998120921 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:58:02.520532938 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 19:59:37.618348066 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:00:13.556783896 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:00:54.956129388 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:01:36.645516385 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:02:23.540308792 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:02:58.900911375 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:03:39.401049847 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:04:23.841576152 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:05:10.066146916 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:05:11.613851443 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 é«˜ç¨€ç–å®Œæˆ (1014.6s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:06:27.492021812 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:07:55.443005865 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:09:40.555660965 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:11:28.767754589 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:12:44.585289464 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:14:13.202674431 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:15:55.283659187 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:17:45.716435386 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:18:24.688133514 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:19:16.575796220 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:20:06.944566687 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:20:58.588301553 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:21:40.775384580 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:22:28.697541816 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:23:22.346947454 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:24:16.886935906 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:24:17.366380175 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 é«˜ç¨€ç–å®Œæˆ (1146.3s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:25:38.560382675 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:27:13.225692854 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:29:00.971774112 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:30:49.644749252 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:32:09.700545575 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:33:40.013581032 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:35:25.421221648 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:37:17.430424619 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:38:03.841381805 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:38:56.691285113 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:39:52.026141316 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:40:51.770715802 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:41:35.955007370 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:42:31.847944035 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:43:28.054799790 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:44:25.538541176 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:44:26.908300173 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 é«˜ç¨€ç–å®Œæˆ (1209.0s)

[INFO] cuSPARSELt Model é«˜ç¨€ç–ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 6323.7 seconds (105.4 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 20:44:27
======================================================================


------------------------------------------------------------
  cuSPARSELt Square é«˜ç¨€ç–æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:45:09.834578858 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:45:52.544136422 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:46:40.904448157 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:47:28.461025014 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:48:06.080645265 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:48:46.313034725 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:49:32.410989186 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:50:21.781604787 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:50:40.739184574 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:51:07.085434771 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:51:34.251689444 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 20:52:01.069586419 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:52:21.811220301 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:52:48.753883604 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:53:16.896947051 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 20:53:43.935415810 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:53:44.509534936 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square é«˜ç¨€ç–æµ‹è¯•å®Œæˆ (557.7s)

----------------------------------------------------------------------
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 557.7 seconds (9.3 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf)
Started: 2026-01-27 20:53:45
======================================================================


------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:54:39.327406789 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:55:28.876256725 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:56:21.577799925 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 20:57:15.413405669 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:58:10.938246787 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:59:03.764567807 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 20:59:55.919442748 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:01:01.574761432 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:01:44.453904517 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:02:23.198025531 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:03:03.878547393 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:03:43.077622273 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:04:25.554628002 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:05:06.208323092 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:05:49.416105073 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:06:34.035617920 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 21:06:35.469283983 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 ä½ç¨€ç–å®Œæˆ (771.0s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:07:37.906815939 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:08:34.333021988 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:09:32.609135378 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:10:36.473151147 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:11:34.767734281 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:12:32.247309378 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:13:44.003347526 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:14:50.800268247 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:15:35.350686125 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:16:18.559151833 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:17:07.211986172 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:17:52.375360206 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:18:40.022450871 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:19:31.107808023 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:20:19.767541991 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:21:10.196854150 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 21:21:13.218722260 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 ä½ç¨€ç–å®Œæˆ (878.1s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:22:37.335346849 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:23:56.161069620 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:25:13.636493962 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:26:38.712181992 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:27:54.315304395 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:29:13.861878691 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:30:41.502883390 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:32:10.755764436 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:33:10.515422406 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:34:11.555688510 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:35:19.616322172 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:36:28.453166233 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:37:32.239992012 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:38:37.368512364 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:39:44.426141984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 21:40:52.484199909 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 21:40:55.373842226 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 ä½ç¨€ç–å®Œæˆ (1182.1s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:42:28.967141273 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:43:59.090831763 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:45:32.078984891 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 21:47:08.382955120 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:48:39.353830477 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:50:13.547190736 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:51:50.224986745 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 21:53:37.007111747 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:54:59.113906219 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:56:19.926951721 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:57:33.416424720 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 21:59:01.869463853 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:00:19.037287598 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:01:40.997783492 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:02:58.981354222 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:04:28.673578017 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 22:04:31.251020254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 ä½ç¨€ç–å®Œæˆ (1415.8s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:07:10.895858556 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:09:52.925614391 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:12:35.564875314 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:15:37.301049408 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 22:18:28.335280412 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 22:21:18.598526064 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 22:24:17.444992324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 22:27:29.953184459 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 22:29:33.493585337 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 22:31:34.432461437 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 22:33:47.106198096 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 22:35:59.746814960 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:38:07.868023098 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:40:23.325628666 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:42:44.947694738 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 22:45:09.148521403 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 22:45:17.838000115 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 ä½ç¨€ç–å®Œæˆ (2446.9s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:48:43.148582562 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:52:06.961665178 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 22:55:46.682557117 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 23:00:01.045553033 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 23:03:41.865762776 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 23:07:25.838556408 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 23:11:26.906914608 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W127 23:15:41.872488600 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 23:18:56.430060383 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 23:22:06.013885125 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 23:25:14.694790514 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W127 23:28:42.797629067 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 23:31:55.488792713 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 23:35:11.716512357 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 23:38:23.819158030 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W127 23:41:47.989649374 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 23:42:00.234921213 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 ä½ç¨€ç–å®Œæˆ (3405.2s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 23:46:25.707731821 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 23:51:15.554452891 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W127 23:56:14.065633303 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 00:01:30.461469470 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 00:06:31.399384046 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 00:11:43.672850644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 00:17:04.117295451 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 00:22:36.969787759 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 00:26:42.830670060 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 00:30:53.925538706 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 00:35:05.497473255 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 00:39:17.395966563 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 00:43:23.079503712 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 00:47:40.261631336 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 00:51:57.987954078 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 00:56:15.506501424 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 00:56:37.793813988 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 ä½ç¨€ç–å®Œæˆ (4480.9s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 01:01:53.423082718 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 01:07:44.242131816 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 01:13:46.083880570 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 01:20:08.448365575 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 01:25:29.311598391 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 01:31:38.285131739 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 01:37:59.095982714 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 01:44:39.156642286 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 01:49:34.061987452 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 01:54:37.408640201 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 01:59:34.047334621 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 02:05:24.146476565 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 02:10:20.480462400 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 02:15:47.034215305 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 02:21:19.855023125 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 02:26:59.402677878 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 02:27:20.421925033 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 ä½ç¨€ç–å®Œæˆ (5444.2s)

[INFO] cuSPARSELt Model ä½ç¨€ç–ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf) - SUCCESS
Duration: 20024.3 seconds (333.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 6: cuSPARSELt Square ä½ç¨€ç– (2_12~2_inf)
Started: 2026-01-28 02:27:29
======================================================================


------------------------------------------------------------
  cuSPARSELt Square ä½ç¨€ç–æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 02:30:14.262955244 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 02:33:22.762448693 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1792)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28672)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 02:36:50.897469029 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 5/9: (1024, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP16
============================================================
[W128 02:39:58.169544984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 02:42:45.972607770 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 02:45:58.452224786 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1792)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28672)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 02:48:58.462048694 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 5/9: (1024, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/BF16
============================================================
[W128 02:51:59.104532407 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 02:54:48.514968204 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 02:57:39.499491784 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1792)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28672)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 03:00:17.899251123 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/INT8
============================================================
[W128 03:03:10.496952560 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 03:05:49.481828301 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 03:07:54.680891235 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 1792)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 28672)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 03:10:34.116444706 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/9: (128, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/9: (256, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/9: (512, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/9: (1024, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/9: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/9: (4096, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/9: (8192, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/9: (16384, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX4090_cc89_py312_cu129_x86_64/FP8
============================================================
[W128 03:13:26.562560852 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 4090 (cc89)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:14:03.352511470 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square ä½ç¨€ç–æµ‹è¯•å®Œæˆ (2813.7s)

----------------------------------------------------------------------
TASK 6: cuSPARSELt Square ä½ç¨€ç– (2_12~2_inf) - SUCCESS
Duration: 2813.7 seconds (46.9 minutes)
----------------------------------------------------------------------



============================================================
  æœ€ç»ˆæ€»ç»“
============================================================


  Task 1: cuBLASLt Model æµ‹è¯• - SKIPPED
  Task 2: cuBLASLt Square æµ‹è¯• - SUCCESS (162.5s)
  Task 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10) - SUCCESS (6323.7s)
  Task 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10) - SUCCESS (557.7s)
  Task 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf) - SUCCESS (20024.3s)
  Task 6: cuSPARSELt Square ä½ç¨€ç– (2_12~2_inf) - SUCCESS (2813.7s)

  æ€»è®¡: 5 æˆåŠŸ, 0 å¤±è´¥, 1 è·³è¿‡
  æ€»è€—æ—¶: 29881.9 ç§’ (8.30 å°æ—¶)

[INFO] æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_185621.log
[INFO] çŠ¶æ€æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_185621_status.json

[INFO] ç»“æœä¿å­˜ä½ç½®:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
