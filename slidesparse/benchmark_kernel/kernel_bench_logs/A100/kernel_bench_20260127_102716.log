======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 10:27:16
======================================================================

Hardware:
  GPU: NVIDIA A100 80GB PCIe (cc80)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_102716.log

======================================================================
TASK 1: cuBLASLt Model æµ‹è¯•
Started: 2026-01-27 10:27:16
======================================================================


------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-1B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cublaslt_gemm_A100_cc80_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/cublaslt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcublasLt -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/build/cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
âœ“ Built: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:28:20.886196548 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:29:17.612921930 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:29:33.092914520 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:29:34.974290257 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 å®Œæˆ (138.3s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-1B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:30:31.775361308 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:31:28.051294578 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:31:45.713232603 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:31:46.695454793 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 å®Œæˆ (131.7s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-3B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 6, æœ‰æ•ˆ: 6

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:33:07.138218866 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:34:33.463458282 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:34:55.278834788 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:34:56.236974321 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 å®Œæˆ (190.5s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-3B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 6, æœ‰æ•ˆ: 6

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:36:18.872254872 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:37:43.950073496 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:38:06.879144547 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:38:07.827723147 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 å®Œæˆ (190.6s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-7B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:41:00.630624246 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:44:05.306681055 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:44:50.698671065 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:44:51.668323651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 å®Œæˆ (403.8s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-7B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:47:44.886744507 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:50:50.671623211 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:51:34.830931878 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:51:35.792200407 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 å®Œæˆ (404.1s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-14B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 10:53:46.419654663 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 10:57:21.642410683 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 10:58:12.531386480 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:58:13.490367992 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 å®Œæˆ (397.7s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-14B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 11:00:24.291473694 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 11:03:59.617625378 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 11:04:49.443449622 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 11:04:50.402023624 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 å®Œæˆ (397.9s)

[INFO] cuBLASLt Model ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 1: cuBLASLt Model æµ‹è¯• - SUCCESS
Duration: 2254.8 seconds (37.6 minutes)
----------------------------------------------------------------------


======================================================================
TASK 2: cuBLASLt Square æµ‹è¯•
Started: 2026-01-27 11:04:51
======================================================================


------------------------------------------------------------
  cuBLASLt Square æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model square

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 9, æœ‰æ•ˆ: 9
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 7, æœ‰æ•ˆ: 7
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 7, æœ‰æ•ˆ: 7
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 6, æœ‰æ•ˆ: 6
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 11:40:07.453202204 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:14:30.204492459 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 2, æœ‰æ•ˆ: 2

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:22:19.047234935 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 12:22:20.967137665 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square æµ‹è¯•å®Œæˆ (4649.5s)

----------------------------------------------------------------------
TASK 2: cuBLASLt Square æµ‹è¯• - SUCCESS
Duration: 4649.5 seconds (77.5 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 12:22:20
======================================================================


------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cusparselt_gemm_A100_cc80_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/cusparselt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/build/cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
âœ“ Built: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:23:01.712655049 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:23:38.764160055 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:24:18.161156010 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:25:02.680928494 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:25:31.782667691 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:26:08.347202199 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:26:49.207933376 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:27:33.149124267 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:27:52.707123927 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:28:14.868309141 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:28:38.444205279 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:29:04.828949117 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 12:29:05.768768138 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 é«˜ç¨€ç–å®Œæˆ (404.8s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:29:39.524469085 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:30:16.709109820 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:30:56.375282285 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:31:40.944671668 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:32:09.200979176 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:32:47.732956145 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:33:28.472727603 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:34:11.394204673 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:34:30.895559565 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:34:52.170135600 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:35:16.668329499 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:35:42.133643763 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 12:35:43.067591124 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 é«˜ç¨€ç–å®Œæˆ (398.3s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:36:30.782311554 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:37:24.287798630 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:38:25.223137475 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:39:29.411905890 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:40:12.565252961 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:41:06.090141305 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:42:07.967564921 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:43:12.697414728 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:43:37.730786525 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:44:08.579328218 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:44:41.919383662 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:45:17.532842856 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 12:45:18.498498468 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 é«˜ç¨€ç–å®Œæˆ (574.4s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:46:04.296262421 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:46:59.591079534 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:47:59.846785730 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:49:03.937239801 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:49:45.099228570 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:50:40.523097760 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:51:40.265239406 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 12:52:45.811172387 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:53:10.814128018 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:53:41.532477592 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:54:14.849181126 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 12:54:50.470577649 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 12:54:50.403086844 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 é«˜ç¨€ç–å®Œæˆ (572.9s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:56:28.210582622 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 12:58:31.900472855 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:00:48.382984576 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:03:15.345127150 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:04:50.461396612 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:06:54.201820038 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:09:13.795420887 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:11:42.672957611 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:12:32.360367331 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:13:36.437851969 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:14:47.922914812 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:16:02.963261804 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 13:16:03.836071652 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 é«˜ç¨€ç–å®Œæˆ (1272.4s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:17:40.432106027 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:19:43.094849507 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:22:01.586467749 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:24:28.505953414 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:26:02.613285278 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:28:06.185967103 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:30:25.106083307 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:32:54.745222607 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:33:43.718903581 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:34:47.110272393 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:35:58.603370634 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:37:13.783097430 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 13:37:14.748717288 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 é«˜ç¨€ç–å®Œæˆ (1271.0s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:39:04.140693061 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:41:26.104128141 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:44:07.326627651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 13:47:00.465148513 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:48:47.720026888 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:51:10.055866885 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:53:53.224579370 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 13:56:47.722961543 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:57:42.505874473 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 13:58:54.776025599 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:00:13.873857560 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:01:38.622601988 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 14:01:39.480502622 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 é«˜ç¨€ç–å®Œæˆ (1464.7s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:03:29.301892249 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:05:52.319991733 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:08:33.273430571 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:11:25.751327418 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 14:13:12.834734465 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 14:15:36.702499323 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 14:18:19.212088540 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 14:21:13.810163929 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:22:08.733950273 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:23:20.015420273 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:24:39.044081421 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 14:26:04.655424865 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 14:26:05.614493973 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 é«˜ç¨€ç–å®Œæˆ (1466.2s)

[INFO] cuSPARSELt Model é«˜ç¨€ç–ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 7424.7 seconds (123.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 14:26:05
======================================================================


------------------------------------------------------------
  cuSPARSELt Square é«˜ç¨€ç–æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model square --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:43:01.389474156 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 43712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 87392)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 1

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:51:41.917681164 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 49152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 98304)
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 52448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 104864)
 ** On entry to cusparseLtSpMMACompress() parameter number 4 (d_compressed) had an illegal value: NULL pointer

      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 0

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=1, é”™è¯¯=0
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 14:59:22.229671642 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 15:16:26.222255305 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 352)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 704)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 2752)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 5472)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 10944)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 21856)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 43712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 87392)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 1

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 15:25:09.577339815 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3072)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 12288)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 24576)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 49152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 98304)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 1

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 15:34:52.578357201 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 416)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 832)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3296)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6560)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 13120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 26240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 52448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 104864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 1

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 15:45:36.359414075 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 15:54:46.533139578 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/11: (256, 352)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/11: (512, 704)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 5/11: (1024, 1376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 6/11: (2048, 2752)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 7/11: (4096, 5472)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 8/11: (8192, 10944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/11: (16384, 21856)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 10/11: (32768, 43712)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 11/11: (65536, 87392)
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 96)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/11: (128, 192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/11: (256, 384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/11: (512, 768)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 5/11: (1024, 1536)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 6/11: (2048, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 7/11: (4096, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 8/11: (8192, 12288)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/11: (16384, 24576)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 10/11: (32768, 49152)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 11/11: (65536, 98304)
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/11: (256, 416)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/11: (512, 832)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 5/11: (1024, 1664)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 6/11: (2048, 3296)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 7/11: (4096, 6560)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 8/11: (8192, 13120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/11: (16384, 26240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 10/11: (32768, 52448)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 11/11: (65536, 104864)
 ** On entry to cusparseLtSpMMACompress() parameter number 4 (d_compressed) had an illegal value: NULL pointer

      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 0

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=1, é”™è¯¯=0
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:01:49.672664375 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 16:01:50.613033936 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square é«˜ç¨€ç–æµ‹è¯•å®Œæˆ (5745.0s)

----------------------------------------------------------------------
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 5745.0 seconds (95.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf)
Started: 2026-01-27 16:01:50
======================================================================


------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:02:40.558132959 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:03:25.258086643 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:04:12.837793986 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:05:04.306326556 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:05:50.025110550 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:06:36.022798010 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:07:23.847178161 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:08:16.556551471 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:08:44.489786686 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:09:10.368224174 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:09:36.305644356 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:10:05.929363142 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 16:10:06.898611807 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 ä½ç¨€ç–å®Œæˆ (496.3s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:10:56.965483320 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:11:42.565227478 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:12:28.002016855 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:13:20.303279557 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:14:06.081767329 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:14:52.175301567 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:15:39.928316291 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:16:32.666668227 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:17:00.597383748 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:17:26.303385729 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:17:52.372847532 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:18:21.897690745 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 16:18:22.753678032 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 ä½ç¨€ç–å®Œæˆ (495.8s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:19:33.386779573 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:20:43.330542321 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:21:53.858771575 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:23:12.272693219 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:24:20.200129700 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:25:31.699836683 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:26:41.983115763 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:28:01.259372174 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:28:38.404614732 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:29:20.995309290 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:29:58.637591577 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:30:40.458364919 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 16:30:40.406084308 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 ä½ç¨€ç–å®Œæˆ (738.7s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:31:52.201573712 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:33:02.838931994 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:34:12.460660516 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:35:31.164095184 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:36:39.986317514 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:37:50.490878569 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:39:00.690271417 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:40:20.217293269 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:40:57.438051323 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:41:39.205088537 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:42:17.858067984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 16:42:59.817786357 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 16:43:00.767053231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 ä½ç¨€ç–å®Œæˆ (739.4s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:45:40.534394692 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:48:18.033722560 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:50:59.177954074 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 16:54:09.343300647 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:56:46.873054323 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 16:59:26.952858285 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:02:09.431623349 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:05:22.792777823 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 17:06:48.954825486 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 17:08:11.526655968 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 33152)
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 37888)
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 17:11:01.888068236 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 ä½ç¨€ç–å®Œæˆ (1681.1s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:13:40.348412200 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:16:18.291241215 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:18:59.412248252 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:22:09.406829726 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:24:46.900017236 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:27:26.949963287 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:30:09.038277673 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:33:21.161936723 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 17:34:47.321207362 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 17:36:10.718662546 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 33152)
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 37888)
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 17:39:00.606862504 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 ä½ç¨€ç–å®Œæˆ (1678.7s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:42:11.815572733 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:45:18.129434224 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:48:24.116879758 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 17:51:56.510280760 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:54:58.402686336 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 17:58:07.394185201 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:01:15.387292247 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:04:49.429775350 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:06:26.829071798 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:08:09.668050310 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:09:40.155737782 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:11:25.221588392 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 18:11:26.055516596 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 ä½ç¨€ç–å®Œæˆ (1946.4s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:14:31.978691906 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:17:38.944825429 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:20:43.442494760 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:24:15.613418302 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:27:17.048198170 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:30:26.863783613 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:33:34.822049329 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 18:37:08.692060958 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8544)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 23040)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:38:44.022973668 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8800)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 23712)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:40:27.876099466 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 8960)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 24192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:41:59.569883783 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 10240)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 27648)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/INT8
============================================================
[W127 18:43:44.803832779 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 18:43:45.802163109 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 ä½ç¨€ç–å®Œæˆ (1938.8s)

[INFO] cuSPARSELt Model ä½ç¨€ç–ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf) - SUCCESS
Duration: 9715.2 seconds (161.9 minutes)
----------------------------------------------------------------------


======================================================================
TASK 6: cuSPARSELt Square ä½ç¨€ç– (2_12~2_inf)
Started: 2026-01-27 18:43:45
======================================================================


------------------------------------------------------------
  cuSPARSELt Square ä½ç¨€ç–æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model square --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 54624)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 109248)
      â†’ ç®—æ³•æ•°: 0, æœ‰æ•ˆ: 0

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=0, é”™è¯¯=1
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:47:23.702379060 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 56192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 112352)
 ** On entry to cusparseLtSpMMACompress() parameter number 4 (d_compressed) had an illegal value: NULL pointer

      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 0

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=1, é”™è¯¯=0
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:51:00.058138797 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1792)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3584)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 7168)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 14336)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 28672)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 57344)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 114688)
      â†’ ç®—æ³•æ•°: 0, æœ‰æ•ˆ: 0

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=0, é”™è¯¯=1
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:54:42.474384545 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 256)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 512)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 1024)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 2048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 4096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 5
    NK 7/11: (4096, 8192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 16384)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 32768)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 65536)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 131072)
      âš  æ¿€æ´»å‡†å¤‡å¤±è´¥: CUDA OOM during activation prep: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.25 GiB of which 10.35 GiB is free. Process 764501 has 416.00 MiB memory in use. Process 1448578 has 68.48 GiB memory in use. Of the allocated memory 68.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=10, å¤±è´¥=0, é”™è¯¯=1
    æˆåŠŸç‡: 90.9%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/FP16
============================================================
[W127 18:59:01.161351499 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 864)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1728)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3424)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 6848)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 13664)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 27328)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 54624)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 109248)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 1

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/A100_cc80_py312_cu129_x86_64/BF16
============================================================
[W127 19:10:07.984138019 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å…³é—­
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: å¦

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 128)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 2/11: (128, 224)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 3/11: (256, 448)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 4/11: (512, 896)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 5/11: (1024, 1760)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 6/11: (2048, 3520)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 7/11: (4096, 7040)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 8/11: (8192, 14048)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 9/11: (16384, 28096)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 10/11: (32768, 56192)
      â†’ ç®—æ³•æ•°: 4, æœ‰æ•ˆ: 4
    NK 11/11: (65536, 112352)

======================================================================
æ”¶åˆ°ä¸­æ–­ä¿¡å· (signal 2)
======================================================================
[INFO] çŠ¶æ€å·²ä¿å­˜: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_102716_status.json
