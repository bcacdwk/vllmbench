======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 10:31:37
======================================================================

Hardware:
  GPU: NVIDIA B200 (cc100)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_103137.log

======================================================================
TASK 1: cuBLASLt Model æµ‹è¯•
Started: 2026-01-27 10:31:37
======================================================================


------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-1B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cublaslt_gemm_B200_cc100_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/cublaslt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcublasLt -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/build/cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
âœ“ Built: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:32:03.724076105 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:32:17.144124711 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:32:35.471034830 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:32:45.114764612 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:32:51.193579865 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:32:52.005576249 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 å®Œæˆ (75.6s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-1B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:33:11.696607705 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:33:25.067646084 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:33:43.312300986 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:33:53.046876257 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:34:00.923720705 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:34:01.799570245 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 å®Œæˆ (68.8s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-3B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:34:24.953835550 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:34:43.887472696 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:35:08.294542854 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:35:21.574995317 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:35:28.307355554 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:35:28.196732952 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 å®Œæˆ (87.4s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Llama3.2-3B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:35:52.398821950 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:36:11.243439614 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:36:35.474728195 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:36:48.727059703 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:36:55.326851872 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:36:55.223227091 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 å®Œæˆ (87.0s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-7B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:37:34.729363736 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:38:09.250036925 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:38:56.608243609 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:39:17.901714709 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:39:24.337589407 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:39:24.205700121 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 å®Œæˆ (149.0s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-7B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:40:03.499653416 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:40:37.738243829 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:41:24.777678383 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:41:46.256057261 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:41:52.605998299 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:41:53.592672716 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 å®Œæˆ (148.4s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-14B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:42:36.743665279 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:43:15.960845795 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:44:09.021629950 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:44:33.690498861 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:44:39.971133526 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:44:40.787248036 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 å®Œæˆ (167.2s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model Qwen2.5-14B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:45:24.289684357 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:46:03.540647589 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 10:46:57.692869460 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 10:47:20.056272332 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 641, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 616, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py", line 407, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal memory access was encountered
Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 10:47:26.215291071 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuBLASLt search failed with code 1

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 10:47:27.095998339 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 å®Œæˆ (167.3s)

[INFO] cuBLASLt Model ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 1: cuBLASLt Model æµ‹è¯• - SUCCESS
Duration: 950.7 seconds (15.8 minutes)
----------------------------------------------------------------------


======================================================================
TASK 2: cuBLASLt Square æµ‹è¯•
Started: 2026-01-27 10:47:28
======================================================================


------------------------------------------------------------
  cuBLASLt Square æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cublaslt --model square

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 10:52:49.219890764 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 10:58:12.323722085 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 1, æœ‰æ•ˆ: 1
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 11:05:03.663854578 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 11:07:49.634820605 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/11: (64, 64)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/11: (128, 128)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/11: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/11: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/11: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/11: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/11: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/11: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/11: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 10/11: (32768, 32768)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 11/11: (65536, 65536)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=11, æˆåŠŸ=11, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 11:08:30.811506509 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 11:08:31.700012808 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square æµ‹è¯•å®Œæˆ (1263.6s)

----------------------------------------------------------------------
TASK 2: cuBLASLt Square æµ‹è¯• - SUCCESS
Duration: 1263.6 seconds (21.1 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 11:08:31
======================================================================


------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cusparselt_gemm_B200_cc100_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/cusparselt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/build/cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
âœ“ Built: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 412
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 456
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 11:14:33.239224813 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 424
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 443

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 11:22:06.818751439 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 428
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 403
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 11:30:22.729197798 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 421
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 421
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 450
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 11:39:26.987052736 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 428
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 11:45:28.550681350 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 451
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 423
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 11:53:02.668465125 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 12:01:22.854936731 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 422
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 12:10:41.973607402 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 405
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 397
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 411

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 12:14:08.623918031 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 12:18:39.227269478 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 412
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 398
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 440
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 12:23:11.496304164 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 405
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 442
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 12:28:41.150849217 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 396
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 403
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 12:32:18.798071205 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 393
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 12:37:00.855346972 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 398
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 445
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 12:41:48.013216380 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 12:47:37.915423674 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 222
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 219
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 229
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 230

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 12:49:06.143731237 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 233
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 213
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 227
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 220

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 12:51:03.296584571 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 225
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 214
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 222
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 226

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 12:52:53.993168052 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3328), (2048, 3328), (16384, 3328), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 231
    NK 2/4: (2048, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 233
    NK 3/4: (16384, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 232
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 217

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 12:54:52.694859465 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 12:54:53.519499701 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 é«˜ç¨€ç–å®Œæˆ (6381.8s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 13:00:53.755826917 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 442
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 13:08:23.786957530 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 452
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 13:16:34.389530983 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 426
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 448
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 446

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 13:25:45.110606728 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 444
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 13:31:43.187035161 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 441
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 418

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 13:39:17.610329585 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 410
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 450
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 408

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 13:47:32.098385543 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 452
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 13:56:41.810660319 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 410
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 392

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 14:00:07.916699620 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 416
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 409
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 14:04:38.104532717 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 408
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 451
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 405

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 14:09:11.124791318 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 14:14:42.023379709 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 410
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 419
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 408

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 14:18:20.336776326 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 411
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 421
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 450
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 14:23:03.444810119 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 401
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 400
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 452
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 417

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 14:27:53.459904432 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 435
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 14:33:46.518718800 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 228
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 231
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 232
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 221

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 14:35:15.071955016 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 227
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 224
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 235
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 222

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 14:37:13.152654902 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 232
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 221
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 219
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 229

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 14:39:05.323819151 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3328), (2048, 3328), (16384, 3328), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (3072, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 230
    NK 2/4: (2048, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 233
    NK 3/4: (16384, 3328)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 242
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 237

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 14:41:04.078055084 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 14:41:05.959351024 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 é«˜ç¨€ç–å®Œæˆ (6372.5s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 439
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 406
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 444

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 14:49:59.578117310 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 422
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 412

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 15:01:18.915884380 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 424
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 421
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 423

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 15:14:01.793892791 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 425
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 435
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 15:27:38.662133204 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 418
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 440
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 448

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 15:36:32.203927167 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 408
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 15:48:12.357397821 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 443
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 442

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 16:01:08.590993351 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 441
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 439
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 440

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 16:15:07.252937420 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 416
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 404
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 450
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 16:20:02.993296546 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 410
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 408
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 446
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 418

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 16:26:13.515989578 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 418

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 16:32:47.927562948 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 441
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 424

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 16:40:17.382266877 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 411
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 402
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 410

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 16:45:28.674414957 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 424
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 407
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 438

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 16:51:57.721751192 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 415
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 416
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 444
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 440

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 16:59:03.964796020 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 435
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 418
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 442
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 433

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 17:07:02.444503651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_4[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 219
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 235
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 242
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 212

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 17:09:00.985608848 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 230
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 232
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 231
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 235

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 17:11:27.778761798 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 220
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 237
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 237
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 232

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 17:13:56.098453858 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 238
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 240
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 247
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 60, æœ‰æ•ˆ: 234

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 17:16:59.249923564 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 17:16:59.062361719 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 é«˜ç¨€ç–å®Œæˆ (9354.1s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 416
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 422
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 415

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 17:25:49.062821893 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 421
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 435
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 426

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 17:37:09.879926857 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 451
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 17:49:55.046187694 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 432
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 428
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 429

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 18:03:38.949571937 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 420
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 440
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 427

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 18:12:30.013344085 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 422
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 433
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 434

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 18:24:05.830299974 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 436
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 449
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 430
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 439

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 18:36:53.469082194 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 441
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 437
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 459

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 18:50:43.425348720 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 415
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 414
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 431
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 413

    æœç´¢ç»Ÿè®¡: æ€»è®¡=44, æˆåŠŸ=44, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 18:55:36.888008349 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 422
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 108, æœ‰æ•ˆ: 406
    NK 3/4: (16384, 4096)

======================================================================
æ”¶åˆ°ä¸­æ–­ä¿¡å· (signal 2)
======================================================================
[INFO] çŠ¶æ€å·²ä¿å­˜: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_103137_status.json
