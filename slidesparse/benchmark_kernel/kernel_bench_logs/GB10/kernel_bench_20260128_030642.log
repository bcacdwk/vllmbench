======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-28 03:06:42
======================================================================

Hardware:
  GPU: NVIDIA GB10 (cc121)
  Python: py312
  CUDA: cu129
  Arch: aarch64

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_030642.log
[INFO] 跳过 Task 1: cuBLASLt Model 测试
[INFO] 跳过 Task 2: cuBLASLt Square 测试
[INFO] 跳过 Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10)

======================================================================
TASK 4: cuSPARSELt Square 高稀疏 (2_4~2_10)
Started: 2026-01-28 03:06:42
======================================================================


------------------------------------------------------------
  cuSPARSELt Square 高稀疏测试
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_4,2_6,2_8,2_10

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 128)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 256)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 512)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1024)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2048)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 4096)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 8192)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 03:07:47.389777009 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 352)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 704)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1376)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2752)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 5472)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 10944)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 21856)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 03:09:29.357085579 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 384)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 768)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1536)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3072)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6144)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 12288)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 24576)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 03:11:00.800941670 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 416)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 832)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1664)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3296)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6560)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13120)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 26240)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 03:12:37.745030321 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 128)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 256)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 512)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1024)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2048)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 4096)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 8192)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 03:13:40.683206129 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 352)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 704)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1376)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2752)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 5472)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 10944)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 21856)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 03:15:21.894434172 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 384)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 768)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1536)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3072)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6144)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 12288)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 24576)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 03:16:53.296024171 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 416)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 832)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1664)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3296)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6560)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13120)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 26240)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 03:18:30.178842440 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 128)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 256)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 512)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1024)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2048)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 4096)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 8192)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:18:46.159044258 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 352)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 704)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1376)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 2752)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 5472)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 10944)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 21856)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:19:07.560476540 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 384)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 768)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1536)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3072)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6144)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 12288)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 24576)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:19:30.338269587 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 416)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 832)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1664)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3296)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6560)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13120)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 26240)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:19:53.577305767 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 4, 有效: 10
    NK 2/9: (128, 128)
      → 算法数: 4, 有效: 10
    NK 3/9: (256, 256)
      → 算法数: 4, 有效: 12
    NK 4/9: (512, 512)
      → 算法数: 4, 有效: 14
    NK 5/9: (1024, 1024)
      → 算法数: 4, 有效: 14
    NK 6/9: (2048, 2048)
      → 算法数: 4, 有效: 13
    NK 7/9: (4096, 4096)
      → 算法数: 4, 有效: 13
    NK 8/9: (8192, 8192)
      → 算法数: 4, 有效: 15
    NK 9/9: (16384, 16384)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:22:19.661507708 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 4, 有效: 12
    NK 2/9: (128, 192)
      → 算法数: 4, 有效: 10
    NK 3/9: (256, 352)
      → 算法数: 4, 有效: 11
    NK 4/9: (512, 704)
      → 算法数: 4, 有效: 16
    NK 5/9: (1024, 1376)
      → 算法数: 4, 有效: 12
    NK 6/9: (2048, 2752)
      → 算法数: 4, 有效: 15
    NK 7/9: (4096, 5472)
      → 算法数: 4, 有效: 13
    NK 8/9: (8192, 10944)
      → 算法数: 4, 有效: 14
    NK 9/9: (16384, 21856)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:26:22.548269201 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 4, 有效: 11
    NK 2/9: (128, 192)
      → 算法数: 4, 有效: 13
    NK 3/9: (256, 384)
      → 算法数: 4, 有效: 16
    NK 4/9: (512, 768)
      → 算法数: 4, 有效: 14
    NK 5/9: (1024, 1536)
      → 算法数: 4, 有效: 13
    NK 6/9: (2048, 3072)
      → 算法数: 4, 有效: 15
    NK 7/9: (4096, 6144)
      → 算法数: 4, 有效: 12
    NK 8/9: (8192, 12288)
      → 算法数: 4, 有效: 15
    NK 9/9: (16384, 24576)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:30:01.849352471 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 14
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 14
    NK 3/9: (256, 416)
      → 算法数: 4, 有效: 14
    NK 4/9: (512, 832)
      → 算法数: 4, 有效: 17
    NK 5/9: (1024, 1664)
      → 算法数: 4, 有效: 13
    NK 6/9: (2048, 3296)
      → 算法数: 4, 有效: 16
    NK 7/9: (4096, 6560)
      → 算法数: 4, 有效: 12
    NK 8/9: (8192, 13120)
      → 算法数: 4, 有效: 15
    NK 9/9: (16384, 26240)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:35:32.591226232 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 2, 有效: 10
    NK 2/9: (128, 128)
      → 算法数: 2, 有效: 7
    NK 3/9: (256, 256)
      → 算法数: 2, 有效: 8
    NK 4/9: (512, 512)
      → 算法数: 2, 有效: 10
    NK 5/9: (1024, 1024)
      → 算法数: 2, 有效: 10
    NK 6/9: (2048, 2048)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 4096)
      → 算法数: 2, 有效: 8
    NK 8/9: (8192, 8192)
      → 算法数: 2, 有效: 7
    NK 9/9: (16384, 16384)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 03:36:07.274444008 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 128), (128, 192), (256, 384), (512, 704), (1024, 1408)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 7
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 6
    NK 3/9: (256, 384)
      → 算法数: 2, 有效: 8
    NK 4/9: (512, 704)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 1408)
      → 算法数: 2, 有效: 9
    NK 6/9: (2048, 2752)
      → 算法数: 2, 有效: 8
    NK 7/9: (4096, 5504)
      → 算法数: 2, 有效: 9
    NK 8/9: (8192, 10944)
      → 算法数: 2, 有效: 8
    NK 9/9: (16384, 21888)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 03:36:54.510164327 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 128), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 5
    NK 2/9: (128, 192)
      → 算法数: 2, 有效: 9
    NK 3/9: (256, 384)
      → 算法数: 2, 有效: 7
    NK 4/9: (512, 768)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 1536)
      → 算法数: 2, 有效: 8
    NK 6/9: (2048, 3072)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 6144)
      → 算法数: 2, 有效: 7
    NK 8/9: (8192, 12288)
      → 算法数: 2, 有效: 7
    NK 9/9: (16384, 24576)
      → 算法数: 2, 有效: 6

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 03:37:43.619571779 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 5
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 6
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 9
    NK 4/9: (512, 832)
      → 算法数: 2, 有效: 10
    NK 5/9: (1024, 1664)
      → 算法数: 2, 有效: 7
    NK 6/9: (2048, 3328)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 6592)
      → 算法数: 2, 有效: 8
    NK 8/9: (8192, 13120)
      → 算法数: 2, 有效: 8
    NK 9/9: (16384, 26240)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 03:38:42.073749552 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:38:42.864144802 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square [all] 高稀疏测试完成 (1920.7s)
[INFO] cuSPARSELt Square 高稀疏统计: 成功 1, 失败 0

----------------------------------------------------------------------
TASK 4: cuSPARSELt Square 高稀疏 (2_4~2_10) - SUCCESS
Duration: 1920.7 seconds (32.0 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf)
Started: 2026-01-28 03:38:42
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 4, 有效: 17
    NK 2/4: (2048, 3424)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 3424)
      → 算法数: 4, 有效: 17
    NK 4/4: (2048, 13664)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:39:59.466851716 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 4, 有效: 14
    NK 2/4: (2048, 3520)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 3520)
      → 算法数: 4, 有效: 16
    NK 4/4: (2048, 14048)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:41:15.736813259 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 4, 有效: 16
    NK 2/4: (2048, 3584)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 3584)
      → 算法数: 4, 有效: 12
    NK 4/4: (2048, 14336)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:42:26.652123071 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 4, 有效: 15
    NK 2/4: (2048, 4096)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 4096)
      → 算法数: 4, 有效: 13
    NK 4/4: (2048, 16384)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:43:51.011555154 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:43:52.586353617 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [fp8e4m3] 低稀疏完成 (309.7s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:44:08.895641369 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:44:22.548411934 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:44:35.912391802 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:44:50.139513513 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:44:50.805232035 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [int8] 低稀疏完成 (58.2s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 4, 有效: 16
    NK 2/4: (2048, 3424)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 3424)
      → 算法数: 4, 有效: 13
    NK 4/4: (2048, 13664)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:46:13.713940019 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 4, 有效: 14
    NK 2/4: (2048, 3520)
      → 算法数: 4, 有效: 18
    NK 3/4: (16384, 3520)
      → 算法数: 4, 有效: 15
    NK 4/4: (2048, 14048)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:47:29.222796627 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 4, 有效: 14
    NK 2/4: (2048, 3584)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 3584)
      → 算法数: 4, 有效: 15
    NK 4/4: (2048, 14336)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:48:38.951152235 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 4, 有效: 17
    NK 2/4: (2048, 4096)
      → 算法数: 4, 有效: 18
    NK 3/4: (16384, 4096)
      → 算法数: 4, 有效: 15
    NK 4/4: (2048, 16384)
      → 算法数: 4, 有效: 19

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:49:58.641537779 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:49:59.290939952 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [fp8e4m3] 低稀疏完成 (308.5s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:50:15.607047965 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:50:29.316128067 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:50:42.769657854 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:50:57.042296402 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:50:57.676485134 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [int8] 低稀疏完成 (58.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 4, 有效: 15
    NK 2/4: (3072, 5120)
      → 算法数: 4, 有效: 18
    NK 3/4: (16384, 5120)
      → 算法数: 4, 有效: 13
    NK 4/4: (3072, 13664)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:52:51.513031157 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 4, 有效: 15
    NK 2/4: (3072, 5280)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 5280)
      → 算法数: 4, 有效: 16
    NK 4/4: (3072, 14048)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:55:04.180487322 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 4, 有效: 20
    NK 2/4: (3072, 5376)
      → 算法数: 4, 有效: 13
    NK 3/4: (16384, 5376)
      → 算法数: 4, 有效: 12
    NK 4/4: (3072, 14336)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:56:57.887965685 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 4, 有效: 16
    NK 2/4: (3072, 6144)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 6144)
      → 算法数: 4, 有效: 15
    NK 4/4: (3072, 16384)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 03:59:21.409552174 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:59:22.078234582 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [fp8e4m3] 低稀疏完成 (504.4s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:59:41.118131985 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 03:59:59.236017596 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:00:16.234109520 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:00:34.651146936 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:00:35.243529120 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [int8] 低稀疏完成 (73.1s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 4, 有效: 15
    NK 2/4: (3072, 5120)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 5120)
      → 算法数: 4, 有效: 14
    NK 4/4: (3072, 13664)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:02:30.483854551 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 4, 有效: 17
    NK 2/4: (3072, 5280)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 5280)
      → 算法数: 4, 有效: 18
    NK 4/4: (3072, 14048)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:04:53.054261393 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 4, 有效: 15
    NK 2/4: (3072, 5376)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 5376)
      → 算法数: 4, 有效: 15
    NK 4/4: (3072, 14336)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:06:49.897018059 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 4, 有效: 15
    NK 2/4: (3072, 6144)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 6144)
      → 算法数: 4, 有效: 14
    NK 4/4: (3072, 16384)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:09:07.499575054 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:09:08.079909268 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [fp8e4m3] 低稀疏完成 (512.9s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:09:27.156568121 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:09:45.388677511 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:10:02.276248754 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:10:20.688649196 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:10:21.356102942 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [int8] 低稀疏完成 (73.3s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 4, 有效: 18
    NK 2/4: (3584, 5984)
      → 算法数: 4, 有效: 16
    NK 3/4: (37888, 5984)
      → 算法数: 4, 有效: 14
    NK 4/4: (3584, 31584)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:15:41.533664275 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 4, 有效: 15
    NK 2/4: (3584, 6144)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 6144)
      → 算法数: 4, 有效: 15
    NK 4/4: (3584, 32480)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:21:01.471482141 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 4, 有效: 14
    NK 2/4: (3584, 6272)
      → 算法数: 4, 有效: 17
    NK 3/4: (37888, 6272)
      → 算法数: 4, 有效: 18
    NK 4/4: (3584, 33152)
      → 算法数: 4, 有效: 19

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:25:53.006914342 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 4, 有效: 14
    NK 2/4: (3584, 7168)
      → 算法数: 4, 有效: 16
    NK 3/4: (37888, 7168)
      → 算法数: 4, 有效: 21
    NK 4/4: (3584, 37888)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:31:00.504317829 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:31:01.085466324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [fp8e4m3] 低稀疏完成 (1239.7s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:31:37.106352444 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:32:09.502829340 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:32:41.063621830 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:33:16.530248486 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:33:17.191136392 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [int8] 低稀疏完成 (136.1s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 4, 有效: 14
    NK 2/4: (3584, 5984)
      → 算法数: 4, 有效: 16
    NK 3/4: (37888, 5984)
      → 算法数: 4, 有效: 13
    NK 4/4: (3584, 31584)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:38:52.583305074 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 4, 有效: 17
    NK 2/4: (3584, 6144)
      → 算法数: 4, 有效: 18
    NK 3/4: (37888, 6144)
      → 算法数: 4, 有效: 17
    NK 4/4: (3584, 32480)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:44:08.277312321 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 4, 有效: 15
    NK 2/4: (3584, 6272)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 6272)
      → 算法数: 4, 有效: 15
    NK 4/4: (3584, 33152)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:49:17.308110976 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 4, 有效: 13
    NK 2/4: (3584, 7168)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 7168)
      → 算法数: 4, 有效: 17
    NK 4/4: (3584, 37888)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 04:54:46.251634018 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:54:46.826042411 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [fp8e4m3] 低稀疏完成 (1289.6s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:55:22.738325301 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:55:55.082969074 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:56:26.550311995 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 04:57:01.612122800 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:57:02.211749836 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [int8] 低稀疏完成 (135.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 4, 有效: 15
    NK 2/4: (5120, 8544)
      → 算法数: 4, 有效: 14
    NK 3/4: (27648, 8544)
      → 算法数: 4, 有效: 17
    NK 4/4: (5120, 23040)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:03:15.534826998 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 4, 有效: 13
    NK 2/4: (5120, 8800)
      → 算法数: 4, 有效: 15
    NK 3/4: (27648, 8800)
      → 算法数: 4, 有效: 14
    NK 4/4: (5120, 23712)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:09:47.076738500 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 4, 有效: 16
    NK 2/4: (5120, 8960)
      → 算法数: 4, 有效: 14
    NK 3/4: (27648, 8960)
      → 算法数: 4, 有效: 17
    NK 4/4: (5120, 24192)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:15:26.972872923 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 4, 有效: 16
    NK 2/4: (5120, 10240)
      → 算法数: 4, 有效: 15
    NK 3/4: (27648, 10240)
      → 算法数: 4, 有效: 16
    NK 4/4: (5120, 27648)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:21:55.565038666 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:21:56.150427682 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [fp8e4m3] 低稀疏完成 (1493.9s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:22:33.584658250 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:23:10.927722153 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:23:44.855634696 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:24:22.807969289 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:24:23.387842876 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [int8] 低稀疏完成 (147.2s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 4, 有效: 14
    NK 2/4: (5120, 8544)
      → 算法数: 4, 有效: 13
    NK 3/4: (27648, 8544)
      → 算法数: 4, 有效: 16
    NK 4/4: (5120, 23040)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:30:34.358011134 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 4, 有效: 12
    NK 2/4: (5120, 8800)
      → 算法数: 4, 有效: 14
    NK 3/4: (27648, 8800)
      → 算法数: 4, 有效: 17
    NK 4/4: (5120, 23712)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:37:10.740684440 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 4, 有效: 16
    NK 2/4: (5120, 8960)
      → 算法数: 4, 有效: 18
    NK 3/4: (27648, 8960)
      → 算法数: 4, 有效: 15
    NK 4/4: (5120, 24192)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:42:48.375166132 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 4, 有效: 13
    NK 2/4: (5120, 10240)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 10240)
      → 算法数: 4, 有效: 23
    NK 4/4: (5120, 27648)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 05:49:14.630060815 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:49:15.285921465 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [fp8e4m3] 低稀疏完成 (1491.9s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:49:52.617235570 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:50:29.915390375 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:51:03.819688045 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 05:51:41.739453929 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:51:42.401288428 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [int8] 低稀疏完成 (147.1s)

[INFO] cuSPARSELt Model 低稀疏统计: 成功 16, 失败 0

----------------------------------------------------------------------
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 7979.5 seconds (133.0 minutes)
----------------------------------------------------------------------


======================================================================
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf)
Started: 2026-01-28 05:51:42
======================================================================


------------------------------------------------------------
  cuSPARSELt Square 低稀疏测试
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_12,2_14,2_16,2_inf

/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 05:53:28.239017743 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 05:55:14.557460618 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 05:56:59.554336967 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 3
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP16
============================================================
[W128 05:59:01.818727731 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 06:00:45.122703422 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 06:02:31.034412610 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 06:04:15.663902181 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 3
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/BF16
============================================================
[W128 06:06:16.466989995 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 06:06:41.091669214 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 06:07:06.127256324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 06:07:30.306592265 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/INT8
============================================================
[W128 06:08:00.199798084 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 11
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 12
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 16
    NK 4/9: (512, 864)
      → 算法数: 4, 有效: 15
    NK 5/9: (1024, 1728)
      → 算法数: 4, 有效: 19
    NK 6/9: (2048, 3424)
      → 算法数: 4, 有效: 14
    NK 7/9: (4096, 6848)
      → 算法数: 4, 有效: 17
    NK 8/9: (8192, 13664)
      → 算法数: 4, 有效: 14
    NK 9/9: (16384, 27328)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 06:12:31.345327879 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 10
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 12
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 12
    NK 4/9: (512, 896)
      → 算法数: 4, 有效: 18
    NK 5/9: (1024, 1760)
      → 算法数: 4, 有效: 15
    NK 6/9: (2048, 3520)
      → 算法数: 4, 有效: 14
    NK 7/9: (4096, 7040)
      → 算法数: 4, 有效: 13
    NK 8/9: (8192, 14048)
      → 算法数: 4, 有效: 12
    NK 9/9: (16384, 28096)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 06:16:45.433541346 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 16
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 14
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 10
    NK 4/9: (512, 896)
      → 算法数: 4, 有效: 20
    NK 5/9: (1024, 1792)
      → 算法数: 4, 有效: 13
    NK 6/9: (2048, 3584)
      → 算法数: 4, 有效: 13
    NK 7/9: (4096, 7168)
      → 算法数: 4, 有效: 15
    NK 8/9: (8192, 14336)
      → 算法数: 4, 有效: 13
    NK 9/9: (16384, 28672)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 06:21:22.782196765 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 13
    NK 2/9: (128, 256)
      → 算法数: 4, 有效: 15
    NK 3/9: (256, 512)
      → 算法数: 4, 有效: 10
    NK 4/9: (512, 1024)
      → 算法数: 4, 有效: 17
    NK 5/9: (1024, 2048)
      → 算法数: 4, 有效: 17
    NK 6/9: (2048, 4096)
      → 算法数: 4, 有效: 15
    NK 7/9: (4096, 8192)
      → 算法数: 4, 有效: 17
    NK 8/9: (8192, 16384)
      → 算法数: 4, 有效: 13
    NK 9/9: (16384, 32768)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP8
============================================================
[W128 06:25:54.404402608 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 7
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 8
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 7
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 8
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 7
    NK 6/9: (2048, 3456)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 9
    NK 8/9: (8192, 13696)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 6

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 06:26:55.181673552 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 6
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 5
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 6
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 9
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 10
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 8
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 7
    NK 8/9: (8192, 14080)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 06:28:13.430646331 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 9
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 7
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 7
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 9
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 7
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 9
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 06:29:22.464361007 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GB10 (cc121)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 10
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 7
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 5
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 7
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 11
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 9
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 6

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/GB10_cc121_py312_cu129_aarch64/FP4
============================================================
[W128 06:30:27.549986467 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:30:28.326496412 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square [all] 低稀疏测试完成 (2325.9s)
[INFO] cuSPARSELt Square 低稀疏统计: 成功 1, 失败 0

----------------------------------------------------------------------
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 2325.9 seconds (38.8 minutes)
----------------------------------------------------------------------



============================================================
  最终总结
============================================================


  Task 1: cuBLASLt Model 测试 - SKIPPED
  Task 2: cuBLASLt Square 测试 - SKIPPED
  Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10) - SKIPPED
  Task 4: cuSPARSELt Square 高稀疏 (2_4~2_10) - SUCCESS (1920.7s)
  Task 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS (7979.5s)
  Task 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS (2325.9s)

  总计: 3 成功, 0 失败, 3 跳过
  总耗时: 12226.1 秒 (3.40 小时)

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_030642.log
[INFO] 状态文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_030642_status.json

[INFO] 结果保存位置:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
