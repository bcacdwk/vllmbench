======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 19:00:34
======================================================================

Hardware:
  GPU: NVIDIA B200 (cc100)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_190034.log
[INFO] 跳过 Task 1: cuBLASLt Model 测试
[INFO] 跳过 Task 2: cuBLASLt Square 测试

======================================================================
TASK 3: cuSPARSELt Model 高稀疏 (2_4~2_10)
Started: 2026-01-27 19:00:34
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 412
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 397
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 446
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 422

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:02:54.974347781 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 417
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 416
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 447
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:05:35.860438710 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 424
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 408
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 445
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 437

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:08:28.767925156 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 426
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 447
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 439
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 417

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:11:36.165539338 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 402
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 419
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 458
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:13:52.147620919 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 440
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 427
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:16:35.861018836 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 425
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 410
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 454
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:19:29.703644687 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 431
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 444
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 412

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:22:40.153799388 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 412
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 403
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 423
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 419

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 19:24:11.785635672 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 421
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 406
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 416
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 19:26:00.849893782 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 402
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 411
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 412
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 399

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 19:27:49.980312881 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 422
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 394
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 442
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 430

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 19:29:58.508975128 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 414
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 408
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 429
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 19:31:31.910494443 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 413
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 401
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 440
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 19:33:25.591212755 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 413
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 407
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 440
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 420

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 19:35:19.514855812 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 403
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 406
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 425
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 419

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 19:37:33.834500000 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 60, 有效: 227
    NK 2/4: (2048, 2048)
      → 算法数: 60, 有效: 229
    NK 3/4: (16384, 2048)
      → 算法数: 60, 有效: 220
    NK 4/4: (2048, 8192)
      → 算法数: 60, 有效: 236

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 19:38:17.950095091 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 60, 有效: 218
    NK 2/4: (2048, 2752)
      → 算法数: 60, 有效: 215
    NK 3/4: (16384, 2752)
      → 算法数: 60, 有效: 228
    NK 4/4: (2048, 10944)
      → 算法数: 60, 有效: 245

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 19:39:10.508424741 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 60, 有效: 230
    NK 2/4: (2048, 3072)
      → 算法数: 60, 有效: 238
    NK 3/4: (16384, 3072)
      → 算法数: 60, 有效: 237
    NK 4/4: (2048, 12288)
      → 算法数: 60, 有效: 225

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 19:40:01.035510829 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3328), (2048, 3328), (16384, 3328), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3328)
      → 算法数: 60, 有效: 218
    NK 2/4: (2048, 3328)
      → 算法数: 60, 有效: 224
    NK 3/4: (16384, 3328)
      → 算法数: 60, 有效: 221
    NK 4/4: (2048, 13120)
      → 算法数: 60, 有效: 231

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 19:40:56.769559076 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:40:57.668654808 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 高稀疏完成 (2422.9s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 425
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 427
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 455
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 444

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:43:17.473587791 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 450
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 412
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 442
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:45:59.597523830 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 414
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 412
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 464
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:48:52.672843145 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 422
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 415
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 443
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 19:52:00.190131939 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 404
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 413
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 440
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:54:17.716059048 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 411
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 428
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 454
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:56:59.144959152 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 435
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 428
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 451
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 402

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 19:59:54.950768675 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 426
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 434
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 432
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 20:03:06.689314880 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 403
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 403
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 419
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 404

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:04:35.031516964 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 406
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 402
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 437
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 418

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:06:25.954599324 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 422
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 407
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 454
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:08:16.787688794 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 409
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 410
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 419
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 439

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:10:23.954116900 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 401
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 392
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 418
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 413

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 20:11:56.804757267 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 403
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 381
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 443
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 20:13:49.035744080 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 409
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 411
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 436
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 20:15:43.163435465 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 402
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 431
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 441
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 20:17:56.373820552 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 60, 有效: 227
    NK 2/4: (2048, 2048)
      → 算法数: 60, 有效: 214
    NK 3/4: (16384, 2048)
      → 算法数: 60, 有效: 233
    NK 4/4: (2048, 8192)
      → 算法数: 60, 有效: 237

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 20:18:40.563561560 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 60, 有效: 224
    NK 2/4: (2048, 2752)
      → 算法数: 60, 有效: 231
    NK 3/4: (16384, 2752)
      → 算法数: 60, 有效: 221
    NK 4/4: (2048, 10944)
      → 算法数: 60, 有效: 231

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 20:19:32.893719677 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 60, 有效: 221
    NK 2/4: (2048, 3072)
      → 算法数: 60, 有效: 227
    NK 3/4: (16384, 3072)
      → 算法数: 60, 有效: 240
    NK 4/4: (2048, 12288)
      → 算法数: 60, 有效: 230

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 20:20:24.356806541 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3328), (2048, 3328), (16384, 3328), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3328)
      → 算法数: 60, 有效: 231
    NK 2/4: (2048, 3328)
      → 算法数: 60, 有效: 212
    NK 3/4: (16384, 3328)
      → 算法数: 60, 有效: 231
    NK 4/4: (2048, 13120)
      → 算法数: 60, 有效: 233

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 20:21:17.077078682 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:21:18.899520452 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 高稀疏完成 (2421.2s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 419
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 432
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 439
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 20:24:26.435639929 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 427
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 426
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 438
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 443

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 20:28:09.839663167 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 438
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 425
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 426
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 441

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 20:32:19.419748075 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 448
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 442
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 434
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 444

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 20:37:03.233247039 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 417
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 430
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 448
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 429

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 20:40:07.353624149 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 405
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 436
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 428
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 422

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 20:43:52.288134429 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 430
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 423
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 442
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 20:48:00.967569955 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 446
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 437
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 435
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 20:52:35.769060390 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 413
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 419
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 465
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 424

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:54:45.190847190 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 412
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 406
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 443
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 421

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:57:03.713393499 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 408
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 405
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 434
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 412

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 20:59:28.953062773 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 432
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 437
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 425
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 21:02:09.334654210 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 405
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 410
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 446
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 401

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 21:04:08.579750267 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 418
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 400
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 443
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 421

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 21:06:31.305379186 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 407
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 404
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 446
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 414

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 21:09:03.030018039 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 437
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 428
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 424
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 21:11:50.905995793 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 60, 有效: 224
    NK 2/4: (3072, 3072)
      → 算法数: 60, 有效: 220
    NK 3/4: (16384, 3072)
      → 算法数: 60, 有效: 224
    NK 4/4: (3072, 8192)
      → 算法数: 60, 有效: 210

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 21:12:42.149106821 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 60, 有效: 225
    NK 2/4: (3072, 4096)
      → 算法数: 60, 有效: 213
    NK 3/4: (16384, 4096)
      → 算法数: 60, 有效: 239
    NK 4/4: (3072, 10944)
      → 算法数: 60, 有效: 230

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 21:13:44.054871349 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 60, 有效: 229
    NK 2/4: (3072, 4608)
      → 算法数: 60, 有效: 219
    NK 3/4: (16384, 4608)
      → 算法数: 60, 有效: 232
    NK 4/4: (3072, 12288)
      → 算法数: 60, 有效: 234

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 21:14:47.602635477 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 60, 有效: 226
    NK 2/4: (3072, 4928)
      → 算法数: 60, 有效: 227
    NK 3/4: (16384, 4928)
      → 算法数: 60, 有效: 250
    NK 4/4: (3072, 13120)
      → 算法数: 60, 有效: 229

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 21:16:00.728535483 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 21:16:01.628564492 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 高稀疏完成 (3282.7s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 426
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 413
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 450
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 456

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 21:19:06.379112117 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 425
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 425
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 428
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 446

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 21:22:50.146455617 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 423
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 433
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 444
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 428

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 21:26:54.646221850 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 454
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 443
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 452
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 437

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 21:31:11.427818972 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 430
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 413
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 445
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 21:34:16.847580599 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 433
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 410
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 441
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 428

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 21:37:59.664789695 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 435
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 439
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 421
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 21:42:06.620941022 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 435
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 427
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 445
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 444

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 21:46:26.939132231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 413
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 401
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 439
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 406

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 21:48:22.775562058 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 421
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 424
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 424
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 414

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 21:50:38.008516041 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 412
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 414
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 439
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 424

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 21:53:02.056615040 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 425
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 436
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 438
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 439

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 21:55:43.812018642 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 421
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 413
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 452
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 426

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 21:57:44.264298463 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 407
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 418
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 453
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 22:00:06.984850846 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 413
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 415
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 438
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 410

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 22:02:38.001625443 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 450
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 426
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 426
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 438

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 22:05:28.415579282 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 60, 有效: 222
    NK 2/4: (3072, 3072)
      → 算法数: 60, 有效: 226
    NK 3/4: (16384, 3072)
      → 算法数: 60, 有效: 232
    NK 4/4: (3072, 8192)
      → 算法数: 60, 有效: 229

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 22:06:21.205035273 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 60, 有效: 233
    NK 2/4: (3072, 4096)
      → 算法数: 60, 有效: 222
    NK 3/4: (16384, 4096)
      → 算法数: 60, 有效: 246
    NK 4/4: (3072, 10944)
      → 算法数: 60, 有效: 230

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 22:07:25.750193438 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 60, 有效: 230
    NK 2/4: (3072, 4608)
      → 算法数: 60, 有效: 224
    NK 3/4: (16384, 4608)
      → 算法数: 60, 有效: 243
    NK 4/4: (3072, 12288)
      → 算法数: 60, 有效: 228

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 22:08:28.975365552 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 60, 有效: 229
    NK 2/4: (3072, 4928)
      → 算法数: 60, 有效: 227
    NK 3/4: (16384, 4928)
      → 算法数: 60, 有效: 236
    NK 4/4: (3072, 13120)
      → 算法数: 60, 有效: 220

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 22:09:40.184576217 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 22:09:41.076749670 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 高稀疏完成 (3220.4s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 435
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 442
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 402
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 537

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 22:15:35.054130687 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 464
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 434
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 389
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 22:23:01.958731990 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 439
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 450
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 372
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 405

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 22:31:05.022440176 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 418
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 428
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 382
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 397

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 22:39:45.056985389 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 439
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 445
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 394
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 467

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 22:45:39.043133745 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 457
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 439
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 397
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 431

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 22:53:09.589325823 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 425
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 425
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 385
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 405

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 23:01:22.168228801 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 404
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 442
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 393
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 408

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W127 23:10:11.358315823 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 420
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 421
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 425
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 419

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 23:13:24.129646573 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 398
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 410
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 407
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 23:17:41.166592339 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 436
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 435
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 397
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 429

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 23:22:13.979278334 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 423
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 406
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 403
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 476

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W127 23:27:00.745867291 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 402
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 407
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 435
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 23:30:21.506057809 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 419
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 413
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 421
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 438

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 23:34:57.347179269 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 423
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 413
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 406
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 23:39:38.816455230 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 421
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 418
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 412
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 426

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W127 23:44:37.950761487 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 60, 有效: 238
    NK 2/4: (3584, 3584)
      → 算法数: 60, 有效: 230
    NK 3/4: (37888, 3584)
      → 算法数: 60, 有效: 216
    NK 4/4: (3584, 18944)
      → 算法数: 60, 有效: 241

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 23:45:58.329937512 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 60, 有效: 227
    NK 2/4: (3584, 4800)
      → 算法数: 60, 有效: 232
    NK 3/4: (37888, 4800)
      → 算法数: 60, 有效: 252
    NK 4/4: (3584, 25280)
      → 算法数: 60, 有效: 236

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 23:47:41.155262774 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 60, 有效: 236
    NK 2/4: (3584, 5376)
      → 算法数: 60, 有效: 226
    NK 3/4: (37888, 5376)
      → 算法数: 60, 有效: 243
    NK 4/4: (3584, 28416)
      → 算法数: 60, 有效: 241

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 23:49:24.674776868 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 60, 有效: 238
    NK 2/4: (3584, 5760)
      → 算法数: 60, 有效: 222
    NK 3/4: (37888, 5760)
      → 算法数: 60, 有效: 228
    NK 4/4: (3584, 30336)
      → 算法数: 60, 有效: 241

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W127 23:51:14.689601991 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 23:51:15.597189040 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 高稀疏完成 (6093.5s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 441
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 430
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 409
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 543

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W127 23:57:10.837754633 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 450
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 423
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 395
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 00:04:31.552901889 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 450
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 408
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 393
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 409

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 00:12:42.024789330 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 431
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 448
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 392
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 394

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 00:21:26.799357774 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 426
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 416
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 403
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 449

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 00:27:20.170398559 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 440
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 442
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 405
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 00:34:51.420478624 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 449
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 419
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 383
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 389

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 00:43:07.777217859 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 437
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 424
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 370
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 407

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 00:51:57.188033545 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 413
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 397
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 421
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 426

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 00:55:13.832412421 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 429
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 410
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 394
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 439

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 00:59:35.783528538 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 417
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 440
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 408
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 438

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 01:04:02.716682307 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 417
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 401
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 396
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 478

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 01:08:49.294905511 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 416
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 404
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 429
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 453

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 01:12:12.052957077 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 404
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 427
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 415
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 01:16:46.374781513 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 424
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 407
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 411
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 448

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 01:21:31.660944384 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 426
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 429
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 407
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 01:26:30.124607743 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 60, 有效: 230
    NK 2/4: (3584, 3584)
      → 算法数: 60, 有效: 220
    NK 3/4: (37888, 3584)
      → 算法数: 60, 有效: 236
    NK 4/4: (3584, 18944)
      → 算法数: 60, 有效: 241

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 01:27:51.347117922 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 60, 有效: 226
    NK 2/4: (3584, 4800)
      → 算法数: 60, 有效: 225
    NK 3/4: (37888, 4800)
      → 算法数: 60, 有效: 240
    NK 4/4: (3584, 25280)
      → 算法数: 60, 有效: 216

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 01:29:34.138824956 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 60, 有效: 232
    NK 2/4: (3584, 5376)
      → 算法数: 60, 有效: 225
    NK 3/4: (37888, 5376)
      → 算法数: 60, 有效: 245
    NK 4/4: (3584, 28416)
      → 算法数: 60, 有效: 248

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 01:31:15.214208231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 60, 有效: 223
    NK 2/4: (3584, 5760)
      → 算法数: 60, 有效: 233
    NK 3/4: (37888, 5760)
      → 算法数: 60, 有效: 233
    NK 4/4: (3584, 30336)
      → 算法数: 60, 有效: 241

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 01:33:06.234364356 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())

[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 01:33:06.100438589 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 高稀疏完成 (6111.5s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 454
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 448
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 405
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 481

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 01:39:46.840615478 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 432
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 448
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 387
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 412

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 01:48:17.334803534 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 452
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 423
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 387
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 406

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 01:57:43.073241631 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 436
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 441
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 389
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 407

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 02:07:46.049372652 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 455
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 417
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 402
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 461

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 02:14:24.898163859 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 450
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 430
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 404
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 419

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 02:23:01.396071983 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 437
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 439
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 385
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 401

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 02:32:29.176056539 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 451
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 438
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 368
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 388

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 02:42:38.297632060 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 425
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 418
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 450
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 02:46:15.698535584 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 444
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 431
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 388
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 444

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 02:51:02.018810455 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 429
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 423
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 406
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 422

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 02:56:02.858111293 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 412
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 418
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 412
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 470

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:01:20.856635526 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 423
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 424
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 439
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 443

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:05:06.185473589 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 445
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 440
    NK 3/4: (27648, 6848)
