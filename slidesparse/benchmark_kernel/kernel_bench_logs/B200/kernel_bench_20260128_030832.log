======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-28 03:08:32
======================================================================

Hardware:
  GPU: NVIDIA B200 (cc100)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_030832.log
[INFO] 跳过 Task 1: cuBLASLt Model 测试
[INFO] 跳过 Task 2: cuBLASLt Square 测试

======================================================================
TASK 3: cuSPARSELt Model 高稀疏 (2_4~2_10)
Started: 2026-01-28 03:08:32
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 394
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 398
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 417
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 408

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:10:09.312301137 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 411
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 422
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 424
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 420

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:12:03.592076777 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 427
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 416
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 422
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 434

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:13:57.982648934 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 420
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 420
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 445
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 446

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:16:12.704447346 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:16:13.593641361 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [fp8e4m3] 高稀疏完成 (461.3s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 415
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 418
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 427
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 414

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:17:48.976094141 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 418
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 396
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 426
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:19:37.953881981 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 401
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 395
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 447
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 395

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:21:28.679020665 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 416
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 399
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 427
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 424

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:23:35.170025624 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:23:36.051424151 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [int8] 高稀疏完成 (443.5s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 399
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 419
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 407
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 400

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:25:13.018151818 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 402
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 408
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 426
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 430

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:27:08.242006028 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 416
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 400
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 443
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 416

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:29:01.332517750 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 417
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 438
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 440

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:31:15.214249482 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:31:16.050697561 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [fp8e4m3] 高稀疏完成 (460.0s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      → 算法数: 108, 有效: 384
    NK 2/4: (2048, 2048)
      → 算法数: 108, 有效: 397
    NK 3/4: (16384, 2048)
      → 算法数: 108, 有效: 421
    NK 4/4: (2048, 8192)
      → 算法数: 108, 有效: 408

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:32:50.416947717 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      → 算法数: 108, 有效: 402
    NK 2/4: (2048, 2752)
      → 算法数: 108, 有效: 405
    NK 3/4: (16384, 2752)
      → 算法数: 108, 有效: 414
    NK 4/4: (2048, 10944)
      → 算法数: 108, 有效: 412

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:34:39.448358470 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      → 算法数: 108, 有效: 419
    NK 2/4: (2048, 3072)
      → 算法数: 108, 有效: 416
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 442
    NK 4/4: (2048, 12288)
      → 算法数: 108, 有效: 419

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:36:29.856130498 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      → 算法数: 108, 有效: 416
    NK 2/4: (2048, 3296)
      → 算法数: 108, 有效: 408
    NK 3/4: (16384, 3296)
      → 算法数: 108, 有效: 428
    NK 4/4: (2048, 13120)
      → 算法数: 108, 有效: 442

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:38:37.004325536 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:38:38.823759564 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [int8] 高稀疏完成 (441.8s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 397
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 423
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 442
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 426

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:40:41.602759564 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 429
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 426
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 443
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 435

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:43:03.391223622 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 426
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 420
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 439
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 422

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:45:34.214560511 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 433
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 419
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 420
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 424

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:48:23.819291356 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:48:24.615801212 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [fp8e4m3] 高稀疏完成 (585.8s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 404
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 403
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 439
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:50:23.266475385 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 416
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 423
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 455
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 452

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:52:39.787194506 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 426
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 411
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 426
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 422

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:55:03.929632100 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 437
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 419
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 420
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 431

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 03:57:44.677367037 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:57:45.518835339 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [int8] 高稀疏完成 (560.9s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 427
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 407
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 426
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 396

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 03:59:46.006104934 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 404
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 409
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 443
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:02:09.187985745 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 423
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 416
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 442
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 410

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:04:41.971916432 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 439
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 405
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 418
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 431

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:07:28.709912693 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:07:29.599919794 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [fp8e4m3] 高稀疏完成 (584.1s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      → 算法数: 108, 有效: 394
    NK 2/4: (3072, 3072)
      → 算法数: 108, 有效: 403
    NK 3/4: (16384, 3072)
      → 算法数: 108, 有效: 455
    NK 4/4: (3072, 8192)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:09:26.301855896 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      → 算法数: 108, 有效: 426
    NK 2/4: (3072, 4096)
      → 算法数: 108, 有效: 406
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 444
    NK 4/4: (3072, 10944)
      → 算法数: 108, 有效: 430

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:11:43.667981149 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      → 算法数: 108, 有效: 418
    NK 2/4: (3072, 4608)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 4608)
      → 算法数: 108, 有效: 450
    NK 4/4: (3072, 12288)
      → 算法数: 108, 有效: 421

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:14:08.405366117 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      → 算法数: 108, 有效: 430
    NK 2/4: (3072, 4928)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 4928)
      → 算法数: 108, 有效: 445
    NK 4/4: (3072, 13120)
      → 算法数: 108, 有效: 438

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:16:47.497272900 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:16:48.355934742 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [int8] 高稀疏完成 (558.7s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 412
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 414
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 432
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 426

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:20:16.270802754 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 421
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 439
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 420
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:24:52.044663410 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 419
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 439
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 406
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 417

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:29:33.140800432 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 434
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 401
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 400
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 447

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:34:34.269191488 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:34:34.133963984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [fp8e4m3] 高稀疏完成 (1066.8s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 424
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 399
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 423
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:37:54.704006882 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 416
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 449
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 416
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 444

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:42:15.074469931 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 420
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 408
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 400
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 439

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:46:48.516588046 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 416
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 419
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 401
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 458

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 04:51:33.492251812 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:51:34.314764940 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [int8] 高稀疏完成 (1019.2s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 406
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 415
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 427
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 445

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:55:00.649350266 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 432
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 413
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 408
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 421

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 04:59:34.067579578 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 431
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 436
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 414
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:04:17.515149755 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 452
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 415
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 417
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:09:19.045091325 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:09:20.881016441 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [fp8e4m3] 高稀疏完成 (1066.6s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      → 算法数: 108, 有效: 416
    NK 2/4: (3584, 3584)
      → 算法数: 108, 有效: 402
    NK 3/4: (37888, 3584)
      → 算法数: 108, 有效: 446
    NK 4/4: (3584, 18944)
      → 算法数: 108, 有效: 443

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:12:38.867707293 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      → 算法数: 108, 有效: 427
    NK 2/4: (3584, 4800)
      → 算法数: 108, 有效: 416
    NK 3/4: (37888, 4800)
      → 算法数: 108, 有效: 404
    NK 4/4: (3584, 25280)
      → 算法数: 108, 有效: 437

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:17:04.362503520 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      → 算法数: 108, 有效: 422
    NK 2/4: (3584, 5376)
      → 算法数: 108, 有效: 406
    NK 3/4: (37888, 5376)
      → 算法数: 108, 有效: 391
    NK 4/4: (3584, 28416)
      → 算法数: 108, 有效: 435

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:21:33.375502120 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      → 算法数: 108, 有效: 416
    NK 2/4: (3584, 5760)
      → 算法数: 108, 有效: 406
    NK 3/4: (37888, 5760)
      → 算法数: 108, 有效: 398
    NK 4/4: (3584, 30336)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:26:22.739919691 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:26:23.639420676 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [int8] 高稀疏完成 (1022.7s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 415
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 439
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 429
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 456

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:30:16.271133672 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 437
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 430
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 403
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 448

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:35:17.518284571 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 432
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 432
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 405
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 451

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:40:27.110581551 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 434
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 434
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 400
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 431

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 05:46:03.344318917 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:46:03.168510937 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [fp8e4m3] 高稀疏完成 (1180.5s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 424
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 423
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 438
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 447

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:49:44.243600758 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 437
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 437
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 403
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 468

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:54:31.572203574 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 450
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 420
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 404
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 05:59:33.629289203 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 447
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 425
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 410
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 474

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 06:04:48.781823287 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:04:49.686950075 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [int8] 高稀疏完成 (1125.5s)

------------------------------------------------------------
  cuSPARSELt Model 高稀疏: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 431
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 430
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 438
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 435

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 06:08:43.942392923 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 447
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 430
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 394
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 448

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 06:13:42.195713231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 421
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 436
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 406
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 451

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 06:18:54.624792516 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 429
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 428
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 409
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 437

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 06:24:28.028344727 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:24:29.870754734 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [fp8e4m3] 高稀疏完成 (1180.2s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      → 算法数: 108, 有效: 416
    NK 2/4: (5120, 5120)
      → 算法数: 108, 有效: 417
    NK 3/4: (27648, 5120)
      → 算法数: 108, 有效: 434
    NK 4/4: (5120, 13824)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 06:28:10.938246952 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      → 算法数: 108, 有效: 429
    NK 2/4: (5120, 6848)
      → 算法数: 108, 有效: 423
    NK 3/4: (27648, 6848)
      → 算法数: 108, 有效: 405
    NK 4/4: (5120, 18432)
      → 算法数: 108, 有效: 443

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 06:32:55.192541342 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      → 算法数: 108, 有效: 430
    NK 2/4: (5120, 7680)
      → 算法数: 108, 有效: 419
    NK 3/4: (27648, 7680)
      → 算法数: 108, 有效: 421
    NK 4/4: (5120, 20736)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 06:37:55.627027605 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      → 算法数: 108, 有效: 445
    NK 2/4: (5120, 8192)
      → 算法数: 108, 有效: 431
    NK 3/4: (27648, 8192)
      → 算法数: 108, 有效: 399
    NK 4/4: (5120, 22144)
      → 算法数: 108, 有效: 445

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 06:43:13.009523644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:43:14.847156312 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [int8] 高稀疏完成 (1125.0s)

[INFO] cuSPARSELt Model 高稀疏统计: 成功 16, 失败 0

----------------------------------------------------------------------
TASK 3: cuSPARSELt Model 高稀疏 (2_4~2_10) - SUCCESS
Duration: 12882.5 seconds (214.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: cuSPARSELt Square 高稀疏 (2_4~2_10)
Started: 2026-01-28 06:43:14
======================================================================


------------------------------------------------------------
  cuSPARSELt Square 高稀疏测试
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 108, 有效: 281
    NK 2/9: (128, 128)
      → 算法数: 108, 有效: 309
    NK 3/9: (256, 256)
      → 算法数: 108, 有效: 303
    NK 4/9: (512, 512)
      → 算法数: 108, 有效: 410
    NK 5/9: (1024, 1024)
      → 算法数: 108, 有效: 415
    NK 6/9: (2048, 2048)
      → 算法数: 108, 有效: 455
    NK 7/9: (4096, 4096)
      → 算法数: 108, 有效: 416
    NK 8/9: (8192, 8192)
      → 算法数: 108, 有效: 415
    NK 9/9: (16384, 16384)
      → 算法数: 108, 有效: 396

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 06:46:59.768059836 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 312
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 270
    NK 3/9: (256, 352)
      → 算法数: 108, 有效: 293
    NK 4/9: (512, 704)
      → 算法数: 108, 有效: 409
    NK 5/9: (1024, 1376)
      → 算法数: 108, 有效: 412
    NK 6/9: (2048, 2752)
      → 算法数: 108, 有效: 446
    NK 7/9: (4096, 5472)
      → 算法数: 108, 有效: 439
    NK 8/9: (8192, 10944)
      → 算法数: 108, 有效: 403
    NK 9/9: (16384, 21856)
      → 算法数: 108, 有效: 403

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 06:52:00.164719845 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 285
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 285
    NK 3/9: (256, 384)
      → 算法数: 108, 有效: 300
    NK 4/9: (512, 768)
      → 算法数: 108, 有效: 418
    NK 5/9: (1024, 1536)
      → 算法数: 108, 有效: 414
    NK 6/9: (2048, 3072)
      → 算法数: 108, 有效: 447
    NK 7/9: (4096, 6144)
      → 算法数: 108, 有效: 432
    NK 8/9: (8192, 12288)
      → 算法数: 108, 有效: 379
    NK 9/9: (16384, 24576)
      → 算法数: 108, 有效: 414

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 06:57:33.090112190 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 108, 有效: 289
    NK 2/9: (128, 224)
      → 算法数: 108, 有效: 297
    NK 3/9: (256, 416)
      → 算法数: 108, 有效: 283
    NK 4/9: (512, 832)
      → 算法数: 108, 有效: 400
    NK 5/9: (1024, 1664)
      → 算法数: 108, 有效: 425
    NK 6/9: (2048, 3296)
      → 算法数: 108, 有效: 452
    NK 7/9: (4096, 6560)
      → 算法数: 108, 有效: 435
    NK 8/9: (8192, 13120)
      → 算法数: 108, 有效: 376
    NK 9/9: (16384, 26240)
      → 算法数: 108, 有效: 413

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP16
============================================================
[W128 07:03:26.664671807 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 108, 有效: 302
    NK 2/9: (128, 128)
      → 算法数: 108, 有效: 297
    NK 3/9: (256, 256)
      → 算法数: 108, 有效: 294
    NK 4/9: (512, 512)
      → 算法数: 108, 有效: 403
    NK 5/9: (1024, 1024)
      → 算法数: 108, 有效: 411
    NK 6/9: (2048, 2048)
      → 算法数: 108, 有效: 445
    NK 7/9: (4096, 4096)
      → 算法数: 108, 有效: 454
    NK 8/9: (8192, 8192)
      → 算法数: 108, 有效: 411
    NK 9/9: (16384, 16384)
      → 算法数: 108, 有效: 400

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 07:07:08.863416943 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 276
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 269
    NK 3/9: (256, 352)
      → 算法数: 108, 有效: 292
    NK 4/9: (512, 704)
      → 算法数: 108, 有效: 394
    NK 5/9: (1024, 1376)
      → 算法数: 108, 有效: 422
    NK 6/9: (2048, 2752)
      → 算法数: 108, 有效: 495
    NK 7/9: (4096, 5472)
      → 算法数: 108, 有效: 440
    NK 8/9: (8192, 10944)
      → 算法数: 108, 有效: 386
    NK 9/9: (16384, 21856)
      → 算法数: 108, 有效: 416

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 07:12:19.668360587 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 302
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 311
    NK 3/9: (256, 384)
      → 算法数: 108, 有效: 283
    NK 4/9: (512, 768)
      → 算法数: 108, 有效: 405
    NK 5/9: (1024, 1536)
      → 算法数: 108, 有效: 413
    NK 6/9: (2048, 3072)
      → 算法数: 108, 有效: 461
    NK 7/9: (4096, 6144)
      → 算法数: 108, 有效: 447
    NK 8/9: (8192, 12288)
      → 算法数: 108, 有效: 394
    NK 9/9: (16384, 24576)
      → 算法数: 108, 有效: 407

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 07:17:52.579923723 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 108, 有效: 306
    NK 2/9: (128, 224)
      → 算法数: 108, 有效: 295
    NK 3/9: (256, 416)
      → 算法数: 108, 有效: 289
    NK 4/9: (512, 832)
      → 算法数: 108, 有效: 386
    NK 5/9: (1024, 1664)
      → 算法数: 108, 有效: 414
    NK 6/9: (2048, 3296)
      → 算法数: 108, 有效: 476
    NK 7/9: (4096, 6560)
      → 算法数: 108, 有效: 432
    NK 8/9: (8192, 13120)
      → 算法数: 108, 有效: 386
    NK 9/9: (16384, 26240)
      → 算法数: 108, 有效: 420

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/BF16
============================================================
[W128 07:23:56.665004046 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 108, 有效: 289
    NK 2/9: (128, 128)
      → 算法数: 108, 有效: 295
    NK 3/9: (256, 256)
      → 算法数: 108, 有效: 282
    NK 4/9: (512, 512)
      → 算法数: 108, 有效: 405
    NK 5/9: (1024, 1024)
      → 算法数: 108, 有效: 404
    NK 6/9: (2048, 2048)
      → 算法数: 108, 有效: 448
    NK 7/9: (4096, 4096)
      → 算法数: 108, 有效: 474
    NK 8/9: (8192, 8192)
      → 算法数: 108, 有效: 437
    NK 9/9: (16384, 16384)
      → 算法数: 108, 有效: 365

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 07:25:43.025214612 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 287
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 282
    NK 3/9: (256, 352)
      → 算法数: 108, 有效: 285
    NK 4/9: (512, 704)
      → 算法数: 108, 有效: 391
    NK 5/9: (1024, 1376)
      → 算法数: 108, 有效: 396
    NK 6/9: (2048, 2752)
      → 算法数: 108, 有效: 424
    NK 7/9: (4096, 5472)
      → 算法数: 108, 有效: 437
    NK 8/9: (8192, 10944)
      → 算法数: 108, 有效: 427
    NK 9/9: (16384, 21856)
      → 算法数: 108, 有效: 397

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 07:28:31.586577984 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 293
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 303
    NK 3/9: (256, 384)
      → 算法数: 108, 有效: 293
    NK 4/9: (512, 768)
      → 算法数: 108, 有效: 405
    NK 5/9: (1024, 1536)
      → 算法数: 108, 有效: 404
    NK 6/9: (2048, 3072)
      → 算法数: 108, 有效: 428
    NK 7/9: (4096, 6144)
      → 算法数: 108, 有效: 459
    NK 8/9: (8192, 12288)
      → 算法数: 108, 有效: 416
    NK 9/9: (16384, 24576)
      → 算法数: 108, 有效: 397

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 07:31:17.613232141 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 108, 有效: 296
    NK 2/9: (128, 224)
      → 算法数: 108, 有效: 299
    NK 3/9: (256, 416)
      → 算法数: 108, 有效: 299
    NK 4/9: (512, 832)
      → 算法数: 108, 有效: 411
    NK 5/9: (1024, 1664)
      → 算法数: 108, 有效: 414
    NK 6/9: (2048, 3296)
      → 算法数: 108, 有效: 439
    NK 7/9: (4096, 6560)
      → 算法数: 108, 有效: 426
    NK 8/9: (8192, 13120)
      → 算法数: 108, 有效: 412
    NK 9/9: (16384, 26240)
      → 算法数: 108, 有效: 379

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 07:34:10.738723624 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 108, 有效: 282
    NK 2/9: (128, 128)
      → 算法数: 108, 有效: 297
    NK 3/9: (256, 256)
      → 算法数: 108, 有效: 274
    NK 4/9: (512, 512)
      → 算法数: 108, 有效: 398
    NK 5/9: (1024, 1024)
      → 算法数: 108, 有效: 397
    NK 6/9: (2048, 2048)
      → 算法数: 108, 有效: 454
    NK 7/9: (4096, 4096)
      → 算法数: 108, 有效: 480
    NK 8/9: (8192, 8192)
      → 算法数: 108, 有效: 439
    NK 9/9: (16384, 16384)
      → 算法数: 108, 有效: 359

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:36:01.524513326 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 285
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 291
    NK 3/9: (256, 352)
      → 算法数: 108, 有效: 299
    NK 4/9: (512, 704)
      → 算法数: 108, 有效: 402
    NK 5/9: (1024, 1376)
      → 算法数: 108, 有效: 410
    NK 6/9: (2048, 2752)
      → 算法数: 108, 有效: 431
    NK 7/9: (4096, 5472)
      → 算法数: 108, 有效: 458
    NK 8/9: (8192, 10944)
      → 算法数: 108, 有效: 453
    NK 9/9: (16384, 21856)
      → 算法数: 108, 有效: 399

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:38:58.253980761 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      → 算法数: 108, 有效: 301
    NK 2/9: (128, 192)
      → 算法数: 108, 有效: 287
    NK 3/9: (256, 384)
      → 算法数: 108, 有效: 287
    NK 4/9: (512, 768)
      → 算法数: 108, 有效: 395
    NK 5/9: (1024, 1536)
      → 算法数: 108, 有效: 393
    NK 6/9: (2048, 3072)
      → 算法数: 108, 有效: 430
    NK 7/9: (4096, 6144)
      → 算法数: 108, 有效: 458
    NK 8/9: (8192, 12288)
      → 算法数: 108, 有效: 421
    NK 9/9: (16384, 24576)
      → 算法数: 108, 有效: 392

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:41:50.806668873 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 108, 有效: 296
    NK 2/9: (128, 224)
      → 算法数: 108, 有效: 281
    NK 3/9: (256, 416)
      → 算法数: 108, 有效: 298
    NK 4/9: (512, 832)
      → 算法数: 108, 有效: 410
    NK 5/9: (1024, 1664)
      → 算法数: 108, 有效: 401
    NK 6/9: (2048, 3296)
      → 算法数: 108, 有效: 464
    NK 7/9: (4096, 6560)
      → 算法数: 108, 有效: 460
    NK 8/9: (8192, 13120)
      → 算法数: 108, 有效: 431
    NK 9/9: (16384, 26240)
      → 算法数: 108, 有效: 388

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:44:53.704260450 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_4
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      → 算法数: 60, 有效: 153
    NK 2/9: (128, 128)
      → 算法数: 60, 有效: 162
    NK 3/9: (256, 256)
      → 算法数: 60, 有效: 172
    NK 4/9: (512, 512)
      → 算法数: 60, 有效: 228
    NK 5/9: (1024, 1024)
      → 算法数: 60, 有效: 213
    NK 6/9: (2048, 2048)
      → 算法数: 60, 有效: 228
    NK 7/9: (4096, 4096)
      → 算法数: 60, 有效: 234
    NK 8/9: (8192, 8192)
      → 算法数: 60, 有效: 250
    NK 9/9: (16384, 16384)
      → 算法数: 60, 有效: 211

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_4.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 07:45:33.163864793 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 128), (128, 192), (256, 384), (512, 704), (1024, 1408)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_6
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 60, 有效: 155
    NK 2/9: (128, 192)
      → 算法数: 60, 有效: 152
    NK 3/9: (256, 384)
      → 算法数: 60, 有效: 149
    NK 4/9: (512, 704)
      → 算法数: 60, 有效: 228
    NK 5/9: (1024, 1408)
      → 算法数: 60, 有效: 230
    NK 6/9: (2048, 2752)
      → 算法数: 60, 有效: 245
    NK 7/9: (4096, 5504)
      → 算法数: 60, 有效: 241
    NK 8/9: (8192, 10944)
      → 算法数: 60, 有效: 276
    NK 9/9: (16384, 21888)
      → 算法数: 60, 有效: 192

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_6.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 07:46:23.451296085 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 128), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_8
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 60, 有效: 150
    NK 2/9: (128, 192)
      → 算法数: 60, 有效: 156
    NK 3/9: (256, 384)
      → 算法数: 60, 有效: 165
    NK 4/9: (512, 768)
      → 算法数: 60, 有效: 223
    NK 5/9: (1024, 1536)
      → 算法数: 60, 有效: 219
    NK 6/9: (2048, 3072)
      → 算法数: 60, 有效: 247
    NK 7/9: (4096, 6144)
      → 算法数: 60, 有效: 255
    NK 8/9: (8192, 12288)
      → 算法数: 60, 有效: 267
    NK 9/9: (16384, 24576)
      → 算法数: 60, 有效: 204

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_8.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 07:47:16.054402373 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_10
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 60, 有效: 162
    NK 2/9: (128, 256)
      → 算法数: 60, 有效: 153
    NK 3/9: (256, 448)
      → 算法数: 60, 有效: 161
    NK 4/9: (512, 832)
      → 算法数: 60, 有效: 221
    NK 5/9: (1024, 1664)
      → 算法数: 60, 有效: 235
    NK 6/9: (2048, 3328)
      → 算法数: 60, 有效: 246
    NK 7/9: (4096, 6592)
      → 算法数: 60, 有效: 235
    NK 8/9: (8192, 13120)
      → 算法数: 60, 有效: 279
    NK 9/9: (16384, 26240)
      → 算法数: 60, 有效: 200

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_10.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP4
============================================================
[W128 07:48:15.488957093 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 07:48:16.424750629 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square [all] 高稀疏测试完成 (3901.6s)
[INFO] cuSPARSELt Square 高稀疏统计: 成功 1, 失败 0

----------------------------------------------------------------------
TASK 4: cuSPARSELt Square 高稀疏 (2_4~2_10) - SUCCESS
Duration: 3901.6 seconds (65.0 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf)
Started: 2026-01-28 07:48:16
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 108, 有效: 421
    NK 2/4: (2048, 3424)
      → 算法数: 108, 有效: 415
    NK 3/4: (16384, 3424)
      → 算法数: 108, 有效: 438
    NK 4/4: (2048, 13664)
      → 算法数: 108, 有效: 420

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:50:42.410420548 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 108, 有效: 403
    NK 2/4: (2048, 3520)
      → 算法数: 108, 有效: 401
    NK 3/4: (16384, 3520)
      → 算法数: 108, 有效: 453
    NK 4/4: (2048, 14048)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:52:55.435739127 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 108, 有效: 408
    NK 2/4: (2048, 3584)
      → 算法数: 108, 有效: 428
    NK 3/4: (16384, 3584)
      → 算法数: 108, 有效: 428
    NK 4/4: (2048, 14336)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:55:00.783021797 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 108, 有效: 407
    NK 2/4: (2048, 4096)
      → 算法数: 108, 有效: 411
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 450
    NK 4/4: (2048, 16384)
      → 算法数: 108, 有效: 423

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 07:57:14.307152618 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 07:57:15.237797087 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [fp8e4m3] 低稀疏完成 (538.8s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 108, 有效: 426
    NK 2/4: (2048, 3424)
      → 算法数: 108, 有效: 401
    NK 3/4: (16384, 3424)
      → 算法数: 108, 有效: 452
    NK 4/4: (2048, 13664)
      → 算法数: 108, 有效: 437

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 07:59:36.469719287 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 108, 有效: 415
    NK 2/4: (2048, 3520)
      → 算法数: 108, 有效: 402
    NK 3/4: (16384, 3520)
      → 算法数: 108, 有效: 441
    NK 4/4: (2048, 14048)
      → 算法数: 108, 有效: 407

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:01:45.042731493 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 108, 有效: 405
    NK 2/4: (2048, 3584)
      → 算法数: 108, 有效: 399
    NK 3/4: (16384, 3584)
      → 算法数: 108, 有效: 420
    NK 4/4: (2048, 14336)
      → 算法数: 108, 有效: 436

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:03:45.089695358 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 108, 有效: 392
    NK 2/4: (2048, 4096)
      → 算法数: 108, 有效: 397
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 460
    NK 4/4: (2048, 16384)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:05:55.391478668 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 08:05:55.198401777 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [int8] 低稀疏完成 (520.9s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 108, 有效: 408
    NK 2/4: (2048, 3424)
      → 算法数: 108, 有效: 416
    NK 3/4: (16384, 3424)
      → 算法数: 108, 有效: 429
    NK 4/4: (2048, 13664)
      → 算法数: 108, 有效: 433

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 08:08:21.498563118 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 108, 有效: 415
    NK 2/4: (2048, 3520)
      → 算法数: 108, 有效: 401
    NK 3/4: (16384, 3520)
      → 算法数: 108, 有效: 434
    NK 4/4: (2048, 14048)
      → 算法数: 108, 有效: 425

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 08:10:36.311411622 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 108, 有效: 394
    NK 2/4: (2048, 3584)
      → 算法数: 108, 有效: 411
    NK 3/4: (16384, 3584)
      → 算法数: 108, 有效: 420
    NK 4/4: (2048, 14336)
      → 算法数: 108, 有效: 413

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 08:12:39.601037837 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 108, 有效: 406
    NK 2/4: (2048, 4096)
      → 算法数: 108, 有效: 424
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 455
    NK 4/4: (2048, 16384)
      → 算法数: 108, 有效: 432

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 08:14:54.034619831 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 08:14:55.839956802 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [fp8e4m3] 低稀疏完成 (539.6s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 108, 有效: 415
    NK 2/4: (2048, 3424)
      → 算法数: 108, 有效: 420
    NK 3/4: (16384, 3424)
      → 算法数: 108, 有效: 416
    NK 4/4: (2048, 13664)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:17:15.289012099 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 108, 有效: 389
    NK 2/4: (2048, 3520)
      → 算法数: 108, 有效: 400
    NK 3/4: (16384, 3520)
      → 算法数: 108, 有效: 435
    NK 4/4: (2048, 14048)
      → 算法数: 108, 有效: 415

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:19:23.744459562 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 108, 有效: 409
    NK 2/4: (2048, 3584)
      → 算法数: 108, 有效: 421
    NK 3/4: (16384, 3584)
      → 算法数: 108, 有效: 422
    NK 4/4: (2048, 14336)
      → 算法数: 108, 有效: 411

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:21:22.133817644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 108, 有效: 408
    NK 2/4: (2048, 4096)
      → 算法数: 108, 有效: 402
    NK 3/4: (16384, 4096)
      → 算法数: 108, 有效: 449
    NK 4/4: (2048, 16384)
      → 算法数: 108, 有效: 427

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/INT8
============================================================
[W128 08:23:32.127545393 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 08:23:33.943986350 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [int8] 低稀疏完成 (518.1s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 108, 有效: 438
    NK 2/4: (3072, 5120)
      → 算法数: 108, 有效: 423
    NK 3/4: (16384, 5120)
      → 算法数: 108, 有效: 434
    NK 4/4: (3072, 13664)
      → 算法数: 108, 有效: 431

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/B200_cc100_py312_cu129_x86_64/FP8
============================================================
[W128 08:26:28.037697818 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA B200 (cc100)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 108, 有效: 429
    NK 2/4: (3072, 5280)
      → 算法数: 108, 有效: 407
    NK 3/4: (16384, 5280)

======================================================================
收到中断信号 (signal 2)
======================================================================
[INFO] 状态已保存: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_030832_status.json
