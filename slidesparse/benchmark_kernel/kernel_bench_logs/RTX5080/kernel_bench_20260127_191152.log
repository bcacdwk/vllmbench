======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 19:11:52
======================================================================

Hardware:
  GPU: NVIDIA GeForce RTX 5080 (cc120)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_191152.log
[INFO] 跳过 Task 1: cuBLASLt Model 测试
[INFO] 跳过 Task 2: cuBLASLt Square 测试
[INFO] 跳过 Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10)
[INFO] 跳过 Task 4: cuSPARSELt Square 高稀疏 (2_4~2_10)

======================================================================
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf)
Started: 2026-01-27 19:11:52
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:12:07.767269512 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:12:21.036465289 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:12:34.703011284 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:12:50.148213343 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:13:03.069872145 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:13:16.625744354 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:13:30.193512890 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:13:45.776750901 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:13:53.368976807 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:14:00.708932914 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:14:08.977349174 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:14:15.622295051 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 4, 有效: 13
    NK 2/4: (2048, 3424)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 3424)
      → 算法数: 4, 有效: 16
    NK 4/4: (2048, 13664)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:14:39.760234636 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 4, 有效: 15
    NK 2/4: (2048, 3520)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 3520)
      → 算法数: 4, 有效: 13
    NK 4/4: (2048, 14048)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:15:04.611421158 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 4, 有效: 15
    NK 2/4: (2048, 3584)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 3584)
      → 算法数: 4, 有效: 18
    NK 4/4: (2048, 14336)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:15:29.192433635 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 4, 有效: 19
    NK 2/4: (2048, 4096)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 4096)
      → 算法数: 4, 有效: 15
    NK 4/4: (2048, 16384)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:15:55.607819512 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3456), (2048, 3456), (16384, 3456), (2048, 13696)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3456)
      → 算法数: 2, 有效: 7
    NK 2/4: (2048, 3456)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 3456)
      → 算法数: 2, 有效: 7
    NK 4/4: (2048, 13696)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:16:03.669904012 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14080)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 6
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 10
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 6
    NK 4/4: (2048, 14080)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:16:12.160415835 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 7
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 7
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 8
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:16:20.108987756 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 8
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 6
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 9
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:16:28.451092543 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:16:29.976480513 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 低稀疏完成 (276.8s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:16:44.772324348 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:16:58.095280229 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:17:11.509736568 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:17:26.762021998 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:17:40.911017540 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:17:53.278858532 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:18:06.738395717 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 3
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:18:22.209848067 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3424)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:18:30.882426533 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:18:37.433975478 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:18:45.847529928 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 2
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 2
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:18:52.443093282 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 4, 有效: 15
    NK 2/4: (2048, 3424)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 3424)
      → 算法数: 4, 有效: 14
    NK 4/4: (2048, 13664)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:19:16.549169424 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 4, 有效: 13
    NK 2/4: (2048, 3520)
      → 算法数: 4, 有效: 14
    NK 3/4: (16384, 3520)
      → 算法数: 4, 有效: 18
    NK 4/4: (2048, 14048)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:19:40.436488966 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 4, 有效: 19
    NK 2/4: (2048, 3584)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 3584)
      → 算法数: 4, 有效: 15
    NK 4/4: (2048, 14336)
      → 算法数: 4, 有效: 21

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:20:05.021267709 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 4, 有效: 18
    NK 2/4: (2048, 4096)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 4096)
      → 算法数: 4, 有效: 16
    NK 4/4: (2048, 16384)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:20:32.431195624 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3456), (2048, 3456), (16384, 3456), (2048, 13696)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3456)
      → 算法数: 2, 有效: 7
    NK 2/4: (2048, 3456)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 3456)
      → 算法数: 2, 有效: 7
    NK 4/4: (2048, 13696)
      → 算法数: 2, 有效: 12

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:20:40.640890574 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14080)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 2, 有效: 10
    NK 2/4: (2048, 3520)
      → 算法数: 2, 有效: 9
    NK 3/4: (16384, 3520)
      → 算法数: 2, 有效: 9
    NK 4/4: (2048, 14080)
      → 算法数: 2, 有效: 8

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:20:49.603466087 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 2, 有效: 7
    NK 2/4: (2048, 3584)
      → 算法数: 2, 有效: 6
    NK 3/4: (16384, 3584)
      → 算法数: 2, 有效: 7
    NK 4/4: (2048, 14336)
      → 算法数: 2, 有效: 10

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:20:57.525220353 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 2, 有效: 8
    NK 2/4: (2048, 4096)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 4096)
      → 算法数: 2, 有效: 8
    NK 4/4: (2048, 16384)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:21:05.662222638 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:21:06.181979383 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 低稀疏完成 (277.2s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:21:27.536857356 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:21:46.734047698 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:22:06.537026783 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:22:29.111920516 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:22:47.789333595 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:23:07.177108859 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:23:26.795653123 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:23:49.450202913 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:23:58.208498664 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:24:07.725766602 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:24:16.652904039 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:24:26.040156924 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 4, 有效: 19
    NK 2/4: (3072, 5120)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 5120)
      → 算法数: 4, 有效: 16
    NK 4/4: (3072, 13664)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:25:01.297777312 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 4, 有效: 20
    NK 2/4: (3072, 5280)
      → 算法数: 4, 有效: 18
    NK 3/4: (16384, 5280)
      → 算法数: 4, 有效: 19
    NK 4/4: (3072, 14048)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:25:39.656976832 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 4, 有效: 14
    NK 2/4: (3072, 5376)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 5376)
      → 算法数: 4, 有效: 16
    NK 4/4: (3072, 14336)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:26:16.985973264 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 4, 有效: 16
    NK 2/4: (3072, 6144)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 6144)
      → 算法数: 4, 有效: 15
    NK 4/4: (3072, 16384)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:26:58.692562790 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13696)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 9
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 7
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 7
    NK 4/4: (3072, 13696)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:27:08.355237723 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5312), (3072, 5312), (16384, 5312), (3072, 14080)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5312)
      → 算法数: 2, 有效: 7
    NK 2/4: (3072, 5312)
      → 算法数: 2, 有效: 7
    NK 3/4: (16384, 5312)
      → 算法数: 2, 有效: 7
    NK 4/4: (3072, 14080)
      → 算法数: 2, 有效: 11

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:27:20.430259838 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 7
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 6
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:27:30.689048016 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 6
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 6
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 11
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:27:42.011137671 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:27:42.561227588 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 低稀疏完成 (396.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:28:04.050157138 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:28:23.276554184 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:28:43.943232741 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:29:05.412016850 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:29:24.389857684 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:29:44.300512508 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:30:04.934322232 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 3
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:30:26.419558157 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 13664)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:30:35.009476401 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5280)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5280)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14048)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:30:44.306811260 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:30:53.952434915 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:31:02.198495644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 4, 有效: 16
    NK 2/4: (3072, 5120)
      → 算法数: 4, 有效: 16
    NK 3/4: (16384, 5120)
      → 算法数: 4, 有效: 14
    NK 4/4: (3072, 13664)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:31:37.073163512 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 4, 有效: 19
    NK 2/4: (3072, 5280)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 5280)
      → 算法数: 4, 有效: 13
    NK 4/4: (3072, 14048)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:32:17.725683747 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 4, 有效: 17
    NK 2/4: (3072, 5376)
      → 算法数: 4, 有效: 15
    NK 3/4: (16384, 5376)
      → 算法数: 4, 有效: 20
    NK 4/4: (3072, 14336)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:32:53.525495372 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 4, 有效: 17
    NK 2/4: (3072, 6144)
      → 算法数: 4, 有效: 17
    NK 3/4: (16384, 6144)
      → 算法数: 4, 有效: 15
    NK 4/4: (3072, 16384)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:33:35.625511455 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13696)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 2, 有效: 8
    NK 2/4: (3072, 5120)
      → 算法数: 2, 有效: 7
    NK 3/4: (16384, 5120)
      → 算法数: 2, 有效: 9
    NK 4/4: (3072, 13696)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:33:45.587320569 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5312), (3072, 5312), (16384, 5312), (3072, 14080)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5312)
      → 算法数: 2, 有效: 7
    NK 2/4: (3072, 5312)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 5312)
      → 算法数: 2, 有效: 7
    NK 4/4: (3072, 14080)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:33:57.167196509 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 2, 有效: 7
    NK 2/4: (3072, 5376)
      → 算法数: 2, 有效: 8
    NK 3/4: (16384, 5376)
      → 算法数: 2, 有效: 9
    NK 4/4: (3072, 14336)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:34:07.399711899 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 2, 有效: 6
    NK 2/4: (3072, 6144)
      → 算法数: 2, 有效: 9
    NK 3/4: (16384, 6144)
      → 算法数: 2, 有效: 9
    NK 4/4: (3072, 16384)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:34:18.526659830 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:34:19.057315996 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 低稀疏完成 (396.5s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:35:01.848202152 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:35:41.353606669 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:36:23.239895880 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:37:11.885971678 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:37:50.326158807 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:38:30.775029636 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:39:12.728013289 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:40:00.583873413 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:40:15.620461473 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:40:29.593153277 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:40:43.262294856 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:40:58.103431746 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 4, 有效: 15
    NK 2/4: (3584, 5984)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 5984)
      → 算法数: 4, 有效: 16
    NK 4/4: (3584, 31584)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:42:24.376066731 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 4, 有效: 18
    NK 2/4: (3584, 6144)
      → 算法数: 4, 有效: 16
    NK 3/4: (37888, 6144)
      → 算法数: 4, 有效: 16
    NK 4/4: (3584, 32480)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:43:53.431363313 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 4, 有效: 18
    NK 2/4: (3584, 6272)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 6272)
      → 算法数: 4, 有效: 16
    NK 4/4: (3584, 33152)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:45:16.439298560 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 4, 有效: 18
    NK 2/4: (3584, 7168)
      → 算法数: 4, 有效: 15
    NK 3/4: (37888, 7168)
      → 算法数: 4, 有效: 16
    NK 4/4: (3584, 37888)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:46:50.295733840 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 6016), (3584, 6016), (37888, 6016), (3584, 31616)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6016)
      → 算法数: 2, 有效: 8
    NK 2/4: (3584, 6016)
      → 算法数: 2, 有效: 7
    NK 3/4: (37888, 6016)
      → 算法数: 2, 有效: 8
    NK 4/4: (3584, 31616)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:47:09.744624462 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32512)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 8
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 7
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 7
    NK 4/4: (3584, 32512)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:47:22.615978127 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 7
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 6
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 8
    NK 4/4: (3584, 33152)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:47:38.337241647 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 7
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 9
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 11
    NK 4/4: (3584, 37888)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 19:47:57.197312309 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:47:57.730710829 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 低稀疏完成 (818.7s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:48:39.706411862 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:49:20.126860446 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:50:01.762032871 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 19:50:49.295942016 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:51:29.819795352 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:52:09.519255239 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:52:51.336425363 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 3
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 3
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 19:53:39.149389573 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 5984)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 5984)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 31584)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:53:54.529829550 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 32480)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:54:08.524583258 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 33152)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:54:22.163384705 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 2
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 2
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 2
    NK 4/4: (3584, 37888)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 19:54:37.108288466 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 4, 有效: 16
    NK 2/4: (3584, 5984)
      → 算法数: 4, 有效: 17
    NK 3/4: (37888, 5984)
      → 算法数: 4, 有效: 17
    NK 4/4: (3584, 31584)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:56:07.991322522 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 4, 有效: 19
    NK 2/4: (3584, 6144)
      → 算法数: 4, 有效: 14
    NK 3/4: (37888, 6144)
      → 算法数: 4, 有效: 17
    NK 4/4: (3584, 32480)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:57:30.542050303 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 4, 有效: 16
    NK 2/4: (3584, 6272)
      → 算法数: 4, 有效: 20
    NK 3/4: (37888, 6272)
      → 算法数: 4, 有效: 16
    NK 4/4: (3584, 33152)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 19:58:54.681901292 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 4, 有效: 18
    NK 2/4: (3584, 7168)
      → 算法数: 4, 有效: 18
    NK 3/4: (37888, 7168)
      → 算法数: 4, 有效: 18
    NK 4/4: (3584, 37888)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:00:35.057507464 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 6016), (3584, 6016), (37888, 6016), (3584, 31616)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6016)
      → 算法数: 2, 有效: 6
    NK 2/4: (3584, 6016)
      → 算法数: 2, 有效: 7
    NK 3/4: (37888, 6016)
      → 算法数: 2, 有效: 7
    NK 4/4: (3584, 31616)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:00:54.197450476 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32512)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 2, 有效: 7
    NK 2/4: (3584, 6144)
      → 算法数: 2, 有效: 6
    NK 3/4: (37888, 6144)
      → 算法数: 2, 有效: 10
    NK 4/4: (3584, 32512)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:01:07.295960537 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 2, 有效: 7
    NK 2/4: (3584, 6272)
      → 算法数: 2, 有效: 7
    NK 3/4: (37888, 6272)
      → 算法数: 2, 有效: 6
    NK 4/4: (3584, 33152)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:01:20.688810897 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 2, 有效: 7
    NK 2/4: (3584, 7168)
      → 算法数: 2, 有效: 11
    NK 3/4: (37888, 7168)
      → 算法数: 2, 有效: 7
    NK 4/4: (3584, 37888)
      → 算法数: 0, 有效: 0

    搜索统计: 总计=36, 成功=27, 失败=0, 错误=9
    成功率: 75.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:01:38.528250318 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:01:39.095111029 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 低稀疏完成 (821.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:02:27.573138944 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:03:16.870827202 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:04:04.038967868 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:04:58.588010912 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:05:44.300625005 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:06:32.629740445 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:07:20.560343528 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:08:15.124669519 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:08:31.372045669 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:08:48.134406635 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:09:03.663199187 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:09:20.143953192 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 4, 有效: 16
    NK 2/4: (5120, 8544)
      → 算法数: 4, 有效: 19
    NK 3/4: (27648, 8544)
      → 算法数: 4, 有效: 17
    NK 4/4: (5120, 23040)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:11:01.381714152 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 4, 有效: 14
    NK 2/4: (5120, 8800)
      → 算法数: 4, 有效: 16
    NK 3/4: (27648, 8800)
      → 算法数: 4, 有效: 21
    NK 4/4: (5120, 23712)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:12:44.208938697 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 4, 有效: 18
    NK 2/4: (5120, 8960)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 8960)
      → 算法数: 4, 有效: 15
    NK 4/4: (5120, 24192)
      → 算法数: 4, 有效: 20

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:14:23.116134507 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 4, 有效: 15
    NK 2/4: (5120, 10240)
      → 算法数: 4, 有效: 15
    NK 3/4: (27648, 10240)
      → 算法数: 4, 有效: 19
    NK 4/4: (5120, 27648)
      → 算法数: 4, 有效: 16

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:16:16.546859983 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8576), (5120, 8576), (27648, 8576), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8576)
      → 算法数: 2, 有效: 6
    NK 2/4: (5120, 8576)
      → 算法数: 2, 有效: 8
    NK 3/4: (27648, 8576)
      → 算法数: 2, 有效: 7
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:16:39.559007326 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8832), (5120, 8832), (27648, 8832), (5120, 23744)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8832)
      → 算法数: 2, 有效: 8
    NK 2/4: (5120, 8832)
      → 算法数: 2, 有效: 7
    NK 3/4: (27648, 8832)
      → 算法数: 2, 有效: 8
    NK 4/4: (5120, 23744)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:17:07.542503796 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 8
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 8
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 8
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:17:29.724092233 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 6
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 9
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 7
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:17:56.103435400 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:17:56.634993161 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 低稀疏完成 (977.5s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:18:44.642974866 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:19:33.803829062 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:20:21.067584043 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:21:16.855992555 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:22:01.543661439 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:22:50.823278437 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:23:38.191293757 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 3
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 3
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 3

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:24:32.712139525 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8544)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8544)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:24:48.668627147 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8800)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8800)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 23712)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:25:05.210128336 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:25:20.429281583 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 2
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 2
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 2
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:25:37.865497425 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 4, 有效: 15
    NK 2/4: (5120, 8544)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 8544)
      → 算法数: 4, 有效: 14
    NK 4/4: (5120, 23040)
      → 算法数: 4, 有效: 18

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:27:23.259647087 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 4, 有效: 13
    NK 2/4: (5120, 8800)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 8800)
      → 算法数: 4, 有效: 17
    NK 4/4: (5120, 23712)
      → 算法数: 4, 有效: 14

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:29:05.387965938 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 4, 有效: 15
    NK 2/4: (5120, 8960)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 8960)
      → 算法数: 4, 有效: 21
    NK 4/4: (5120, 24192)
      → 算法数: 4, 有效: 17

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:30:44.470508886 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 4, 有效: 14
    NK 2/4: (5120, 10240)
      → 算法数: 4, 有效: 17
    NK 3/4: (27648, 10240)
      → 算法数: 4, 有效: 16
    NK 4/4: (5120, 27648)
      → 算法数: 4, 有效: 15

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:32:46.917593136 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8576), (5120, 8576), (27648, 8576), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8576)
      → 算法数: 2, 有效: 6
    NK 2/4: (5120, 8576)
      → 算法数: 2, 有效: 10
    NK 3/4: (27648, 8576)
      → 算法数: 2, 有效: 7
    NK 4/4: (5120, 23040)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:33:10.533805191 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8832), (5120, 8832), (27648, 8832), (5120, 23744)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8832)
      → 算法数: 2, 有效: 7
    NK 2/4: (5120, 8832)
      → 算法数: 2, 有效: 10
    NK 3/4: (27648, 8832)
      → 算法数: 2, 有效: 7
    NK 4/4: (5120, 23744)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:33:37.806729718 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 2, 有效: 7
    NK 2/4: (5120, 8960)
      → 算法数: 2, 有效: 7
    NK 3/4: (27648, 8960)
      → 算法数: 2, 有效: 8
    NK 4/4: (5120, 24192)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:34:02.208239076 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 2, 有效: 10
    NK 2/4: (5120, 10240)
      → 算法数: 2, 有效: 7
    NK 3/4: (27648, 10240)
      → 算法数: 2, 有效: 6
    NK 4/4: (5120, 27648)
      → 算法数: 2, 有效: 10

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:34:29.469319901 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:34:30.996965131 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 低稀疏完成 (993.4s)

[INFO] cuSPARSELt Model 低稀疏统计: 成功 8, 失败 0

----------------------------------------------------------------------
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 4957.8 seconds (82.6 minutes)
----------------------------------------------------------------------


======================================================================
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf)
Started: 2026-01-27 20:34:30
======================================================================


------------------------------------------------------------
  cuSPARSELt Square 低稀疏测试
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:34:59.229574334 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:35:26.412505825 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:35:55.801465467 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP16
============================================================
[W127 20:36:27.841298833 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:36:53.624905199 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:37:21.915617303 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:37:49.283238398 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/BF16
============================================================
[W127 20:38:21.138506371 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 864)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3424)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 13664)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:38:32.645891143 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1760)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14048)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:38:44.892211737 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 224)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:38:55.004103320 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 2
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 2
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 2
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 2
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 2
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 2
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 2
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 2
    NK 9/9: (16384, 32768)
      → 算法数: 2, 有效: 2

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/INT8
============================================================
[W127 20:39:07.865236868 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 15
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 14
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 13
    NK 4/9: (512, 864)
      → 算法数: 4, 有效: 17
    NK 5/9: (1024, 1728)
      → 算法数: 4, 有效: 15
    NK 6/9: (2048, 3424)
      → 算法数: 4, 有效: 14
    NK 7/9: (4096, 6848)
      → 算法数: 4, 有效: 15
    NK 8/9: (8192, 13664)
      → 算法数: 4, 有效: 13
    NK 9/9: (16384, 27328)
      → 算法数: 4, 有效: 13

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:40:13.916534703 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 14
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 9
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 11
    NK 4/9: (512, 896)
      → 算法数: 4, 有效: 14
    NK 5/9: (1024, 1760)
      → 算法数: 4, 有效: 16
    NK 6/9: (2048, 3520)
      → 算法数: 4, 有效: 13
    NK 7/9: (4096, 7040)
      → 算法数: 4, 有效: 14
    NK 8/9: (8192, 14048)
      → 算法数: 4, 有效: 12
    NK 9/9: (16384, 28096)
      → 算法数: 4, 有效: 12

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:41:16.822053811 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 17
    NK 2/9: (128, 224)
      → 算法数: 4, 有效: 11
    NK 3/9: (256, 448)
      → 算法数: 4, 有效: 12
    NK 4/9: (512, 896)
      → 算法数: 4, 有效: 15
    NK 5/9: (1024, 1792)
      → 算法数: 4, 有效: 17
    NK 6/9: (2048, 3584)
      → 算法数: 4, 有效: 15
    NK 7/9: (4096, 7168)
      → 算法数: 4, 有效: 14
    NK 8/9: (8192, 14336)
      → 算法数: 4, 有效: 15
    NK 9/9: (16384, 28672)
      → 算法数: 4, 有效: 12

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:42:21.037771290 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 4, 有效: 12
    NK 2/9: (128, 256)
      → 算法数: 4, 有效: 11
    NK 3/9: (256, 512)
      → 算法数: 4, 有效: 10
    NK 4/9: (512, 1024)
      → 算法数: 4, 有效: 15
    NK 5/9: (1024, 2048)
      → 算法数: 4, 有效: 15
    NK 6/9: (2048, 4096)
      → 算法数: 4, 有效: 16
    NK 7/9: (4096, 8192)
      → 算法数: 4, 有效: 14
    NK 8/9: (8192, 16384)
      → 算法数: 4, 有效: 12
    NK 9/9: (16384, 32768)
      → 算法数: 4, 有效: 12

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP8
============================================================
[W127 20:43:33.573993106 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 8
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 6
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 5
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 1728)
      → 算法数: 2, 有效: 9
    NK 6/9: (2048, 3456)
      → 算法数: 2, 有效: 9
    NK 7/9: (4096, 6848)
      → 算法数: 2, 有效: 8
    NK 8/9: (8192, 13696)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 27328)
      → 算法数: 2, 有效: 6

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:43:50.163973725 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3', 'fp4e2m1']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP4E2M1
============================================================

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 7
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 6
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 7
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 6
    NK 6/9: (2048, 3520)
      → 算法数: 2, 有效: 12
    NK 7/9: (4096, 7040)
      → 算法数: 2, 有效: 7
    NK 8/9: (8192, 14080)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 28096)
      → 算法数: 2, 有效: 7

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:44:10.886403860 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 5
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 6
    NK 3/9: (256, 448)
      → 算法数: 2, 有效: 5
    NK 4/9: (512, 896)
      → 算法数: 2, 有效: 7
    NK 5/9: (1024, 1792)
      → 算法数: 2, 有效: 8
    NK 6/9: (2048, 3584)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 7168)
      → 算法数: 2, 有效: 6
    NK 8/9: (8192, 14336)
      → 算法数: 2, 有效: 6
    NK 9/9: (16384, 28672)
      → 算法数: 2, 有效: 9

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:44:34.581899971 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA GeForce RTX 5080 (cc120)
Mode: SQUARE
Model: SQUARE
dtype: fp4e2m1 -> fp4e2m1 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 2, 有效: 6
    NK 2/9: (128, 256)
      → 算法数: 2, 有效: 7
    NK 3/9: (256, 512)
      → 算法数: 2, 有效: 7
    NK 4/9: (512, 1024)
      → 算法数: 2, 有效: 8
    NK 5/9: (1024, 2048)
      → 算法数: 2, 有效: 7
    NK 6/9: (2048, 4096)
      → 算法数: 2, 有效: 7
    NK 7/9: (4096, 8192)
      → 算法数: 2, 有效: 8
    NK 8/9: (8192, 16384)
      → 算法数: 2, 有效: 8
    NK 9/9: (16384, 32768)
[cuSPARSELt WARN] Failed to allocate scale_B for FP4
      → 算法数: 0, 有效: 0

    搜索统计: 总计=9, 成功=8, 失败=0, 错误=1
    成功率: 88.9%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/RTX5080_cc120_py312_cu129_x86_64/FP4
============================================================
[W127 20:44:40.291312733 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())


[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp4e2m1] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp4e2m1 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:44:41.878819018 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square 低稀疏测试完成 (610.9s)

----------------------------------------------------------------------
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 610.9 seconds (10.2 minutes)
----------------------------------------------------------------------



============================================================
  最终总结
============================================================


  Task 1: cuBLASLt Model 测试 - SKIPPED
  Task 2: cuBLASLt Square 测试 - SKIPPED
  Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10) - SKIPPED
  Task 4: cuSPARSELt Square 高稀疏 (2_4~2_10) - SKIPPED
  Task 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS (4957.8s)
  Task 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS (610.9s)

  总计: 2 成功, 0 失败, 4 跳过
  总耗时: 5568.7 秒 (1.55 小时)

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_191152.log
[INFO] 状态文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_191152_status.json

[INFO] 结果保存位置:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
