======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-28 03:28:38
======================================================================

Hardware:
  GPU: NVIDIA H100 PCIe (cc90)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_032838.log
[INFO] 跳过 Task 1: cuBLASLt Model 测试
[INFO] 跳过 Task 2: cuBLASLt Square 测试
[INFO] 跳过 Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10)
[INFO] 跳过 Task 4: cuSPARSELt Square 高稀疏 (2_4~2_10)

======================================================================
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf)
Started: 2026-01-28 03:28:38
======================================================================


------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3424)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3424)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 13664)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:29:49.368465789 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3520)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3520)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 14048)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:30:54.359528967 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3584)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3584)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 14336)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:31:56.085768825 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 4096)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 4096)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 16384)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:33:05.492851993 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:33:06.470499226 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [fp8e4m3] 低稀疏完成 (268.1s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3424)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3424)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 13664)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:34:08.114449661 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3520)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3520)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 14048)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:35:02.898387758 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3584)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3584)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 14336)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:35:55.760441487 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 4096)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 4096)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 16384)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:36:53.830578615 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:36:54.768144195 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 [int8] 低稀疏完成 (228.3s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3424)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3424)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 13664)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:38:09.371382397 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3520)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3520)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 14048)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:39:15.343224824 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 3584)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 3584)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 14336)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:40:18.930268433 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 30, 有效: 60
    NK 2/4: (2048, 4096)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 4096)
      → 算法数: 30, 有效: 60
    NK 4/4: (2048, 16384)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:41:29.287532193 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:41:30.258421243 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [fp8e4m3] 低稀疏完成 (275.4s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3424)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3424)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 13664)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:42:32.928811534 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3520)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3520)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 14048)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:43:28.080635197 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 3584)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 3584)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 14336)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:44:20.689593786 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      → 算法数: 25, 有效: 50
    NK 2/4: (2048, 4096)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 4096)
      → 算法数: 25, 有效: 50
    NK 4/4: (2048, 16384)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:45:18.745070190 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:45:19.687720258 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 [int8] 低稀疏完成 (229.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5120)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5120)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 13664)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:46:56.947910117 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5280)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5280)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 14048)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:48:42.604623105 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5376)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5376)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 14336)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:50:18.288136889 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 6144)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 6144)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 16384)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:52:05.476889129 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:52:06.412977727 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [fp8e4m3] 低稀疏完成 (406.7s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5120)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5120)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 13664)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:53:28.517038402 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5280)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5280)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 14048)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:54:57.246639754 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5376)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5376)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 14336)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:56:15.749321270 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 6144)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 6144)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 16384)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:57:43.776184365 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 03:57:44.786520231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 [int8] 低稀疏完成 (338.4s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5120)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5120)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 13664)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 03:59:23.423093837 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5280)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5280)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 14048)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:01:09.020204025 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 5376)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 5376)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 14336)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:02:44.420216610 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 30, 有效: 60
    NK 2/4: (3072, 6144)
      → 算法数: 30, 有效: 60
    NK 3/4: (16384, 6144)
      → 算法数: 30, 有效: 60
    NK 4/4: (3072, 16384)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:04:31.004593604 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:04:31.956782196 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [fp8e4m3] 低稀疏完成 (407.2s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5120)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5120)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 13664)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:05:54.654101758 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5280)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5280)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 14048)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:07:23.144909437 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 5376)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 5376)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 14336)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:08:41.292242675 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      → 算法数: 25, 有效: 50
    NK 2/4: (3072, 6144)
      → 算法数: 25, 有效: 50
    NK 3/4: (16384, 6144)
      → 算法数: 25, 有效: 50
    NK 4/4: (3072, 16384)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:10:08.726372650 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:10:09.670304772 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 [int8] 低稀疏完成 (337.7s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 5984)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 5984)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 31584)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:14:03.643816471 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 6144)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 6144)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 32480)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:17:35.702116667 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 6272)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 6272)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 33152)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:21:04.314783167 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 7168)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 7168)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 37888)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:24:59.584337608 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:25:00.613542535 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [fp8e4m3] 低稀疏完成 (890.9s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 5984)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 5984)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 31584)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:28:13.219650267 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 6144)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 6144)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 32480)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:31:06.188481903 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 6272)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 6272)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 33152)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:33:57.650409065 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 7168)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 7168)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 37888)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:37:10.918773706 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:37:11.863361160 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 [int8] 低稀疏完成 (731.3s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 5984)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 5984)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 31584)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:41:05.067323217 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 6144)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 6144)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 32480)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:44:36.443776724 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 6272)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 6272)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 33152)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:48:04.220414234 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 30, 有效: 60
    NK 2/4: (3584, 7168)
      → 算法数: 30, 有效: 60
    NK 3/4: (37888, 7168)
      → 算法数: 30, 有效: 60
    NK 4/4: (3584, 37888)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 04:51:58.624736927 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 04:51:59.548539023 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [fp8e4m3] 低稀疏完成 (887.7s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 5984)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 5984)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 31584)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:55:13.886817407 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 6144)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 6144)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 32480)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 04:58:08.307374931 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 6272)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 6272)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 33152)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:00:59.450225435 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      → 算法数: 25, 有效: 50
    NK 2/4: (3584, 7168)
      → 算法数: 25, 有效: 50
    NK 3/4: (37888, 7168)
      → 算法数: 25, 有效: 50
    NK 4/4: (3584, 37888)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:04:12.706356394 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:04:13.713118379 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 [int8] 低稀疏完成 (734.1s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8544)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8544)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 23040)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:08:30.293314077 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8800)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8800)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 23712)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:13:01.171060855 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8960)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8960)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 24192)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:17:00.442228502 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 10240)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 10240)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 27648)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:21:33.256533409 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:21:34.213631420 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [fp8e4m3] 低稀疏完成 (1040.5s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8544)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8544)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 23040)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:25:07.301896786 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8800)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8800)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 23712)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:28:51.036402682 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8960)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8960)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 24192)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:32:07.585543746 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 10240)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 10240)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 27648)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:35:50.242355660 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:35:51.181928483 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 [int8] 低稀疏完成 (857.0s)

------------------------------------------------------------
  cuSPARSELt Model 低稀疏: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype fp8e4m3 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8544)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8544)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 23040)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:40:08.990256237 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8800)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8800)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 23712)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:44:39.410656026 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 8960)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 8960)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 24192)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:48:38.130111025 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 30, 有效: 60
    NK 2/4: (5120, 10240)
      → 算法数: 30, 有效: 60
    NK 3/4: (27648, 10240)
      → 算法数: 30, 有效: 60
    NK 4/4: (5120, 27648)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 05:53:11.020964525 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 05:53:12.030239119 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [fp8e4m3] 低稀疏完成 (1040.9s)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype int8 --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(7168, 8544), (5120, 8544), (27648, 8544), (5120, 23040)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8544)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8544)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8544)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 23040)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 05:56:44.884775405 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(7168, 8800), (5120, 8800), (27648, 8800), (5120, 23712)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8800)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8800)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8800)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 23712)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:00:28.656032714 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(7168, 8960), (5120, 8960), (27648, 8960), (5120, 24192)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8960)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 8960)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 8960)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 24192)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:03:43.837197623 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(7168, 10240), (5120, 10240), (27648, 10240), (5120, 27648)]
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      NK 组合: 4 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 10240)
      → 算法数: 25, 有效: 50
    NK 2/4: (5120, 10240)
      → 算法数: 25, 有效: 50
    NK 3/4: (27648, 10240)
      → 算法数: 25, 有效: 50
    NK 4/4: (5120, 27648)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=36, 成功=36, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:07:27.399807850 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['int8']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:07:28.408439518 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 [int8] 低稀疏完成 (856.3s)

[INFO] cuSPARSELt Model 低稀疏统计: 成功 16, 失败 0

----------------------------------------------------------------------
TASK 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 9530.0 seconds (158.8 minutes)
----------------------------------------------------------------------


======================================================================
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf)
Started: 2026-01-28 06:07:28
======================================================================


------------------------------------------------------------
  cuSPARSELt Square 低稀疏测试
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 52, 有效: 38
    NK 2/9: (128, 224)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 448)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 864)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1728)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 3424)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 6848)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 13664)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 27328)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    搜索统计: 总计=9, 成功=1, 失败=0, 错误=8
    成功率: 11.1%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W128 06:07:53.157623909 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 52, 有效: 38
    NK 2/9: (128, 224)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 448)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 896)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1760)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 3520)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 7040)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 14048)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 28096)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    搜索统计: 总计=9, 成功=1, 失败=0, 错误=8
    成功率: 11.1%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W128 06:08:12.831407596 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 52, 有效: 38
    NK 2/9: (128, 224)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 448)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 896)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1792)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 3584)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 7168)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 14336)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 28672)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    搜索统计: 总计=9, 成功=1, 失败=0, 错误=8
    成功率: 11.1%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W128 06:08:32.487284795 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 52, 有效: 38
    NK 2/9: (128, 256)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 512)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 1024)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 2048)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 4096)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 8192)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 16384)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 32768)
      ⚠ 生成数据失败: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    搜索统计: 总计=9, 成功=1, 失败=0, 错误=8
    成功率: 11.1%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W128 06:08:52.785033757 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 21, 有效: 22
    NK 2/9: (128, 224)
      → 算法数: 21, 有效: 22
    NK 3/9: (256, 448)
      → 算法数: 21, 有效: 22
    NK 4/9: (512, 864)
      → 算法数: 21, 有效: 42
    NK 5/9: (1024, 1728)
      → 算法数: 21, 有效: 42
    NK 6/9: (2048, 3424)
      → 算法数: 21, 有效: 42
    NK 7/9: (4096, 6848)
      → 算法数: 21, 有效: 42
    NK 8/9: (8192, 13664)
      → 算法数: 21, 有效: 42
    NK 9/9: (16384, 27328)
      → 算法数: 21, 有效: 42

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 06:11:57.317680382 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 21, 有效: 22
    NK 2/9: (128, 224)
      → 算法数: 21, 有效: 22
    NK 3/9: (256, 448)
      → 算法数: 21, 有效: 22
    NK 4/9: (512, 896)
      → 算法数: 21, 有效: 42
    NK 5/9: (1024, 1760)
      → 算法数: 21, 有效: 42
    NK 6/9: (2048, 3520)
      → 算法数: 21, 有效: 42
    NK 7/9: (4096, 7040)
      → 算法数: 21, 有效: 42
    NK 8/9: (8192, 14048)
      → 算法数: 21, 有效: 42
    NK 9/9: (16384, 28096)
      → 算法数: 21, 有效: 42

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 06:15:08.301073782 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 21, 有效: 22
    NK 2/9: (128, 224)
      → 算法数: 21, 有效: 22
    NK 3/9: (256, 448)
      → 算法数: 21, 有效: 22
    NK 4/9: (512, 896)
      → 算法数: 21, 有效: 42
    NK 5/9: (1024, 1792)
      → 算法数: 21, 有效: 42
    NK 6/9: (2048, 3584)
      → 算法数: 21, 有效: 42
    NK 7/9: (4096, 7168)
      → 算法数: 21, 有效: 42
    NK 8/9: (8192, 14336)
      → 算法数: 21, 有效: 42
    NK 9/9: (16384, 28672)
      → 算法数: 21, 有效: 42

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 06:18:23.247637101 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 21, 有效: 22
    NK 2/9: (128, 256)
      → 算法数: 21, 有效: 22
    NK 3/9: (256, 512)
      → 算法数: 21, 有效: 22
    NK 4/9: (512, 1024)
      → 算法数: 21, 有效: 42
    NK 5/9: (1024, 2048)
      → 算法数: 21, 有效: 42
    NK 6/9: (2048, 4096)
      → 算法数: 21, 有效: 42
    NK 7/9: (4096, 8192)
      → 算法数: 21, 有效: 42
    NK 8/9: (8192, 16384)
      → 算法数: 21, 有效: 42
    NK 9/9: (16384, 32768)
      → 算法数: 21, 有效: 42

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 06:22:05.173510997 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 25, 有效: 26
    NK 2/9: (128, 224)
      → 算法数: 25, 有效: 26
    NK 3/9: (256, 448)
      → 算法数: 25, 有效: 26
    NK 4/9: (512, 864)
      → 算法数: 25, 有效: 50
    NK 5/9: (1024, 1728)
      → 算法数: 25, 有效: 50
    NK 6/9: (2048, 3424)
      → 算法数: 25, 有效: 50
    NK 7/9: (4096, 6848)
      → 算法数: 25, 有效: 50
    NK 8/9: (8192, 13664)
      → 算法数: 25, 有效: 50
    NK 9/9: (16384, 27328)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:24:01.565989659 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 25, 有效: 26
    NK 2/9: (128, 224)
      → 算法数: 25, 有效: 26
    NK 3/9: (256, 448)
      → 算法数: 25, 有效: 26
    NK 4/9: (512, 896)
      → 算法数: 25, 有效: 50
    NK 5/9: (1024, 1760)
      → 算法数: 25, 有效: 50
    NK 6/9: (2048, 3520)
      → 算法数: 25, 有效: 50
    NK 7/9: (4096, 7040)
      → 算法数: 25, 有效: 50
    NK 8/9: (8192, 14048)
      → 算法数: 25, 有效: 50
    NK 9/9: (16384, 28096)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:26:00.959239497 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 25, 有效: 26
    NK 2/9: (128, 224)
      → 算法数: 25, 有效: 26
    NK 3/9: (256, 448)
      → 算法数: 25, 有效: 26
    NK 4/9: (512, 896)
      → 算法数: 25, 有效: 50
    NK 5/9: (1024, 1792)
      → 算法数: 25, 有效: 50
    NK 6/9: (2048, 3584)
      → 算法数: 25, 有效: 50
    NK 7/9: (4096, 7168)
      → 算法数: 25, 有效: 50
    NK 8/9: (8192, 14336)
      → 算法数: 25, 有效: 50
    NK 9/9: (16384, 28672)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:27:56.974285802 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 25, 有效: 26
    NK 2/9: (128, 256)
      → 算法数: 25, 有效: 26
    NK 3/9: (256, 512)
      → 算法数: 25, 有效: 26
    NK 4/9: (512, 1024)
      → 算法数: 25, 有效: 50
    NK 5/9: (1024, 2048)
      → 算法数: 25, 有效: 50
    NK 6/9: (2048, 4096)
      → 算法数: 25, 有效: 50
    NK 7/9: (4096, 8192)
      → 算法数: 25, 有效: 50
    NK 8/9: (8192, 16384)
      → 算法数: 25, 有效: 50
    NK 9/9: (16384, 32768)
      → 算法数: 25, 有效: 50

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 06:30:08.007959322 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 864), (1024, 1728)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 30, 有效: 31
    NK 2/9: (128, 224)
      → 算法数: 30, 有效: 31
    NK 3/9: (256, 448)
      → 算法数: 30, 有效: 31
    NK 4/9: (512, 864)
      → 算法数: 30, 有效: 60
    NK 5/9: (1024, 1728)
      → 算法数: 30, 有效: 60
    NK 6/9: (2048, 3424)
      → 算法数: 30, 有效: 60
    NK 7/9: (4096, 6848)
      → 算法数: 30, 有效: 60
    NK 8/9: (8192, 13664)
      → 算法数: 30, 有效: 60
    NK 9/9: (16384, 27328)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_12.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 06:32:28.134528922 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1760)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 30, 有效: 31
    NK 2/9: (128, 224)
      → 算法数: 30, 有效: 31
    NK 3/9: (256, 448)
      → 算法数: 30, 有效: 31
    NK 4/9: (512, 896)
      → 算法数: 30, 有效: 60
    NK 5/9: (1024, 1760)
      → 算法数: 30, 有效: 60
    NK 6/9: (2048, 3520)
      → 算法数: 30, 有效: 60
    NK 7/9: (4096, 7040)
      → 算法数: 30, 有效: 60
    NK 8/9: (8192, 14048)
      → 算法数: 30, 有效: 60
    NK 9/9: (16384, 28096)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_14.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 06:34:51.170283954 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 448), (512, 896), (1024, 1792)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 30, 有效: 31
    NK 2/9: (128, 224)
      → 算法数: 30, 有效: 31
    NK 3/9: (256, 448)
      → 算法数: 30, 有效: 31
    NK 4/9: (512, 896)
      → 算法数: 30, 有效: 60
    NK 5/9: (1024, 1792)
      → 算法数: 30, 有效: 60
    NK 6/9: (2048, 3584)
      → 算法数: 30, 有效: 60
    NK 7/9: (4096, 7168)
      → 算法数: 30, 有效: 60
    NK 8/9: (8192, 14336)
      → 算法数: 30, 有效: 60
    NK 9/9: (16384, 28672)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_16.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 06:37:09.471730472 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(64, 128), (128, 256), (256, 512), (512, 1024), (1024, 2048)]...
============================================================
cuSPARSELt Sparse GEMM 算法搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K 测试: 开启
API 搜索对比: 开启
warmup=25, repeat=50

[1/4] 编译 CUDA 扩展...
✓ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 是

[3/4] 开始算法搜索...
      M=N=K 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      → 算法数: 30, 有效: 31
    NK 2/9: (128, 256)
      → 算法数: 30, 有效: 31
    NK 3/9: (256, 512)
      → 算法数: 30, 有效: 31
    NK 4/9: (512, 1024)
      → 算法数: 30, 有效: 60
    NK 5/9: (1024, 2048)
      → 算法数: 30, 有效: 60
    NK 6/9: (2048, 4096)
      → 算法数: 30, 有效: 60
    NK 7/9: (4096, 8192)
      → 算法数: 30, 有效: 60
    NK 8/9: (8192, 16384)
      → 算法数: 30, 有效: 60
    NK 9/9: (16384, 32768)
      → 算法数: 30, 有效: 60

    搜索统计: 总计=9, 成功=9, 失败=0, 错误=0
    成功率: 100.0%

[4/4] 保存结果...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_inf.json

✓ 完成! 结果已保存到: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 06:39:47.015282959 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, 将测试: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 06:39:48.029785990 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square [all] 低稀疏测试完成 (1939.6s)
[INFO] cuSPARSELt Square 低稀疏统计: 成功 1, 失败 0

----------------------------------------------------------------------
TASK 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS
Duration: 1939.6 seconds (32.3 minutes)
----------------------------------------------------------------------



============================================================
  最终总结
============================================================


  Task 1: cuBLASLt Model 测试 - SKIPPED
  Task 2: cuBLASLt Square 测试 - SKIPPED
  Task 3: cuSPARSELt Model 高稀疏 (2_4~2_10) - SKIPPED
  Task 4: cuSPARSELt Square 高稀疏 (2_4~2_10) - SKIPPED
  Task 5: cuSPARSELt Model 低稀疏 (2_12~2_inf) - SUCCESS (9530.0s)
  Task 6: cuSPARSELt Square 低稀疏 (2_12~2_inf) - SUCCESS (1939.6s)

  总计: 2 成功, 0 失败, 4 跳过
  总耗时: 11469.6 秒 (3.19 小时)

[INFO] 日志文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_032838.log
[INFO] 状态文件: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260128_032838_status.json

[INFO] 结果保存位置:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
