======================================================================
SlideSparse Kernel Benchmark Log
Started: 2026-01-27 19:04:18
======================================================================

Hardware:
  GPU: NVIDIA H100 PCIe (cc90)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_190418.log

======================================================================
TASK 1: cuBLASLt Model æµ‹è¯•
Started: 2026-01-27 19:04:18
======================================================================


------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Llama3.2-1B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cublaslt_gemm_H100_cc90_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/cublaslt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcublasLt -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/build/cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
âœ“ Built: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:04:47.139887496 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:05:02.304173336 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:05:16.957016047 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:05:30.510206060 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:05:31.934834104 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 å®Œæˆ (73.7s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Llama3.2-1B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:05:54.164310944 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:06:09.159062720 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:06:24.256873182 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:06:36.088194778 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:06:37.053906639 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 å®Œæˆ (65.2s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Llama3.2-3B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:07:01.050989593 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:07:20.345692146 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:07:39.144436906 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:07:53.036340828 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:07:54.053774028 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 å®Œæˆ (76.9s)

------------------------------------------------------------
  cuBLASLt Model: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Llama3.2-3B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:08:18.622185423 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:08:37.791226392 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:08:56.955523866 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:09:11.245060254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:09:12.180659728 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 å®Œæˆ (78.1s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Qwen2.5-7B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:09:49.749889546 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:10:23.511592120 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:10:55.478503003 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:11:18.588363812 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:11:19.942743708 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 å®Œæˆ (127.8s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Qwen2.5-7B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:11:59.540564281 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:12:33.260863518 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:13:04.137155148 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:13:27.960770593 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:13:28.900525283 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 å®Œæˆ (129.0s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Qwen2.5-14B-INT8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:14:14.212463621 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:14:53.404182896 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:15:29.183892746 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:15:54.508545144 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:15:55.736434643 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 å®Œæˆ (146.8s)

------------------------------------------------------------
  cuBLASLt Model: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model Qwen2.5-14B-FP8

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:16:38.690888862 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:17:19.206802725 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:17:55.432208265 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:18:22.072019922 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:18:23.318376940 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 å®Œæˆ (147.6s)

[INFO] cuBLASLt Model ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 1: cuBLASLt Model æµ‹è¯• - SUCCESS
Duration: 845.1 seconds (14.1 minutes)
----------------------------------------------------------------------


======================================================================
TASK 2: cuBLASLt Square æµ‹è¯•
Started: 2026-01-27 19:18:23
======================================================================


------------------------------------------------------------
  cuBLASLt Square æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cublaslt --model square

============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 7, æœ‰æ•ˆ: 7
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 19:18:51.106889223 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 7, æœ‰æ•ˆ: 7
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:19:14.457045704 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 5, æœ‰æ•ˆ: 5

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:19:36.277566016 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
============================================================
cuBLASLt Dense GEMM ç®—æ³•æœç´¢
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuBLASLt å¯ç”¨

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 3, æœ‰æ•ˆ: 3
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 6, æœ‰æ•ˆ: 6
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 8, æœ‰æ•ˆ: 8

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:19:53.376865332 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cublaslt
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuBLASLt Dense GEMM Search
[cuBLASLt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuBLASLt:   /root/vllmbench/slidesparse/benchmark_kernel/cuBLASLt/alg_search_results
[W127 19:19:54.652063975 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square æµ‹è¯•å®Œæˆ (91.4s)

----------------------------------------------------------------------
TASK 2: cuBLASLt Square æµ‹è¯• - SUCCESS
Duration: 91.4 seconds (1.5 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 19:19:54
======================================================================


------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
ğŸ”¨ Building cusparselt_gemm_H100_cc90_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/cusparselt_gemm.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/build/cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
âœ“ Built: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:20:46.358405317 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:21:26.056431651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:22:05.895191690 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:22:45.557982998 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:23:51.535273828 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:25:13.945588610 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:26:44.167817644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:28:20.825982308 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:29:06.439998027 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:30:04.217601556 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:31:03.351012657 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:32:11.130734045 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:33:04.630527846 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:34:10.934473535 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:35:22.358927119 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:36:41.875156987 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:36:42.918205576 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 é«˜ç¨€ç–å®Œæˆ (1008.2s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:37:27.870823900 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:38:08.327294384 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:38:48.938050912 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:39:29.428262842 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:40:34.374453763 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:41:56.171543794 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:43:24.303855183 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:45:03.796734953 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:45:50.023089787 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:46:47.277512969 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:47:47.484450957 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 19:48:54.349185013 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(3072, 2048), (2048, 2048), (16384, 2048), (2048, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:49:48.930123099 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(3072, 2752), (2048, 2752), (16384, 2752), (2048, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 10944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:50:54.739153760 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(3072, 3072), (2048, 3072), (16384, 3072), (2048, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 12288)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:52:05.428142306 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(3072, 3296), (2048, 3296), (16384, 3296), (2048, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 13120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 19:53:26.436227197 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 19:53:27.447326051 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 é«˜ç¨€ç–å®Œæˆ (1004.6s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:54:15.178941730 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:54:58.550491223 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:55:39.888821559 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 19:56:22.894681762 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 19:57:58.213544476 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:00:01.624128848 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:02:20.104764516 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:04:45.679495580 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:05:50.738360115 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:07:08.114472143 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:08:34.474460089 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:10:06.566059375 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:11:24.648421684 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:12:59.578433265 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:14:41.139690412 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:16:33.281452406 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:16:34.266890696 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 é«˜ç¨€ç–å®Œæˆ (1386.9s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:17:20.686233879 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:18:02.589981905 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:18:44.284687172 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:19:27.871433245 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:21:04.302317219 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:23:09.524984784 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:25:25.341406241 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:27:53.725332001 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:28:57.530479427 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:30:16.524636852 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:31:42.241474755 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 20:33:15.852542795 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(5120, 3072), (3072, 3072), (16384, 3072), (3072, 8192)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:34:33.236508617 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(5120, 4096), (3072, 4096), (16384, 4096), (3072, 10944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 10944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:36:07.043831312 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(5120, 4608), (3072, 4608), (16384, 4608), (3072, 12288)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4608)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 12288)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:37:49.655022648 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(5120, 4928), (3072, 4928), (16384, 4928), (3072, 13120)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4928)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 13120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 20:39:44.543907067 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 20:39:45.509852243 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 é«˜ç¨€ç–å®Œæˆ (1391.1s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:40:32.953396601 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:41:16.013013750 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:41:59.235061663 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 20:42:42.348894131 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:45:56.851896146 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:50:19.412043794 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 20:55:08.071463059 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 21:00:19.088366331 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:02:17.863319981 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:04:57.491746450 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:07:48.591637720 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:10:51.870538191 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:13:17.688651577 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:16:35.819726382 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:20:11.267200486 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:23:43.927220227 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 21:23:44.956061407 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 é«˜ç¨€ç–å®Œæˆ (2639.4s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 21:24:27.967845399 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 21:25:06.753260456 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 21:25:45.394699569 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 21:26:24.423509165 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 21:29:19.710177254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 21:33:16.844424389 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 21:37:44.792795921 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 21:42:32.689704601 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:44:17.556180967 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:46:46.682901186 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:49:34.087635254 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 21:52:33.852324261 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(4608, 3584), (3584, 3584), (37888, 3584), (3584, 18944)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 18944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:54:53.664612337 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(4608, 4800), (3584, 4800), (37888, 4800), (3584, 25280)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 4800)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 25280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 21:58:05.156437730 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(4608, 5376), (3584, 5376), (37888, 5376), (3584, 28416)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 28416)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:01:26.585052466 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(4608, 5760), (3584, 5760), (37888, 5760), (3584, 30336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 5760)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 30336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:05:04.019426988 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 22:05:04.980279982 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-FP8 é«˜ç¨€ç–å®Œæˆ (2480.1s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-INT8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 73
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 22:05:52.379290181 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 22:06:34.782521399 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 22:07:17.558232006 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 22:08:00.615703502 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 22:12:17.925491539 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 22:17:56.536495053 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 22:24:08.061094401 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 22:30:14.378462626 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 22:32:29.046418759 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 22:35:30.088185852 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 22:39:04.335344994 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 22:42:29.232472644 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:45:41.220573249 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:49:21.211316779 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:54:07.825004740 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-INT8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 22:59:01.702089718 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 22:59:02.707116609 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-INT8 é«˜ç¨€ç–å®Œæˆ (3237.7s)

------------------------------------------------------------
  cuSPARSELt Model é«˜ç¨€ç–: Qwen2.5-14B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-14B-FP8 --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 22:59:49.752329514 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 23:00:31.614852370 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 23:01:14.340902449 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W127 23:01:56.621731289 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:06:27.419516302 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:11:18.470643191 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:16:42.158232925 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:22:25.236309125 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 23:24:40.922223865 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 23:27:36.328612615 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 23:30:47.213685268 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W127 23:34:09.694133654 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(7168, 5120), (5120, 5120), (27648, 5120), (5120, 13824)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 13824)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 23:36:53.042750499 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(7168, 6848), (5120, 6848), (27648, 6848), (5120, 18432)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 6848)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 18432)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 23:40:54.509246213 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(7168, 7680), (5120, 7680), (27648, 7680), (5120, 20736)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 7680)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 20736)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 23:45:06.943341091 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(7168, 8192), (5120, 8192), (27648, 8192), (5120, 22144)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (7168, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (5120, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (27648, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (5120, 22144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-14B-FP8_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W127 23:49:41.086808045 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-14B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4
[ERROR] cuSPARSELt search (sparsity=2_4) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6
[ERROR] cuSPARSELt search (sparsity=2_6) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8
[ERROR] cuSPARSELt search (sparsity=2_8) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10
[ERROR] cuSPARSELt search (sparsity=2_10) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W127 23:49:42.019684501 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-14B-FP8 é«˜ç¨€ç–å®Œæˆ (3039.3s)

[INFO] cuSPARSELt Model é«˜ç¨€ç–ç»Ÿè®¡: æˆåŠŸ 8, å¤±è´¥ 0

----------------------------------------------------------------------
TASK 3: cuSPARSELt Model é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 16187.3 seconds (269.8 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10)
Started: 2026-01-27 23:49:42
======================================================================


------------------------------------------------------------
  cuSPARSELt Square é«˜ç¨€ç–æµ‹è¯•
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model square --sparsity 2_4,2_6,2_8,2_10

[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 38
    NK 2/9: (128, 128)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 256)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 512)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1024)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 2048)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 4096)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 8192)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 16384)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=1, å¤±è´¥=0, é”™è¯¯=8
    æˆåŠŸç‡: 11.1%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 23:50:09.624252147 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 38
    NK 2/9: (128, 192)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 352)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 704)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1376)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 2752)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 5472)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 10944)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 21856)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=1, å¤±è´¥=0, é”™è¯¯=8
    æˆåŠŸç‡: 11.1%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 23:50:31.503760760 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 38
    NK 2/9: (128, 192)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 384)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 768)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1536)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 3072)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 6144)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 12288)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 24576)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=1, å¤±è´¥=0, é”™è¯¯=8
    æˆåŠŸç‡: 11.1%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 23:50:53.426100453 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 38
    NK 2/9: (128, 224)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 3/9: (256, 416)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 4/9: (512, 832)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 5/9: (1024, 1664)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 6/9: (2048, 3296)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 7/9: (4096, 6560)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 8/9: (8192, 13120)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

    NK 9/9: (16384, 26240)
      âš  ç”Ÿæˆæ•°æ®å¤±è´¥: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=1, å¤±è´¥=0, é”™è¯¯=8
    æˆåŠŸç‡: 11.1%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP16
============================================================
[W127 23:51:16.148246177 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:53:12.233833970 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W127 23:56:26.969862230 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:00:03.091604976 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 22
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:03:39.302952391 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:05:01.751747240 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:06:53.928146331 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:08:36.639505462 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: int8 -> int8 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 26
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:10:55.971444264 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_4, K_factor=1.000
[INFO] NK list adjusted: [(64, 64), (128, 128), (256, 256), (512, 512), (1024, 1024)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_4
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 64)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 2/9: (128, 128)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 3/9: (256, 256)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 4/9: (512, 512)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 5/9: (1024, 1024)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 6/9: (2048, 2048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 7/9: (4096, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 8/9: (8192, 8192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 9/9: (16384, 16384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_4.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:12:30.756111691 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_6, K_factor=1.333
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 352), (512, 704), (1024, 1376)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_6
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 3/9: (256, 352)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 4/9: (512, 704)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 5/9: (1024, 1376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 6/9: (2048, 2752)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 7/9: (4096, 5472)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 8/9: (8192, 10944)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 9/9: (16384, 21856)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_6.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:14:37.881923042 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_8, K_factor=1.500
[INFO] NK list adjusted: [(64, 96), (128, 192), (256, 384), (512, 768), (1024, 1536)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_8
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 96)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 2/9: (128, 192)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 3/9: (256, 384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 4/9: (512, 768)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 5/9: (1024, 1536)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 6/9: (2048, 3072)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 7/9: (4096, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 8/9: (8192, 12288)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 9/9: (16384, 24576)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_8.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:16:41.855795748 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_10, K_factor=1.600
[INFO] NK list adjusted: [(64, 128), (128, 224), (256, 416), (512, 832), (1024, 1664)]...
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_10
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      M=N=K åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/9: (64, 128)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 2/9: (128, 224)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 3/9: (256, 416)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 31
    NK 4/9: (512, 832)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 5/9: (1024, 1664)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 6/9: (2048, 3296)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 7/9: (4096, 6560)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 8/9: (8192, 13120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 9/9: (16384, 26240)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=9, æˆåŠŸ=9, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_SQUARE_2_10.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:18:59.847379669 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: SQUARE
Model: SQUARE
M=N=K: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_4', '2_6', '2_8', '2_10']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_4)
[INFO] K_factor = 1.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_4

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_6)
[INFO] K_factor = 1.333
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_6

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_8)
[INFO] K_factor = 1.500
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_8

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_10)
[INFO] K_factor = 1.600
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model SQUARE --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_10

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 00:19:00.863760607 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Square é«˜ç¨€ç–æµ‹è¯•å®Œæˆ (1758.8s)

----------------------------------------------------------------------
TASK 4: cuSPARSELt Square é«˜ç¨€ç– (2_4~2_10) - SUCCESS
Duration: 1758.8 seconds (29.3 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: cuSPARSELt Model ä½ç¨€ç– (2_12~2_inf)
Started: 2026-01-28 00:19:01
======================================================================


------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:19:42.250546116 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:20:19.101111118 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:20:56.310588552 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:21:34.720719981 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:22:59.154874231 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:24:36.799588855 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:26:01.286063333 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:27:58.463756026 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:29:04.149123192 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:30:02.688201166 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:30:56.809348347 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:31:56.098144212 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:33:04.928521348 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:34:14.341553124 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:35:18.283602757 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:36:30.879381662 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12
[ERROR] cuSPARSELt search (sparsity=2_12) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14
[ERROR] cuSPARSELt search (sparsity=2_14) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 00:36:31.793853440 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-INT8 ä½ç¨€ç–å®Œæˆ (1051.0s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-1B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-1B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:37:14.192557835 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:37:51.934779256 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:38:29.017548889 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:39:06.217788012 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:40:43.925317929 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:42:23.212933701 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:43:48.421153403 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:45:23.100975142 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:46:21.131357741 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:47:17.229551771 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:48:11.023098347 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 00:49:09.892523098 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(3072, 3424), (2048, 3424), (16384, 3424), (2048, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3424)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 13664)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:50:20.008319959 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(3072, 3520), (2048, 3520), (16384, 3520), (2048, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3520)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 14048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:51:27.421029518 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(3072, 3584), (2048, 3584), (16384, 3584), (2048, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 3584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 14336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:52:33.597982606 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(3072, 4096), (2048, 4096), (16384, 4096), (2048, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (3072, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (2048, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 4096)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (2048, 16384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-1B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 00:53:46.168180472 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-1B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12
[ERROR] cuSPARSELt search (sparsity=2_12) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14
[ERROR] cuSPARSELt search (sparsity=2_14) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-1B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 00:53:47.091277094 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-1B-FP8 ä½ç¨€ç–å®Œæˆ (1035.2s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:54:31.928068447 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:55:12.256077824 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:55:52.174796587 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 00:56:32.668645181 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 00:58:40.757274651 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:00:57.623178027 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:03:11.021983178 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:05:42.668607405 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:07:02.719650427 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:08:31.516146328 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:09:49.898326516 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:11:17.935769694 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:12:53.437929339 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:14:42.217019017 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:16:20.595147908 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:18:08.886850898 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12
[ERROR] cuSPARSELt search (sparsity=2_12) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14
[ERROR] cuSPARSELt search (sparsity=2_14) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 01:18:09.828329553 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-INT8 ä½ç¨€ç–å®Œæˆ (1462.8s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Llama3.2-3B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Llama3.2-3B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:18:53.550745235 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:19:32.984337817 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:20:13.247306839 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:20:52.422731466 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:23:00.926363271 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:25:16.680727848 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:27:30.235205675 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:30:23.179324536 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:31:54.916179908 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:33:37.501545305 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:35:10.664204289 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 01:36:52.617481650 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(5120, 5120), (3072, 5120), (16384, 5120), (3072, 13664)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5120)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 13664)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:38:42.325759772 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(5120, 5280), (3072, 5280), (16384, 5280), (3072, 14048)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5280)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 14048)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:40:44.766117913 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(5120, 5376), (3072, 5376), (16384, 5376), (3072, 14336)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 5376)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 14336)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:42:25.303619687 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(5120, 6144), (3072, 6144), (16384, 6144), (3072, 16384)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (5120, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3072, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (16384, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3072, 16384)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Llama3.2-3B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 01:44:14.385159288 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Llama3.2-3B-FP8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12
[ERROR] cuSPARSELt search (sparsity=2_12) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14
[ERROR] cuSPARSELt search (sparsity=2_14) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Llama3.2-3B-FP8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 01:44:15.352200966 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Llama3.2-3B-FP8 ä½ç¨€ç–å®Œæˆ (1565.5s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-INT8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-INT8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:44:59.987901911 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:45:38.552302742 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:46:18.077580851 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 01:46:57.607765641 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:51:57.975882221 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 01:56:58.668879648 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 02:02:00.469412566 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 02:07:58.234757772 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 02:11:11.039151434 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 02:14:27.549048838 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 02:17:43.452628647 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 02:21:24.587665885 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 02:25:45.334958857 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 02:29:30.156950340 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 02:33:03.287679980 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
dtype: fp8e4m3 -> fp8e4m3 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 30, æœ‰æ•ˆ: 60

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8/alg_search_Qwen2.5-7B-INT8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/FP8
============================================================
[W128 02:37:04.422395327 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] dtype=all, å°†æµ‹è¯•: ['fp16', 'bf16', 'int8', 'fp8e4m3']
============================================================
SlideSparse Kernel Benchmark
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-INT8
M_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]
dtype: ['fp16', 'bf16', 'int8', 'fp8e4m3']
Backend: cusparselt
Sparsity: ['2_12', '2_14', '2_16', '2_inf']
warmup=25, repeat=50
============================================================

============================================================
Benchmark dtype=FP16
============================================================

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12
[ERROR] cuSPARSELt search (sparsity=2_12) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14
[ERROR] cuSPARSELt search (sparsity=2_14) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16
[ERROR] cuSPARSELt search (sparsity=2_16) failed

[fp16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf
[ERROR] cuSPARSELt search (sparsity=2_inf) failed

============================================================
Benchmark dtype=BF16
============================================================

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[bf16] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=INT8
============================================================

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[int8] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype int8 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark dtype=FP8E4M3
============================================================

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_12)
[INFO] K_factor = 1.667
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_12

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_14)
[INFO] K_factor = 1.714
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_14

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_16)
[INFO] K_factor = 1.750
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_16

[fp8e4m3] Running cuSPARSELt Sparse GEMM Search (sparsity=2_inf)
[INFO] K_factor = 2.000
[cuSPARSELt] Running: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py --dtype fp8e4m3 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 50 --out_dir /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results --m_list 64,128,256,512,1024,2048,4096,8192,16384 --sparsity 2_inf

============================================================
Benchmark Complete!
============================================================

Results saved to:
  - cuSPARSELt: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results
[W128 02:37:05.338041149 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[SUCCESS] Qwen2.5-7B-INT8 ä½ç¨€ç–å®Œæˆ (3170.0s)

------------------------------------------------------------
  cuSPARSELt Model ä½ç¨€ç–: Qwen2.5-7B-FP8
------------------------------------------------------------
[INFO] æ‰§è¡Œ: /usr/bin/python3 /root/vllmbench/slidesparse/benchmark_kernel/benchmark_entry.py --dtype all --warmup 25 --repeat 50 --m_list 64,128,256,512,1024,2048,4096,8192,16384 --backend cusparselt --model Qwen2.5-7B-FP8 --sparsity 2_12,2_14,2_16,2_inf

[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 02:37:49.273420247 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 02:38:28.798953988 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 02:39:10.153982247 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: fp16 -> fp16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 52, æœ‰æ•ˆ: 74
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 893, in <module>
    main()
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 866, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search.py", line 619, in run_search
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.12/dist-packages/torch/cuda/memory.py", line 224, in empty_cache
    torch._C._cuda_emptyCache()
torch.AcceleratorError: CUDA error: an illegal instruction was encountered
Search for `cudaErrorIllegalInstruction' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W128 02:39:49.710884442 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 02:44:50.655260564 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 02:49:50.294725820 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 02:54:53.834750375 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: bf16 -> bf16 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 3/4: (37888, 7168)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42
    NK 4/4: (3584, 37888)
      â†’ ç®—æ³•æ•°: 21, æœ‰æ•ˆ: 42

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16/alg_search_Qwen2.5-7B-FP8_2_inf.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/BF16
============================================================
[W128 03:00:44.090052385 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_12, K_factor=1.667
[INFO] NK list adjusted: [(4608, 5984), (3584, 5984), (37888, 5984), (3584, 31584)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_12
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 5984)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 31584)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_12.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:03:57.585095447 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_14, K_factor=1.714
[INFO] NK list adjusted: [(4608, 6144), (3584, 6144), (37888, 6144), (3584, 32480)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_14
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 6144)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 32480)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_14.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:06:56.068114002 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_16, K_factor=1.750
[INFO] NK list adjusted: [(4608, 6272), (3584, 6272), (37888, 6272), (3584, 33152)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_16
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 6272)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 4/4: (3584, 33152)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50

    æœç´¢ç»Ÿè®¡: æ€»è®¡=36, æˆåŠŸ=36, å¤±è´¥=0, é”™è¯¯=0
    æˆåŠŸç‡: 100.0%

[4/4] ä¿å­˜ç»“æœ...
    CSV: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.csv
    JSON: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8/alg_search_Qwen2.5-7B-FP8_2_16.json

âœ“ å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: /root/vllmbench/slidesparse/benchmark_kernel/cuSPARSELt/alg_search_results/H100_cc90_py312_cu129_x86_64/INT8
============================================================
[W128 03:09:51.012361911 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[INFO] Sparsity=2_inf, K_factor=2.000
[INFO] NK list adjusted: [(4608, 7168), (3584, 7168), (37888, 7168), (3584, 37888)]
============================================================
cuSPARSELt Sparse GEMM ç®—æ³•æœç´¢ (2:4 ç¨€ç–)
============================================================
GPU: NVIDIA H100 PCIe (cc90)
Mode: MODEL
Model: Qwen2.5-7B-FP8
dtype: int8 -> int8 (same input/output)
Sparsity: 2_inf
Segment-K æµ‹è¯•: å¼€å¯
API æœç´¢å¯¹æ¯”: å¼€å¯
warmup=25, repeat=50

[1/4] ç¼–è¯‘ CUDA æ‰©å±•...
âœ“ Using existing: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
[2/4] åŠ è½½ CUDA æ‰©å±•...
âœ“ cuSPARSELt å¯ç”¨
âœ“ Segment-K æ”¯æŒ: æ˜¯

[3/4] å¼€å§‹ç®—æ³•æœç´¢...
      NK ç»„åˆ: 4 ä¸ª, M åˆ—è¡¨: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]

    NK 1/4: (4608, 7168)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 2/4: (3584, 7168)
      â†’ ç®—æ³•æ•°: 25, æœ‰æ•ˆ: 50
    NK 3/4: (37888, 7168)

======================================================================
æ”¶åˆ°ä¸­æ–­ä¿¡å· (signal 2)
======================================================================
[INFO] çŠ¶æ€å·²ä¿å­˜: /root/vllmbench/slidesparse/benchmark_kernel/kernel_bench_logs/kernel_bench_20260127_190418_status.json
