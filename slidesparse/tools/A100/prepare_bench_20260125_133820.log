======================================================================
SlideSparse Prepare Benchmark Log
Started: 2026-01-25 13:38:20
======================================================================

Hardware:
  GPU: NVIDIA A100 80GB PCIe (cc80)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_133820.log

======================================================================
TASK 1: 模型下载
Started: 2026-01-25 13:38:20
======================================================================


------------------------------------------------------------
  下载: llama3.2-1b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-1b-int8


============================================================
  准备下载 1 个模型 (~1.9 GB)
============================================================

  - Llama3.2-1B-INT8 (1.9 GB)


============================================================
  下载: Llama3.2-1B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-1B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-1B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-1B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] llama3.2-1b-int8 下载完成 (6.1s)

------------------------------------------------------------
  下载: llama3.2-1b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-1b-fp8


============================================================
  准备下载 1 个模型 (~1.9 GB)
============================================================

  - Llama3.2-1B-FP8 (1.9 GB)


============================================================
  下载: Llama3.2-1B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-1B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-1B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-1B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] llama3.2-1b-fp8 下载完成 (5.9s)

------------------------------------------------------------
  下载: llama3.2-3b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-3b-int8


============================================================
  准备下载 1 个模型 (~4.0 GB)
============================================================

  - Llama3.2-3B-INT8 (4.0 GB)


============================================================
  下载: Llama3.2-3B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-3B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-3B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-3B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] llama3.2-3b-int8 下载完成 (5.8s)

------------------------------------------------------------
  下载: llama3.2-3b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-3b-fp8


============================================================
  准备下载 1 个模型 (~4.0 GB)
============================================================

  - Llama3.2-3B-FP8 (4.0 GB)


============================================================
  下载: Llama3.2-3B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-3B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-3B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-3B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] llama3.2-3b-fp8 下载完成 (5.8s)

------------------------------------------------------------
  下载: qwen2.5-7b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-7b-int8


============================================================
  准备下载 1 个模型 (~8.1 GB)
============================================================

  - Qwen2.5-7B-INT8 (8.1 GB)


============================================================
  下载: Qwen2.5-7B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-7B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] qwen2.5-7b-int8 下载完成 (5.9s)

------------------------------------------------------------
  下载: qwen2.5-7b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-7b-fp8


============================================================
  准备下载 1 个模型 (~8.1 GB)
============================================================

  - Qwen2.5-7B-FP8 (8.1 GB)


============================================================
  下载: Qwen2.5-7B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-7B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-7B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Qwen2.5-7B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] qwen2.5-7b-fp8 下载完成 (5.8s)

------------------------------------------------------------
  下载: qwen2.5-14b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-14b-int8


Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]Still waiting to acquire lock on /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)
Still waiting to acquire lock on /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/.gitignore.lock (elapsed: 0.1 seconds)
Downloading 'model-00002-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/t9msAuTjAZjuQnmzGOwTjiptvIU=.91aa389be2ee0ada147eec7bc346ddd0dbc9c1eace9f233065ac225b22d98c15.incomplete'
Downloading 'model-00001-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/IO4xwqmZYzFmxznkwkiNSBwO1H0=.43b9886f741a9ffa73248db4607311b2b67cae71160f3b8da22ce9bf50b541b9.incomplete'
Downloading 'added_tokens.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.482ced4679301bf287ebb310bdd1790eb4514232.incomplete'
Downloading 'generation_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.2e995d693e130e3e92b87ff760bbe99ccdc54ea0.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/added_tokens.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/generation_config.json
Downloading 'README.md' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.2a9847668030cc8e2e3ca698eb0eb25e3a8b98d6.incomplete'
Downloading '.gitattributes' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/README.md
Downloading 'config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.0475d3a8eec471324033f7dab7861fe047ea3bbe.incomplete'
Downloading 'merges.txt' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/PtHk0z_I45atnj23IIRhTExwT3w=.31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.incomplete'
Downloading 'model-00003-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/DaGOU-KRMVrY0aYktrsE34tL0Bs=.a95b39396a6de7716743660583d3d468fa31d103ebf1d1b444efe1ed8fc0f562.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/config.json
Downloading 'model-00004-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/-dFtyT7kcgbTHt1cy9JKqruJCR4=.961282a7d1b18000f29487a35cc8e5357190a5222db03c2434bdf25e6d97731f.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.gitattributes

Fetching 16 files:   6%|▋         | 1/16 [00:00<00:06,  2.31it/s]Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/merges.txt
Downloading 'model.safetensors.index.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.5ba6d9c419ff1c46aa0b188643370ae1c63b80cf.incomplete'
Downloading 'tokenizer.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.bb73a25aba3c83c6c815a03a334b0440bd549f9a54fa3673e005f5532f6b32fe.incomplete'
Downloading 'recipe.yaml' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/bnSmoKA-HyCrq3IlqBFOc_V8_a4=.2c73d48fd4321a955af603297216d4668904e7b2.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model.safetensors.index.json
Downloading 'special_tokens_map.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.ac23c0aaa2434523c494330aeb79c58395378103.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/recipe.yaml
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/special_tokens_map.json
Downloading 'tokenizer_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.8adf747ccaf85ff9587338cee6ed6be027b98210.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/tokenizer_config.json
Downloading 'vocab.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.4783fe10ac3adce15ac8f358ef5462739852c569.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/vocab.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/tokenizer.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00004-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00002-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00003-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00001-of-00004.safetensors

Fetching 16 files:  44%|████▍     | 7/16 [00:14<00:19,  2.13s/it]
Fetching 16 files: 100%|██████████| 16/16 [00:14<00:00,  1.11it/s]
/root/vllmbench/checkpoints/Qwen2.5-14B-INT8

============================================================
  准备下载 1 个模型 (~15.2 GB)
============================================================

  - Qwen2.5-14B-INT8 (15.2 GB)


============================================================
  下载: Qwen2.5-14B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-14B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8

[INFO] 下载命令: hf download RedHatAI/Qwen2.5-14B-Instruct-quantized.w8a8 --local-dir /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[SUCCESS] 下载成功: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✓ Qwen2.5-14B-INT8 - 15.2 GB

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 8 已下载, 7 缺失
[INFO] Checkpoints 目录大小: 59G
[SUCCESS] qwen2.5-14b-int8 下载完成 (21.1s)

------------------------------------------------------------
  下载: qwen2.5-14b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-14b-fp8


============================================================
  准备下载 1 个模型 (~15.2 GB)
============================================================

  - Qwen2.5-14B-FP8 (15.2 GB)


============================================================
  下载: Qwen2.5-14B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-14B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✓ Qwen2.5-14B-INT8 - 15.2 GB

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 8 已下载, 7 缺失
[INFO] Checkpoints 目录大小: 59G
[SUCCESS] qwen2.5-14b-fp8 下载完成 (5.9s)

[INFO] 下载统计: 成功 8, 失败 0

----------------------------------------------------------------------
TASK 1: 模型下载 - SUCCESS
Duration: 62.3 seconds (1.0 minutes)
----------------------------------------------------------------------


======================================================================
TASK 2: 模型转换 (SlideSparse)
Started: 2026-01-25 13:39:23
======================================================================


------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 8.57s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_4 转换完成 (14.5s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 9.07s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_6 转换完成 (15.0s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 9.45s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_8 转换完成 (15.5s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 11.10s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_10 转换完成 (18.6s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 9.32s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_4 转换完成 (15.4s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 20.80s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_6 转换完成 (31.7s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 19.06s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_8 转换完成 (25.0s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 21.12s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_10 转换完成 (29.0s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 40.19s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_4 转换完成 (48.2s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 30.36s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_6 转换完成 (37.0s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 45.66s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_8 转换完成 (53.2s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 33.17s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_10 转换完成 (42.2s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 40.94s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_4 转换完成 (47.8s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 52.21s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_6 转换完成 (59.9s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 35.75s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_8 转换完成 (43.2s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, recipe.yaml...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 52.99s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_10 转换完成 (59.1s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 72.41s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_4 转换完成 (78.7s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 102.83s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_6 转换完成 (109.1s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 87.59s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_8 转换完成 (93.7s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 72.68s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_10 转换完成 (79.5s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 54.05s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_4 转换完成 (66.4s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 91.78s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_6 转换完成 (98.0s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 159.10s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_8 转换完成 (165.3s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 97.87s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_10 转换完成 (104.2s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 183.17s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_4 转换完成 (189.5s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 429.22s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_6 转换完成 (437.2s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 139.03s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_8 转换完成 (147.3s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 138.69s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_10 转换完成 (146.5s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 591.34s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_4 转换完成 (597.6s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 143.64s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_6 转换完成 (149.9s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 155.77s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_8 转换完成 (162.2s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, config.json, special_tokens_map.json, generation_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 177.44s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_10 转换完成 (183.7s)

[INFO] 转换统计: 成功 32, 失败 0

----------------------------------------------------------------------
TASK 2: 模型转换 (SlideSparse) - SUCCESS
Duration: 3385.3 seconds (56.4 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: 离线粗调优 (cuBLAS + quant_only)
Started: 2026-01-25 14:35:48
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 256,1024,4096,16384,32768 --Lmax 10 --warmup 10 --repeat 50 --kernels 1,0,0,0,1


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA A100 80GB PCIe (cc80)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [256, 1024, 4096, 16384, 32768]
  Warmup/Repeat: 10/50

  Kernel 调优:
    ✓ cuBLASLt GEMM
    ✗ cuSPARSELt GEMM
    ✗ Triton Dequant + Bias
    ✗ Triton Quant + Slide
    ✓ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-7B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-14B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

============================================================
  Step 2: cuSPARSELt GEMM [跳过]
============================================================


============================================================
  Step 3: Triton Dequant + Bias [跳过]
============================================================


============================================================
  Step 4: Triton Quant + Slide [跳过]
============================================================


============================================================
  Step 5: Triton Quant Only
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

============================================================
  调优总结
============================================================

  cuBLASLt GEMM: [全部成功] (8/8)
  cuSPARSELt GEMM: [跳过]
  Triton Dequant + Bias: [跳过]
  Triton Quant + Slide: [跳过]
  Triton Quant Only: [全部成功] (4/4)

总计: 成功 12, 失败 0, 跳过 3

----------------------------------------------------------------------
TASK 3: 离线粗调优 (cuBLAS + quant_only) - SUCCESS
Duration: 1418.2 seconds (23.6 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: 离线细调优 (cuSPARSE + Triton)
Started: 2026-01-25 14:59:26
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --Lmax 10 --warmup 25 --repeat 100 --kernels 0,1,1,1,0


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA A100 80GB PCIe (cc80)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
  Warmup/Repeat: 25/100

  Kernel 调优:
    ✗ cuBLASLt GEMM
    ✓ cuSPARSELt GEMM
    ✓ Triton Dequant + Bias
    ✓ Triton Quant + Slide
    ✗ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM [跳过]
============================================================


============================================================
  Step 2: cuSPARSELt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (fp8) 失败:
============================================================
cuSPARSELt 算法离线搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80, Ampere)
模型: Llama3.2-1B-FP8
参数: dtype=fp8e4m3, outdtype=bf16
Segment-K 测试: 开启
API 搜索对比: 开启

[1/4] 编译 CUDA 扩展...
🔨 Building alg_search_cusparselt_A100_cc80_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search_cusparselt.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/build/alg_search_cusparselt_A100_cc80_py312_cu129_x86_64.so
✓ Built: alg_search_cusparselt_A100_cc80_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 否
Lmax: 10 (slide sparse L=4,6,...,10)

[3/4] 开始算法搜索...
      NK 组合: 16 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/16: (3072, 2048)
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 737, in <module>
    main()
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 701, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 519, in run_search
    W_pruned, _, W_q_pruned = prepare_and_prune_weight(lib, W, dtype)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 188, in prepare_and_prune_weight
    raise RuntimeError("获取压缩大小失败")
RuntimeError: 获取压缩大小失败


------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (fp8) 失败:
============================================================
cuSPARSELt 算法离线搜索 (2:4 稀疏)
============================================================
GPU: NVIDIA A100 80GB PCIe (cc80, Ampere)
模型: Llama3.2-3B-FP8
参数: dtype=fp8e4m3, outdtype=bf16
Segment-K 测试: 开启
API 搜索对比: 开启

[1/4] 编译 CUDA 扩展...
🔨 Building alg_search_cusparselt_A100_cc80_py312_cu129_x86_64...
Command: /usr/local/cuda/bin/nvcc -std=c++17 -O3 -Xcompiler -fPIC --shared -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_89,code=sm_89 -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_100,code=sm_100 -gencode=arch=compute_120,code=sm_120 -gencode=arch=compute_121,code=sm_121 -I /usr/local/cuda/include /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search_cusparselt.cu -L/usr/lib/x86_64-linux-gnu -lcusparseLt -lcusparse -lcublas -lcuda -o /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/build/alg_search_cusparselt_A100_cc80_py312_cu129_x86_64.so
✓ Built: alg_search_cusparselt_A100_cc80_py312_cu129_x86_64.so
[2/4] 加载 CUDA 扩展...
✓ cuSPARSELt 可用
✓ Segment-K 支持: 否
Lmax: 10 (slide sparse L=4,6,...,10)

[3/4] 开始算法搜索...
      NK 组合: 16 个, M 列表: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]

    NK 1/16: (5120, 3072)
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 737, in <module>
    main()
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 701, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 519, in run_search
    W_pruned, _, W_q_pruned = prepare_and_prune_weight(lib, W, dtype)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 188, in prepare_and_prune_weight
    raise RuntimeError("获取压缩大小失败")
RuntimeError: 获取压缩大小失败

======================================================================
收到中断信号 (signal 2)
======================================================================
[INFO] 状态已保存: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_133820_status.json
