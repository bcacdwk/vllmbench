======================================================================
SlideSparse Recovery Benchmark Log
Started: 2026-01-26 01:31:39
======================================================================

[INFO] 日志文件: /root/vllmbench/slidesparse/tools/recovery_bench_20260126_013139.log
============================================================
  恢复 Benchmark 脚本
  开始时间: 2026-01-26 01:31:39
============================================================

  Prefill 模型: ['qwen2.5-7b-int8', 'qwen2.5-7b-fp8', 'qwen2.5-14b-int8', 'qwen2.5-14b-fp8']
  Decode 模型: ['llama3.2-1b-int8', 'llama3.2-1b-fp8', 'llama3.2-3b-int8', 'llama3.2-3b-fp8', 'qwen2.5-7b-int8', 'qwen2.5-7b-fp8', 'qwen2.5-14b-int8', 'qwen2.5-14b-fp8']


============================================================
  阶段 1: Prefill Benchmark (7B/14B 模型)
============================================================

[1/4] Prefill: qwen2.5-7b-int8

============================================================
  PREFILL: qwen2.5-7b-int8
  时间: 2026-01-26 01:31:39
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536


[FAILED] qwen2.5-7b-int8 prefill 失败! 返回码: 1, 耗时: 6131.4s

[2/4] Prefill: qwen2.5-7b-fp8

============================================================
  PREFILL: qwen2.5-7b-fp8
  时间: 2026-01-26 03:13:50
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-fp8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536


[FAILED] qwen2.5-7b-fp8 prefill 失败! 返回码: 1, 耗时: 7140.0s

[3/4] Prefill: qwen2.5-14b-int8

============================================================
  PREFILL: qwen2.5-14b-int8
  时间: 2026-01-26 05:12:50
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536


[FAILED] qwen2.5-14b-int8 prefill 失败! 返回码: 1, 耗时: 6071.9s

[4/4] Prefill: qwen2.5-14b-fp8

============================================================
  PREFILL: qwen2.5-14b-fp8
  时间: 2026-01-26 06:54:02
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536


[FAILED] qwen2.5-14b-fp8 prefill 失败! 返回码: 1, 耗时: 6673.9s

============================================================
  阶段 2: Decode Benchmark (完整 8 个模型)
============================================================

[1/8] Decode: llama3.2-1b-int8

============================================================
  DECODE: llama3.2-1b-int8
  时间: 2026-01-26 08:45:16
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model llama3.2-1b-int8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] llama3.2-1b-int8 decode 完成! 耗时: 1018.7s (17.0min)

[2/8] Decode: llama3.2-1b-fp8

============================================================
  DECODE: llama3.2-1b-fp8
  时间: 2026-01-26 09:02:15
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model llama3.2-1b-fp8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] llama3.2-1b-fp8 decode 完成! 耗时: 1037.3s (17.3min)

[3/8] Decode: llama3.2-3b-int8

============================================================
  DECODE: llama3.2-3b-int8
  时间: 2026-01-26 09:19:32
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model llama3.2-3b-int8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] llama3.2-3b-int8 decode 完成! 耗时: 1278.6s (21.3min)

[4/8] Decode: llama3.2-3b-fp8

============================================================
  DECODE: llama3.2-3b-fp8
  时间: 2026-01-26 09:40:51
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model llama3.2-3b-fp8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] llama3.2-3b-fp8 decode 完成! 耗时: 1313.8s (21.9min)

[5/8] Decode: qwen2.5-7b-int8

============================================================
  DECODE: qwen2.5-7b-int8
  时间: 2026-01-26 10:02:44
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] qwen2.5-7b-int8 decode 完成! 耗时: 1408.2s (23.5min)

[6/8] Decode: qwen2.5-7b-fp8

============================================================
  DECODE: qwen2.5-7b-fp8
  时间: 2026-01-26 10:26:13
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-fp8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[SUCCESS] qwen2.5-7b-fp8 decode 完成! 耗时: 1440.1s (24.0min)

[7/8] Decode: qwen2.5-14b-int8

============================================================
  DECODE: qwen2.5-14b-int8
  时间: 2026-01-26 10:50:13
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[FAILED] qwen2.5-14b-int8 decode 失败! 返回码: 1, 耗时: 2152.7s

[8/8] Decode: qwen2.5-14b-fp8

============================================================
  DECODE: qwen2.5-14b-fp8
  时间: 2026-01-26 11:26:06
============================================================
  命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt,cusparselt --stage decode --sparsity 2_4,2_6,2_8,2_10 --M 64,128,256,512


[FAILED] qwen2.5-14b-fp8 decode 失败! 返回码: 1, 耗时: 2187.2s

============================================================
  最终总结
============================================================

  Prefill 结果:
    qwen2.5-7b-int8: ✗ FAILED
    qwen2.5-7b-fp8: ✗ FAILED
    qwen2.5-14b-int8: ✗ FAILED
    qwen2.5-14b-fp8: ✗ FAILED

  Decode 结果:
    llama3.2-1b-int8: ✓ SUCCESS
    llama3.2-1b-fp8: ✓ SUCCESS
    llama3.2-3b-int8: ✓ SUCCESS
    llama3.2-3b-fp8: ✓ SUCCESS
    qwen2.5-7b-int8: ✓ SUCCESS
    qwen2.5-7b-fp8: ✓ SUCCESS
    qwen2.5-14b-int8: ✗ FAILED
    qwen2.5-14b-fp8: ✗ FAILED

  统计:
    Prefill: 0/4 成功
    Decode:  6/8 成功
    总耗时:  37853.9s (10.51h)

  结束时间: 2026-01-26 12:02:33
============================================================

[INFO] 日志文件: /root/vllmbench/slidesparse/tools/recovery_bench_20260126_013139.log
[INFO] 状态文件: /root/vllmbench/slidesparse/tools/recovery_bench_20260126_013139_status.json
