======================================================================
SlideSparse Prepare Benchmark Log
Started: 2026-01-25 13:41:24
======================================================================

Hardware:
  GPU: NVIDIA GeForce RTX 5080 (cc120)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_134124.log

======================================================================
TASK 1: 模型下载
Started: 2026-01-25 13:41:24
======================================================================


------------------------------------------------------------
  下载: llama3.2-1b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-1b-int8


============================================================
  准备下载 1 个模型 (~1.9 GB)
============================================================

  - Llama3.2-1B-INT8 (1.9 GB)


============================================================
  下载: Llama3.2-1B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-1B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-1B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-1B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] llama3.2-1b-int8 下载完成 (3.3s)

------------------------------------------------------------
  下载: llama3.2-1b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-1b-fp8


============================================================
  准备下载 1 个模型 (~1.9 GB)
============================================================

  - Llama3.2-1B-FP8 (1.9 GB)


============================================================
  下载: Llama3.2-1B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-1B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-1B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-1B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] llama3.2-1b-fp8 下载完成 (3.2s)

------------------------------------------------------------
  下载: llama3.2-3b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-3b-int8


============================================================
  准备下载 1 个模型 (~4.0 GB)
============================================================

  - Llama3.2-3B-INT8 (4.0 GB)


============================================================
  下载: Llama3.2-3B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-3B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-3B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-3B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] llama3.2-3b-int8 下载完成 (3.2s)

------------------------------------------------------------
  下载: llama3.2-3b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model llama3.2-3b-fp8


============================================================
  准备下载 1 个模型 (~4.0 GB)
============================================================

  - Llama3.2-3B-FP8 (4.0 GB)


============================================================
  下载: Llama3.2-3B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Llama-3.2-3B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Llama3.2-3B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Llama3.2-3B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] llama3.2-3b-fp8 下载完成 (3.2s)

------------------------------------------------------------
  下载: qwen2.5-7b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-7b-int8


============================================================
  准备下载 1 个模型 (~8.1 GB)
============================================================

  - Qwen2.5-7B-INT8 (8.1 GB)


============================================================
  下载: Qwen2.5-7B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-7B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] qwen2.5-7b-int8 下载完成 (3.3s)

------------------------------------------------------------
  下载: qwen2.5-7b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-7b-fp8


============================================================
  准备下载 1 个模型 (~8.1 GB)
============================================================

  - Qwen2.5-7B-FP8 (8.1 GB)


============================================================
  下载: Qwen2.5-7B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-7B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-7B-FP8

[SUCCESS] 模型已存在: /root/vllmbench/checkpoints/Qwen2.5-7B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✗ Qwen2.5-14B-INT8 - not downloaded

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 6 已下载, 9 缺失
[INFO] Checkpoints 目录大小: 29G
[SUCCESS] qwen2.5-7b-fp8 下载完成 (3.3s)

------------------------------------------------------------
  下载: qwen2.5-14b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-14b-int8


Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]Downloading '.gitattributes' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'
Downloading 'model-00002-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/t9msAuTjAZjuQnmzGOwTjiptvIU=.91aa389be2ee0ada147eec7bc346ddd0dbc9c1eace9f233065ac225b22d98c15.incomplete'
Downloading 'model-00001-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/IO4xwqmZYzFmxznkwkiNSBwO1H0=.43b9886f741a9ffa73248db4607311b2b67cae71160f3b8da22ce9bf50b541b9.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.gitattributes

Fetching 16 files:   6%|▋         | 1/16 [00:00<00:06,  2.23it/s]Downloading 'added_tokens.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.482ced4679301bf287ebb310bdd1790eb4514232.incomplete'
Downloading 'merges.txt' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/PtHk0z_I45atnj23IIRhTExwT3w=.31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.incomplete'
Downloading 'README.md' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.2a9847668030cc8e2e3ca698eb0eb25e3a8b98d6.incomplete'
Downloading 'config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.0475d3a8eec471324033f7dab7861fe047ea3bbe.incomplete'
Downloading 'generation_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.2e995d693e130e3e92b87ff760bbe99ccdc54ea0.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/added_tokens.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/README.md
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/config.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/generation_config.json

Fetching 16 files:  31%|███▏      | 5/16 [00:00<00:00, 11.29it/s]Downloading 'model-00003-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/DaGOU-KRMVrY0aYktrsE34tL0Bs=.a95b39396a6de7716743660583d3d468fa31d103ebf1d1b444efe1ed8fc0f562.incomplete'
Downloading 'model-00004-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/-dFtyT7kcgbTHt1cy9JKqruJCR4=.961282a7d1b18000f29487a35cc8e5357190a5222db03c2434bdf25e6d97731f.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/merges.txt
Downloading 'model.safetensors.index.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.5ba6d9c419ff1c46aa0b188643370ae1c63b80cf.incomplete'
Downloading 'recipe.yaml' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/bnSmoKA-HyCrq3IlqBFOc_V8_a4=.2c73d48fd4321a955af603297216d4668904e7b2.incomplete'
Downloading 'special_tokens_map.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.ac23c0aaa2434523c494330aeb79c58395378103.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model.safetensors.index.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/recipe.yaml
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/special_tokens_map.json
Downloading 'tokenizer.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.bb73a25aba3c83c6c815a03a334b0440bd549f9a54fa3673e005f5532f6b32fe.incomplete'
Downloading 'tokenizer_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.8adf747ccaf85ff9587338cee6ed6be027b98210.incomplete'
Downloading 'vocab.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-INT8/.cache/huggingface/download/j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.4783fe10ac3adce15ac8f358ef5462739852c569.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/tokenizer_config.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/vocab.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/tokenizer.json

Fetching 16 files:  31%|███▏      | 5/16 [00:19<00:00, 11.29it/s]Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00004-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00002-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00001-of-00004.safetensors

Fetching 16 files:  44%|████▍     | 7/16 [02:18<03:55, 26.20s/it]Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-INT8/model-00003-of-00004.safetensors

Fetching 16 files:  56%|█████▋    | 9/16 [02:19<02:00, 17.15s/it]
Fetching 16 files: 100%|██████████| 16/16 [02:19<00:00,  8.73s/it]
/root/vllmbench/checkpoints/Qwen2.5-14B-INT8

============================================================
  准备下载 1 个模型 (~15.2 GB)
============================================================

  - Qwen2.5-14B-INT8 (15.2 GB)


============================================================
  下载: Qwen2.5-14B-INT8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-14B-Instruct-quantized.w8a8
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8

[INFO] 下载命令: hf download RedHatAI/Qwen2.5-14B-Instruct-quantized.w8a8 --local-dir /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[SUCCESS] 下载成功: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✓ Qwen2.5-14B-INT8 - 15.2 GB

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✗ Qwen2.5-14B-FP8 - not downloaded

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 7 已下载, 8 缺失
[INFO] Checkpoints 目录大小: 44G
[SUCCESS] qwen2.5-14b-int8 下载完成 (143.7s)

------------------------------------------------------------
  下载: qwen2.5-14b-fp8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/model_download.py --model qwen2.5-14b-fp8


Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]Downloading 'model-00001-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/IO4xwqmZYzFmxznkwkiNSBwO1H0=.06870e1a28f391e4af2cbe7a2f2c05e1f159384520461baf566619ed60d967eb.incomplete'
Downloading 'model-00002-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/t9msAuTjAZjuQnmzGOwTjiptvIU=.a8cd6b4e8fb6da282c98f4db14061646865514d940a684db3d1810f6775c89ce.incomplete'
Downloading '.gitattributes' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.52373fe24473b1aa44333d318f578ae6bf04b49b.incomplete'
Downloading 'generation_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.2e995d693e130e3e92b87ff760bbe99ccdc54ea0.incomplete'
Downloading 'model-00003-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/DaGOU-KRMVrY0aYktrsE34tL0Bs=.0180c47b8559b331c38bd977aa332514e17ad06c12ddc2794fa199e43c160c96.incomplete'
Downloading 'merges.txt' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/PtHk0z_I45atnj23IIRhTExwT3w=.31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.gitattributes

Fetching 15 files:   7%|▋         | 1/15 [00:00<00:11,  1.23it/s]Downloading 'added_tokens.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.482ced4679301bf287ebb310bdd1790eb4514232.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/generation_config.json
Downloading 'config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.b4be294e9a47de022ef6b4f65722d853dda12a26.incomplete'
Downloading 'model-00004-of-00004.safetensors' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/-dFtyT7kcgbTHt1cy9JKqruJCR4=.961282a7d1b18000f29487a35cc8e5357190a5222db03c2434bdf25e6d97731f.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/added_tokens.json

Fetching 15 files:  13%|█▎        | 2/15 [00:01<00:06,  2.12it/s]Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/merges.txt
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/config.json
Downloading 'model.safetensors.index.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.5ba6d9c419ff1c46aa0b188643370ae1c63b80cf.incomplete'
Downloading 'tokenizer.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.913950e4971737031da511cdd1b410daae4566f62eb845b3975bca5a102323d8.incomplete'
Downloading 'special_tokens_map.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.ac23c0aaa2434523c494330aeb79c58395378103.incomplete'
Downloading 'recipe.yaml' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/bnSmoKA-HyCrq3IlqBFOc_V8_a4=.044a5bfd17808741714fc0e6a5e95974475bd268.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/model.safetensors.index.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/special_tokens_map.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/recipe.yaml
Downloading 'tokenizer_config.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.8adf747ccaf85ff9587338cee6ed6be027b98210.incomplete'
Downloading 'vocab.json' to '/root/vllmbench/checkpoints/Qwen2.5-14B-FP8/.cache/huggingface/download/j3m-Hy6QvBddw8RXA1uSWl1AJ0c=.4783fe10ac3adce15ac8f358ef5462739852c569.incomplete'
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/tokenizer_config.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/vocab.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/tokenizer.json
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/model-00004-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/model-00002-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/model-00003-of-00004.safetensors
Download complete. Moving file to /root/vllmbench/checkpoints/Qwen2.5-14B-FP8/model-00001-of-00004.safetensors

Fetching 15 files:  40%|████      | 6/15 [02:21<04:04, 27.11s/it]
Fetching 15 files: 100%|██████████| 15/15 [02:21<00:00,  9.41s/it]
/root/vllmbench/checkpoints/Qwen2.5-14B-FP8

============================================================
  准备下载 1 个模型 (~15.2 GB)
============================================================

  - Qwen2.5-14B-FP8 (15.2 GB)


============================================================
  下载: Qwen2.5-14B-FP8
============================================================

[INFO] HuggingFace: RedHatAI/Qwen2.5-14B-Instruct-FP8-dynamic
[INFO] 本地目录: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8

[INFO] 下载命令: hf download RedHatAI/Qwen2.5-14B-Instruct-FP8-dynamic --local-dir /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[SUCCESS] 下载成功: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8


============================================================
  下载完成
============================================================

成功: 1/1

============================================================
  模型下载状态
============================================================


INT8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-INT8 - not downloaded
  ✓ Llama3.2-1B-INT8 - 1.9 GB
  ✗ Qwen2.5-1.5B-INT8 - not downloaded
  ✗ Qwen2.5-3B-INT8 - not downloaded
  ✓ Llama3.2-3B-INT8 - 4.1 GB
  ✓ Qwen2.5-7B-INT8 - 8.1 GB
  ✓ Qwen2.5-14B-INT8 - 15.2 GB

FP8 模型:
----------------------------------------
  ✗ Qwen2.5-0.5B-FP8 - not downloaded
  ✓ Llama3.2-1B-FP8 - 1.9 GB
  ✗ Qwen2.5-1.5B-FP8 - not downloaded
  ✗ Qwen2.5-3B-FP8 - not downloaded
  ✓ Llama3.2-3B-FP8 - 4.1 GB
  ✓ Qwen2.5-7B-FP8 - 8.1 GB
  ✓ Qwen2.5-14B-FP8 - 15.2 GB

BF16 模型:
----------------------------------------
  ✗ BitNet-2B-BF16 - not downloaded

----------------------------------------
总计: 8 已下载, 7 缺失
[INFO] Checkpoints 目录大小: 59G
[SUCCESS] qwen2.5-14b-fp8 下载完成 (145.3s)

[INFO] 下载统计: 成功 8, 失败 0

----------------------------------------------------------------------
TASK 1: 模型下载 - SUCCESS
Duration: 308.6 seconds (5.1 minutes)
----------------------------------------------------------------------


======================================================================
TASK 2: 模型转换 (SlideSparse)
Started: 2026-01-25 13:46:33
======================================================================


------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 25.20s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_4 转换完成 (29.1s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 28.14s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_6 转换完成 (31.5s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 23.40s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_8 转换完成 (26.7s)

------------------------------------------------------------
  转换: llama3.2-1b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 27.18s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-1b-int8 2_10 转换完成 (30.8s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 8192] -> [2048, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 2048] -> [8192, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [2048, 2048] -> [2048, 2048]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 2048] -> [512, 2048]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 22.88s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_4 转换完成 (26.1s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 8192] -> [2048, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 2048] -> [8192, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [2048, 2048] -> [2048, 2752]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 2048] -> [512, 2752]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 27.48s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_6 转换完成 (30.9s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 8192] -> [2048, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 2048] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [2048, 2048] -> [2048, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 2048] -> [512, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 25.39s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_8 转换完成 (28.7s)

------------------------------------------------------------
  转换: llama3.2-1b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-1b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-1B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[2048, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 8192] -> [2048, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 2048] -> [8192, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[2048, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [2048, 2048] -> [2048, 3296]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 2048], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 2048] -> [512, 3296]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 112 layers
[INFO] Skipped: 147 layers
[INFO] Time: 25.95s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-1b-fp8 2_10 转换完成 (29.3s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 46.75s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_4 转换完成 (50.2s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 46.17s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_6 转换完成 (49.6s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 48.78s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_8 转换完成 (52.2s)

------------------------------------------------------------
  转换: llama3.2-3b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 54.33s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-3b-int8 2_10 转换完成 (57.8s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 8192] -> [3072, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [8192, 3072] -> [8192, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3072, 3072] -> [3072, 3072]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 3072] -> [1024, 3072]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 44.63s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_4 转换完成 (48.2s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 8192] -> [3072, 10944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [8192, 3072] -> [8192, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3072, 3072] -> [3072, 4096]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 3072] -> [1024, 4096]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 47.37s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_6 转换完成 (50.8s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 8192] -> [3072, 12288]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [8192, 3072] -> [8192, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3072, 3072] -> [3072, 4608]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 3072] -> [1024, 4608]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 47.16s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_8 转换完成 (50.8s)

------------------------------------------------------------
  转换: llama3.2-3b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model llama3.2-3b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Llama3.2-3B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: tokenizer.json, special_tokens_map.json, tokenizer_config.json, config.json, .gitattributes...

[INFO] Processing file: model.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3072, 8192], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 8192] -> [3072, 13120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[8192, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [8192, 3072] -> [8192, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3072, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3072, 3072] -> [3072, 4928]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 3072], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 3072] -> [1024, 4928]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10/model.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 255 layers
[INFO] Time: 51.81s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] llama3.2-3b-fp8 2_10 转换完成 (55.3s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 77.84s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_4 转换完成 (81.3s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 88.46s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_6 转换完成 (92.2s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 85.57s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_8 转换完成 (89.0s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 91.61s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_10 转换完成 (95.1s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 77.48s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_4 转换完成 (80.8s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 90.28s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_6 转换完成 (93.8s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 82.00s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_8 转换完成 (85.5s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 88.67s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_10 转换完成 (92.1s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 150.05s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_4 转换完成 (153.4s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 160.75s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_6 转换完成 (164.1s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 158.30s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_8 转换完成 (161.7s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 165.45s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_10 转换完成 (168.7s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 176.79s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_4 转换完成 (182.3s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 164.56s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_6 转换完成 (167.8s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 153.73s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_8 转换完成 (157.1s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: model.safetensors.index.json, tokenizer.json, special_tokens_map.json, tokenizer_config.json, added_tokens.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 182.16s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_10 转换完成 (185.5s)

[INFO] 转换统计: 成功 32, 失败 0

----------------------------------------------------------------------
TASK 2: 模型转换 (SlideSparse) - SUCCESS
Duration: 2698.4 seconds (45.0 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: 离线粗调优 (cuBLAS + quant_only)
Started: 2026-01-25 14:31:33
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 256,1024,4096,16384,32768 --Lmax 10 --warmup 10 --repeat 50 --kernels 1,0,0,0,1


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA GeForce RTX 5080 (cc120)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [256, 1024, 4096, 16384, 32768]
  Warmup/Repeat: 10/50

  Kernel 调优:
    ✓ cuBLASLt GEMM
    ✗ cuSPARSELt GEMM
    ✗ Triton Dequant + Bias
    ✗ Triton Quant + Slide
    ✓ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-7B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-14B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

============================================================
  Step 2: cuSPARSELt GEMM [跳过]
============================================================


============================================================
  Step 3: Triton Dequant + Bias [跳过]
============================================================


============================================================
  Step 4: Triton Quant + Slide [跳过]
============================================================


============================================================
  Step 5: Triton Quant Only
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

============================================================
  调优总结
============================================================

  cuBLASLt GEMM: [全部成功] (8/8)
  cuSPARSELt GEMM: [跳过]
  Triton Dequant + Bias: [跳过]
  Triton Quant + Slide: [跳过]
  Triton Quant Only: [全部成功] (4/4)

总计: 成功 12, 失败 0, 跳过 3

----------------------------------------------------------------------
TASK 3: 离线粗调优 (cuBLAS + quant_only) - SUCCESS
Duration: 1034.5 seconds (17.2 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: 离线细调优 (cuSPARSE + Triton)
Started: 2026-01-25 14:48:47
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --Lmax 10 --warmup 25 --repeat 100 --kernels 0,1,1,1,0


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA GeForce RTX 5080 (cc120)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
  Warmup/Repeat: 25/100

  Kernel 调优:
    ✗ cuBLASLt GEMM
    ✓ cuSPARSELt GEMM
    ✓ Triton Dequant + Bias
    ✓ Triton Quant + Slide
    ✗ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM [跳过]
============================================================


============================================================
  Step 2: cuSPARSELt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (int8) 失败:
 有效: 1 (rerank 后)
    NK 3/16: (37888, 3584)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 4/16: (3584, 18944)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 5/16: (4608, 4800)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 6/16: (3584, 4800)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 7/16: (37888, 4800)
      → 算法数: 2, 有效: 2 (rerank 后)
    NK 8/16: (3584, 25280)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 9/16: (4608, 5376)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 10/16: (3584, 5376)
      → 算法数: 2, 有效: 1 (rerank 后)
    NK 11/16: (37888, 5376)
      → 算法数: 2, 有效: 2 (rerank 后)
    NK 12/16: (3584, 28416)
Traceback (most recent call last):
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 737, in <module>
    main()
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 701, in main
    ret = run_search(
          ^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 523, in run_search
    A_transposed, A_q = prepare_activation(A, dtype)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py", line 225, in prepare_activation
    A_q, _ = quantize_int8(A_bf16)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/slidesparse/search/utils.py", line 165, in quantize_int8
    q = (x * scale).round().clamp(-128, 127).to(torch.int8)
        ^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.47 GiB. GPU 0 has a total capacity of 15.46 GiB of which 3.07 GiB is free. Including non-PyTorch memory, this process has 12.17 GiB memory in use. Of the allocated memory 7.62 GiB is allocated by PyTorch, and 4.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16

======================================================================
收到中断信号 (signal 2)
======================================================================
[INFO] 状态已保存: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_134124_status.json
