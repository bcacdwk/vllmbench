======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-25 18:58:06
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-7b-int8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: A100
  Compute Capability: cc80
  VRAM: 79.3 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-7B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:58:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=334142) WARNING 01-25 19:06:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.81 requests/s, 10164.96 total tokens/s, 19.81 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 18:58:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:58:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 18:58:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 18:58:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:58:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:58:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:58:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:58:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:58:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:58:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 18:58:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 18:58:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 18:58:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:58:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:58:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:58:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:58:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=334142) [2026-01-25 18:58:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=334142) [2026-01-25 18:58:29] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=334142) [2026-01-25 18:58:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=334142) [2026-01-25 18:58:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=334142) [2026-01-25 18:58:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=334142) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=334142) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [04:36<04:36, 276.85s/it]
(EngineCore_DP0 pid=334142) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [07:47<00:00, 226.08s/it]
(EngineCore_DP0 pid=334142) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [07:47<00:00, 233.69s/it]
(EngineCore_DP0 pid=334142) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=334142) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]
(EngineCore_DP0 pid=334142) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.58it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.56it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  36%|███▌      | 46/128 [00:00<00:00, 459.96it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 460.87it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 466.83it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:48,  2.64it/s, est. speed input: 1353.46 toks/s, output: 2.64 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:13,  9.19it/s, est. speed input: 3968.32 toks/s, output: 7.75 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 13.15it/s, est. speed input: 5436.57 toks/s, output: 10.62 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:07, 15.62it/s, est. speed input: 6365.86 toks/s, output: 12.43 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:06, 17.49it/s, est. speed input: 7059.48 toks/s, output: 13.79 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:05, 19.05it/s, est. speed input: 7623.84 toks/s, output: 14.89 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:05, 19.78it/s, est. speed input: 8008.48 toks/s, output: 15.64 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 20.61it/s, est. speed input: 8359.43 toks/s, output: 16.33 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 21.10it/s, est. speed input: 8634.36 toks/s, output: 16.86 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 21.38it/s, est. speed input: 8856.85 toks/s, output: 17.30 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 21.11it/s, est. speed input: 8993.58 toks/s, output: 17.57 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:04, 21.11it/s, est. speed input: 9128.71 toks/s, output: 17.83 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:04, 21.40it/s, est. speed input: 9274.56 toks/s, output: 18.11 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:04, 21.75it/s, est. speed input: 9414.24 toks/s, output: 18.39 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:03, 21.70it/s, est. speed input: 9512.29 toks/s, output: 18.58 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 21.97it/s, est. speed input: 9625.06 toks/s, output: 18.80 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 22.11it/s, est. speed input: 9721.23 toks/s, output: 18.99 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 21.97it/s, est. speed input: 9790.64 toks/s, output: 19.12 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 21.66it/s, est. speed input: 9837.86 toks/s, output: 19.21 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:03, 21.67it/s, est. speed input: 9896.41 toks/s, output: 19.33 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 21.83it/s, est. speed input: 9960.35 toks/s, output: 19.45 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:02, 22.04it/s, est. speed input: 10024.50 toks/s, output: 19.58 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:02, 22.19it/s, est. speed input: 10083.96 toks/s, output: 19.70 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 22.26it/s, est. speed input: 10137.15 toks/s, output: 19.80 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 22.14it/s, est. speed input: 10176.53 toks/s, output: 19.88 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 21.96it/s, est. speed input: 10207.93 toks/s, output: 19.94 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 21.89it/s, est. speed input: 10239.77 toks/s, output: 20.00 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 22.02it/s, est. speed input: 10278.99 toks/s, output: 20.08 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 21.47it/s, est. speed input: 10282.63 toks/s, output: 20.08 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:01, 21.70it/s, est. speed input: 10317.30 toks/s, output: 20.15 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 21.90it/s, est. speed input: 10351.12 toks/s, output: 20.22 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 21.71it/s, est. speed input: 10367.79 toks/s, output: 20.25 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 21.89it/s, est. speed input: 10397.39 toks/s, output: 20.31 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 21.90it/s, est. speed input: 10420.41 toks/s, output: 20.35 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 21.94it/s, est. speed input: 10443.82 toks/s, output: 20.40 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 21.94it/s, est. speed input: 10464.64 toks/s, output: 20.44 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:00, 22.10it/s, est. speed input: 10490.69 toks/s, output: 20.49 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 22.27it/s, est. speed input: 10517.92 toks/s, output: 20.54 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 22.35it/s, est. speed input: 10542.12 toks/s, output: 20.59 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 22.39it/s, est. speed input: 10564.67 toks/s, output: 20.63 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 22.31it/s, est. speed input: 10582.63 toks/s, output: 20.67 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 21.68it/s, est. speed input: 10578.38 toks/s, output: 20.66 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 21.83it/s, est. speed input: 10595.70 toks/s, output: 20.69 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 21.83it/s, est. speed input: 10597.30 toks/s, output: 20.70 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 20.70it/s, est. speed input: 10597.30 toks/s, output: 20.70 toks/s]
[rank0]:[W125 19:06:53.251280141 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 529.0s

测试结果:
  Requests/s:   19.81
  Tokens/s:     10164.96
  Total Reqs:   128
  Elapsed:      6.46s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     10145.15

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:07:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=341910) WARNING 01-25 19:07:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.57 requests/s, 18008.70 total tokens/s, 17.57 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 19:07:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:07:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:07:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:07:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:07:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:07:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:07:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:07:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:07:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=341910) [2026-01-25 19:07:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=341910) [2026-01-25 19:07:13] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=341910) [2026-01-25 19:07:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=341910) [2026-01-25 19:07:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=341910) [2026-01-25 19:07:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=341910) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=341910) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=341910) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=341910) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.75it/s]
(EngineCore_DP0 pid=341910) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=341910) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.06it/s]
(EngineCore_DP0 pid=341910) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.66it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 245.92it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 258.06it/s]
Adding requests:  62%|██████▎   | 80/128 [00:00<00:00, 267.98it/s]
Adding requests:  84%|████████▍ | 108/128 [00:00<00:00, 267.40it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 264.75it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:02, 54.84it/s, est. speed input: 56163.00 toks/s, output: 54.84 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:04, 26.78it/s, est. speed input: 30058.13 toks/s, output: 29.35 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:04, 23.05it/s, est. speed input: 26353.13 toks/s, output: 25.73 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:04, 21.51it/s, est. speed input: 24848.79 toks/s, output: 24.27 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 20.46it/s, est. speed input: 23834.16 toks/s, output: 23.28 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 19.74it/s, est. speed input: 23098.11 toks/s, output: 22.56 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 19.22it/s, est. speed input: 22535.31 toks/s, output: 22.01 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 18.97it/s, est. speed input: 22236.07 toks/s, output: 21.71 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 18.76it/s, est. speed input: 21977.87 toks/s, output: 21.46 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:04, 18.60it/s, est. speed input: 21756.05 toks/s, output: 21.25 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:04, 18.44it/s, est. speed input: 21552.47 toks/s, output: 21.05 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:04, 18.34it/s, est. speed input: 21376.33 toks/s, output: 20.88 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 18.21it/s, est. speed input: 21207.46 toks/s, output: 20.71 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 18.16it/s, est. speed input: 21064.91 toks/s, output: 20.57 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 18.12it/s, est. speed input: 20936.52 toks/s, output: 20.45 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 18.14it/s, est. speed input: 20828.33 toks/s, output: 20.34 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 18.07it/s, est. speed input: 20715.73 toks/s, output: 20.23 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 18.06it/s, est. speed input: 20619.24 toks/s, output: 20.14 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:04, 18.05it/s, est. speed input: 20529.75 toks/s, output: 20.05 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 18.06it/s, est. speed input: 20451.41 toks/s, output: 19.97 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:03, 18.02it/s, est. speed input: 20371.33 toks/s, output: 19.89 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 18.03it/s, est. speed input: 20301.57 toks/s, output: 19.83 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.98it/s, est. speed input: 20230.04 toks/s, output: 19.76 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 18.00it/s, est. speed input: 20170.11 toks/s, output: 19.70 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.98it/s, est. speed input: 20110.22 toks/s, output: 19.64 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 18.01it/s, est. speed input: 20059.41 toks/s, output: 19.59 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.99it/s, est. speed input: 20007.58 toks/s, output: 19.54 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 18.01it/s, est. speed input: 19961.23 toks/s, output: 19.49 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 18.01it/s, est. speed input: 19917.41 toks/s, output: 19.45 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 18.05it/s, est. speed input: 19879.78 toks/s, output: 19.41 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 18.04it/s, est. speed input: 19840.53 toks/s, output: 19.38 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 18.03it/s, est. speed input: 19802.20 toks/s, output: 19.34 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 18.04it/s, est. speed input: 19768.49 toks/s, output: 19.31 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 18.01it/s, est. speed input: 19732.72 toks/s, output: 19.27 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 18.04it/s, est. speed input: 19703.33 toks/s, output: 19.24 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 18.04it/s, est. speed input: 19673.42 toks/s, output: 19.21 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:02, 18.04it/s, est. speed input: 19645.43 toks/s, output: 19.18 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:01, 18.03it/s, est. speed input: 19617.40 toks/s, output: 19.16 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 18.03it/s, est. speed input: 19590.88 toks/s, output: 19.13 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 18.01it/s, est. speed input: 19564.44 toks/s, output: 19.11 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 18.03it/s, est. speed input: 19541.91 toks/s, output: 19.08 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 18.02it/s, est. speed input: 19518.47 toks/s, output: 19.06 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 18.02it/s, est. speed input: 19496.34 toks/s, output: 19.04 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 18.04it/s, est. speed input: 19476.45 toks/s, output: 19.02 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 18.06it/s, est. speed input: 19458.15 toks/s, output: 19.00 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:01, 18.04it/s, est. speed input: 19437.62 toks/s, output: 18.98 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:05<00:00, 18.05it/s, est. speed input: 19420.10 toks/s, output: 18.96 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 18.03it/s, est. speed input: 19401.05 toks/s, output: 18.95 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 18.03it/s, est. speed input: 19383.90 toks/s, output: 18.93 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 18.01it/s, est. speed input: 19365.57 toks/s, output: 18.91 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 18.01it/s, est. speed input: 19349.32 toks/s, output: 18.90 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.99it/s, est. speed input: 19332.57 toks/s, output: 18.88 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 18.02it/s, est. speed input: 19318.51 toks/s, output: 18.87 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 18.00it/s, est. speed input: 19302.78 toks/s, output: 18.85 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 18.03it/s, est. speed input: 19289.82 toks/s, output: 18.84 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 17.99it/s, est. speed input: 19274.19 toks/s, output: 18.82 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 17.99it/s, est. speed input: 19274.19 toks/s, output: 18.82 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.82it/s, est. speed input: 19274.19 toks/s, output: 18.82 toks/s]
[rank0]:[W125 19:07:48.299791250 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 55.0s

测试结果:
  Requests/s:   17.57
  Tokens/s:     18008.70
  Total Reqs:   128
  Elapsed:      7.29s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     17991.13

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:08:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=342939) WARNING 01-25 19:08:18 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.35 requests/s, 19829.94 total tokens/s, 19.35 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 19:08:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:08:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:08:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:08:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:08:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:08:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:08:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:08:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:08:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:08:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:08:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:08:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:08:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=342939) [2026-01-25 19:08:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=342939) [2026-01-25 19:08:09] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=342939) [2026-01-25 19:08:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=342939) [2026-01-25 19:08:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=342939) [2026-01-25 19:08:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=342939) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=342939) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.77it/s]
(EngineCore_DP0 pid=342939) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
(EngineCore_DP0 pid=342939) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.73it/s]
(EngineCore_DP0 pid=342939) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=342939) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  9.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  9.67it/s]
(EngineCore_DP0 pid=342939) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  9.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  9.96it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 28/256 [00:00<00:00, 272.28it/s]
Adding requests:  22%|██▏       | 57/256 [00:00<00:00, 281.43it/s]
Adding requests:  34%|███▎      | 86/256 [00:00<00:00, 278.79it/s]
Adding requests:  45%|████▍     | 114/256 [00:00<00:00, 274.09it/s]
Adding requests:  56%|█████▋    | 144/256 [00:00<00:00, 282.28it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 289.91it/s]
Adding requests:  80%|████████  | 205/256 [00:00<00:00, 289.54it/s]
Adding requests:  92%|█████████▏| 236/256 [00:00<00:00, 294.36it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 285.28it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 18/256 [00:00<00:01, 172.37it/s, est. speed input: 176545.81 toks/s, output: 172.38 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:01<00:07, 30.52it/s, est. speed input: 35655.83 toks/s, output: 34.82 toks/s]   
Processed prompts:  18%|█▊        | 45/256 [00:01<00:07, 27.28it/s, est. speed input: 31839.13 toks/s, output: 31.09 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:01<00:08, 25.03it/s, est. speed input: 29719.28 toks/s, output: 29.02 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:08, 22.48it/s, est. speed input: 27752.25 toks/s, output: 27.10 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:08, 21.81it/s, est. speed input: 27032.43 toks/s, output: 26.40 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:02<00:08, 22.75it/s, est. speed input: 27142.42 toks/s, output: 26.51 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:09, 20.48it/s, est. speed input: 26159.59 toks/s, output: 25.55 toks/s]
Processed prompts:  27%|██▋       | 69/256 [00:02<00:08, 21.86it/s, est. speed input: 26288.80 toks/s, output: 25.67 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:09, 19.50it/s, est. speed input: 25471.19 toks/s, output: 24.87 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:02<00:08, 21.27it/s, est. speed input: 25617.34 toks/s, output: 25.02 toks/s]
Processed prompts:  30%|███       | 78/256 [00:03<00:09, 18.94it/s, est. speed input: 24927.02 toks/s, output: 24.34 toks/s]
Processed prompts:  32%|███▏      | 81/256 [00:03<00:08, 20.93it/s, est. speed input: 25073.99 toks/s, output: 24.49 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:09, 18.56it/s, est. speed input: 24463.77 toks/s, output: 23.89 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:03<00:08, 20.73it/s, est. speed input: 24617.35 toks/s, output: 24.04 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:09, 18.42it/s, est. speed input: 24088.40 toks/s, output: 23.52 toks/s]
Processed prompts:  36%|███▋      | 93/256 [00:03<00:07, 20.64it/s, est. speed input: 24237.01 toks/s, output: 23.67 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:08, 18.37it/s, est. speed input: 23771.58 toks/s, output: 23.21 toks/s]
Processed prompts:  39%|███▊      | 99/256 [00:04<00:07, 20.61it/s, est. speed input: 23916.36 toks/s, output: 23.36 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:04<00:08, 18.27it/s, est. speed input: 23487.98 toks/s, output: 22.94 toks/s]
Processed prompts:  41%|████      | 105/256 [00:04<00:07, 20.55it/s, est. speed input: 23630.35 toks/s, output: 23.08 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:08, 18.28it/s, est. speed input: 23249.03 toks/s, output: 22.70 toks/s]
Processed prompts:  43%|████▎     | 111/256 [00:04<00:07, 20.57it/s, est. speed input: 23387.96 toks/s, output: 22.84 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:05<00:07, 18.28it/s, est. speed input: 23039.46 toks/s, output: 22.50 toks/s]
Processed prompts:  46%|████▌     | 117/256 [00:05<00:06, 20.56it/s, est. speed input: 23173.36 toks/s, output: 22.63 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:07, 18.26it/s, est. speed input: 22851.48 toks/s, output: 22.32 toks/s]
Processed prompts:  48%|████▊     | 123/256 [00:05<00:06, 20.56it/s, est. speed input: 22982.88 toks/s, output: 22.44 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:05<00:07, 18.26it/s, est. speed input: 22685.57 toks/s, output: 22.15 toks/s]
Processed prompts:  50%|█████     | 129/256 [00:05<00:06, 20.53it/s, est. speed input: 22809.25 toks/s, output: 22.27 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:06, 18.26it/s, est. speed input: 22535.55 toks/s, output: 22.01 toks/s]
Processed prompts:  53%|█████▎    | 135/256 [00:06<00:05, 20.57it/s, est. speed input: 22659.56 toks/s, output: 22.13 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:06<00:06, 18.22it/s, est. speed input: 22397.89 toks/s, output: 21.87 toks/s]
Processed prompts:  55%|█████▌    | 141/256 [00:06<00:05, 20.49it/s, est. speed input: 22513.71 toks/s, output: 21.99 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:06, 18.19it/s, est. speed input: 22270.47 toks/s, output: 21.75 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:06<00:05, 20.49it/s, est. speed input: 22385.46 toks/s, output: 21.86 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:06<00:05, 18.23it/s, est. speed input: 22160.59 toks/s, output: 21.64 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:07<00:05, 20.54it/s, est. speed input: 22272.77 toks/s, output: 21.75 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:05, 18.27it/s, est. speed input: 22062.17 toks/s, output: 21.55 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:07<00:04, 20.54it/s, est. speed input: 22168.89 toks/s, output: 21.65 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:07<00:05, 18.22it/s, est. speed input: 21964.42 toks/s, output: 21.45 toks/s]
Processed prompts:  64%|██████▍   | 165/256 [00:07<00:04, 20.50it/s, est. speed input: 22068.42 toks/s, output: 21.55 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:07<00:04, 18.24it/s, est. speed input: 21879.10 toks/s, output: 21.37 toks/s]
Processed prompts:  67%|██████▋   | 171/256 [00:07<00:04, 20.51it/s, est. speed input: 21979.19 toks/s, output: 21.46 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:08<00:04, 18.25it/s, est. speed input: 21799.76 toks/s, output: 21.29 toks/s]
Processed prompts:  69%|██████▉   | 177/256 [00:08<00:03, 20.54it/s, est. speed input: 21898.51 toks/s, output: 21.39 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:08<00:04, 18.22it/s, est. speed input: 21723.66 toks/s, output: 21.21 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:08<00:03, 20.46it/s, est. speed input: 21816.80 toks/s, output: 21.31 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:08<00:03, 18.22it/s, est. speed input: 21653.22 toks/s, output: 21.15 toks/s]
Processed prompts:  74%|███████▍  | 189/256 [00:08<00:03, 20.46it/s, est. speed input: 21743.96 toks/s, output: 21.23 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:09<00:03, 18.22it/s, est. speed input: 21587.60 toks/s, output: 21.08 toks/s]
Processed prompts:  76%|███████▌  | 195/256 [00:09<00:02, 20.51it/s, est. speed input: 21679.13 toks/s, output: 21.17 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:09<00:03, 18.20it/s, est. speed input: 21526.48 toks/s, output: 21.02 toks/s]
Processed prompts:  79%|███████▊  | 201/256 [00:09<00:02, 20.47it/s, est. speed input: 21614.11 toks/s, output: 21.11 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:09<00:02, 19.83it/s, est. speed input: 21568.67 toks/s, output: 21.06 toks/s]
Processed prompts:  81%|████████  | 207/256 [00:09<00:02, 21.86it/s, est. speed input: 21652.46 toks/s, output: 21.14 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:09<00:02, 18.95it/s, est. speed input: 21510.16 toks/s, output: 21.01 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:10<00:02, 21.14it/s, est. speed input: 21593.65 toks/s, output: 21.09 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:10<00:02, 18.60it/s, est. speed input: 21459.38 toks/s, output: 20.96 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:10<00:01, 20.86it/s, est. speed input: 21541.79 toks/s, output: 21.04 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:10<00:01, 18.39it/s, est. speed input: 21408.96 toks/s, output: 20.91 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:10<00:01, 20.63it/s, est. speed input: 21487.67 toks/s, output: 20.98 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:10<00:01, 18.29it/s, est. speed input: 21360.95 toks/s, output: 20.86 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:11<00:01, 20.57it/s, est. speed input: 21438.86 toks/s, output: 20.94 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:11<00:01, 18.30it/s, est. speed input: 21318.89 toks/s, output: 20.82 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:11<00:00, 20.54it/s, est. speed input: 21393.95 toks/s, output: 20.89 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:11<00:00, 18.28it/s, est. speed input: 21277.63 toks/s, output: 20.78 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:11<00:00, 20.53it/s, est. speed input: 21351.29 toks/s, output: 20.85 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:11<00:00, 18.24it/s, est. speed input: 21237.12 toks/s, output: 20.74 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:11<00:00, 20.50it/s, est. speed input: 21309.26 toks/s, output: 20.81 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:12<00:00, 18.20it/s, est. speed input: 21197.75 toks/s, output: 20.70 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:12<00:00, 20.51it/s, est. speed input: 21269.94 toks/s, output: 20.77 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.51it/s, est. speed input: 21254.25 toks/s, output: 20.76 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:12<00:00, 20.76it/s, est. speed input: 21254.25 toks/s, output: 20.76 toks/s]
[rank0]:[W125 19:08:50.429578088 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 62.2s

测试结果:
  Requests/s:   19.35
  Tokens/s:     19829.94
  Total Reqs:   256
  Elapsed:      13.23s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     19810.60

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:09:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=344070) WARNING 01-25 19:09:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.06 requests/s, 20563.23 total tokens/s, 20.06 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 19:09:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:09:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:09:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:09:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:09:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:09:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:09:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:09:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:09:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:09:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:09:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:09:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:09:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:09:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:09:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:09:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:09:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=344070) [2026-01-25 19:09:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=344070) [2026-01-25 19:09:12] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=344070) [2026-01-25 19:09:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=344070) [2026-01-25 19:09:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=344070) [2026-01-25 19:09:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=344070) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=344070) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.83it/s]
(EngineCore_DP0 pid=344070) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.75it/s]
(EngineCore_DP0 pid=344070) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=344070) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=344070) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 10.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.73it/s]
(EngineCore_DP0 pid=344070) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 10.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 10.41it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 27/512 [00:00<00:01, 266.24it/s]
Adding requests:  11%|█         | 56/512 [00:00<00:01, 280.05it/s]
Adding requests:  17%|█▋        | 86/512 [00:00<00:01, 285.74it/s]
Adding requests:  22%|██▏       | 115/512 [00:00<00:01, 275.23it/s]
Adding requests:  28%|██▊       | 145/512 [00:00<00:01, 280.82it/s]
Adding requests:  34%|███▍      | 175/512 [00:00<00:01, 285.73it/s]
Adding requests:  40%|████      | 207/512 [00:00<00:01, 293.79it/s]
Adding requests:  46%|████▋     | 238/512 [00:00<00:00, 298.23it/s]
Adding requests:  52%|█████▏    | 268/512 [00:00<00:00, 292.46it/s]
Adding requests:  58%|█████▊    | 298/512 [00:01<00:00, 292.91it/s]
Adding requests:  64%|██████▍   | 328/512 [00:01<00:00, 285.22it/s]
Adding requests:  70%|███████   | 359/512 [00:01<00:00, 291.13it/s]
Adding requests:  76%|███████▋  | 391/512 [00:01<00:00, 298.15it/s]
Adding requests:  83%|████████▎ | 424/512 [00:01<00:00, 306.30it/s]
Adding requests:  89%|████████▉ | 455/512 [00:01<00:00, 304.10it/s]
Adding requests:  95%|█████████▌| 488/512 [00:01<00:00, 311.56it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 296.08it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:00<00:01, 242.91it/s, est. speed input: 248766.44 toks/s, output: 242.92 toks/s]
Processed prompts:  12%|█▏        | 59/512 [00:01<00:12, 37.63it/s, est. speed input: 45125.20 toks/s, output: 44.07 toks/s]   
Processed prompts:  14%|█▍        | 71/512 [00:01<00:14, 30.63it/s, est. speed input: 37518.47 toks/s, output: 36.64 toks/s]
Processed prompts:  15%|█▌        | 79/512 [00:02<00:15, 27.71it/s, est. speed input: 34605.27 toks/s, output: 33.79 toks/s]
Processed prompts:  17%|█▋        | 85/512 [00:02<00:15, 28.09it/s, est. speed input: 34299.85 toks/s, output: 33.50 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:18, 23.12it/s, est. speed input: 31378.28 toks/s, output: 30.64 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:18, 22.55it/s, est. speed input: 30685.34 toks/s, output: 29.97 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:18, 22.03it/s, est. speed input: 30080.12 toks/s, output: 29.37 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:19, 21.56it/s, est. speed input: 29536.23 toks/s, output: 28.84 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:19, 21.17it/s, est. speed input: 29050.68 toks/s, output: 28.37 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:19, 20.88it/s, est. speed input: 28619.84 toks/s, output: 27.95 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:19, 20.63it/s, est. speed input: 28224.18 toks/s, output: 27.56 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:19, 20.47it/s, est. speed input: 27869.60 toks/s, output: 27.22 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:19, 20.30it/s, est. speed input: 27537.42 toks/s, output: 26.89 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:19, 20.22it/s, est. speed input: 27241.14 toks/s, output: 26.60 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:18, 20.15it/s, est. speed input: 26965.10 toks/s, output: 26.33 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:18, 20.08it/s, est. speed input: 26708.13 toks/s, output: 26.08 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:18, 20.10it/s, est. speed input: 26481.84 toks/s, output: 25.86 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:18, 20.09it/s, est. speed input: 26268.85 toks/s, output: 25.65 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:18, 20.04it/s, est. speed input: 26063.60 toks/s, output: 25.45 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:18, 20.04it/s, est. speed input: 25876.97 toks/s, output: 25.27 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:17, 20.03it/s, est. speed input: 25701.93 toks/s, output: 25.10 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:17, 20.03it/s, est. speed input: 25537.95 toks/s, output: 24.94 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:17, 20.01it/s, est. speed input: 25381.93 toks/s, output: 24.79 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:17, 19.99it/s, est. speed input: 25233.89 toks/s, output: 24.64 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:17, 20.00it/s, est. speed input: 25097.21 toks/s, output: 24.51 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:16, 19.99it/s, est. speed input: 24967.38 toks/s, output: 24.38 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:16, 20.02it/s, est. speed input: 24847.59 toks/s, output: 24.27 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:16, 20.02it/s, est. speed input: 24732.27 toks/s, output: 24.15 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:07<00:16, 20.03it/s, est. speed input: 24623.67 toks/s, output: 24.05 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:16, 20.01it/s, est. speed input: 24518.31 toks/s, output: 23.94 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:15, 20.00it/s, est. speed input: 24418.56 toks/s, output: 23.85 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:15, 20.03it/s, est. speed input: 24327.09 toks/s, output: 23.76 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:14, 21.45it/s, est. speed input: 24363.84 toks/s, output: 23.79 toks/s]
Processed prompts:  40%|████      | 206/512 [00:08<00:14, 20.98it/s, est. speed input: 24272.98 toks/s, output: 23.70 toks/s]
Processed prompts:  41%|████      | 210/512 [00:08<00:14, 20.66it/s, est. speed input: 24186.04 toks/s, output: 23.62 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:09<00:14, 20.43it/s, est. speed input: 24102.58 toks/s, output: 23.54 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:14, 20.32it/s, est. speed input: 24026.47 toks/s, output: 23.46 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:14, 20.26it/s, est. speed input: 23954.52 toks/s, output: 23.39 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:09<00:14, 20.17it/s, est. speed input: 23881.83 toks/s, output: 23.32 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:09<00:14, 20.11it/s, est. speed input: 23812.16 toks/s, output: 23.25 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:10<00:13, 20.07it/s, est. speed input: 23745.88 toks/s, output: 23.19 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:13, 20.06it/s, est. speed input: 23682.93 toks/s, output: 23.13 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:13, 20.03it/s, est. speed input: 23621.28 toks/s, output: 23.07 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:10<00:13, 20.01it/s, est. speed input: 23561.62 toks/s, output: 23.01 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:10<00:13, 20.02it/s, est. speed input: 23505.79 toks/s, output: 22.95 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:11<00:12, 20.00it/s, est. speed input: 23450.58 toks/s, output: 22.90 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:12, 20.01it/s, est. speed input: 23398.18 toks/s, output: 22.85 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:12, 20.01it/s, est. speed input: 23347.65 toks/s, output: 22.80 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:11<00:12, 20.02it/s, est. speed input: 23299.37 toks/s, output: 22.75 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:11<00:12, 20.01it/s, est. speed input: 23251.94 toks/s, output: 22.71 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:12<00:11, 20.00it/s, est. speed input: 23205.49 toks/s, output: 22.66 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:12<00:11, 19.99it/s, est. speed input: 23160.70 toks/s, output: 22.62 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:11, 20.00it/s, est. speed input: 23117.87 toks/s, output: 22.58 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:12<00:11, 19.96it/s, est. speed input: 23073.94 toks/s, output: 22.53 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:12<00:11, 19.97it/s, est. speed input: 23033.76 toks/s, output: 22.49 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:13<00:10, 20.00it/s, est. speed input: 22995.88 toks/s, output: 22.46 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:13<00:10, 19.96it/s, est. speed input: 22955.92 toks/s, output: 22.42 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:10, 19.98it/s, est. speed input: 22919.65 toks/s, output: 22.38 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:13<00:09, 21.43it/s, est. speed input: 22959.23 toks/s, output: 22.42 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:13<00:09, 20.97it/s, est. speed input: 22923.10 toks/s, output: 22.39 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:14<00:09, 20.68it/s, est. speed input: 22888.81 toks/s, output: 22.35 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:14<00:09, 20.48it/s, est. speed input: 22855.31 toks/s, output: 22.32 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:09, 20.33it/s, est. speed input: 22822.37 toks/s, output: 22.29 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:14<00:09, 20.20it/s, est. speed input: 22788.91 toks/s, output: 22.25 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:14<00:09, 20.11it/s, est. speed input: 22756.33 toks/s, output: 22.22 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:15<00:08, 20.06it/s, est. speed input: 22725.23 toks/s, output: 22.19 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:15<00:08, 20.00it/s, est. speed input: 22693.76 toks/s, output: 22.16 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:15<00:08, 20.01it/s, est. speed input: 22665.36 toks/s, output: 22.13 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:15<00:08, 19.99it/s, est. speed input: 22636.67 toks/s, output: 22.11 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:15<00:08, 19.98it/s, est. speed input: 22608.78 toks/s, output: 22.08 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:16<00:07, 19.98it/s, est. speed input: 22582.08 toks/s, output: 22.05 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:16<00:07, 19.99it/s, est. speed input: 22556.51 toks/s, output: 22.03 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:16<00:07, 19.97it/s, est. speed input: 22530.34 toks/s, output: 22.00 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:16<00:07, 19.98it/s, est. speed input: 22505.55 toks/s, output: 21.98 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:16<00:07, 19.96it/s, est. speed input: 22480.61 toks/s, output: 21.95 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:17<00:06, 19.96it/s, est. speed input: 22456.41 toks/s, output: 21.93 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:17<00:06, 19.96it/s, est. speed input: 22432.86 toks/s, output: 21.91 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:17<00:06, 19.94it/s, est. speed input: 22409.39 toks/s, output: 21.88 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:17<00:06, 19.94it/s, est. speed input: 22386.86 toks/s, output: 21.86 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:17<00:06, 19.94it/s, est. speed input: 22364.78 toks/s, output: 21.84 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:18<00:05, 19.93it/s, est. speed input: 22342.48 toks/s, output: 21.82 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:18<00:05, 19.91it/s, est. speed input: 22320.64 toks/s, output: 21.80 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:18<00:05, 19.92it/s, est. speed input: 22299.83 toks/s, output: 21.78 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:18<00:05, 19.95it/s, est. speed input: 22280.62 toks/s, output: 21.76 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:18<00:05, 19.98it/s, est. speed input: 22262.23 toks/s, output: 21.74 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:19<00:04, 19.97it/s, est. speed input: 22242.94 toks/s, output: 21.72 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:19<00:04, 19.95it/s, est. speed input: 22223.30 toks/s, output: 21.70 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:19<00:04, 19.94it/s, est. speed input: 22204.65 toks/s, output: 21.68 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:19<00:04, 19.94it/s, est. speed input: 22186.50 toks/s, output: 21.67 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:19<00:04, 19.95it/s, est. speed input: 22168.83 toks/s, output: 21.65 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:20<00:03, 21.41it/s, est. speed input: 22201.87 toks/s, output: 21.68 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:20<00:03, 20.93it/s, est. speed input: 22183.74 toks/s, output: 21.66 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:20<00:03, 20.63it/s, est. speed input: 22166.44 toks/s, output: 21.65 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:20<00:03, 20.41it/s, est. speed input: 22149.16 toks/s, output: 21.63 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:20<00:03, 20.27it/s, est. speed input: 22132.82 toks/s, output: 21.61 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:21<00:02, 20.19it/s, est. speed input: 22117.06 toks/s, output: 21.60 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:21<00:02, 20.10it/s, est. speed input: 22100.40 toks/s, output: 21.58 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:21<00:02, 20.04it/s, est. speed input: 22084.19 toks/s, output: 21.57 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:21<00:02, 19.98it/s, est. speed input: 22067.75 toks/s, output: 21.55 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:21<00:02, 19.94it/s, est. speed input: 22051.62 toks/s, output: 21.53 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:22<00:01, 19.93it/s, est. speed input: 22036.48 toks/s, output: 21.52 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:22<00:01, 19.91it/s, est. speed input: 22020.95 toks/s, output: 21.50 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:22<00:01, 19.89it/s, est. speed input: 22005.92 toks/s, output: 21.49 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:22<00:01, 19.91it/s, est. speed input: 21991.79 toks/s, output: 21.48 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:22<00:01, 19.87it/s, est. speed input: 21976.46 toks/s, output: 21.46 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:23<00:00, 19.89it/s, est. speed input: 21962.74 toks/s, output: 21.45 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:23<00:00, 19.87it/s, est. speed input: 21948.52 toks/s, output: 21.43 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:23<00:00, 19.86it/s, est. speed input: 21934.29 toks/s, output: 21.42 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:23<00:00, 19.88it/s, est. speed input: 21921.25 toks/s, output: 21.41 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:23<00:00, 21.39it/s, est. speed input: 21951.65 toks/s, output: 21.44 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:23<00:00, 21.39it/s, est. speed input: 22037.57 toks/s, output: 21.52 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:23<00:00, 21.52it/s, est. speed input: 22037.57 toks/s, output: 21.52 toks/s]
[rank0]:[W125 19:10:06.310227802 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 75.9s

测试结果:
  Requests/s:   20.06
  Tokens/s:     20563.23
  Total Reqs:   512
  Elapsed:      25.52s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     20543.17

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:10:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=345398) WARNING 01-25 19:10:41 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.30 requests/s, 20804.99 total tokens/s, 20.30 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 19:10:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:10:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:10:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:10:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:10:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:10:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:10:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:10:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:10:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:10:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:10:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:10:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:10:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:10:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:10:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:10:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:10:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=345398) [2026-01-25 19:10:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=345398) [2026-01-25 19:10:32] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=345398) [2026-01-25 19:10:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=345398) [2026-01-25 19:10:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=345398) [2026-01-25 19:10:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=345398) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=345398) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.84it/s]
(EngineCore_DP0 pid=345398) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.77it/s]
(EngineCore_DP0 pid=345398) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
(EngineCore_DP0 pid=345398) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=345398) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  6.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  5.94it/s]
(EngineCore_DP0 pid=345398) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  8.41it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  9.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 10.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.75it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 26/1024 [00:00<00:03, 253.84it/s]
Adding requests:   5%|▌         | 55/1024 [00:00<00:03, 274.22it/s]
Adding requests:   8%|▊         | 86/1024 [00:00<00:03, 288.13it/s]
Adding requests:  11%|█         | 115/1024 [00:00<00:03, 281.53it/s]
Adding requests:  14%|█▍        | 146/1024 [00:00<00:03, 290.61it/s]
Adding requests:  17%|█▋        | 177/1024 [00:00<00:02, 294.16it/s]
Adding requests:  21%|██        | 210/1024 [00:00<00:02, 305.48it/s]
Adding requests:  24%|██▎       | 241/1024 [00:00<00:02, 306.76it/s]
Adding requests:  27%|██▋       | 272/1024 [00:00<00:02, 299.10it/s]
Adding requests:  30%|██▉       | 304/1024 [00:01<00:02, 304.51it/s]
Adding requests:  33%|███▎      | 335/1024 [00:01<00:02, 301.38it/s]
Adding requests:  36%|███▌      | 366/1024 [00:01<00:02, 292.39it/s]
Adding requests:  39%|███▊      | 396/1024 [00:01<00:02, 293.54it/s]
Adding requests:  42%|████▏     | 426/1024 [00:01<00:02, 291.62it/s]
Adding requests:  45%|████▍     | 456/1024 [00:01<00:01, 287.23it/s]
Adding requests:  48%|████▊     | 490/1024 [00:01<00:01, 300.75it/s]
Adding requests:  51%|█████     | 523/1024 [00:01<00:01, 308.19it/s]
Adding requests:  54%|█████▍    | 554/1024 [00:01<00:01, 307.34it/s]
Adding requests:  57%|█████▋    | 585/1024 [00:01<00:01, 304.31it/s]
Adding requests:  60%|██████    | 616/1024 [00:02<00:01, 302.58it/s]
Adding requests:  63%|██████▎   | 647/1024 [00:02<00:01, 295.04it/s]
Adding requests:  66%|██████▌   | 677/1024 [00:02<00:01, 284.53it/s]
Adding requests:  69%|██████▉   | 707/1024 [00:02<00:01, 288.71it/s]
Adding requests:  72%|███████▏  | 736/1024 [00:02<00:01, 278.51it/s]
Adding requests:  75%|███████▍  | 765/1024 [00:02<00:00, 280.65it/s]
Adding requests:  78%|███████▊  | 796/1024 [00:02<00:00, 287.66it/s]
Adding requests:  81%|████████  | 825/1024 [00:02<00:00, 283.64it/s]
Adding requests:  83%|████████▎ | 855/1024 [00:02<00:00, 285.57it/s]
Adding requests:  87%|████████▋ | 888/1024 [00:03<00:00, 297.32it/s]
Adding requests:  90%|████████▉ | 918/1024 [00:03<00:00, 296.41it/s]
Adding requests:  93%|█████████▎| 948/1024 [00:03<00:00, 292.96it/s]
Adding requests:  96%|█████████▌| 978/1024 [00:03<00:00, 289.87it/s]
Adding requests:  98%|█████████▊| 1008/1024 [00:03<00:00, 284.69it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 292.10it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:00<00:01, 659.44it/s, est. speed input: 675372.07 toks/s, output: 659.46 toks/s]
Processed prompts:  13%|█▎        | 132/1024 [00:03<00:25, 35.04it/s, est. speed input: 41822.41 toks/s, output: 40.84 toks/s]  
Processed prompts:  16%|█▌        | 161/1024 [00:04<00:27, 31.46it/s, est. speed input: 37389.76 toks/s, output: 36.51 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:32, 25.84it/s, est. speed input: 32624.04 toks/s, output: 31.86 toks/s]
Processed prompts:  18%|█▊        | 189/1024 [00:05<00:31, 26.14it/s, est. speed input: 32367.85 toks/s, output: 31.61 toks/s]
Processed prompts:  19%|█▉        | 197/1024 [00:06<00:32, 25.20it/s, est. speed input: 31655.49 toks/s, output: 30.91 toks/s]
Processed prompts:  20%|█▉        | 203/1024 [00:06<00:34, 23.86it/s, est. speed input: 30939.80 toks/s, output: 30.21 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:07<00:36, 22.55it/s, est. speed input: 30237.41 toks/s, output: 29.53 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:36, 22.03it/s, est. speed input: 29744.63 toks/s, output: 29.05 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:36, 21.61it/s, est. speed input: 29302.83 toks/s, output: 28.62 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:08<00:37, 21.24it/s, est. speed input: 28892.45 toks/s, output: 28.22 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:37, 21.00it/s, est. speed input: 28528.72 toks/s, output: 27.86 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:09<00:37, 20.80it/s, est. speed input: 28191.85 toks/s, output: 27.53 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:09<00:37, 20.65it/s, est. speed input: 27882.73 toks/s, output: 27.23 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:36, 20.55it/s, est. speed input: 27599.02 toks/s, output: 26.95 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:10<00:36, 20.50it/s, est. speed input: 27342.20 toks/s, output: 26.70 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:10<00:36, 20.42it/s, est. speed input: 27096.36 toks/s, output: 26.46 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:11<00:36, 20.37it/s, est. speed input: 26868.44 toks/s, output: 26.24 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:11<00:35, 20.36it/s, est. speed input: 26661.16 toks/s, output: 26.04 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:34, 21.09it/s, est. speed input: 26570.19 toks/s, output: 25.95 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:12<00:34, 20.83it/s, est. speed input: 26380.73 toks/s, output: 25.76 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:12<00:34, 20.65it/s, est. speed input: 26202.81 toks/s, output: 25.59 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:33, 20.53it/s, est. speed input: 26037.03 toks/s, output: 25.43 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:13<00:33, 20.46it/s, est. speed input: 25882.07 toks/s, output: 25.28 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:13<00:33, 20.41it/s, est. speed input: 25735.62 toks/s, output: 25.13 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:14<00:32, 20.37it/s, est. speed input: 25597.27 toks/s, output: 25.00 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:14<00:32, 20.33it/s, est. speed input: 25464.57 toks/s, output: 24.87 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:14<00:32, 20.31it/s, est. speed input: 25339.82 toks/s, output: 24.75 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:15<00:31, 20.29it/s, est. speed input: 25221.14 toks/s, output: 24.63 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:15<00:31, 20.30it/s, est. speed input: 25110.79 toks/s, output: 24.52 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:16<00:31, 20.30it/s, est. speed input: 25005.07 toks/s, output: 24.42 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:16<00:30, 20.27it/s, est. speed input: 24902.02 toks/s, output: 24.32 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:16<00:30, 20.28it/s, est. speed input: 24806.13 toks/s, output: 24.22 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:17<00:29, 20.26it/s, est. speed input: 24712.63 toks/s, output: 24.13 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:17<00:29, 20.26it/s, est. speed input: 24624.33 toks/s, output: 24.05 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:18<00:28, 21.00it/s, est. speed input: 24602.78 toks/s, output: 24.03 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:18<00:28, 20.78it/s, est. speed input: 24520.77 toks/s, output: 23.95 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:18<00:27, 20.61it/s, est. speed input: 24440.83 toks/s, output: 23.87 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:19<00:27, 20.51it/s, est. speed input: 24365.69 toks/s, output: 23.79 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:19<00:27, 20.41it/s, est. speed input: 24291.23 toks/s, output: 23.72 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:20<00:27, 20.35it/s, est. speed input: 24220.03 toks/s, output: 23.65 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:20<00:26, 20.32it/s, est. speed input: 24152.91 toks/s, output: 23.59 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:20<00:26, 20.29it/s, est. speed input: 24087.03 toks/s, output: 23.52 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:21<00:25, 20.29it/s, est. speed input: 24025.41 toks/s, output: 23.46 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:21<00:25, 20.26it/s, est. speed input: 23964.28 toks/s, output: 23.40 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:22<00:25, 20.23it/s, est. speed input: 23904.46 toks/s, output: 23.34 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:22<00:24, 20.25it/s, est. speed input: 23849.24 toks/s, output: 23.29 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:22<00:24, 20.24it/s, est. speed input: 23794.62 toks/s, output: 23.24 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:23<00:24, 20.22it/s, est. speed input: 23741.14 toks/s, output: 23.18 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:23<00:23, 20.22it/s, est. speed input: 23690.16 toks/s, output: 23.13 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:23<00:23, 20.22it/s, est. speed input: 23641.08 toks/s, output: 23.09 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:24<00:22, 20.23it/s, est. speed input: 23593.89 toks/s, output: 23.04 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:24<00:22, 20.21it/s, est. speed input: 23546.84 toks/s, output: 22.99 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:25<00:22, 20.20it/s, est. speed input: 23501.56 toks/s, output: 22.95 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:25<00:21, 20.22it/s, est. speed input: 23459.08 toks/s, output: 22.91 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:25<00:21, 20.21it/s, est. speed input: 23416.40 toks/s, output: 22.87 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:26<00:20, 20.18it/s, est. speed input: 23374.11 toks/s, output: 22.83 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:26<00:20, 20.21it/s, est. speed input: 23335.37 toks/s, output: 22.79 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:27<00:20, 20.21it/s, est. speed input: 23296.91 toks/s, output: 22.75 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:27<00:19, 20.17it/s, est. speed input: 23257.58 toks/s, output: 22.71 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:27<00:19, 20.20it/s, est. speed input: 23221.98 toks/s, output: 22.68 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:28<00:18, 20.19it/s, est. speed input: 23185.97 toks/s, output: 22.64 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:28<00:18, 20.17it/s, est. speed input: 23150.54 toks/s, output: 22.61 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:29<00:18, 20.17it/s, est. speed input: 23116.53 toks/s, output: 22.57 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:29<00:17, 20.17it/s, est. speed input: 23083.63 toks/s, output: 22.54 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:29<00:17, 20.16it/s, est. speed input: 23050.62 toks/s, output: 22.51 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:30<00:16, 20.15it/s, est. speed input: 23018.92 toks/s, output: 22.48 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:30<00:16, 20.18it/s, est. speed input: 22989.30 toks/s, output: 22.45 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:31<00:16, 20.16it/s, est. speed input: 22958.64 toks/s, output: 22.42 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:31<00:15, 20.18it/s, est. speed input: 22930.41 toks/s, output: 22.39 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:31<00:15, 20.18it/s, est. speed input: 22902.58 toks/s, output: 22.37 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:32<00:14, 20.16it/s, est. speed input: 22873.99 toks/s, output: 22.34 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:32<00:14, 20.17it/s, est. speed input: 22847.49 toks/s, output: 22.31 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:33<00:14, 20.17it/s, est. speed input: 22821.27 toks/s, output: 22.29 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:33<00:13, 20.15it/s, est. speed input: 22794.60 toks/s, output: 22.26 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:33<00:13, 20.15it/s, est. speed input: 22769.29 toks/s, output: 22.24 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:34<00:13, 20.15it/s, est. speed input: 22744.45 toks/s, output: 22.21 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:34<00:12, 20.14it/s, est. speed input: 22719.86 toks/s, output: 22.19 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:35<00:12, 20.14it/s, est. speed input: 22696.30 toks/s, output: 22.16 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:35<00:11, 20.88it/s, est. speed input: 22703.12 toks/s, output: 22.17 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:35<00:11, 20.65it/s, est. speed input: 22679.81 toks/s, output: 22.15 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:36<00:10, 20.50it/s, est. speed input: 22657.46 toks/s, output: 22.13 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:36<00:10, 20.39it/s, est. speed input: 22635.55 toks/s, output: 22.11 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:37<00:10, 20.31it/s, est. speed input: 22613.66 toks/s, output: 22.08 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:37<00:09, 20.25it/s, est. speed input: 22592.20 toks/s, output: 22.06 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:37<00:09, 20.21it/s, est. speed input: 22571.12 toks/s, output: 22.04 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:38<00:09, 20.18it/s, est. speed input: 22550.65 toks/s, output: 22.02 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:38<00:08, 20.17it/s, est. speed input: 22530.79 toks/s, output: 22.00 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:39<00:08, 20.16it/s, est. speed input: 22511.24 toks/s, output: 21.98 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:39<00:07, 20.11it/s, est. speed input: 22490.78 toks/s, output: 21.96 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:39<00:07, 20.12it/s, est. speed input: 22472.00 toks/s, output: 21.95 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:40<00:07, 20.12it/s, est. speed input: 22453.57 toks/s, output: 21.93 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:40<00:06, 20.10it/s, est. speed input: 22434.92 toks/s, output: 21.91 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:41<00:06, 20.11it/s, est. speed input: 22417.14 toks/s, output: 21.89 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:41<00:05, 20.10it/s, est. speed input: 22399.18 toks/s, output: 21.87 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:41<00:05, 20.10it/s, est. speed input: 22382.03 toks/s, output: 21.86 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:42<00:05, 20.12it/s, est. speed input: 22365.88 toks/s, output: 21.84 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:42<00:04, 20.11it/s, est. speed input: 22349.10 toks/s, output: 21.83 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:43<00:04, 20.12it/s, est. speed input: 22333.02 toks/s, output: 21.81 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:43<00:03, 20.10it/s, est. speed input: 22316.62 toks/s, output: 21.79 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:43<00:03, 20.09it/s, est. speed input: 22300.55 toks/s, output: 21.78 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:44<00:03, 20.11it/s, est. speed input: 22285.64 toks/s, output: 21.76 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:44<00:02, 20.10it/s, est. speed input: 22270.23 toks/s, output: 21.75 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:45<00:02, 20.08it/s, est. speed input: 22254.74 toks/s, output: 21.73 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:45<00:01, 20.10it/s, est. speed input: 22240.46 toks/s, output: 21.72 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:45<00:01, 20.10it/s, est. speed input: 22225.96 toks/s, output: 21.71 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:46<00:01, 20.09it/s, est. speed input: 22211.65 toks/s, output: 21.69 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:46<00:00, 20.09it/s, est. speed input: 22197.46 toks/s, output: 21.68 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:46<00:00, 20.86it/s, est. speed input: 22206.80 toks/s, output: 21.69 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:46<00:00, 20.86it/s, est. speed input: 22337.53 toks/s, output: 21.81 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:46<00:00, 21.81it/s, est. speed input: 22337.53 toks/s, output: 21.81 toks/s]
[rank0]:[W125 19:11:52.212314893 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 105.8s

测试结果:
  Requests/s:   20.30
  Tokens/s:     20804.99
  Total Reqs:   1024
  Elapsed:      50.45s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     20784.69

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:12:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=347218) WARNING 01-25 19:12:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.34 requests/s, 20853.29 total tokens/s, 20.34 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 19:12:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:12:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:12:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:12:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:12:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:12:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:12:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:12:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:12:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:12:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:12:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:12:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:12:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:12:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:12:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:12:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:12:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=347218) [2026-01-25 19:12:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=347218) [2026-01-25 19:12:25] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=347218) [2026-01-25 19:12:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=347218) [2026-01-25 19:12:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=347218) [2026-01-25 19:12:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=347218) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=347218) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.84it/s]
(EngineCore_DP0 pid=347218) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.77it/s]
(EngineCore_DP0 pid=347218) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
(EngineCore_DP0 pid=347218) 
(EngineCore_DP0 pid=347218) [rank0]:W0125 19:12:43.599000 347218 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=347218) [rank0]:W0125 19:12:44.457000 347218 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=347218) [rank0]:W0125 19:12:46.747000 347218 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=347218) [rank0]:W0125 19:12:46.946000 347218 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=347218) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  9.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  9.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 10.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 10.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.10it/s]
(EngineCore_DP0 pid=347218) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  9.58it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 10.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.45it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 246.44it/s]
Adding requests:   3%|▎         | 52/2048 [00:00<00:07, 259.78it/s]
Adding requests:   4%|▍         | 81/2048 [00:00<00:07, 271.52it/s]
Adding requests:   5%|▌         | 111/2048 [00:00<00:06, 279.55it/s]
Adding requests:   7%|▋         | 141/2048 [00:00<00:06, 284.33it/s]
Adding requests:   8%|▊         | 172/2048 [00:00<00:06, 292.57it/s]
Adding requests:  10%|▉         | 202/2048 [00:00<00:06, 293.69it/s]
Adding requests:  11%|█▏        | 232/2048 [00:00<00:06, 290.41it/s]
Adding requests:  13%|█▎        | 262/2048 [00:00<00:06, 286.17it/s]
Adding requests:  14%|█▍        | 291/2048 [00:01<00:06, 286.26it/s]
Adding requests:  16%|█▌        | 323/2048 [00:01<00:05, 296.28it/s]
Adding requests:  17%|█▋        | 356/2048 [00:01<00:05, 304.79it/s]
Adding requests:  19%|█▉        | 387/2048 [00:01<00:05, 302.28it/s]
Adding requests:  21%|██        | 420/2048 [00:01<00:05, 309.15it/s]
Adding requests:  22%|██▏       | 451/2048 [00:01<00:05, 304.91it/s]
Adding requests:  24%|██▎       | 485/2048 [00:01<00:04, 314.90it/s]
Adding requests:  25%|██▌       | 517/2048 [00:01<00:04, 315.75it/s]
Adding requests:  27%|██▋       | 549/2048 [00:01<00:04, 310.22it/s]
Adding requests:  28%|██▊       | 581/2048 [00:01<00:04, 308.25it/s]
Adding requests:  30%|██▉       | 612/2048 [00:02<00:04, 292.91it/s]
Adding requests:  31%|███▏      | 642/2048 [00:02<00:04, 288.26it/s]
Adding requests:  33%|███▎      | 671/2048 [00:02<00:04, 281.83it/s]
Adding requests:  34%|███▍      | 704/2048 [00:02<00:04, 293.13it/s]
Adding requests:  36%|███▌      | 734/2048 [00:02<00:04, 292.22it/s]
Adding requests:  37%|███▋      | 764/2048 [00:02<00:04, 284.43it/s]
Adding requests:  39%|███▉      | 795/2048 [00:02<00:04, 290.03it/s]
Adding requests:  40%|████      | 825/2048 [00:02<00:04, 288.13it/s]
Adding requests:  42%|████▏     | 856/2048 [00:02<00:04, 293.18it/s]
Adding requests:  43%|████▎     | 887/2048 [00:03<00:03, 296.58it/s]
Adding requests:  45%|████▍     | 917/2048 [00:03<00:03, 296.71it/s]
Adding requests:  46%|████▋     | 948/2048 [00:03<00:03, 297.47it/s]
Adding requests:  48%|████▊     | 979/2048 [00:03<00:03, 300.43it/s]
Adding requests:  49%|████▉     | 1010/2048 [00:03<00:03, 294.78it/s]
Adding requests:  51%|█████     | 1040/2048 [00:03<00:03, 295.23it/s]
Adding requests:  52%|█████▏    | 1070/2048 [00:03<00:03, 295.31it/s]
Adding requests:  54%|█████▎    | 1100/2048 [00:03<00:03, 295.87it/s]
Adding requests:  55%|█████▌    | 1131/2048 [00:03<00:03, 298.88it/s]
Adding requests:  57%|█████▋    | 1161/2048 [00:03<00:03, 281.23it/s]
Adding requests:  58%|█████▊    | 1191/2048 [00:04<00:02, 285.95it/s]
Adding requests:  60%|█████▉    | 1222/2048 [00:04<00:02, 290.86it/s]
Adding requests:  61%|██████    | 1252/2048 [00:04<00:02, 286.66it/s]
Adding requests:  63%|██████▎   | 1281/2048 [00:04<00:02, 284.11it/s]
Adding requests:  64%|██████▍   | 1312/2048 [00:04<00:02, 290.00it/s]
Adding requests:  66%|██████▌   | 1344/2048 [00:04<00:02, 298.11it/s]
Adding requests:  67%|██████▋   | 1377/2048 [00:04<00:02, 305.76it/s]
Adding requests:  69%|██████▉   | 1408/2048 [00:04<00:02, 303.34it/s]
Adding requests:  70%|███████   | 1439/2048 [00:04<00:02, 299.73it/s]
Adding requests:  72%|███████▏  | 1471/2048 [00:04<00:01, 301.88it/s]
Adding requests:  73%|███████▎  | 1504/2048 [00:05<00:01, 308.28it/s]
Adding requests:  75%|███████▍  | 1535/2048 [00:05<00:01, 306.55it/s]
Adding requests:  76%|███████▋  | 1566/2048 [00:05<00:01, 299.09it/s]
Adding requests:  78%|███████▊  | 1596/2048 [00:05<00:01, 296.86it/s]
Adding requests:  79%|███████▉  | 1626/2048 [00:05<00:01, 296.59it/s]
Adding requests:  81%|████████  | 1656/2048 [00:05<00:01, 292.29it/s]
Adding requests:  82%|████████▏ | 1687/2048 [00:05<00:01, 296.80it/s]
Adding requests:  84%|████████▍ | 1718/2048 [00:05<00:01, 297.95it/s]
Adding requests:  85%|████████▌ | 1748/2048 [00:05<00:01, 291.09it/s]
Adding requests:  87%|████████▋ | 1778/2048 [00:06<00:00, 291.82it/s]
Adding requests:  88%|████████▊ | 1808/2048 [00:06<00:00, 290.76it/s]
Adding requests:  90%|████████▉ | 1838/2048 [00:06<00:00, 292.17it/s]
Adding requests:  91%|█████████ | 1868/2048 [00:06<00:00, 288.02it/s]
Adding requests:  93%|█████████▎| 1897/2048 [00:06<00:00, 285.97it/s]
Adding requests:  94%|█████████▍| 1926/2048 [00:06<00:00, 284.31it/s]
Adding requests:  96%|█████████▌| 1957/2048 [00:06<00:00, 289.34it/s]
Adding requests:  97%|█████████▋| 1986/2048 [00:06<00:00, 287.26it/s]
Adding requests:  98%|█████████▊| 2015/2048 [00:06<00:00, 286.88it/s]
Adding requests: 100%|█████████▉| 2044/2048 [00:06<00:00, 281.83it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 293.33it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:00<00:01, 1059.38it/s, est. speed input: 1084994.47 toks/s, output: 1059.43 toks/s]
Processed prompts:  12%|█▏        | 236/2048 [00:04<00:43, 41.62it/s, est. speed input: 50666.13 toks/s, output: 49.48 toks/s]      
Processed prompts:  14%|█▎        | 281/2048 [00:07<00:54, 32.29it/s, est. speed input: 40408.37 toks/s, output: 39.46 toks/s]
Processed prompts:  15%|█▍        | 307/2048 [00:08<01:01, 28.08it/s, est. speed input: 36380.12 toks/s, output: 35.53 toks/s]
Processed prompts:  16%|█▌        | 323/2048 [00:09<01:04, 26.78it/s, est. speed input: 35090.57 toks/s, output: 34.27 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:10<01:07, 25.28it/s, est. speed input: 33895.57 toks/s, output: 33.10 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:10<01:09, 24.22it/s, est. speed input: 32970.03 toks/s, output: 32.20 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:11<01:11, 23.31it/s, est. speed input: 32166.17 toks/s, output: 31.41 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:12<01:13, 22.57it/s, est. speed input: 31459.65 toks/s, output: 30.72 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:13<01:14, 21.98it/s, est. speed input: 30835.69 toks/s, output: 30.11 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:14<01:15, 21.53it/s, est. speed input: 30277.83 toks/s, output: 29.57 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:14<01:14, 21.57it/s, est. speed input: 29877.57 toks/s, output: 29.18 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:15<01:15, 21.22it/s, est. speed input: 29425.39 toks/s, output: 28.74 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:16<01:15, 20.97it/s, est. speed input: 29015.97 toks/s, output: 28.34 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:17<01:15, 20.79it/s, est. speed input: 28643.19 toks/s, output: 27.97 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:18<01:15, 20.66it/s, est. speed input: 28302.24 toks/s, output: 27.64 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:18<01:14, 20.56it/s, est. speed input: 27989.90 toks/s, output: 27.33 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:19<01:14, 20.50it/s, est. speed input: 27702.72 toks/s, output: 27.05 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:20<01:13, 20.45it/s, est. speed input: 27436.92 toks/s, output: 26.79 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:21<01:12, 20.41it/s, est. speed input: 27190.65 toks/s, output: 26.55 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:21<01:12, 20.39it/s, est. speed input: 26963.04 toks/s, output: 26.33 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:22<01:11, 20.36it/s, est. speed input: 26748.78 toks/s, output: 26.12 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:23<01:10, 20.35it/s, est. speed input: 26550.31 toks/s, output: 25.93 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:24<01:09, 20.34it/s, est. speed input: 26363.78 toks/s, output: 25.75 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:25<01:09, 20.32it/s, est. speed input: 26187.96 toks/s, output: 25.57 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:25<01:08, 20.30it/s, est. speed input: 26022.12 toks/s, output: 25.41 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:26<01:07, 20.29it/s, est. speed input: 25865.60 toks/s, output: 25.26 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:27<01:06, 20.29it/s, est. speed input: 25719.94 toks/s, output: 25.12 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:28<01:06, 20.29it/s, est. speed input: 25581.95 toks/s, output: 24.98 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:29<01:05, 20.28it/s, est. speed input: 25449.96 toks/s, output: 24.85 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:29<01:04, 20.27it/s, est. speed input: 25325.58 toks/s, output: 24.73 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:30<01:03, 20.25it/s, est. speed input: 25205.57 toks/s, output: 24.61 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:31<01:03, 20.26it/s, est. speed input: 25094.17 toks/s, output: 24.51 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:32<01:01, 20.63it/s, est. speed input: 25024.27 toks/s, output: 24.44 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:32<01:00, 20.51it/s, est. speed input: 24920.85 toks/s, output: 24.34 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:33<01:00, 20.44it/s, est. speed input: 24823.34 toks/s, output: 24.24 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:34<00:59, 20.38it/s, est. speed input: 24729.44 toks/s, output: 24.15 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:35<00:58, 20.33it/s, est. speed input: 24639.82 toks/s, output: 24.06 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:36<00:58, 20.30it/s, est. speed input: 24553.47 toks/s, output: 23.98 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:36<00:57, 20.26it/s, est. speed input: 24470.03 toks/s, output: 23.90 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:37<00:56, 20.25it/s, est. speed input: 24391.29 toks/s, output: 23.82 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:38<00:56, 20.24it/s, est. speed input: 24315.03 toks/s, output: 23.75 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:39<00:55, 20.22it/s, est. speed input: 24241.30 toks/s, output: 23.67 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:40<00:54, 20.20it/s, est. speed input: 24169.89 toks/s, output: 23.60 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:40<00:53, 20.22it/s, est. speed input: 24103.84 toks/s, output: 23.54 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:41<00:52, 20.20it/s, est. speed input: 24037.58 toks/s, output: 23.47 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:42<00:52, 20.18it/s, est. speed input: 23973.88 toks/s, output: 23.41 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:43<00:51, 20.18it/s, est. speed input: 23913.12 toks/s, output: 23.35 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:44<00:50, 20.19it/s, est. speed input: 23855.59 toks/s, output: 23.30 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:44<00:49, 20.18it/s, est. speed input: 23798.30 toks/s, output: 23.24 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:45<00:49, 20.18it/s, est. speed input: 23743.88 toks/s, output: 23.19 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:46<00:48, 20.17it/s, est. speed input: 23690.80 toks/s, output: 23.14 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:47<00:47, 20.16it/s, est. speed input: 23638.94 toks/s, output: 23.08 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:48<00:46, 20.16it/s, est. speed input: 23589.20 toks/s, output: 23.04 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:48<00:45, 20.16it/s, est. speed input: 23541.28 toks/s, output: 22.99 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:49<00:45, 20.15it/s, est. speed input: 23494.77 toks/s, output: 22.94 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:50<00:44, 20.14it/s, est. speed input: 23448.98 toks/s, output: 22.90 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:51<00:43, 20.14it/s, est. speed input: 23405.19 toks/s, output: 22.86 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:51<00:42, 20.15it/s, est. speed input: 23362.90 toks/s, output: 22.82 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:52<00:41, 20.51it/s, est. speed input: 23342.66 toks/s, output: 22.80 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:53<00:40, 20.39it/s, est. speed input: 23301.95 toks/s, output: 22.76 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:54<00:39, 20.69it/s, est. speed input: 23283.14 toks/s, output: 22.74 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:55<00:38, 20.51it/s, est. speed input: 23244.18 toks/s, output: 22.70 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:55<00:38, 20.39it/s, est. speed input: 23206.52 toks/s, output: 22.66 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:56<00:37, 20.31it/s, est. speed input: 23170.04 toks/s, output: 22.63 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:57<00:37, 20.24it/s, est. speed input: 23134.00 toks/s, output: 22.59 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:58<00:36, 20.20it/s, est. speed input: 23099.17 toks/s, output: 22.56 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:58<00:34, 20.53it/s, est. speed input: 23083.47 toks/s, output: 22.54 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:59<00:34, 20.39it/s, est. speed input: 23049.67 toks/s, output: 22.51 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:00<00:33, 20.30it/s, est. speed input: 23017.32 toks/s, output: 22.48 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:01<00:33, 20.23it/s, est. speed input: 22985.32 toks/s, output: 22.45 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:02<00:32, 20.20it/s, est. speed input: 22954.66 toks/s, output: 22.42 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:02<00:31, 20.16it/s, est. speed input: 22924.34 toks/s, output: 22.39 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:03<00:30, 20.13it/s, est. speed input: 22894.62 toks/s, output: 22.36 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:04<00:30, 20.10it/s, est. speed input: 22864.98 toks/s, output: 22.33 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:05<00:28, 20.47it/s, est. speed input: 22853.94 toks/s, output: 22.32 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:06<00:28, 20.35it/s, est. speed input: 22826.35 toks/s, output: 22.29 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:06<00:27, 20.26it/s, est. speed input: 22798.82 toks/s, output: 22.26 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:07<00:26, 20.21it/s, est. speed input: 22772.76 toks/s, output: 22.24 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:08<00:25, 20.54it/s, est. speed input: 22762.79 toks/s, output: 22.23 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:09<00:25, 20.40it/s, est. speed input: 22737.33 toks/s, output: 22.20 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:10<00:23, 20.68it/s, est. speed input: 22728.27 toks/s, output: 22.20 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:10<00:23, 20.49it/s, est. speed input: 22703.72 toks/s, output: 22.17 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:11<00:22, 20.36it/s, est. speed input: 22679.57 toks/s, output: 22.15 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:12<00:22, 20.26it/s, est. speed input: 22655.69 toks/s, output: 22.12 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:13<00:20, 20.58it/s, est. speed input: 22647.68 toks/s, output: 22.12 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:13<00:20, 20.40it/s, est. speed input: 22624.21 toks/s, output: 22.09 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:14<00:19, 20.30it/s, est. speed input: 22602.14 toks/s, output: 22.07 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:15<00:18, 20.23it/s, est. speed input: 22580.31 toks/s, output: 22.05 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:16<00:18, 20.16it/s, est. speed input: 22558.47 toks/s, output: 22.03 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:17<00:17, 20.13it/s, est. speed input: 22537.58 toks/s, output: 22.01 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:17<00:16, 20.11it/s, est. speed input: 22517.19 toks/s, output: 21.99 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:18<00:15, 20.46it/s, est. speed input: 22510.57 toks/s, output: 21.98 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:19<00:14, 20.71it/s, est. speed input: 22504.28 toks/s, output: 21.98 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:20<00:13, 20.50it/s, est. speed input: 22484.33 toks/s, output: 21.96 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:21<00:13, 20.35it/s, est. speed input: 22464.75 toks/s, output: 21.94 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:21<00:12, 20.26it/s, est. speed input: 22445.81 toks/s, output: 21.92 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:22<00:11, 20.18it/s, est. speed input: 22426.76 toks/s, output: 21.90 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:23<00:11, 20.15it/s, est. speed input: 22408.91 toks/s, output: 21.88 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:24<00:10, 20.10it/s, est. speed input: 22390.58 toks/s, output: 21.87 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:25<00:09, 20.09it/s, est. speed input: 22373.22 toks/s, output: 21.85 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:25<00:08, 20.07it/s, est. speed input: 22355.76 toks/s, output: 21.83 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:26<00:07, 20.42it/s, est. speed input: 22351.09 toks/s, output: 21.83 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:27<00:06, 20.31it/s, est. speed input: 22334.38 toks/s, output: 21.81 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:28<00:06, 20.22it/s, est. speed input: 22317.89 toks/s, output: 21.79 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:28<00:05, 20.17it/s, est. speed input: 22301.70 toks/s, output: 21.78 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:29<00:04, 20.12it/s, est. speed input: 22285.68 toks/s, output: 21.76 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:30<00:03, 20.09it/s, est. speed input: 22269.79 toks/s, output: 21.75 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:31<00:03, 20.44it/s, est. speed input: 22266.05 toks/s, output: 21.74 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:32<00:02, 20.30it/s, est. speed input: 22250.48 toks/s, output: 21.73 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:32<00:01, 20.21it/s, est. speed input: 22235.24 toks/s, output: 21.71 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:33<00:00, 20.57it/s, est. speed input: 22233.08 toks/s, output: 21.71 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:33<00:00, 20.57it/s, est. speed input: 22386.00 toks/s, output: 21.86 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:33<00:00, 21.86it/s, est. speed input: 22386.00 toks/s, output: 21.86 toks/s]
[rank0]:[W125 19:14:39.711483183 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 166.6s

测试结果:
  Requests/s:   20.34
  Tokens/s:     20853.29
  Total Reqs:   2048
  Elapsed:      100.67s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     20832.95

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:15:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=350111) WARNING 01-25 19:15:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.26 requests/s, 20765.41 total tokens/s, 20.26 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 19:15:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:15:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:15:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:15:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:15:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:15:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:15:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:15:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:15:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:15:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:15:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:15:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:15:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=350111) [2026-01-25 19:15:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=350111) [2026-01-25 19:15:27] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=350111) [2026-01-25 19:15:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=350111) [2026-01-25 19:15:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=350111) [2026-01-25 19:15:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=350111) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=350111) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.82it/s]
(EngineCore_DP0 pid=350111) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.75it/s]
(EngineCore_DP0 pid=350111) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.76it/s]
(EngineCore_DP0 pid=350111) 
(EngineCore_DP0 pid=350111) [rank0]:W0125 19:15:45.059000 350111 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=350111) [rank0]:W0125 19:15:45.361000 350111 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=350111) [rank0]:W0125 19:15:46.950000 350111 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=350111) [rank0]:W0125 19:15:47.141000 350111 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=350111) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00,  9.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  9.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 10.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 10.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 10.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.29it/s]
(EngineCore_DP0 pid=350111) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  9.60it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 10.68it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 10.98it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.98it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.88it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 245.01it/s]
Adding requests:   1%|▏         | 52/4096 [00:00<00:15, 258.79it/s]
Adding requests:   2%|▏         | 82/4096 [00:00<00:14, 274.35it/s]
Adding requests:   3%|▎         | 111/4096 [00:00<00:14, 277.01it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:14, 272.47it/s]
Adding requests:   4%|▍         | 167/4096 [00:00<00:14, 273.17it/s]
Adding requests:   5%|▍         | 199/4096 [00:00<00:13, 287.08it/s]
Adding requests:   6%|▌         | 231/4096 [00:00<00:13, 293.96it/s]
Adding requests:   6%|▋         | 261/4096 [00:00<00:13, 290.33it/s]
Adding requests:   7%|▋         | 291/4096 [00:01<00:13, 282.70it/s]
Adding requests:   8%|▊         | 322/4096 [00:01<00:13, 287.68it/s]
Adding requests:   9%|▊         | 351/4096 [00:01<00:13, 287.27it/s]
Adding requests:   9%|▉         | 384/4096 [00:01<00:12, 297.27it/s]
Adding requests:  10%|█         | 417/4096 [00:01<00:12, 305.09it/s]
Adding requests:  11%|█         | 448/4096 [00:01<00:12, 302.19it/s]
Adding requests:  12%|█▏        | 479/4096 [00:01<00:11, 302.31it/s]
Adding requests:  12%|█▎        | 512/4096 [00:01<00:11, 309.47it/s]
Adding requests:  13%|█▎        | 545/4096 [00:01<00:11, 315.45it/s]
Adding requests:  14%|█▍        | 578/4096 [00:01<00:11, 317.56it/s]
Adding requests:  15%|█▍        | 610/4096 [00:02<00:11, 305.01it/s]
Adding requests:  16%|█▌        | 641/4096 [00:02<00:11, 305.11it/s]
Adding requests:  16%|█▋        | 672/4096 [00:02<00:11, 293.51it/s]
Adding requests:  17%|█▋        | 705/4096 [00:02<00:11, 301.77it/s]
Adding requests:  18%|█▊        | 736/4096 [00:02<00:11, 296.14it/s]
Adding requests:  19%|█▊        | 767/4096 [00:02<00:11, 297.64it/s]
Adding requests:  20%|█▉        | 799/4096 [00:02<00:10, 302.58it/s]
Adding requests:  20%|██        | 830/4096 [00:02<00:10, 301.59it/s]
Adding requests:  21%|██        | 862/4096 [00:02<00:10, 304.63it/s]
Adding requests:  22%|██▏       | 893/4096 [00:03<00:10, 305.08it/s]
Adding requests:  23%|██▎       | 924/4096 [00:03<00:10, 290.16it/s]
Adding requests:  23%|██▎       | 955/4096 [00:03<00:10, 295.66it/s]
Adding requests:  24%|██▍       | 985/4096 [00:03<00:10, 296.32it/s]
Adding requests:  25%|██▍       | 1015/4096 [00:03<00:10, 295.27it/s]
Adding requests:  26%|██▌       | 1046/4096 [00:03<00:10, 299.45it/s]
Adding requests:  26%|██▋       | 1077/4096 [00:03<00:10, 294.01it/s]
Adding requests:  27%|██▋       | 1107/4096 [00:03<00:10, 280.24it/s]
Adding requests:  28%|██▊       | 1139/4096 [00:03<00:10, 289.06it/s]
Adding requests:  29%|██▊       | 1169/4096 [00:03<00:10, 284.21it/s]
Adding requests:  29%|██▉       | 1198/4096 [00:04<00:10, 284.57it/s]
Adding requests:  30%|███       | 1229/4096 [00:04<00:09, 291.06it/s]
Adding requests:  31%|███       | 1260/4096 [00:04<00:09, 296.05it/s]
Adding requests:  31%|███▏      | 1290/4096 [00:04<00:09, 289.48it/s]
Adding requests:  32%|███▏      | 1321/4096 [00:04<00:09, 295.20it/s]
Adding requests:  33%|███▎      | 1353/4096 [00:04<00:09, 301.48it/s]
Adding requests:  34%|███▍      | 1384/4096 [00:04<00:08, 303.88it/s]
Adding requests:  35%|███▍      | 1415/4096 [00:04<00:08, 302.36it/s]
Adding requests:  35%|███▌      | 1446/4096 [00:04<00:08, 303.53it/s]
Adding requests:  36%|███▌      | 1478/4096 [00:04<00:08, 308.37it/s]
Adding requests:  37%|███▋      | 1509/4096 [00:05<00:08, 308.55it/s]
Adding requests:  38%|███▊      | 1540/4096 [00:05<00:08, 295.60it/s]
Adding requests:  38%|███▊      | 1570/4096 [00:05<00:08, 287.86it/s]
Adding requests:  39%|███▉      | 1599/4096 [00:05<00:08, 286.33it/s]
Adding requests:  40%|███▉      | 1629/4096 [00:05<00:08, 289.57it/s]
Adding requests:  41%|████      | 1659/4096 [00:05<00:08, 283.51it/s]
Adding requests:  41%|████▏     | 1690/4096 [00:05<00:08, 289.27it/s]
Adding requests:  42%|████▏     | 1722/4096 [00:05<00:07, 297.12it/s]
Adding requests:  43%|████▎     | 1755/4096 [00:05<00:07, 303.34it/s]
Adding requests:  44%|████▎     | 1786/4096 [00:06<00:07, 304.11it/s]
Adding requests:  44%|████▍     | 1817/4096 [00:06<00:07, 299.44it/s]
Adding requests:  45%|████▌     | 1848/4096 [00:06<00:07, 299.84it/s]
Adding requests:  46%|████▌     | 1880/4096 [00:06<00:07, 305.52it/s]
Adding requests:  47%|████▋     | 1912/4096 [00:06<00:07, 308.32it/s]
Adding requests:  48%|████▊     | 1946/4096 [00:06<00:06, 314.50it/s]
Adding requests:  48%|████▊     | 1978/4096 [00:06<00:06, 314.19it/s]
Adding requests:  49%|████▉     | 2010/4096 [00:06<00:06, 303.76it/s]
Adding requests:  50%|████▉     | 2041/4096 [00:06<00:07, 291.30it/s]
Adding requests:  51%|█████     | 2071/4096 [00:07<00:07, 285.55it/s]
Adding requests:  51%|█████▏    | 2101/4096 [00:07<00:06, 288.41it/s]
Adding requests:  52%|█████▏    | 2131/4096 [00:07<00:06, 289.50it/s]
Adding requests:  53%|█████▎    | 2161/4096 [00:07<00:06, 284.88it/s]
Adding requests:  53%|█████▎    | 2190/4096 [00:07<00:06, 286.33it/s]
Adding requests:  54%|█████▍    | 2221/4096 [00:07<00:06, 291.18it/s]
Adding requests:  55%|█████▌    | 2253/4096 [00:07<00:06, 298.20it/s]
Adding requests:  56%|█████▌    | 2284/4096 [00:07<00:06, 301.19it/s]
Adding requests:  57%|█████▋    | 2316/4096 [00:07<00:05, 306.73it/s]
Adding requests:  57%|█████▋    | 2347/4096 [00:07<00:05, 306.06it/s]
Adding requests:  58%|█████▊    | 2379/4096 [00:08<00:05, 309.53it/s]
Adding requests:  59%|█████▉    | 2413/4096 [00:08<00:05, 317.27it/s]
Adding requests:  60%|█████▉    | 2445/4096 [00:08<00:05, 313.07it/s]
Adding requests:  60%|██████    | 2477/4096 [00:08<00:05, 310.31it/s]
Adding requests:  61%|██████▏   | 2509/4096 [00:08<00:05, 313.05it/s]
Adding requests:  62%|██████▏   | 2543/4096 [00:08<00:04, 318.49it/s]
Adding requests:  63%|██████▎   | 2578/4096 [00:08<00:04, 326.03it/s]
Adding requests:  64%|██████▎   | 2611/4096 [00:08<00:04, 321.78it/s]
Adding requests:  65%|██████▍   | 2644/4096 [00:08<00:04, 313.62it/s]
Adding requests:  65%|██████▌   | 2676/4096 [00:08<00:04, 311.75it/s]
Adding requests:  66%|██████▌   | 2708/4096 [00:09<00:04, 305.83it/s]
Adding requests:  67%|██████▋   | 2740/4096 [00:09<00:04, 309.10it/s]
Adding requests:  68%|██████▊   | 2771/4096 [00:09<00:04, 309.07it/s]
Adding requests:  68%|██████▊   | 2802/4096 [00:09<00:04, 307.05it/s]
Adding requests:  69%|██████▉   | 2833/4096 [00:09<00:04, 305.88it/s]
Adding requests:  70%|██████▉   | 2865/4096 [00:09<00:03, 309.44it/s]
Adding requests:  71%|███████   | 2897/4096 [00:09<00:03, 309.77it/s]
Adding requests:  71%|███████▏  | 2928/4096 [00:09<00:03, 308.60it/s]
Adding requests:  72%|███████▏  | 2961/4096 [00:09<00:03, 314.50it/s]
Adding requests:  73%|███████▎  | 2993/4096 [00:09<00:03, 304.81it/s]
Adding requests:  74%|███████▍  | 3024/4096 [00:10<00:03, 303.68it/s]
Adding requests:  75%|███████▍  | 3056/4096 [00:10<00:03, 305.17it/s]
Adding requests:  75%|███████▌  | 3087/4096 [00:10<00:03, 295.13it/s]
Adding requests:  76%|███████▌  | 3117/4096 [00:10<00:03, 295.34it/s]
Adding requests:  77%|███████▋  | 3149/4096 [00:10<00:03, 300.43it/s]
Adding requests:  78%|███████▊  | 3180/4096 [00:10<00:03, 298.09it/s]
Adding requests:  78%|███████▊  | 3212/4096 [00:10<00:02, 301.75it/s]
Adding requests:  79%|███████▉  | 3245/4096 [00:10<00:02, 307.98it/s]
Adding requests:  80%|███████▉  | 3276/4096 [00:10<00:02, 297.42it/s]
Adding requests:  81%|████████  | 3306/4096 [00:11<00:02, 284.89it/s]
Adding requests:  81%|████████▏ | 3336/4096 [00:11<00:02, 288.69it/s]
Adding requests:  82%|████████▏ | 3368/4096 [00:11<00:02, 295.00it/s]
Adding requests:  83%|████████▎ | 3399/4096 [00:11<00:02, 297.24it/s]
Adding requests:  84%|████████▎ | 3429/4096 [00:11<00:02, 290.55it/s]
Adding requests:  84%|████████▍ | 3459/4096 [00:11<00:02, 289.87it/s]
Adding requests:  85%|████████▌ | 3489/4096 [00:11<00:02, 286.76it/s]
Adding requests:  86%|████████▌ | 3521/4096 [00:11<00:01, 294.20it/s]
Adding requests:  87%|████████▋ | 3553/4096 [00:11<00:01, 299.05it/s]
Adding requests:  88%|████████▊ | 3584/4096 [00:11<00:01, 300.75it/s]
Adding requests:  88%|████████▊ | 3615/4096 [00:12<00:01, 302.37it/s]
Adding requests:  89%|████████▉ | 3646/4096 [00:12<00:01, 301.53it/s]
Adding requests:  90%|████████▉ | 3677/4096 [00:12<00:01, 298.14it/s]
Adding requests:  91%|█████████ | 3707/4096 [00:12<00:01, 286.06it/s]
Adding requests:  91%|█████████ | 3736/4096 [00:12<00:01, 267.21it/s]
Adding requests:  92%|█████████▏| 3764/4096 [00:12<00:01, 268.50it/s]
Adding requests:  93%|█████████▎| 3792/4096 [00:12<00:01, 267.78it/s]
Adding requests:  93%|█████████▎| 3819/4096 [00:12<00:01, 268.15it/s]
Adding requests:  94%|█████████▍| 3848/4096 [00:12<00:00, 272.15it/s]
Adding requests:  95%|█████████▍| 3880/4096 [00:13<00:00, 284.55it/s]
Adding requests:  95%|█████████▌| 3909/4096 [00:13<00:00, 276.05it/s]
Adding requests:  96%|█████████▌| 3937/4096 [00:13<00:00, 271.99it/s]
Adding requests:  97%|█████████▋| 3968/4096 [00:13<00:00, 280.83it/s]
Adding requests:  98%|█████████▊| 3997/4096 [00:13<00:00, 271.96it/s]
Adding requests:  98%|█████████▊| 4026/4096 [00:13<00:00, 274.13it/s]
Adding requests:  99%|█████████▉| 4054/4096 [00:13<00:00, 274.30it/s]
Adding requests: 100%|█████████▉| 4085/4096 [00:13<00:00, 283.51it/s]
Adding requests: 100%|██████████| 4096/4096 [00:13<00:00, 295.87it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 273/4096 [00:00<00:13, 275.69it/s, est. speed input: 282311.85 toks/s, output: 275.69 toks/s]
Processed prompts:   7%|▋         | 305/4096 [00:02<00:37, 100.72it/s, est. speed input: 124325.81 toks/s, output: 121.41 toks/s]
Processed prompts:   8%|▊         | 337/4096 [00:04<01:02, 60.36it/s, est. speed input: 84597.50 toks/s, output: 82.61 toks/s]   
Processed prompts:   9%|▉         | 369/4096 [00:05<01:25, 43.65it/s, est. speed input: 66908.38 toks/s, output: 65.34 toks/s]
Processed prompts:  10%|▉         | 401/4096 [00:07<01:45, 34.95it/s, est. speed input: 56897.24 toks/s, output: 55.56 toks/s]
Processed prompts:  11%|█         | 433/4096 [00:08<02:01, 30.18it/s, est. speed input: 50724.39 toks/s, output: 49.54 toks/s]
Processed prompts:  11%|█▏        | 465/4096 [00:10<02:15, 26.89it/s, est. speed input: 46167.03 toks/s, output: 45.08 toks/s]
Processed prompts:  12%|█▏        | 497/4096 [00:11<02:25, 24.78it/s, est. speed input: 42819.59 toks/s, output: 41.82 toks/s]
Processed prompts:  13%|█▎        | 529/4096 [00:13<02:32, 23.38it/s, est. speed input: 40254.80 toks/s, output: 39.31 toks/s]
Processed prompts:  14%|█▎        | 561/4096 [00:15<02:37, 22.44it/s, est. speed input: 38224.87 toks/s, output: 37.33 toks/s]
Processed prompts:  14%|█▍        | 593/4096 [00:16<02:40, 21.78it/s, est. speed input: 36571.25 toks/s, output: 35.71 toks/s]
Processed prompts:  15%|█▌        | 625/4096 [00:18<02:42, 21.33it/s, est. speed input: 35201.68 toks/s, output: 34.38 toks/s]
Processed prompts:  16%|█▌        | 657/4096 [00:19<02:43, 21.02it/s, est. speed input: 34053.56 toks/s, output: 33.26 toks/s]
Processed prompts:  17%|█▋        | 689/4096 [00:21<02:43, 20.80it/s, est. speed input: 33072.84 toks/s, output: 32.30 toks/s]
Processed prompts:  18%|█▊        | 721/4096 [00:22<02:43, 20.65it/s, est. speed input: 32225.99 toks/s, output: 31.47 toks/s]
Processed prompts:  18%|█▊        | 753/4096 [00:24<02:42, 20.53it/s, est. speed input: 31486.01 toks/s, output: 30.75 toks/s]
Processed prompts:  19%|█▉        | 785/4096 [00:26<02:40, 20.63it/s, est. speed input: 30889.51 toks/s, output: 30.17 toks/s]
Processed prompts:  20%|█▉        | 817/4096 [00:27<02:39, 20.52it/s, est. speed input: 30308.90 toks/s, output: 29.60 toks/s]
Processed prompts:  21%|██        | 849/4096 [00:29<02:38, 20.43it/s, est. speed input: 29789.16 toks/s, output: 29.09 toks/s]
Processed prompts:  22%|██▏       | 881/4096 [00:30<02:37, 20.37it/s, est. speed input: 29323.55 toks/s, output: 28.64 toks/s]
Processed prompts:  22%|██▏       | 913/4096 [00:32<02:36, 20.33it/s, est. speed input: 28902.73 toks/s, output: 28.23 toks/s]
Processed prompts:  23%|██▎       | 945/4096 [00:33<02:35, 20.30it/s, est. speed input: 28520.92 toks/s, output: 27.85 toks/s]
Processed prompts:  24%|██▍       | 977/4096 [00:35<02:33, 20.26it/s, est. speed input: 28170.28 toks/s, output: 27.51 toks/s]
Processed prompts:  25%|██▍       | 1009/4096 [00:37<02:32, 20.24it/s, est. speed input: 27850.51 toks/s, output: 27.20 toks/s]
Processed prompts:  25%|██▌       | 1041/4096 [00:38<02:31, 20.23it/s, est. speed input: 27556.28 toks/s, output: 26.91 toks/s]
Processed prompts:  26%|██▌       | 1073/4096 [00:40<02:29, 20.22it/s, est. speed input: 27285.63 toks/s, output: 26.65 toks/s]
Processed prompts:  27%|██▋       | 1105/4096 [00:41<02:28, 20.20it/s, est. speed input: 27034.28 toks/s, output: 26.40 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:43<02:26, 20.19it/s, est. speed input: 26801.38 toks/s, output: 26.17 toks/s]
Processed prompts:  29%|██▊       | 1169/4096 [00:45<02:25, 20.18it/s, est. speed input: 26583.65 toks/s, output: 25.96 toks/s]
Processed prompts:  29%|██▉       | 1201/4096 [00:46<02:22, 20.35it/s, est. speed input: 26406.98 toks/s, output: 25.79 toks/s]
Processed prompts:  30%|███       | 1233/4096 [00:48<02:19, 20.46it/s, est. speed input: 26240.25 toks/s, output: 25.63 toks/s]
Processed prompts:  31%|███       | 1265/4096 [00:49<02:19, 20.36it/s, est. speed input: 26061.02 toks/s, output: 25.45 toks/s]
Processed prompts:  32%|███▏      | 1297/4096 [00:51<02:17, 20.29it/s, est. speed input: 25892.11 toks/s, output: 25.29 toks/s]
Processed prompts:  32%|███▏      | 1329/4096 [00:52<02:15, 20.41it/s, est. speed input: 25754.67 toks/s, output: 25.15 toks/s]
Processed prompts:  33%|███▎      | 1361/4096 [00:54<02:14, 20.32it/s, est. speed input: 25603.95 toks/s, output: 25.00 toks/s]
Processed prompts:  34%|███▍      | 1393/4096 [00:56<02:13, 20.26it/s, est. speed input: 25461.54 toks/s, output: 24.86 toks/s]
Processed prompts:  35%|███▍      | 1425/4096 [00:57<02:12, 20.21it/s, est. speed input: 25326.23 toks/s, output: 24.73 toks/s]
Processed prompts:  36%|███▌      | 1457/4096 [00:59<02:09, 20.35it/s, est. speed input: 25218.55 toks/s, output: 24.63 toks/s]
Processed prompts:  36%|███▋      | 1489/4096 [01:00<02:08, 20.29it/s, est. speed input: 25098.44 toks/s, output: 24.51 toks/s]
Processed prompts:  37%|███▋      | 1521/4096 [01:02<02:06, 20.42it/s, est. speed input: 25002.34 toks/s, output: 24.42 toks/s]
Processed prompts:  38%|███▊      | 1553/4096 [01:03<02:03, 20.51it/s, est. speed input: 24911.21 toks/s, output: 24.33 toks/s]
Processed prompts:  39%|███▊      | 1585/4096 [01:05<02:03, 20.39it/s, est. speed input: 24806.16 toks/s, output: 24.22 toks/s]
Processed prompts:  39%|███▉      | 1617/4096 [01:06<02:00, 20.49it/s, est. speed input: 24723.98 toks/s, output: 24.14 toks/s]
Processed prompts:  40%|████      | 1649/4096 [01:08<02:00, 20.38it/s, est. speed input: 24628.28 toks/s, output: 24.05 toks/s]
Processed prompts:  41%|████      | 1681/4096 [01:10<01:58, 20.30it/s, est. speed input: 24536.57 toks/s, output: 23.96 toks/s]
Processed prompts:  42%|████▏     | 1713/4096 [01:11<01:56, 20.41it/s, est. speed input: 24464.36 toks/s, output: 23.89 toks/s]
Processed prompts:  43%|████▎     | 1745/4096 [01:13<01:54, 20.50it/s, est. speed input: 24395.84 toks/s, output: 23.82 toks/s]
Processed prompts:  43%|████▎     | 1777/4096 [01:14<01:53, 20.39it/s, est. speed input: 24315.11 toks/s, output: 23.75 toks/s]
Processed prompts:  44%|████▍     | 1809/4096 [01:16<01:52, 20.31it/s, est. speed input: 24238.12 toks/s, output: 23.67 toks/s]
Processed prompts:  45%|████▍     | 1841/4096 [01:18<01:51, 20.25it/s, est. speed input: 24163.59 toks/s, output: 23.60 toks/s]
Processed prompts:  46%|████▌     | 1873/4096 [01:19<01:49, 20.38it/s, est. speed input: 24105.79 toks/s, output: 23.54 toks/s]
Processed prompts:  47%|████▋     | 1905/4096 [01:21<01:47, 20.29it/s, est. speed input: 24036.54 toks/s, output: 23.47 toks/s]
Processed prompts:  47%|████▋     | 1937/4096 [01:22<01:46, 20.23it/s, est. speed input: 23970.14 toks/s, output: 23.41 toks/s]
Processed prompts:  48%|████▊     | 1969/4096 [01:24<01:44, 20.37it/s, est. speed input: 23919.14 toks/s, output: 23.36 toks/s]
Processed prompts:  49%|████▉     | 2001/4096 [01:25<01:43, 20.27it/s, est. speed input: 23856.31 toks/s, output: 23.30 toks/s]
Processed prompts:  50%|████▉     | 2033/4096 [01:27<01:42, 20.21it/s, est. speed input: 23796.19 toks/s, output: 23.24 toks/s]
Processed prompts:  50%|█████     | 2065/4096 [01:29<01:39, 20.34it/s, est. speed input: 23749.72 toks/s, output: 23.19 toks/s]
Processed prompts:  51%|█████     | 2097/4096 [01:30<01:38, 20.26it/s, est. speed input: 23693.48 toks/s, output: 23.14 toks/s]
Processed prompts:  52%|█████▏    | 2129/4096 [01:32<01:37, 20.19it/s, est. speed input: 23638.60 toks/s, output: 23.08 toks/s]
Processed prompts:  53%|█████▎    | 2161/4096 [01:33<01:36, 20.16it/s, est. speed input: 23586.12 toks/s, output: 23.03 toks/s]
Processed prompts:  54%|█████▎    | 2193/4096 [01:35<01:33, 20.31it/s, est. speed input: 23546.93 toks/s, output: 23.00 toks/s]
Processed prompts:  54%|█████▍    | 2225/4096 [01:36<01:32, 20.23it/s, est. speed input: 23497.58 toks/s, output: 22.95 toks/s]
Processed prompts:  55%|█████▌    | 2257/4096 [01:38<01:31, 20.18it/s, est. speed input: 23449.47 toks/s, output: 22.90 toks/s]
Processed prompts:  56%|█████▌    | 2289/4096 [01:40<01:29, 20.14it/s, est. speed input: 23402.71 toks/s, output: 22.85 toks/s]
Processed prompts:  57%|█████▋    | 2321/4096 [01:41<01:28, 20.10it/s, est. speed input: 23357.30 toks/s, output: 22.81 toks/s]
Processed prompts:  57%|█████▋    | 2353/4096 [01:43<01:26, 20.08it/s, est. speed input: 23313.18 toks/s, output: 22.77 toks/s]
Processed prompts:  58%|█████▊    | 2385/4096 [01:44<01:25, 20.07it/s, est. speed input: 23270.67 toks/s, output: 22.73 toks/s]
Processed prompts:  59%|█████▉    | 2417/4096 [01:46<01:23, 20.06it/s, est. speed input: 23229.40 toks/s, output: 22.68 toks/s]
Processed prompts:  60%|█████▉    | 2449/4096 [01:48<01:22, 20.05it/s, est. speed input: 23189.44 toks/s, output: 22.65 toks/s]
Processed prompts:  61%|██████    | 2481/4096 [01:49<01:20, 20.05it/s, est. speed input: 23150.62 toks/s, output: 22.61 toks/s]
Processed prompts:  61%|██████▏   | 2513/4096 [01:51<01:19, 20.04it/s, est. speed input: 23112.42 toks/s, output: 22.57 toks/s]
Processed prompts:  62%|██████▏   | 2545/4096 [01:52<01:16, 20.21it/s, est. speed input: 23084.94 toks/s, output: 22.54 toks/s]
Processed prompts:  63%|██████▎   | 2577/4096 [01:54<01:14, 20.33it/s, est. speed input: 23058.14 toks/s, output: 22.52 toks/s]
Processed prompts:  64%|██████▎   | 2609/4096 [01:56<01:13, 20.24it/s, est. speed input: 23023.05 toks/s, output: 22.48 toks/s]
Processed prompts:  64%|██████▍   | 2641/4096 [01:57<01:12, 20.17it/s, est. speed input: 22988.89 toks/s, output: 22.45 toks/s]
Processed prompts:  65%|██████▌   | 2673/4096 [01:59<01:10, 20.13it/s, est. speed input: 22955.56 toks/s, output: 22.42 toks/s]
Processed prompts:  66%|██████▌   | 2705/4096 [02:00<01:09, 20.10it/s, est. speed input: 22923.41 toks/s, output: 22.39 toks/s]
Processed prompts:  67%|██████▋   | 2737/4096 [02:02<01:07, 20.26it/s, est. speed input: 22900.65 toks/s, output: 22.36 toks/s]
Processed prompts:  68%|██████▊   | 2769/4096 [02:03<01:05, 20.18it/s, est. speed input: 22869.50 toks/s, output: 22.33 toks/s]
Processed prompts:  68%|██████▊   | 2801/4096 [02:05<01:04, 20.13it/s, est. speed input: 22839.36 toks/s, output: 22.30 toks/s]
Processed prompts:  69%|██████▉   | 2833/4096 [02:07<01:02, 20.09it/s, est. speed input: 22809.76 toks/s, output: 22.28 toks/s]
Processed prompts:  70%|██████▉   | 2865/4096 [02:08<01:01, 20.06it/s, est. speed input: 22780.74 toks/s, output: 22.25 toks/s]
Processed prompts:  71%|███████   | 2897/4096 [02:10<00:58, 20.61it/s, est. speed input: 22777.98 toks/s, output: 22.24 toks/s]
Processed prompts:  72%|███████▏  | 2929/4096 [02:11<00:57, 20.43it/s, est. speed input: 22750.32 toks/s, output: 22.22 toks/s]
Processed prompts:  72%|███████▏  | 2961/4096 [02:13<00:55, 20.31it/s, est. speed input: 22723.48 toks/s, output: 22.19 toks/s]
Processed prompts:  73%|███████▎  | 2993/4096 [02:15<00:54, 20.23it/s, est. speed input: 22697.47 toks/s, output: 22.17 toks/s]
Processed prompts:  74%|███████▍  | 3025/4096 [02:16<00:53, 20.16it/s, est. speed input: 22671.60 toks/s, output: 22.14 toks/s]
Processed prompts:  75%|███████▍  | 3057/4096 [02:18<00:51, 20.11it/s, est. speed input: 22646.27 toks/s, output: 22.12 toks/s]
Processed prompts:  75%|███████▌  | 3089/4096 [02:19<00:50, 20.08it/s, est. speed input: 22621.74 toks/s, output: 22.09 toks/s]
Processed prompts:  76%|███████▌  | 3121/4096 [02:21<00:48, 20.06it/s, est. speed input: 22597.43 toks/s, output: 22.07 toks/s]
Processed prompts:  77%|███████▋  | 3153/4096 [02:23<00:47, 20.04it/s, est. speed input: 22573.71 toks/s, output: 22.04 toks/s]
Processed prompts:  78%|███████▊  | 3185/4096 [02:24<00:45, 20.03it/s, est. speed input: 22550.56 toks/s, output: 22.02 toks/s]
Processed prompts:  79%|███████▊  | 3217/4096 [02:26<00:43, 20.02it/s, est. speed input: 22527.93 toks/s, output: 22.00 toks/s]
Processed prompts:  79%|███████▉  | 3249/4096 [02:27<00:42, 20.01it/s, est. speed input: 22505.65 toks/s, output: 21.98 toks/s]
Processed prompts:  80%|████████  | 3281/4096 [02:29<00:40, 20.01it/s, est. speed input: 22484.06 toks/s, output: 21.96 toks/s]
Processed prompts:  81%|████████  | 3313/4096 [02:31<00:39, 20.01it/s, est. speed input: 22462.98 toks/s, output: 21.94 toks/s]
Processed prompts:  82%|████████▏ | 3345/4096 [02:32<00:37, 20.01it/s, est. speed input: 22442.29 toks/s, output: 21.92 toks/s]
Processed prompts:  82%|████████▏ | 3377/4096 [02:34<00:35, 20.01it/s, est. speed input: 22422.02 toks/s, output: 21.90 toks/s]
Processed prompts:  83%|████████▎ | 3409/4096 [02:35<00:34, 20.01it/s, est. speed input: 22402.17 toks/s, output: 21.88 toks/s]
Processed prompts:  84%|████████▍ | 3441/4096 [02:37<00:32, 20.01it/s, est. speed input: 22382.84 toks/s, output: 21.86 toks/s]
Processed prompts:  85%|████████▍ | 3473/4096 [02:39<00:31, 20.01it/s, est. speed input: 22363.75 toks/s, output: 21.84 toks/s]
Processed prompts:  86%|████████▌ | 3505/4096 [02:40<00:29, 20.00it/s, est. speed input: 22344.90 toks/s, output: 21.82 toks/s]
Processed prompts:  86%|████████▋ | 3537/4096 [02:42<00:27, 20.17it/s, est. speed input: 22332.73 toks/s, output: 21.81 toks/s]
Processed prompts:  87%|████████▋ | 3569/4096 [02:43<00:26, 20.12it/s, est. speed input: 22314.63 toks/s, output: 21.79 toks/s]
Processed prompts:  88%|████████▊ | 3601/4096 [02:45<00:24, 20.09it/s, est. speed input: 22296.92 toks/s, output: 21.77 toks/s]
Processed prompts:  89%|████████▊ | 3633/4096 [02:46<00:23, 20.06it/s, est. speed input: 22279.62 toks/s, output: 21.76 toks/s]
Processed prompts:  89%|████████▉ | 3665/4096 [02:48<00:21, 20.22it/s, est. speed input: 22268.77 toks/s, output: 21.75 toks/s]
Processed prompts:  90%|█████████ | 3697/4096 [02:50<00:19, 20.16it/s, est. speed input: 22252.13 toks/s, output: 21.73 toks/s]
Processed prompts:  91%|█████████ | 3729/4096 [02:51<00:18, 20.11it/s, est. speed input: 22235.68 toks/s, output: 21.71 toks/s]
Processed prompts:  92%|█████████▏| 3761/4096 [02:53<00:16, 20.08it/s, est. speed input: 22219.60 toks/s, output: 21.70 toks/s]
Processed prompts:  93%|█████████▎| 3793/4096 [02:54<00:15, 20.06it/s, est. speed input: 22203.60 toks/s, output: 21.68 toks/s]
Processed prompts:  93%|█████████▎| 3825/4096 [02:56<00:13, 20.04it/s, est. speed input: 22187.98 toks/s, output: 21.67 toks/s]
Processed prompts:  94%|█████████▍| 3857/4096 [02:58<00:11, 20.03it/s, est. speed input: 22172.79 toks/s, output: 21.65 toks/s]
Processed prompts:  95%|█████████▍| 3889/4096 [02:59<00:10, 20.03it/s, est. speed input: 22157.91 toks/s, output: 21.64 toks/s]
Processed prompts:  96%|█████████▌| 3921/4096 [03:01<00:08, 20.38it/s, est. speed input: 22154.50 toks/s, output: 21.64 toks/s]
Processed prompts:  97%|█████████▋| 3953/4096 [03:02<00:07, 20.26it/s, est. speed input: 22139.91 toks/s, output: 21.62 toks/s]
Processed prompts:  97%|█████████▋| 3985/4096 [03:04<00:05, 20.36it/s, est. speed input: 22130.84 toks/s, output: 21.61 toks/s]
Processed prompts:  98%|█████████▊| 4017/4096 [03:05<00:03, 20.25it/s, est. speed input: 22116.61 toks/s, output: 21.60 toks/s]
Processed prompts:  99%|█████████▉| 4049/4096 [03:07<00:02, 20.18it/s, est. speed input: 22103.03 toks/s, output: 21.58 toks/s]
Processed prompts: 100%|█████████▉| 4081/4096 [03:08<00:00, 23.97it/s, est. speed input: 22188.81 toks/s, output: 21.67 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:08<00:00, 23.97it/s, est. speed input: 22270.33 toks/s, output: 21.75 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [03:08<00:00, 21.75it/s, est. speed input: 22270.33 toks/s, output: 21.75 toks/s]
[rank0]:[W125 19:19:21.226383970 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 282.5s

测试结果:
  Requests/s:   20.26
  Tokens/s:     20765.41
  Total Reqs:   4096
  Elapsed:      202.18s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     20745.16

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:20:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=354650) WARNING 01-25 19:20:48 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     def forward(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     raise e
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1090, in call
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     triton_poi_fused_mul_quant_only_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_only_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=354650) ERROR 01-25 19:21:00 [core.py:866] 


─── STDERR ───
[2026-01-25 19:20:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:20:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:20:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:20:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:20:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:20:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:20:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:20:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:20:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:39] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=354650) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=354650) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
(EngineCore_DP0 pid=354650) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
(EngineCore_DP0 pid=354650) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
(EngineCore_DP0 pid=354650) 
(EngineCore_DP0 pid=354650) [rank0]:W0125 19:20:57.480000 354650 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=354650) [rank0]:W0125 19:20:57.808000 354650 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=354650) [2026-01-25 19:20:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=354650) [rank0]:W0125 19:20:59.474000 354650 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=354650) [rank0]:W0125 19:20:59.657000 354650 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=354650) [2026-01-25 19:21:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=354650) [2026-01-25 19:21:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=354650) Process EngineCore_DP0:
(EngineCore_DP0 pid=354650) Traceback (most recent call last):
(EngineCore_DP0 pid=354650)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=354650)     self.run()
(EngineCore_DP0 pid=354650)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=354650)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=354650)     raise e
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=354650)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=354650)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=354650)     super().__init__(
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=354650)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=354650)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=354650)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=354650)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=354650)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=354650)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=354650)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=354650)     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=354650)     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=354650)     self.model_runner.profile_run()
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=354650)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=354650)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=354650)     return func(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=354650)     outputs = self.model(
(EngineCore_DP0 pid=354650)               ^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=354650)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=354650)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=354650)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=354650)     hidden_states = self.model(
(EngineCore_DP0 pid=354650)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=354650)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=354650)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=354650)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=354650)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=354650)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=354650)     def forward(
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=354650)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=354650)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=354650)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=354650)     raise e
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=354650)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=354650)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=354650)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=354650)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=354650)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=354650)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=354650)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=354650)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=354650)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=354650)     return compiled_fn(full_args)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=354650)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=354650)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=354650)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=354650)                             ^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=354650)     outs = compiled_fn(args)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=354650)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=354650)     return self.current_callable(inputs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=354650)     out = model(new_inputs)
(EngineCore_DP0 pid=354650)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1090, in call
(EngineCore_DP0 pid=354650)     triton_poi_fused_mul_quant_only_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_only_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=354650)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=354650)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=354650)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=354650)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=354650)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=354650)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=354650)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=354650)     torch.cuda.synchronize()
(EngineCore_DP0 pid=354650)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=354650)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=354650)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=354650) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=354650) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=354650) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=354650) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=354650) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=354650) 
[rank0]:[W125 19:21:01.871337558 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,19.8147,10164.9602,6.4598
1024,1024,1,128,128,17.5695,18008.7032,7.2854
2048,1024,2,256,128,19.3463,19829.9434,13.2325
4096,1024,4,512,128,20.0617,20563.2271,25.5213
8192,1024,8,1024,128,20.2975,20804.9854,50.4494
16384,1024,16,2048,128,20.3447,20853.2950,100.6651
32768,1024,32,4096,128,20.2589,20765.4150,202.1823
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:21:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=355439) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=355439) WARNING 01-25 19:28:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.77 requests/s, 10657.22 total tokens/s, 20.77 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 19:21:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:21:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:21:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:21:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:21:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:21:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:21:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:21:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:21:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=355439) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=355439) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=355439) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [04:05<04:05, 245.05s/it]
(EngineCore_DP0 pid=355439) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [07:22<00:00, 216.88s/it]
(EngineCore_DP0 pid=355439) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [07:22<00:00, 221.10s/it]
(EngineCore_DP0 pid=355439) 
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=355439) [2026-01-25 19:28:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=355439) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.51it/s]
(EngineCore_DP0 pid=355439) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.09it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  35%|███▌      | 45/128 [00:00<00:00, 449.70it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 466.57it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 467.85it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:58,  2.16it/s, est. speed input: 1107.63 toks/s, output: 2.16 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:15,  8.03it/s, est. speed input: 3416.83 toks/s, output: 6.67 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 12.29it/s, est. speed input: 4897.89 toks/s, output: 9.57 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:07, 15.31it/s, est. speed input: 5920.87 toks/s, output: 11.56 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:06, 17.61it/s, est. speed input: 6697.60 toks/s, output: 13.08 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:05, 19.37it/s, est. speed input: 7311.36 toks/s, output: 14.28 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:05, 20.61it/s, est. speed input: 7798.09 toks/s, output: 15.23 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 21.55it/s, est. speed input: 8201.21 toks/s, output: 16.02 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 22.21it/s, est. speed input: 8536.17 toks/s, output: 16.67 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 22.75it/s, est. speed input: 8825.11 toks/s, output: 17.24 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.06it/s, est. speed input: 9067.57 toks/s, output: 17.71 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:04, 22.62it/s, est. speed input: 9216.51 toks/s, output: 18.00 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:03, 22.79it/s, est. speed input: 9386.86 toks/s, output: 18.33 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:03, 22.67it/s, est. speed input: 9515.84 toks/s, output: 18.59 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:03, 22.94it/s, est. speed input: 9658.71 toks/s, output: 18.86 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 23.13it/s, est. speed input: 9786.54 toks/s, output: 19.11 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 23.32it/s, est. speed input: 9905.48 toks/s, output: 19.35 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 23.49it/s, est. speed input: 10015.31 toks/s, output: 19.56 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 23.34it/s, est. speed input: 10097.71 toks/s, output: 19.72 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 23.38it/s, est. speed input: 10181.79 toks/s, output: 19.89 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:02, 23.41it/s, est. speed input: 10259.10 toks/s, output: 20.04 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:02, 23.31it/s, est. speed input: 10322.59 toks/s, output: 20.16 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:02, 23.44it/s, est. speed input: 10393.11 toks/s, output: 20.30 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 23.51it/s, est. speed input: 10457.12 toks/s, output: 20.42 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 23.65it/s, est. speed input: 10521.31 toks/s, output: 20.55 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.61it/s, est. speed input: 10574.05 toks/s, output: 20.65 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.52it/s, est. speed input: 10619.88 toks/s, output: 20.74 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 23.21it/s, est. speed input: 10650.63 toks/s, output: 20.80 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:01, 23.29it/s, est. speed input: 10693.51 toks/s, output: 20.89 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:01, 23.47it/s, est. speed input: 10739.72 toks/s, output: 20.98 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 23.54it/s, est. speed input: 10780.55 toks/s, output: 21.06 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.64it/s, est. speed input: 10821.55 toks/s, output: 21.14 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.88it/s, est. speed input: 10867.22 toks/s, output: 21.22 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.97it/s, est. speed input: 10907.08 toks/s, output: 21.30 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 24.01it/s, est. speed input: 10944.03 toks/s, output: 21.37 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 23.80it/s, est. speed input: 10970.17 toks/s, output: 21.43 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:00, 23.13it/s, est. speed input: 10974.11 toks/s, output: 21.43 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 23.16it/s, est. speed input: 10997.01 toks/s, output: 21.48 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 23.27it/s, est. speed input: 11021.88 toks/s, output: 21.53 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 23.37it/s, est. speed input: 11046.57 toks/s, output: 21.58 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 23.57it/s, est. speed input: 11074.87 toks/s, output: 21.63 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.70it/s, est. speed input: 11101.54 toks/s, output: 21.68 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.71it/s, est. speed input: 11124.09 toks/s, output: 21.73 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.71it/s, est. speed input: 11133.14 toks/s, output: 21.74 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.74it/s, est. speed input: 11133.14 toks/s, output: 21.74 toks/s]
[rank0]:[W125 19:29:17.101114947 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 495.5s

测试结果:
  Requests/s:   20.77
  Tokens/s:     10657.22
  Total Reqs:   128
  Elapsed:      6.16s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     10636.44

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:29:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=362691) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=362691) WARNING 01-25 19:29:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.79 requests/s, 22329.88 total tokens/s, 21.79 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 19:29:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:29:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:29:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:29:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:29:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:29:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:29:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:29:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:29:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:29:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:29:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:29:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:29:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:29:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:29:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:29:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:29:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=362691) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=362691) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.81it/s]
(EngineCore_DP0 pid=362691) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
(EngineCore_DP0 pid=362691) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
(EngineCore_DP0 pid=362691) 
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=362691) [2026-01-25 19:29:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=362691) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.74it/s]
(EngineCore_DP0 pid=362691) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.19it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|██        | 26/128 [00:00<00:00, 255.20it/s]
Adding requests:  41%|████▏     | 53/128 [00:00<00:00, 259.28it/s]
Adding requests:  63%|██████▎   | 81/128 [00:00<00:00, 266.15it/s]
Adding requests:  84%|████████▍ | 108/128 [00:00<00:00, 261.43it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 263.08it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 49.67it/s, est. speed input: 50873.53 toks/s, output: 49.68 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:04, 28.94it/s, est. speed input: 31619.59 toks/s, output: 30.88 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:04, 25.82it/s, est. speed input: 28465.05 toks/s, output: 27.80 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 25.08it/s, est. speed input: 27579.99 toks/s, output: 26.93 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:04, 24.61it/s, est. speed input: 27004.81 toks/s, output: 26.37 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:04, 24.18it/s, est. speed input: 26537.48 toks/s, output: 25.92 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:04, 24.07it/s, est. speed input: 26271.14 toks/s, output: 25.65 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:04, 23.38it/s, est. speed input: 25815.47 toks/s, output: 25.21 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:04, 23.56it/s, est. speed input: 25693.40 toks/s, output: 25.09 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:03, 23.39it/s, est. speed input: 25494.06 toks/s, output: 24.90 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:03, 22.90it/s, est. speed input: 25213.56 toks/s, output: 24.62 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:03, 23.12it/s, est. speed input: 25139.46 toks/s, output: 24.55 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:03, 23.38it/s, est. speed input: 25099.30 toks/s, output: 24.51 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:03, 23.61it/s, est. speed input: 25077.15 toks/s, output: 24.49 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:03, 23.80it/s, est. speed input: 25063.00 toks/s, output: 24.48 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 23.82it/s, est. speed input: 25025.66 toks/s, output: 24.44 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 23.85it/s, est. speed input: 24997.78 toks/s, output: 24.41 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:02, 23.84it/s, est. speed input: 24966.54 toks/s, output: 24.38 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:02<00:02, 23.25it/s, est. speed input: 24835.31 toks/s, output: 24.25 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:02, 23.41it/s, est. speed input: 24813.12 toks/s, output: 24.23 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:02, 23.44it/s, est. speed input: 24778.55 toks/s, output: 24.20 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:02, 23.03it/s, est. speed input: 24680.79 toks/s, output: 24.10 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 22.77it/s, est. speed input: 24595.41 toks/s, output: 24.02 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 23.03it/s, est. speed input: 24580.09 toks/s, output: 24.00 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:03<00:02, 23.32it/s, est. speed input: 24581.80 toks/s, output: 24.01 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:01, 23.39it/s, est. speed input: 24564.09 toks/s, output: 23.99 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:03<00:01, 22.98it/s, est. speed input: 24490.57 toks/s, output: 23.92 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 23.15it/s, est. speed input: 24477.72 toks/s, output: 23.90 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 23.27it/s, est. speed input: 24466.10 toks/s, output: 23.89 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:03<00:01, 23.44it/s, est. speed input: 24464.13 toks/s, output: 23.89 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:04<00:01, 23.52it/s, est. speed input: 24458.89 toks/s, output: 23.89 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 23.20it/s, est. speed input: 24413.95 toks/s, output: 23.84 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:04<00:01, 23.51it/s, est. speed input: 24425.72 toks/s, output: 23.85 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:04<00:00, 23.47it/s, est. speed input: 24412.38 toks/s, output: 23.84 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:04<00:00, 23.08it/s, est. speed input: 24363.45 toks/s, output: 23.79 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:04<00:00, 23.14it/s, est. speed input: 24349.89 toks/s, output: 23.78 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:04<00:00, 23.04it/s, est. speed input: 24322.94 toks/s, output: 23.75 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 23.30it/s, est. speed input: 24327.14 toks/s, output: 23.76 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 23.53it/s, est. speed input: 24335.05 toks/s, output: 23.76 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:05<00:00, 23.42it/s, est. speed input: 24319.98 toks/s, output: 23.75 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.62it/s, est. speed input: 24328.35 toks/s, output: 23.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.62it/s, est. speed input: 24328.35 toks/s, output: 23.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.76it/s, est. speed input: 24328.35 toks/s, output: 23.76 toks/s]
[rank0]:[W125 19:30:10.492431160 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 52.4s

测试结果:
  Requests/s:   21.79
  Tokens/s:     22329.88
  Total Reqs:   128
  Elapsed:      5.88s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     22308.10

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:30:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=363683) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363683) WARNING 01-25 19:30:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.57 requests/s, 32364.24 total tokens/s, 31.57 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 19:30:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:30:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:30:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:30:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:30:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:30:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:30:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:30:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:30:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:30:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:30:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:30:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:30:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:30:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:30:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:30:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:30:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:30] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=363683) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=363683) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.75it/s]
(EngineCore_DP0 pid=363683) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=363683) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=363683) 
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=363683) [2026-01-25 19:30:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=363683) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 10.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.19it/s]
(EngineCore_DP0 pid=363683) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  9.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 10.52it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 246.38it/s]
Adding requests:  20%|██        | 52/256 [00:00<00:00, 254.79it/s]
Adding requests:  32%|███▏      | 82/256 [00:00<00:00, 272.71it/s]
Adding requests:  43%|████▎     | 111/256 [00:00<00:00, 278.70it/s]
Adding requests:  54%|█████▍    | 139/256 [00:00<00:00, 273.08it/s]
Adding requests:  65%|██████▌   | 167/256 [00:00<00:00, 270.48it/s]
Adding requests:  77%|███████▋  | 198/256 [00:00<00:00, 280.72it/s]
Adding requests:  89%|████████▊ | 227/256 [00:00<00:00, 281.01it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 282.71it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 276.34it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:00<00:01, 201.88it/s, est. speed input: 206741.03 toks/s, output: 201.88 toks/s]
Processed prompts:  21%|██        | 53/256 [00:00<00:03, 58.70it/s, est. speed input: 68973.11 toks/s, output: 67.36 toks/s]   
Processed prompts:  25%|██▌       | 64/256 [00:01<00:04, 46.20it/s, est. speed input: 56255.33 toks/s, output: 54.94 toks/s]
Processed prompts:  28%|██▊       | 71/256 [00:01<00:04, 44.02it/s, est. speed input: 53649.69 toks/s, output: 52.39 toks/s]
Processed prompts:  30%|███       | 77/256 [00:01<00:04, 41.07it/s, est. speed input: 51122.00 toks/s, output: 49.92 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:04, 37.21it/s, est. speed input: 48486.17 toks/s, output: 47.35 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:01<00:04, 37.68it/s, est. speed input: 47941.32 toks/s, output: 46.82 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:02<00:04, 34.32it/s, est. speed input: 46019.76 toks/s, output: 44.94 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:02<00:04, 33.71it/s, est. speed input: 45223.82 toks/s, output: 44.16 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:02<00:04, 33.25it/s, est. speed input: 44529.07 toks/s, output: 43.48 toks/s]
Processed prompts:  41%|████      | 104/256 [00:02<00:04, 32.85it/s, est. speed input: 43900.65 toks/s, output: 42.87 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:02<00:04, 32.62it/s, est. speed input: 43355.72 toks/s, output: 42.34 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:02<00:04, 32.43it/s, est. speed input: 42856.98 toks/s, output: 41.85 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:02<00:04, 32.17it/s, est. speed input: 42377.66 toks/s, output: 41.38 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:02<00:04, 31.99it/s, est. speed input: 41941.99 toks/s, output: 40.96 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:03<00:04, 32.03it/s, est. speed input: 41573.86 toks/s, output: 40.60 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:03<00:04, 31.99it/s, est. speed input: 41222.33 toks/s, output: 40.26 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:03<00:03, 31.84it/s, est. speed input: 40876.46 toks/s, output: 39.92 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:03<00:03, 31.76it/s, est. speed input: 40560.93 toks/s, output: 39.61 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:03<00:03, 31.80it/s, est. speed input: 40282.45 toks/s, output: 39.34 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:03<00:03, 31.83it/s, est. speed input: 40023.42 toks/s, output: 39.09 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:03<00:03, 31.74it/s, est. speed input: 39765.31 toks/s, output: 38.83 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:03<00:03, 31.69it/s, est. speed input: 39526.64 toks/s, output: 38.60 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:04<00:03, 31.78it/s, est. speed input: 39318.22 toks/s, output: 38.40 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:04<00:03, 31.82it/s, est. speed input: 39119.51 toks/s, output: 38.20 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:04<00:02, 31.73it/s, est. speed input: 38918.96 toks/s, output: 38.01 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:04<00:02, 31.66it/s, est. speed input: 38728.07 toks/s, output: 37.82 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:04<00:02, 31.73it/s, est. speed input: 38561.30 toks/s, output: 37.66 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:04<00:02, 31.78it/s, est. speed input: 38403.16 toks/s, output: 37.50 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:04<00:02, 31.74it/s, est. speed input: 38245.81 toks/s, output: 37.35 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:04<00:02, 31.70it/s, est. speed input: 38095.95 toks/s, output: 37.20 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:05<00:02, 31.74it/s, est. speed input: 37959.09 toks/s, output: 37.07 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:05<00:02, 31.73it/s, est. speed input: 37826.29 toks/s, output: 36.94 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:05<00:01, 31.71it/s, est. speed input: 37698.24 toks/s, output: 36.81 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:05<00:01, 31.71it/s, est. speed input: 37577.38 toks/s, output: 36.70 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:05<00:01, 33.18it/s, est. speed input: 37587.12 toks/s, output: 36.71 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:05<00:01, 32.74it/s, est. speed input: 37475.04 toks/s, output: 36.60 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:05<00:01, 32.38it/s, est. speed input: 37362.24 toks/s, output: 36.49 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:05<00:01, 32.05it/s, est. speed input: 37248.09 toks/s, output: 36.37 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:06<00:01, 31.95it/s, est. speed input: 37149.02 toks/s, output: 36.28 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:06<00:01, 31.91it/s, est. speed input: 37056.58 toks/s, output: 36.19 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:06<00:00, 31.91it/s, est. speed input: 36969.67 toks/s, output: 36.10 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:06<00:00, 31.78it/s, est. speed input: 36875.84 toks/s, output: 36.01 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:06<00:00, 31.73it/s, est. speed input: 36789.01 toks/s, output: 35.93 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:06<00:00, 31.74it/s, est. speed input: 36709.23 toks/s, output: 35.85 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:06<00:00, 31.75it/s, est. speed input: 36631.91 toks/s, output: 35.77 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:06<00:00, 31.73it/s, est. speed input: 36556.13 toks/s, output: 35.70 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:07<00:00, 31.73it/s, est. speed input: 36483.68 toks/s, output: 35.63 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:07<00:00, 33.25it/s, est. speed input: 36511.19 toks/s, output: 35.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:07<00:00, 33.25it/s, est. speed input: 36511.19 toks/s, output: 35.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:07<00:00, 35.65it/s, est. speed input: 36511.19 toks/s, output: 35.66 toks/s]
[rank0]:[W125 19:31:06.594451596 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 56.1s

测试结果:
  Requests/s:   31.57
  Tokens/s:     32364.24
  Total Reqs:   256
  Elapsed:      8.11s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     32332.66

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:31:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=364741) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=364741) WARNING 01-25 19:31:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.89 requests/s, 34736.60 total tokens/s, 33.89 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 19:31:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:31:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:31:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:31:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:31:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:31:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:31:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:31:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:31:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:31:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:31:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:31:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:31:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:31:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:31:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:31:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:31:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=364741) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=364741) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.81it/s]
(EngineCore_DP0 pid=364741) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
(EngineCore_DP0 pid=364741) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
(EngineCore_DP0 pid=364741) 
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=364741) [2026-01-25 19:31:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=364741) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00, 10.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.84it/s]
(EngineCore_DP0 pid=364741) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00, 10.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 10.77it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 27/512 [00:00<00:01, 266.59it/s]
Adding requests:  11%|█         | 54/512 [00:00<00:01, 267.31it/s]
Adding requests:  17%|█▋        | 85/512 [00:00<00:01, 284.36it/s]
Adding requests:  22%|██▏       | 114/512 [00:00<00:01, 281.46it/s]
Adding requests:  28%|██▊       | 144/512 [00:00<00:01, 286.04it/s]
Adding requests:  34%|███▍      | 174/512 [00:00<00:01, 289.80it/s]
Adding requests:  40%|███▉      | 203/512 [00:00<00:01, 284.75it/s]
Adding requests:  46%|████▌     | 235/512 [00:00<00:00, 294.23it/s]
Adding requests:  52%|█████▏    | 265/512 [00:00<00:00, 294.87it/s]
Adding requests:  58%|█████▊    | 296/512 [00:01<00:00, 297.57it/s]
Adding requests:  64%|██████▍   | 328/512 [00:01<00:00, 302.99it/s]
Adding requests:  71%|███████   | 361/512 [00:01<00:00, 309.31it/s]
Adding requests:  77%|███████▋  | 392/512 [00:01<00:00, 309.11it/s]
Adding requests:  83%|████████▎ | 424/512 [00:01<00:00, 310.57it/s]
Adding requests:  89%|████████▉ | 456/512 [00:01<00:00, 301.02it/s]
Adding requests:  96%|█████████▌| 489/512 [00:01<00:00, 308.91it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 297.42it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:00<00:00, 472.56it/s, est. speed input: 483961.60 toks/s, output: 472.57 toks/s]
Processed prompts:  21%|██        | 106/512 [00:01<00:06, 59.04it/s, est. speed input: 70603.52 toks/s, output: 68.95 toks/s]  
Processed prompts:  25%|██▌       | 128/512 [00:02<00:07, 51.20it/s, est. speed input: 61593.76 toks/s, output: 60.15 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:02<00:08, 44.91it/s, est. speed input: 55916.67 toks/s, output: 54.61 toks/s]
Processed prompts:  30%|██▉       | 152/512 [00:02<00:08, 44.49it/s, est. speed input: 54882.40 toks/s, output: 53.60 toks/s]
Processed prompts:  31%|███▏      | 160/512 [00:03<00:08, 42.37it/s, est. speed input: 53318.46 toks/s, output: 52.07 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:03<00:08, 39.57it/s, est. speed input: 51678.88 toks/s, output: 50.47 toks/s]
Processed prompts:  34%|███▍      | 173/512 [00:03<00:08, 41.10it/s, est. speed input: 51693.47 toks/s, output: 50.48 toks/s]
Processed prompts:  35%|███▍      | 179/512 [00:03<00:09, 36.74it/s, est. speed input: 50047.40 toks/s, output: 48.87 toks/s]
Processed prompts:  36%|███▌      | 184/512 [00:03<00:08, 37.72it/s, est. speed input: 49850.01 toks/s, output: 48.68 toks/s]
Processed prompts:  37%|███▋      | 189/512 [00:03<00:08, 38.59it/s, est. speed input: 49648.43 toks/s, output: 48.48 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:04<00:09, 32.43it/s, est. speed input: 48054.15 toks/s, output: 46.93 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:04<00:09, 32.75it/s, est. speed input: 47690.08 toks/s, output: 46.57 toks/s]
Processed prompts:  40%|████      | 206/512 [00:04<00:08, 34.29it/s, est. speed input: 47228.41 toks/s, output: 46.12 toks/s]
Processed prompts:  41%|████      | 210/512 [00:04<00:08, 34.18it/s, est. speed input: 46901.68 toks/s, output: 45.80 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:04<00:08, 34.06it/s, est. speed input: 46587.18 toks/s, output: 45.50 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:04<00:08, 34.08it/s, est. speed input: 46305.32 toks/s, output: 45.22 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:04<00:08, 34.08it/s, est. speed input: 46034.26 toks/s, output: 44.96 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:05<00:08, 34.01it/s, est. speed input: 45767.89 toks/s, output: 44.70 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:05<00:08, 33.93it/s, est. speed input: 45509.98 toks/s, output: 44.44 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:05<00:08, 33.87it/s, est. speed input: 45264.32 toks/s, output: 44.20 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:05<00:08, 33.94it/s, est. speed input: 45040.65 toks/s, output: 43.98 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:05<00:07, 33.80it/s, est. speed input: 44807.71 toks/s, output: 43.76 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:05<00:07, 33.87it/s, est. speed input: 44600.80 toks/s, output: 43.56 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:05<00:07, 33.91it/s, est. speed input: 44400.68 toks/s, output: 43.36 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:05<00:07, 33.93it/s, est. speed input: 44208.50 toks/s, output: 43.17 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:06<00:07, 33.84it/s, est. speed input: 44015.39 toks/s, output: 42.98 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:06<00:07, 33.91it/s, est. speed input: 43840.08 toks/s, output: 42.81 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:06<00:07, 33.88it/s, est. speed input: 43665.01 toks/s, output: 42.64 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:06<00:07, 33.90it/s, est. speed input: 43500.29 toks/s, output: 42.48 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:06<00:07, 33.84it/s, est. speed input: 43335.45 toks/s, output: 42.32 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:06<00:06, 33.83it/s, est. speed input: 43178.86 toks/s, output: 42.17 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:06<00:06, 33.89it/s, est. speed input: 43032.67 toks/s, output: 42.02 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:06<00:06, 33.91it/s, est. speed input: 42890.04 toks/s, output: 41.88 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:06<00:06, 33.84it/s, est. speed input: 42746.72 toks/s, output: 41.74 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:07<00:06, 33.82it/s, est. speed input: 42609.84 toks/s, output: 41.61 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:07<00:06, 33.81it/s, est. speed input: 42477.46 toks/s, output: 41.48 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:07<00:06, 33.85it/s, est. speed input: 42353.32 toks/s, output: 41.36 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:07<00:05, 35.47it/s, est. speed input: 42243.29 toks/s, output: 41.25 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:07<00:05, 34.98it/s, est. speed input: 42120.12 toks/s, output: 41.13 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:07<00:05, 34.63it/s, est. speed input: 42003.52 toks/s, output: 41.02 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:07<00:05, 34.50it/s, est. speed input: 41899.04 toks/s, output: 40.92 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:07<00:05, 34.41it/s, est. speed input: 41797.91 toks/s, output: 40.82 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:08<00:05, 34.26it/s, est. speed input: 41694.51 toks/s, output: 40.72 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:08<00:05, 34.11it/s, est. speed input: 41591.41 toks/s, output: 40.62 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:08<00:05, 33.93it/s, est. speed input: 41487.56 toks/s, output: 40.52 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:08<00:05, 33.96it/s, est. speed input: 41394.89 toks/s, output: 40.42 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:08<00:04, 33.86it/s, est. speed input: 41298.78 toks/s, output: 40.33 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:08<00:04, 33.86it/s, est. speed input: 41208.49 toks/s, output: 40.24 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:08<00:04, 33.86it/s, est. speed input: 41120.68 toks/s, output: 40.16 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:08<00:04, 33.79it/s, est. speed input: 41031.65 toks/s, output: 40.07 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:09<00:04, 33.82it/s, est. speed input: 40949.49 toks/s, output: 39.99 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:09<00:04, 33.83it/s, est. speed input: 40868.35 toks/s, output: 39.91 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:09<00:04, 33.78it/s, est. speed input: 40786.71 toks/s, output: 39.83 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:09<00:04, 33.73it/s, est. speed input: 40706.23 toks/s, output: 39.75 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:09<00:03, 33.70it/s, est. speed input: 40627.82 toks/s, output: 39.68 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:09<00:03, 33.76it/s, est. speed input: 40555.73 toks/s, output: 39.61 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:09<00:03, 33.81it/s, est. speed input: 40485.57 toks/s, output: 39.54 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:09<00:03, 33.80it/s, est. speed input: 40414.64 toks/s, output: 39.47 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:10<00:03, 33.77it/s, est. speed input: 40344.81 toks/s, output: 39.40 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:10<00:03, 33.77it/s, est. speed input: 40277.03 toks/s, output: 39.33 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:10<00:03, 33.77it/s, est. speed input: 40211.50 toks/s, output: 39.27 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:10<00:03, 33.83it/s, est. speed input: 40149.55 toks/s, output: 39.21 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:10<00:03, 33.76it/s, est. speed input: 40084.27 toks/s, output: 39.14 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:10<00:02, 33.72it/s, est. speed input: 40020.96 toks/s, output: 39.08 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:10<00:02, 33.81it/s, est. speed input: 39964.10 toks/s, output: 39.03 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:10<00:02, 33.83it/s, est. speed input: 39906.47 toks/s, output: 38.97 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:10<00:02, 33.84it/s, est. speed input: 39850.18 toks/s, output: 38.92 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:11<00:02, 33.84it/s, est. speed input: 39794.63 toks/s, output: 38.86 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:11<00:02, 35.51it/s, est. speed input: 39771.64 toks/s, output: 38.84 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:11<00:01, 35.11it/s, est. speed input: 39719.97 toks/s, output: 38.79 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:11<00:01, 34.64it/s, est. speed input: 39662.30 toks/s, output: 38.73 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:11<00:01, 34.36it/s, est. speed input: 39608.85 toks/s, output: 38.68 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:11<00:01, 34.19it/s, est. speed input: 39558.16 toks/s, output: 38.63 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:11<00:01, 34.06it/s, est. speed input: 39508.15 toks/s, output: 38.58 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:11<00:01, 33.93it/s, est. speed input: 39457.83 toks/s, output: 38.53 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:12<00:01, 33.91it/s, est. speed input: 39411.10 toks/s, output: 38.49 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:12<00:01, 33.95it/s, est. speed input: 39367.49 toks/s, output: 38.44 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:12<00:01, 34.00it/s, est. speed input: 39325.18 toks/s, output: 38.40 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:12<00:01, 33.86it/s, est. speed input: 39277.56 toks/s, output: 38.36 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:12<00:00, 33.75it/s, est. speed input: 39230.20 toks/s, output: 38.31 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:12<00:00, 33.70it/s, est. speed input: 39184.84 toks/s, output: 38.27 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:12<00:00, 33.67it/s, est. speed input: 39140.43 toks/s, output: 38.22 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:12<00:00, 33.63it/s, est. speed input: 39096.28 toks/s, output: 38.18 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:13<00:00, 33.69it/s, est. speed input: 39056.07 toks/s, output: 38.14 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:13<00:00, 33.79it/s, est. speed input: 39018.53 toks/s, output: 38.10 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:13<00:00, 33.80it/s, est. speed input: 38979.31 toks/s, output: 38.07 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:13<00:00, 33.80it/s, est. speed input: 39169.57 toks/s, output: 38.25 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:13<00:00, 38.25it/s, est. speed input: 39169.57 toks/s, output: 38.25 toks/s]
[rank0]:[W125 19:32:11.260214250 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 65.7s

测试结果:
  Requests/s:   33.89
  Tokens/s:     34736.60
  Total Reqs:   512
  Elapsed:      15.11s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     34702.71

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:32:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=365948) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=365948) WARNING 01-25 19:32:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 34.98 requests/s, 35857.76 total tokens/s, 34.98 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 19:32:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:32:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:32:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:32:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:32:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:32:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:32:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:32:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:32:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:32:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:32:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:32:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:32:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:32:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:32:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:32:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:32:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=365948) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=365948) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.80it/s]
(EngineCore_DP0 pid=365948) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
(EngineCore_DP0 pid=365948) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.78it/s]
(EngineCore_DP0 pid=365948) 
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=365948) [2026-01-25 19:32:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=365948) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  3.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  6.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.46it/s]
(EngineCore_DP0 pid=365948) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  9.11it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00, 11.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.13it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 27/1024 [00:00<00:03, 262.93it/s]
Adding requests:   6%|▌         | 57/1024 [00:00<00:03, 279.38it/s]
Adding requests:   8%|▊         | 86/1024 [00:00<00:03, 280.67it/s]
Adding requests:  11%|█         | 115/1024 [00:00<00:03, 283.81it/s]
Adding requests:  14%|█▍        | 146/1024 [00:00<00:03, 289.00it/s]
Adding requests:  17%|█▋        | 176/1024 [00:00<00:02, 289.09it/s]
Adding requests:  20%|██        | 208/1024 [00:00<00:02, 298.17it/s]
Adding requests:  23%|██▎       | 240/1024 [00:00<00:02, 301.76it/s]
Adding requests:  26%|██▋       | 271/1024 [00:00<00:02, 299.02it/s]
Adding requests:  29%|██▉       | 302/1024 [00:01<00:02, 302.13it/s]
Adding requests:  33%|███▎      | 333/1024 [00:01<00:02, 303.90it/s]
Adding requests:  36%|███▌      | 364/1024 [00:01<00:02, 299.27it/s]
Adding requests:  38%|███▊      | 394/1024 [00:01<00:02, 295.53it/s]
Adding requests:  41%|████▏     | 424/1024 [00:01<00:02, 295.53it/s]
Adding requests:  44%|████▍     | 454/1024 [00:01<00:01, 286.86it/s]
Adding requests:  48%|████▊     | 487/1024 [00:01<00:01, 298.43it/s]
Adding requests:  51%|█████     | 521/1024 [00:01<00:01, 310.48it/s]
Adding requests:  54%|█████▍    | 553/1024 [00:01<00:01, 301.85it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:01<00:01, 300.85it/s]
Adding requests:  60%|██████    | 615/1024 [00:02<00:01, 295.42it/s]
Adding requests:  63%|██████▎   | 645/1024 [00:02<00:01, 288.11it/s]
Adding requests:  66%|██████▌   | 674/1024 [00:02<00:01, 282.02it/s]
Adding requests:  69%|██████▉   | 704/1024 [00:02<00:01, 284.96it/s]
Adding requests:  72%|███████▏  | 733/1024 [00:02<00:01, 281.03it/s]
Adding requests:  74%|███████▍  | 762/1024 [00:02<00:00, 279.41it/s]
Adding requests:  78%|███████▊  | 794/1024 [00:02<00:00, 289.30it/s]
Adding requests:  81%|████████  | 826/1024 [00:02<00:00, 297.93it/s]
Adding requests:  84%|████████▎ | 857/1024 [00:02<00:00, 299.92it/s]
Adding requests:  87%|████████▋ | 889/1024 [00:03<00:00, 304.49it/s]
Adding requests:  90%|████████▉ | 920/1024 [00:03<00:00, 302.02it/s]
Adding requests:  93%|█████████▎| 951/1024 [00:03<00:00, 298.37it/s]
Adding requests:  96%|█████████▌| 981/1024 [00:03<00:00, 298.45it/s]
Adding requests:  99%|█████████▊| 1011/1024 [00:03<00:00, 287.73it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 293.33it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:00<00:01, 524.63it/s, est. speed input: 537273.32 toks/s, output: 524.64 toks/s]
Processed prompts:  17%|█▋        | 175/1024 [00:01<00:09, 90.13it/s, est. speed input: 111629.43 toks/s, output: 109.01 toks/s] 
Processed prompts:  19%|█▉        | 199/1024 [00:02<00:12, 68.66it/s, est. speed input: 88949.03 toks/s, output: 86.86 toks/s]  
Processed prompts:  21%|██        | 214/1024 [00:02<00:13, 59.75it/s, est. speed input: 80390.41 toks/s, output: 78.51 toks/s]
Processed prompts:  22%|██▏       | 225/1024 [00:02<00:13, 57.84it/s, est. speed input: 77982.51 toks/s, output: 76.15 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:03<00:17, 45.66it/s, est. speed input: 70224.14 toks/s, output: 68.58 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:03<00:17, 43.70it/s, est. speed input: 68071.64 toks/s, output: 66.48 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:03<00:18, 41.84it/s, est. speed input: 66153.06 toks/s, output: 64.60 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:04<00:19, 40.29it/s, est. speed input: 64469.92 toks/s, output: 62.96 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:04<00:19, 38.95it/s, est. speed input: 62948.51 toks/s, output: 61.47 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:04<00:19, 37.90it/s, est. speed input: 61580.37 toks/s, output: 60.14 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:04<00:20, 37.08it/s, est. speed input: 60342.11 toks/s, output: 58.93 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:05<00:20, 36.56it/s, est. speed input: 59242.10 toks/s, output: 57.85 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:05<00:20, 36.13it/s, est. speed input: 58225.49 toks/s, output: 56.86 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:05<00:19, 36.90it/s, est. speed input: 57536.25 toks/s, output: 56.19 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:05<00:19, 36.32it/s, est. speed input: 56660.56 toks/s, output: 55.33 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:05<00:19, 35.94it/s, est. speed input: 55856.99 toks/s, output: 54.55 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:06<00:19, 35.66it/s, est. speed input: 55111.51 toks/s, output: 53.82 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:06<00:19, 35.40it/s, est. speed input: 54407.99 toks/s, output: 53.13 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:06<00:19, 35.26it/s, est. speed input: 53759.42 toks/s, output: 52.50 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:06<00:19, 35.08it/s, est. speed input: 53141.60 toks/s, output: 51.90 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:07<00:18, 35.03it/s, est. speed input: 52576.59 toks/s, output: 51.34 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:07<00:18, 35.06it/s, est. speed input: 52057.74 toks/s, output: 50.84 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:07<00:18, 34.99it/s, est. speed input: 51554.95 toks/s, output: 50.35 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:07<00:18, 34.97it/s, est. speed input: 51088.09 toks/s, output: 49.89 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:07<00:18, 34.97it/s, est. speed input: 50649.72 toks/s, output: 49.46 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:08<00:17, 34.99it/s, est. speed input: 50237.81 toks/s, output: 49.06 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:08<00:17, 34.96it/s, est. speed input: 49843.33 toks/s, output: 48.68 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:08<00:17, 35.00it/s, est. speed input: 49475.83 toks/s, output: 48.32 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:08<00:17, 34.98it/s, est. speed input: 49123.21 toks/s, output: 47.97 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:09<00:16, 36.15it/s, est. speed input: 48921.57 toks/s, output: 47.77 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:09<00:16, 35.74it/s, est. speed input: 48594.34 toks/s, output: 47.46 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:09<00:16, 35.50it/s, est. speed input: 48287.67 toks/s, output: 47.16 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:09<00:16, 35.34it/s, est. speed input: 47995.05 toks/s, output: 46.87 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:10<00:15, 35.16it/s, est. speed input: 47709.95 toks/s, output: 46.59 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:10<00:15, 35.05it/s, est. speed input: 47437.91 toks/s, output: 46.33 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:10<00:15, 35.01it/s, est. speed input: 47181.72 toks/s, output: 46.08 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:10<00:15, 35.04it/s, est. speed input: 46942.24 toks/s, output: 45.84 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:10<00:15, 35.02it/s, est. speed input: 46709.14 toks/s, output: 45.61 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:11<00:14, 35.00it/s, est. speed input: 46485.48 toks/s, output: 45.40 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:11<00:14, 34.97it/s, est. speed input: 46268.42 toks/s, output: 45.18 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:11<00:14, 34.99it/s, est. speed input: 46064.10 toks/s, output: 44.98 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:11<00:14, 34.98it/s, est. speed input: 45865.75 toks/s, output: 44.79 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:12<00:13, 34.94it/s, est. speed input: 45671.97 toks/s, output: 44.60 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:12<00:13, 34.93it/s, est. speed input: 45486.43 toks/s, output: 44.42 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:12<00:13, 34.98it/s, est. speed input: 45312.92 toks/s, output: 44.25 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:12<00:13, 34.95it/s, est. speed input: 45140.17 toks/s, output: 44.08 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:12<00:12, 34.94it/s, est. speed input: 44974.40 toks/s, output: 43.92 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:13<00:12, 34.91it/s, est. speed input: 44812.68 toks/s, output: 43.76 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:13<00:12, 34.99it/s, est. speed input: 44664.28 toks/s, output: 43.62 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:13<00:12, 34.97it/s, est. speed input: 44514.61 toks/s, output: 43.47 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:13<00:12, 34.92it/s, est. speed input: 44368.28 toks/s, output: 43.33 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:14<00:11, 34.94it/s, est. speed input: 44229.51 toks/s, output: 43.19 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:14<00:11, 34.95it/s, est. speed input: 44095.48 toks/s, output: 43.06 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:14<00:11, 34.96it/s, est. speed input: 43965.55 toks/s, output: 42.94 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:14<00:11, 34.97it/s, est. speed input: 43840.28 toks/s, output: 42.81 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:15<00:10, 34.97it/s, est. speed input: 43718.24 toks/s, output: 42.69 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:15<00:10, 34.93it/s, est. speed input: 43596.87 toks/s, output: 42.58 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:15<00:10, 34.91it/s, est. speed input: 43480.36 toks/s, output: 42.46 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:15<00:10, 34.89it/s, est. speed input: 43366.17 toks/s, output: 42.35 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:15<00:10, 34.93it/s, est. speed input: 43259.02 toks/s, output: 42.25 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:16<00:09, 34.93it/s, est. speed input: 43153.08 toks/s, output: 42.14 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:16<00:09, 34.91it/s, est. speed input: 43048.84 toks/s, output: 42.04 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:16<00:09, 34.89it/s, est. speed input: 42947.15 toks/s, output: 41.94 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:16<00:09, 34.88it/s, est. speed input: 42848.68 toks/s, output: 41.84 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:17<00:08, 34.93it/s, est. speed input: 42755.41 toks/s, output: 41.75 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:17<00:08, 34.92it/s, est. speed input: 42662.77 toks/s, output: 41.66 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:17<00:08, 34.87it/s, est. speed input: 42570.00 toks/s, output: 41.57 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:17<00:08, 34.82it/s, est. speed input: 42479.02 toks/s, output: 41.48 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:18<00:07, 34.83it/s, est. speed input: 42392.20 toks/s, output: 41.40 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:18<00:07, 34.86it/s, est. speed input: 42309.47 toks/s, output: 41.32 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:18<00:07, 34.90it/s, est. speed input: 42229.35 toks/s, output: 41.24 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:18<00:07, 34.91it/s, est. speed input: 42150.21 toks/s, output: 41.16 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:18<00:07, 34.88it/s, est. speed input: 42071.23 toks/s, output: 41.09 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:19<00:06, 36.07it/s, est. speed input: 42050.47 toks/s, output: 41.06 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:19<00:06, 35.77it/s, est. speed input: 41978.44 toks/s, output: 40.99 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:19<00:06, 35.50it/s, est. speed input: 41905.18 toks/s, output: 40.92 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:19<00:06, 35.29it/s, est. speed input: 41832.86 toks/s, output: 40.85 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:20<00:05, 35.14it/s, est. speed input: 41761.59 toks/s, output: 40.78 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:20<00:05, 35.09it/s, est. speed input: 41694.58 toks/s, output: 40.72 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:20<00:05, 35.01it/s, est. speed input: 41626.93 toks/s, output: 40.65 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:20<00:05, 34.92it/s, est. speed input: 41559.30 toks/s, output: 40.59 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:20<00:04, 34.89it/s, est. speed input: 41494.49 toks/s, output: 40.52 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:21<00:04, 34.89it/s, est. speed input: 41432.48 toks/s, output: 40.46 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:21<00:04, 34.92it/s, est. speed input: 41372.70 toks/s, output: 40.40 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:21<00:04, 34.87it/s, est. speed input: 41311.17 toks/s, output: 40.34 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:21<00:04, 34.86it/s, est. speed input: 41252.17 toks/s, output: 40.29 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:22<00:03, 34.85it/s, est. speed input: 41193.82 toks/s, output: 40.23 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:22<00:03, 34.87it/s, est. speed input: 41138.15 toks/s, output: 40.17 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:22<00:03, 34.83it/s, est. speed input: 41081.40 toks/s, output: 40.12 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:22<00:03, 34.80it/s, est. speed input: 41025.88 toks/s, output: 40.06 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:23<00:02, 34.83it/s, est. speed input: 40973.09 toks/s, output: 40.01 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:23<00:02, 34.79it/s, est. speed input: 40919.01 toks/s, output: 39.96 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:23<00:02, 34.78it/s, est. speed input: 40866.99 toks/s, output: 39.91 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:23<00:02, 34.80it/s, est. speed input: 40816.71 toks/s, output: 39.86 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:23<00:02, 34.74it/s, est. speed input: 40764.72 toks/s, output: 39.81 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:24<00:01, 34.73it/s, est. speed input: 40715.04 toks/s, output: 39.76 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:24<00:01, 34.75it/s, est. speed input: 40667.26 toks/s, output: 39.71 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:24<00:01, 34.75it/s, est. speed input: 40619.78 toks/s, output: 39.67 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:24<00:01, 34.80it/s, est. speed input: 40575.12 toks/s, output: 39.62 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:25<00:00, 34.72it/s, est. speed input: 40527.05 toks/s, output: 39.58 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:25<00:00, 34.74it/s, est. speed input: 40482.35 toks/s, output: 39.53 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:25<00:00, 34.74it/s, est. speed input: 40438.12 toks/s, output: 39.49 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:25<00:00, 36.03it/s, est. speed input: 40437.81 toks/s, output: 39.49 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:25<00:00, 36.03it/s, est. speed input: 40675.74 toks/s, output: 39.72 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:25<00:00, 39.72it/s, est. speed input: 40675.74 toks/s, output: 39.72 toks/s]
[rank0]:[W125 19:33:36.026940926 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 84.8s

测试结果:
  Requests/s:   34.98
  Tokens/s:     35857.76
  Total Reqs:   1024
  Elapsed:      29.27s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     35822.77

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:34:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=367454) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=367454) WARNING 01-25 19:34:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.62 requests/s, 36505.97 total tokens/s, 35.62 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 19:34:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:34:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:34:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:34:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:34:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:34:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:34:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:34:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:34:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:34:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:34:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:34:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:34:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:34:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:34:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:34:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:34:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=367454) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=367454) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.84it/s]
(EngineCore_DP0 pid=367454) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.81it/s]
(EngineCore_DP0 pid=367454) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.81it/s]
(EngineCore_DP0 pid=367454) 
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:11] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=367454) [2026-01-25 19:34:11] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=367454) [rank0]:W0125 19:34:27.724000 367454 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=367454) [rank0]:W0125 19:34:27.847000 367454 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=367454) [rank0]:W0125 19:34:29.552000 367454 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=367454) [rank0]:W0125 19:34:29.751000 367454 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=367454) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 10.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 10.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 11.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.83it/s]
(EngineCore_DP0 pid=367454) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  9.82it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 10.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.98it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 28/2048 [00:00<00:07, 273.34it/s]
Adding requests:   3%|▎         | 59/2048 [00:00<00:06, 293.30it/s]
Adding requests:   4%|▍         | 89/2048 [00:00<00:06, 287.57it/s]
Adding requests:   6%|▌         | 118/2048 [00:00<00:06, 278.75it/s]
Adding requests:   7%|▋         | 146/2048 [00:00<00:06, 276.38it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:06, 287.38it/s]
Adding requests:  10%|█         | 208/2048 [00:00<00:06, 293.13it/s]
Adding requests:  12%|█▏        | 238/2048 [00:00<00:06, 291.44it/s]
Adding requests:  13%|█▎        | 268/2048 [00:00<00:06, 286.26it/s]
Adding requests:  15%|█▍        | 298/2048 [00:01<00:06, 288.68it/s]
Adding requests:  16%|█▌        | 329/2048 [00:01<00:05, 294.67it/s]
Adding requests:  18%|█▊        | 360/2048 [00:01<00:05, 298.84it/s]
Adding requests:  19%|█▉        | 392/2048 [00:01<00:05, 302.65it/s]
Adding requests:  21%|██        | 424/2048 [00:01<00:05, 305.66it/s]
Adding requests:  22%|██▏       | 455/2048 [00:01<00:05, 305.50it/s]
Adding requests:  24%|██▍       | 489/2048 [00:01<00:04, 312.94it/s]
Adding requests:  26%|██▌       | 524/2048 [00:01<00:04, 323.41it/s]
Adding requests:  27%|██▋       | 557/2048 [00:01<00:04, 320.08it/s]
Adding requests:  29%|██▉       | 590/2048 [00:01<00:04, 313.58it/s]
Adding requests:  30%|███       | 622/2048 [00:02<00:04, 304.26it/s]
Adding requests:  32%|███▏      | 653/2048 [00:02<00:04, 300.22it/s]
Adding requests:  33%|███▎      | 685/2048 [00:02<00:04, 304.79it/s]
Adding requests:  35%|███▌      | 717/2048 [00:02<00:04, 308.16it/s]
Adding requests:  37%|███▋      | 748/2048 [00:02<00:04, 299.24it/s]
Adding requests:  38%|███▊      | 778/2048 [00:02<00:04, 294.03it/s]
Adding requests:  40%|███▉      | 809/2048 [00:02<00:04, 295.80it/s]
Adding requests:  41%|████      | 840/2048 [00:02<00:04, 299.90it/s]
Adding requests:  43%|████▎     | 873/2048 [00:02<00:03, 306.11it/s]
Adding requests:  44%|████▍     | 905/2048 [00:03<00:03, 307.77it/s]
Adding requests:  46%|████▌     | 936/2048 [00:03<00:03, 290.89it/s]
Adding requests:  47%|████▋     | 967/2048 [00:03<00:03, 296.10it/s]
Adding requests:  49%|████▊     | 997/2048 [00:03<00:03, 293.19it/s]
Adding requests:  50%|█████     | 1027/2048 [00:03<00:03, 293.63it/s]
Adding requests:  52%|█████▏    | 1057/2048 [00:03<00:03, 287.45it/s]
Adding requests:  53%|█████▎    | 1087/2048 [00:03<00:03, 289.55it/s]
Adding requests:  55%|█████▍    | 1119/2048 [00:03<00:03, 295.27it/s]
Adding requests:  56%|█████▋    | 1152/2048 [00:03<00:02, 302.37it/s]
Adding requests:  58%|█████▊    | 1184/2048 [00:03<00:02, 305.79it/s]
Adding requests:  59%|█████▉    | 1216/2048 [00:04<00:02, 308.88it/s]
Adding requests:  61%|██████    | 1247/2048 [00:04<00:02, 301.78it/s]
Adding requests:  62%|██████▏   | 1278/2048 [00:04<00:02, 296.45it/s]
Adding requests:  64%|██████▍   | 1309/2048 [00:04<00:02, 299.16it/s]
Adding requests:  65%|██████▌   | 1340/2048 [00:04<00:02, 301.40it/s]
Adding requests:  67%|██████▋   | 1371/2048 [00:04<00:02, 299.60it/s]
Adding requests:  68%|██████▊   | 1401/2048 [00:04<00:02, 293.68it/s]
Adding requests:  70%|██████▉   | 1432/2048 [00:04<00:02, 296.51it/s]
Adding requests:  71%|███████▏  | 1463/2048 [00:04<00:01, 300.33it/s]
Adding requests:  73%|███████▎  | 1496/2048 [00:04<00:01, 308.71it/s]
Adding requests:  75%|███████▍  | 1527/2048 [00:05<00:01, 303.75it/s]
Adding requests:  76%|███████▌  | 1558/2048 [00:05<00:01, 303.31it/s]
Adding requests:  78%|███████▊  | 1589/2048 [00:05<00:01, 300.90it/s]
Adding requests:  79%|███████▉  | 1620/2048 [00:05<00:01, 298.43it/s]
Adding requests:  81%|████████  | 1650/2048 [00:05<00:01, 296.83it/s]
Adding requests:  82%|████████▏ | 1680/2048 [00:05<00:01, 289.22it/s]
Adding requests:  84%|████████▎ | 1711/2048 [00:05<00:01, 295.08it/s]
Adding requests:  85%|████████▌ | 1741/2048 [00:05<00:01, 296.38it/s]
Adding requests:  87%|████████▋ | 1774/2048 [00:05<00:00, 304.77it/s]
Adding requests:  88%|████████▊ | 1805/2048 [00:06<00:00, 304.58it/s]
Adding requests:  90%|████████▉ | 1836/2048 [00:06<00:00, 294.70it/s]
Adding requests:  91%|█████████ | 1866/2048 [00:06<00:00, 294.53it/s]
Adding requests:  93%|█████████▎| 1897/2048 [00:06<00:00, 296.93it/s]
Adding requests:  94%|█████████▍| 1929/2048 [00:06<00:00, 302.38it/s]
Adding requests:  96%|█████████▌| 1962/2048 [00:06<00:00, 308.28it/s]
Adding requests:  97%|█████████▋| 1993/2048 [00:06<00:00, 304.96it/s]
Adding requests:  99%|█████████▉| 2024/2048 [00:06<00:00, 281.44it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 298.17it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:00<00:02, 673.42it/s, est. speed input: 689631.39 toks/s, output: 673.43 toks/s]
Processed prompts:  15%|█▌        | 310/2048 [00:02<00:14, 117.56it/s, est. speed input: 149228.34 toks/s, output: 145.73 toks/s]
Processed prompts:  17%|█▋        | 340/2048 [00:03<00:20, 84.93it/s, est. speed input: 115154.31 toks/s, output: 112.46 toks/s] 
Processed prompts:  17%|█▋        | 358/2048 [00:03<00:22, 75.21it/s, est. speed input: 105595.33 toks/s, output: 103.12 toks/s]
Processed prompts:  18%|█▊        | 371/2048 [00:03<00:26, 64.25it/s, est. speed input: 96897.65 toks/s, output: 94.63 toks/s]  
Processed prompts:  19%|█▉        | 386/2048 [00:04<00:29, 56.45it/s, est. speed input: 90457.62 toks/s, output: 88.34 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:04<00:32, 50.96it/s, est. speed input: 85447.09 toks/s, output: 83.44 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:05<00:34, 46.76it/s, est. speed input: 81284.56 toks/s, output: 79.38 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:05<00:36, 44.28it/s, est. speed input: 78085.94 toks/s, output: 76.26 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:06<00:38, 41.69it/s, est. speed input: 75010.87 toks/s, output: 73.25 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:06<00:39, 39.90it/s, est. speed input: 72380.67 toks/s, output: 70.68 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:07<00:40, 38.66it/s, est. speed input: 70097.13 toks/s, output: 68.45 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:07<00:41, 37.76it/s, est. speed input: 68080.41 toks/s, output: 66.48 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:07<00:41, 37.12it/s, est. speed input: 66292.88 toks/s, output: 64.74 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:08<00:41, 36.71it/s, est. speed input: 64706.49 toks/s, output: 63.19 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:08<00:41, 36.38it/s, est. speed input: 63270.88 toks/s, output: 61.79 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:09<00:41, 36.14it/s, est. speed input: 61970.58 toks/s, output: 60.52 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:09<00:40, 35.98it/s, est. speed input: 60793.99 toks/s, output: 59.37 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:10<00:40, 35.87it/s, est. speed input: 59720.39 toks/s, output: 58.32 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:10<00:40, 35.77it/s, est. speed input: 58733.18 toks/s, output: 57.36 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:11<00:39, 35.71it/s, est. speed input: 57827.31 toks/s, output: 56.47 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:11<00:39, 35.66it/s, est. speed input: 56991.20 toks/s, output: 55.66 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:11<00:39, 35.61it/s, est. speed input: 56214.83 toks/s, output: 54.90 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:12<00:38, 35.60it/s, est. speed input: 55498.71 toks/s, output: 54.20 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:12<00:38, 35.58it/s, est. speed input: 54831.95 toks/s, output: 53.55 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:13<00:37, 35.56it/s, est. speed input: 54207.66 toks/s, output: 52.94 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:13<00:37, 35.54it/s, est. speed input: 53623.10 toks/s, output: 52.37 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:14<00:36, 35.56it/s, est. speed input: 53081.70 toks/s, output: 51.84 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:14<00:36, 35.54it/s, est. speed input: 52568.22 toks/s, output: 51.34 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:15<00:35, 35.54it/s, est. speed input: 52086.34 toks/s, output: 50.87 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:15<00:34, 36.07it/s, est. speed input: 51706.62 toks/s, output: 50.49 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:16<00:34, 35.91it/s, est. speed input: 51276.08 toks/s, output: 50.07 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:16<00:34, 35.76it/s, est. speed input: 50864.40 toks/s, output: 49.67 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:16<00:34, 35.66it/s, est. speed input: 50474.67 toks/s, output: 49.29 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:17<00:33, 35.61it/s, est. speed input: 50108.72 toks/s, output: 48.93 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:17<00:33, 35.59it/s, est. speed input: 49762.16 toks/s, output: 48.60 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:18<00:32, 35.53it/s, est. speed input: 49427.24 toks/s, output: 48.27 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:18<00:32, 35.51it/s, est. speed input: 49111.47 toks/s, output: 47.96 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:19<00:31, 35.49it/s, est. speed input: 48809.84 toks/s, output: 47.67 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:19<00:31, 35.50it/s, est. speed input: 48524.13 toks/s, output: 47.39 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:20<00:31, 35.49it/s, est. speed input: 48249.87 toks/s, output: 47.12 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:20<00:30, 35.46it/s, est. speed input: 47985.26 toks/s, output: 46.86 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:20<00:30, 35.45it/s, est. speed input: 47733.17 toks/s, output: 46.61 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:21<00:29, 35.42it/s, est. speed input: 47489.74 toks/s, output: 46.38 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:21<00:29, 35.41it/s, est. speed input: 47257.25 toks/s, output: 46.15 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:22<00:28, 35.40it/s, est. speed input: 47033.68 toks/s, output: 45.93 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:22<00:28, 35.37it/s, est. speed input: 46817.04 toks/s, output: 45.72 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:23<00:27, 35.39it/s, est. speed input: 46612.67 toks/s, output: 45.52 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:23<00:27, 35.38it/s, est. speed input: 46413.85 toks/s, output: 45.33 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:24<00:27, 35.39it/s, est. speed input: 46223.86 toks/s, output: 45.14 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:24<00:26, 35.37it/s, est. speed input: 46038.93 toks/s, output: 44.96 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:25<00:26, 35.39it/s, est. speed input: 45862.95 toks/s, output: 44.79 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:25<00:25, 35.37it/s, est. speed input: 45691.31 toks/s, output: 44.62 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:25<00:25, 35.36it/s, est. speed input: 45525.24 toks/s, output: 44.46 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:26<00:24, 35.35it/s, est. speed input: 45364.77 toks/s, output: 44.30 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:26<00:24, 35.37it/s, est. speed input: 45212.04 toks/s, output: 44.15 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:27<00:23, 35.92it/s, est. speed input: 45100.84 toks/s, output: 44.04 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:27<00:23, 35.76it/s, est. speed input: 44956.84 toks/s, output: 43.90 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:28<00:22, 36.23it/s, est. speed input: 44855.09 toks/s, output: 43.80 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:28<00:22, 35.97it/s, est. speed input: 44718.79 toks/s, output: 43.67 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:29<00:21, 35.77it/s, est. speed input: 44585.16 toks/s, output: 43.54 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:29<00:21, 35.65it/s, est. speed input: 44457.10 toks/s, output: 43.42 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:29<00:21, 35.54it/s, est. speed input: 44331.43 toks/s, output: 43.29 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:30<00:20, 35.48it/s, est. speed input: 44210.52 toks/s, output: 43.17 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:30<00:19, 36.04it/s, est. speed input: 44128.71 toks/s, output: 43.09 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:31<00:19, 35.78it/s, est. speed input: 44010.87 toks/s, output: 42.98 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:31<00:19, 35.64it/s, est. speed input: 43899.08 toks/s, output: 42.87 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:32<00:18, 35.55it/s, est. speed input: 43790.56 toks/s, output: 42.76 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:32<00:18, 35.46it/s, est. speed input: 43683.73 toks/s, output: 42.66 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:33<00:18, 35.43it/s, est. speed input: 43581.93 toks/s, output: 42.56 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:33<00:17, 35.36it/s, est. speed input: 43479.87 toks/s, output: 42.46 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:34<00:17, 35.37it/s, est. speed input: 43383.41 toks/s, output: 42.37 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:34<00:16, 35.92it/s, est. speed input: 43318.47 toks/s, output: 42.30 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:34<00:16, 35.73it/s, est. speed input: 43225.20 toks/s, output: 42.21 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:35<00:15, 35.60it/s, est. speed input: 43134.60 toks/s, output: 42.12 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:35<00:15, 35.47it/s, est. speed input: 43043.98 toks/s, output: 42.04 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:36<00:14, 36.00it/s, est. speed input: 42986.70 toks/s, output: 41.98 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:36<00:14, 35.76it/s, est. speed input: 42900.87 toks/s, output: 41.90 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:37<00:13, 36.21it/s, est. speed input: 42846.47 toks/s, output: 41.84 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:37<00:13, 35.92it/s, est. speed input: 42765.13 toks/s, output: 41.76 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:38<00:12, 35.68it/s, est. speed input: 42684.16 toks/s, output: 41.68 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:38<00:12, 35.54it/s, est. speed input: 42605.73 toks/s, output: 41.61 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:38<00:11, 36.06it/s, est. speed input: 42557.84 toks/s, output: 41.56 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:39<00:11, 35.80it/s, est. speed input: 42482.62 toks/s, output: 41.49 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:39<00:11, 35.61it/s, est. speed input: 42408.93 toks/s, output: 41.41 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:40<00:10, 35.52it/s, est. speed input: 42338.68 toks/s, output: 41.35 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:40<00:10, 35.41it/s, est. speed input: 42267.63 toks/s, output: 41.28 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:41<00:09, 35.38it/s, est. speed input: 42200.62 toks/s, output: 41.21 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:41<00:09, 35.30it/s, est. speed input: 42132.28 toks/s, output: 41.14 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:42<00:08, 35.89it/s, est. speed input: 42092.82 toks/s, output: 41.11 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:42<00:08, 36.31it/s, est. speed input: 42053.82 toks/s, output: 41.07 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:42<00:07, 35.95it/s, est. speed input: 41989.53 toks/s, output: 41.01 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:43<00:07, 35.71it/s, est. speed input: 41926.59 toks/s, output: 40.94 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:43<00:07, 35.53it/s, est. speed input: 41864.58 toks/s, output: 40.88 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:44<00:06, 35.42it/s, est. speed input: 41804.63 toks/s, output: 40.82 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:44<00:06, 35.34it/s, est. speed input: 41745.60 toks/s, output: 40.77 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:45<00:05, 35.27it/s, est. speed input: 41687.21 toks/s, output: 40.71 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:45<00:05, 35.23it/s, est. speed input: 41630.42 toks/s, output: 40.65 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:46<00:04, 35.18it/s, est. speed input: 41573.79 toks/s, output: 40.60 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:46<00:04, 35.78it/s, est. speed input: 41542.47 toks/s, output: 40.57 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:47<00:03, 35.60it/s, est. speed input: 41488.97 toks/s, output: 40.52 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:47<00:03, 35.46it/s, est. speed input: 41436.31 toks/s, output: 40.47 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:47<00:03, 35.33it/s, est. speed input: 41383.42 toks/s, output: 40.41 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:48<00:02, 35.31it/s, est. speed input: 41333.77 toks/s, output: 40.36 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:48<00:02, 35.23it/s, est. speed input: 41282.88 toks/s, output: 40.32 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:49<00:01, 35.79it/s, est. speed input: 41254.66 toks/s, output: 40.29 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:49<00:01, 35.61it/s, est. speed input: 41207.22 toks/s, output: 40.24 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:50<00:00, 35.47it/s, est. speed input: 41159.80 toks/s, output: 40.20 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:50<00:00, 36.04it/s, est. speed input: 41136.14 toks/s, output: 40.17 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:50<00:00, 36.04it/s, est. speed input: 41418.91 toks/s, output: 40.45 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:50<00:00, 40.45it/s, est. speed input: 41418.91 toks/s, output: 40.45 toks/s]
[rank0]:[W125 19:35:37.328737999 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 121.3s

测试结果:
  Requests/s:   35.62
  Tokens/s:     36505.97
  Total Reqs:   2048
  Elapsed:      57.50s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     36470.35

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:36:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=369570) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=369570) WARNING 01-25 19:36:36 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.43 requests/s, 36319.20 total tokens/s, 35.43 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 19:36:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:36:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:36:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:36:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:36:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:36:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:36:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:36:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:36:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:36:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:36:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:36:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:36:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:36:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:36:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:36:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:36:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:26] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=369570) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=369570) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.73it/s]
(EngineCore_DP0 pid=369570) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=369570) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.74it/s]
(EngineCore_DP0 pid=369570) 
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=369570) [2026-01-25 19:36:27] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=369570) [rank0]:W0125 19:36:44.851000 369570 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=369570) [rank0]:W0125 19:36:44.970000 369570 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=369570) [rank0]:W0125 19:36:46.377000 369570 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=369570) [rank0]:W0125 19:36:46.567000 369570 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=369570) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00, 10.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 10.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 10.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 11.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.77it/s]
(EngineCore_DP0 pid=369570) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  9.18it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 10.60it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 11.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.78it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.71it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 242.26it/s]
Adding requests:   1%|▏         | 53/4096 [00:00<00:15, 261.43it/s]
Adding requests:   2%|▏         | 82/4096 [00:00<00:14, 270.17it/s]
Adding requests:   3%|▎         | 110/4096 [00:00<00:14, 266.44it/s]
Adding requests:   3%|▎         | 137/4096 [00:00<00:15, 260.58it/s]
Adding requests:   4%|▍         | 164/4096 [00:00<00:14, 262.37it/s]
Adding requests:   5%|▍         | 193/4096 [00:00<00:14, 270.76it/s]
Adding requests:   5%|▌         | 222/4096 [00:00<00:14, 274.97it/s]
Adding requests:   6%|▌         | 250/4096 [00:00<00:14, 273.30it/s]
Adding requests:   7%|▋         | 279/4096 [00:01<00:13, 276.77it/s]
Adding requests:   8%|▊         | 308/4096 [00:01<00:13, 279.53it/s]
Adding requests:   8%|▊         | 337/4096 [00:01<00:13, 280.71it/s]
Adding requests:   9%|▉         | 366/4096 [00:01<00:13, 279.96it/s]
Adding requests:  10%|▉         | 397/4096 [00:01<00:12, 288.14it/s]
Adding requests:  10%|█         | 428/4096 [00:01<00:12, 294.30it/s]
Adding requests:  11%|█         | 458/4096 [00:01<00:12, 287.53it/s]
Adding requests:  12%|█▏        | 488/4096 [00:01<00:12, 290.52it/s]
Adding requests:  13%|█▎        | 518/4096 [00:01<00:12, 292.02it/s]
Adding requests:  13%|█▎        | 549/4096 [00:01<00:11, 295.87it/s]
Adding requests:  14%|█▍        | 580/4096 [00:02<00:11, 298.03it/s]
Adding requests:  15%|█▍        | 610/4096 [00:02<00:12, 287.08it/s]
Adding requests:  16%|█▌        | 640/4096 [00:02<00:11, 289.25it/s]
Adding requests:  16%|█▋        | 669/4096 [00:02<00:12, 279.61it/s]
Adding requests:  17%|█▋        | 702/4096 [00:02<00:11, 293.01it/s]
Adding requests:  18%|█▊        | 732/4096 [00:02<00:11, 292.75it/s]
Adding requests:  19%|█▊        | 762/4096 [00:02<00:11, 285.66it/s]
Adding requests:  19%|█▉        | 791/4096 [00:02<00:11, 285.17it/s]
Adding requests:  20%|██        | 820/4096 [00:02<00:11, 277.81it/s]
Adding requests:  21%|██        | 853/4096 [00:03<00:11, 292.21it/s]
Adding requests:  22%|██▏       | 885/4096 [00:03<00:10, 296.59it/s]
Adding requests:  22%|██▏       | 915/4096 [00:03<00:10, 295.79it/s]
Adding requests:  23%|██▎       | 945/4096 [00:03<00:10, 296.32it/s]
Adding requests:  24%|██▍       | 976/4096 [00:03<00:10, 299.13it/s]
Adding requests:  25%|██▍       | 1006/4096 [00:03<00:10, 292.98it/s]
Adding requests:  25%|██▌       | 1037/4096 [00:03<00:10, 297.24it/s]
Adding requests:  26%|██▌       | 1067/4096 [00:03<00:10, 293.40it/s]
Adding requests:  27%|██▋       | 1097/4096 [00:03<00:10, 288.84it/s]
Adding requests:  27%|██▋       | 1126/4096 [00:03<00:10, 285.19it/s]
Adding requests:  28%|██▊       | 1155/4096 [00:04<00:10, 280.16it/s]
Adding requests:  29%|██▉       | 1185/4096 [00:04<00:10, 283.55it/s]
Adding requests:  30%|██▉       | 1217/4096 [00:04<00:09, 292.78it/s]
Adding requests:  30%|███       | 1247/4096 [00:04<00:09, 292.21it/s]
Adding requests:  31%|███       | 1278/4096 [00:04<00:09, 294.23it/s]
Adding requests:  32%|███▏      | 1309/4096 [00:04<00:09, 297.92it/s]
Adding requests:  33%|███▎      | 1339/4096 [00:04<00:09, 294.57it/s]
Adding requests:  33%|███▎      | 1369/4096 [00:04<00:09, 292.77it/s]
Adding requests:  34%|███▍      | 1399/4096 [00:04<00:09, 287.02it/s]
Adding requests:  35%|███▍      | 1428/4096 [00:04<00:09, 282.23it/s]
Adding requests:  36%|███▌      | 1458/4096 [00:05<00:09, 287.14it/s]
Adding requests:  36%|███▋      | 1488/4096 [00:05<00:09, 288.09it/s]
Adding requests:  37%|███▋      | 1518/4096 [00:05<00:08, 290.32it/s]
Adding requests:  38%|███▊      | 1548/4096 [00:05<00:08, 292.79it/s]
Adding requests:  39%|███▊      | 1578/4096 [00:05<00:08, 288.89it/s]
Adding requests:  39%|███▉      | 1607/4096 [00:05<00:08, 285.91it/s]
Adding requests:  40%|███▉      | 1636/4096 [00:05<00:08, 285.30it/s]
Adding requests:  41%|████      | 1665/4096 [00:05<00:08, 281.34it/s]
Adding requests:  41%|████▏     | 1695/4096 [00:05<00:08, 285.02it/s]
Adding requests:  42%|████▏     | 1729/4096 [00:06<00:07, 297.87it/s]
Adding requests:  43%|████▎     | 1760/4096 [00:06<00:07, 300.40it/s]
Adding requests:  44%|████▍     | 1792/4096 [00:06<00:07, 303.31it/s]
Adding requests:  45%|████▍     | 1823/4096 [00:06<00:07, 296.00it/s]
Adding requests:  45%|████▌     | 1854/4096 [00:06<00:07, 299.17it/s]
Adding requests:  46%|████▌     | 1884/4096 [00:06<00:07, 299.36it/s]
Adding requests:  47%|████▋     | 1915/4096 [00:06<00:07, 300.63it/s]
Adding requests:  48%|████▊     | 1949/4096 [00:06<00:06, 309.89it/s]
Adding requests:  48%|████▊     | 1981/4096 [00:06<00:06, 305.51it/s]
Adding requests:  49%|████▉     | 2012/4096 [00:06<00:07, 293.43it/s]
Adding requests:  50%|████▉     | 2042/4096 [00:07<00:07, 290.15it/s]
Adding requests:  51%|█████     | 2072/4096 [00:07<00:07, 287.78it/s]
Adding requests:  51%|█████▏    | 2101/4096 [00:07<00:06, 287.93it/s]
Adding requests:  52%|█████▏    | 2131/4096 [00:07<00:06, 290.82it/s]
Adding requests:  53%|█████▎    | 2161/4096 [00:07<00:06, 292.43it/s]
Adding requests:  53%|█████▎    | 2191/4096 [00:07<00:06, 287.20it/s]
Adding requests:  54%|█████▍    | 2220/4096 [00:07<00:06, 281.83it/s]
Adding requests:  55%|█████▍    | 2251/4096 [00:07<00:06, 289.16it/s]
Adding requests:  56%|█████▌    | 2282/4096 [00:07<00:06, 294.91it/s]
Adding requests:  56%|█████▋    | 2312/4096 [00:08<00:06, 283.08it/s]
Adding requests:  57%|█████▋    | 2341/4096 [00:08<00:06, 283.46it/s]
Adding requests:  58%|█████▊    | 2370/4096 [00:08<00:06, 279.26it/s]
Adding requests:  59%|█████▊    | 2400/4096 [00:08<00:05, 282.82it/s]
Adding requests:  59%|█████▉    | 2430/4096 [00:08<00:05, 285.07it/s]
Adding requests:  60%|██████    | 2459/4096 [00:08<00:05, 280.85it/s]
Adding requests:  61%|██████    | 2490/4096 [00:08<00:05, 288.52it/s]
Adding requests:  62%|██████▏   | 2522/4096 [00:08<00:05, 295.28it/s]
Adding requests:  62%|██████▏   | 2554/4096 [00:08<00:05, 299.77it/s]
Adding requests:  63%|██████▎   | 2585/4096 [00:08<00:05, 298.79it/s]
Adding requests:  64%|██████▍   | 2615/4096 [00:09<00:05, 295.41it/s]
Adding requests:  65%|██████▍   | 2645/4096 [00:09<00:04, 294.24it/s]
Adding requests:  65%|██████▌   | 2676/4096 [00:09<00:04, 298.01it/s]
Adding requests:  66%|██████▌   | 2706/4096 [00:09<00:04, 293.40it/s]
Adding requests:  67%|██████▋   | 2736/4096 [00:09<00:04, 289.50it/s]
Adding requests:  68%|██████▊   | 2767/4096 [00:09<00:04, 293.47it/s]
Adding requests:  68%|██████▊   | 2798/4096 [00:09<00:04, 296.05it/s]
Adding requests:  69%|██████▉   | 2828/4096 [00:09<00:04, 293.76it/s]
Adding requests:  70%|██████▉   | 2859/4096 [00:09<00:04, 297.99it/s]
Adding requests:  71%|███████   | 2890/4096 [00:09<00:04, 300.11it/s]
Adding requests:  71%|███████▏  | 2921/4096 [00:10<00:03, 300.34it/s]
Adding requests:  72%|███████▏  | 2953/4096 [00:10<00:03, 305.18it/s]
Adding requests:  73%|███████▎  | 2984/4096 [00:10<00:03, 299.61it/s]
Adding requests:  74%|███████▎  | 3016/4096 [00:10<00:03, 302.28it/s]
Adding requests:  74%|███████▍  | 3048/4096 [00:10<00:03, 303.49it/s]
Adding requests:  75%|███████▌  | 3079/4096 [00:10<00:03, 303.98it/s]
Adding requests:  76%|███████▌  | 3110/4096 [00:10<00:03, 300.07it/s]
Adding requests:  77%|███████▋  | 3143/4096 [00:10<00:03, 307.19it/s]
Adding requests:  77%|███████▋  | 3174/4096 [00:10<00:03, 300.05it/s]
Adding requests:  78%|███████▊  | 3205/4096 [00:11<00:03, 294.81it/s]
Adding requests:  79%|███████▉  | 3235/4096 [00:11<00:02, 295.91it/s]
Adding requests:  80%|███████▉  | 3265/4096 [00:11<00:02, 287.82it/s]
Adding requests:  80%|████████  | 3294/4096 [00:11<00:02, 278.89it/s]
Adding requests:  81%|████████  | 3322/4096 [00:11<00:02, 276.06it/s]
Adding requests:  82%|████████▏ | 3352/4096 [00:11<00:02, 281.11it/s]
Adding requests:  83%|████████▎ | 3383/4096 [00:11<00:02, 287.99it/s]
Adding requests:  83%|████████▎ | 3414/4096 [00:11<00:02, 293.50it/s]
Adding requests:  84%|████████▍ | 3444/4096 [00:11<00:02, 292.14it/s]
Adding requests:  85%|████████▍ | 3476/4096 [00:11<00:02, 299.17it/s]
Adding requests:  86%|████████▌ | 3508/4096 [00:12<00:01, 303.77it/s]
Adding requests:  86%|████████▋ | 3542/4096 [00:12<00:01, 314.33it/s]
Adding requests:  87%|████████▋ | 3574/4096 [00:12<00:01, 307.60it/s]
Adding requests:  88%|████████▊ | 3605/4096 [00:12<00:01, 302.62it/s]
Adding requests:  89%|████████▉ | 3636/4096 [00:12<00:01, 303.03it/s]
Adding requests:  90%|████████▉ | 3667/4096 [00:12<00:01, 293.52it/s]
Adding requests:  90%|█████████ | 3697/4096 [00:12<00:01, 292.77it/s]
Adding requests:  91%|█████████ | 3730/4096 [00:12<00:01, 303.23it/s]
Adding requests:  92%|█████████▏| 3761/4096 [00:12<00:01, 296.20it/s]
Adding requests:  93%|█████████▎| 3791/4096 [00:13<00:01, 288.98it/s]
Adding requests:  93%|█████████▎| 3820/4096 [00:13<00:00, 286.66it/s]
Adding requests:  94%|█████████▍| 3850/4096 [00:13<00:00, 287.89it/s]
Adding requests:  95%|█████████▍| 3882/4096 [00:13<00:00, 294.89it/s]
Adding requests:  96%|█████████▌| 3912/4096 [00:13<00:00, 292.46it/s]
Adding requests:  96%|█████████▌| 3942/4096 [00:13<00:00, 287.71it/s]
Adding requests:  97%|█████████▋| 3973/4096 [00:13<00:00, 291.86it/s]
Adding requests:  98%|█████████▊| 4003/4096 [00:13<00:00, 294.20it/s]
Adding requests:  99%|█████████▊| 4035/4096 [00:13<00:00, 299.41it/s]
Adding requests:  99%|█████████▉| 4065/4096 [00:13<00:00, 298.74it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 301.72it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 291.38it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 497/4096 [00:00<00:05, 696.29it/s, est. speed input: 713029.33 toks/s, output: 696.30 toks/s]
Processed prompts:  14%|█▍        | 567/4096 [00:02<00:19, 182.04it/s, est. speed input: 231341.55 toks/s, output: 225.92 toks/s]
Processed prompts:  15%|█▍        | 598/4096 [00:03<00:27, 129.10it/s, est. speed input: 179633.75 toks/s, output: 175.42 toks/s]
Processed prompts:  15%|█▌        | 625/4096 [00:04<00:36, 95.51it/s, est. speed input: 148539.14 toks/s, output: 145.06 toks/s] 
Processed prompts:  16%|█▌        | 657/4096 [00:05<00:45, 75.99it/s, est. speed input: 129210.25 toks/s, output: 126.18 toks/s]
Processed prompts:  17%|█▋        | 689/4096 [00:06<00:53, 63.15it/s, est. speed input: 115550.82 toks/s, output: 112.84 toks/s]
Processed prompts:  18%|█▊        | 721/4096 [00:07<01:01, 54.55it/s, est. speed input: 105402.78 toks/s, output: 102.93 toks/s]
Processed prompts:  18%|█▊        | 753/4096 [00:07<01:08, 48.69it/s, est. speed input: 97550.42 toks/s, output: 95.26 toks/s]  
Processed prompts:  19%|█▉        | 785/4096 [00:08<01:13, 45.03it/s, est. speed input: 91547.89 toks/s, output: 89.40 toks/s]
Processed prompts:  20%|█▉        | 817/4096 [00:09<01:17, 42.13it/s, est. speed input: 86421.78 toks/s, output: 84.40 toks/s]
Processed prompts:  21%|██        | 849/4096 [00:10<01:20, 40.14it/s, est. speed input: 82173.75 toks/s, output: 80.25 toks/s]
Processed prompts:  22%|██▏       | 881/4096 [00:11<01:23, 38.72it/s, est. speed input: 78568.80 toks/s, output: 76.73 toks/s]
Processed prompts:  22%|██▏       | 913/4096 [00:12<01:24, 37.76it/s, est. speed input: 75501.34 toks/s, output: 73.73 toks/s]
Processed prompts:  23%|██▎       | 945/4096 [00:13<01:25, 37.04it/s, est. speed input: 72829.83 toks/s, output: 71.12 toks/s]
Processed prompts:  24%|██▍       | 977/4096 [00:14<01:25, 36.56it/s, est. speed input: 70503.15 toks/s, output: 68.85 toks/s]
Processed prompts:  25%|██▍       | 1009/4096 [00:15<01:25, 36.22it/s, est. speed input: 68456.05 toks/s, output: 66.85 toks/s]
Processed prompts:  25%|██▌       | 1041/4096 [00:15<01:24, 35.98it/s, est. speed input: 66639.13 toks/s, output: 65.08 toks/s]
Processed prompts:  26%|██▌       | 1073/4096 [00:16<01:24, 35.82it/s, est. speed input: 65018.05 toks/s, output: 63.49 toks/s]
Processed prompts:  27%|██▋       | 1105/4096 [00:17<01:23, 35.70it/s, est. speed input: 63557.77 toks/s, output: 62.07 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:18<01:23, 35.62it/s, est. speed input: 62241.54 toks/s, output: 60.78 toks/s]
Processed prompts:  29%|██▊       | 1169/4096 [00:19<01:22, 35.55it/s, est. speed input: 61041.42 toks/s, output: 59.61 toks/s]
Processed prompts:  29%|██▉       | 1201/4096 [00:20<01:20, 35.81it/s, est. speed input: 60023.86 toks/s, output: 58.62 toks/s]
Processed prompts:  30%|███       | 1233/4096 [00:21<01:19, 35.96it/s, est. speed input: 59082.60 toks/s, output: 57.70 toks/s]
Processed prompts:  31%|███       | 1265/4096 [00:22<01:19, 35.81it/s, est. speed input: 58160.10 toks/s, output: 56.80 toks/s]
Processed prompts:  32%|███▏      | 1297/4096 [00:23<01:18, 35.68it/s, est. speed input: 57303.59 toks/s, output: 55.96 toks/s]
Processed prompts:  32%|███▏      | 1329/4096 [00:24<01:17, 35.87it/s, est. speed input: 56566.89 toks/s, output: 55.24 toks/s]
Processed prompts:  33%|███▎      | 1361/4096 [00:24<01:16, 35.74it/s, est. speed input: 55833.25 toks/s, output: 54.52 toks/s]
Processed prompts:  34%|███▍      | 1393/4096 [00:25<01:15, 35.61it/s, est. speed input: 55143.89 toks/s, output: 53.85 toks/s]
Processed prompts:  35%|███▍      | 1425/4096 [00:26<01:15, 35.52it/s, est. speed input: 54501.71 toks/s, output: 53.22 toks/s]
Processed prompts:  36%|███▌      | 1457/4096 [00:27<01:13, 35.76it/s, est. speed input: 53950.21 toks/s, output: 52.69 toks/s]
Processed prompts:  36%|███▋      | 1489/4096 [00:28<01:13, 35.63it/s, est. speed input: 53387.53 toks/s, output: 52.14 toks/s]
Processed prompts:  37%|███▋      | 1521/4096 [00:29<01:11, 35.84it/s, est. speed input: 52903.39 toks/s, output: 51.66 toks/s]
Processed prompts:  38%|███▊      | 1553/4096 [00:30<01:10, 35.97it/s, est. speed input: 52444.60 toks/s, output: 51.22 toks/s]
Processed prompts:  39%|███▊      | 1585/4096 [00:31<01:10, 35.74it/s, est. speed input: 51968.44 toks/s, output: 50.75 toks/s]
Processed prompts:  39%|███▉      | 1617/4096 [00:32<01:09, 35.88it/s, est. speed input: 51558.84 toks/s, output: 50.35 toks/s]
Processed prompts:  40%|████      | 1649/4096 [00:33<01:08, 35.67it/s, est. speed input: 51131.73 toks/s, output: 49.93 toks/s]
Processed prompts:  41%|████      | 1681/4096 [00:33<01:07, 35.55it/s, est. speed input: 50729.43 toks/s, output: 49.54 toks/s]
Processed prompts:  42%|████▏     | 1713/4096 [00:34<01:06, 35.76it/s, est. speed input: 50385.31 toks/s, output: 49.20 toks/s]
Processed prompts:  43%|████▎     | 1745/4096 [00:35<01:05, 35.90it/s, est. speed input: 50056.19 toks/s, output: 48.88 toks/s]
Processed prompts:  43%|████▎     | 1777/4096 [00:36<01:04, 35.69it/s, est. speed input: 49708.90 toks/s, output: 48.54 toks/s]
Processed prompts:  44%|████▍     | 1809/4096 [00:37<01:04, 35.54it/s, est. speed input: 49377.59 toks/s, output: 48.22 toks/s]
Processed prompts:  45%|████▍     | 1841/4096 [00:38<01:03, 35.44it/s, est. speed input: 49061.90 toks/s, output: 47.91 toks/s]
Processed prompts:  46%|████▌     | 1873/4096 [00:39<01:02, 35.67it/s, est. speed input: 48792.96 toks/s, output: 47.65 toks/s]
Processed prompts:  47%|████▋     | 1905/4096 [00:40<01:01, 35.53it/s, est. speed input: 48504.99 toks/s, output: 47.37 toks/s]
Processed prompts:  47%|████▋     | 1937/4096 [00:41<01:00, 35.44it/s, est. speed input: 48230.51 toks/s, output: 47.10 toks/s]
Processed prompts:  48%|████▊     | 1969/4096 [00:42<00:59, 35.67it/s, est. speed input: 47996.12 toks/s, output: 46.87 toks/s]
Processed prompts:  49%|████▉     | 2001/4096 [00:42<00:59, 35.48it/s, est. speed input: 47738.90 toks/s, output: 46.62 toks/s]
Processed prompts:  50%|████▉     | 2033/4096 [00:43<00:58, 35.39it/s, est. speed input: 47495.54 toks/s, output: 46.38 toks/s]
Processed prompts:  50%|█████     | 2065/4096 [00:44<00:57, 35.59it/s, est. speed input: 47286.30 toks/s, output: 46.18 toks/s]
Processed prompts:  51%|█████     | 2097/4096 [00:45<00:56, 35.46it/s, est. speed input: 47060.99 toks/s, output: 45.96 toks/s]
Processed prompts:  52%|█████▏    | 2129/4096 [00:46<00:55, 35.36it/s, est. speed input: 46844.33 toks/s, output: 45.75 toks/s]
Processed prompts:  53%|█████▎    | 2161/4096 [00:47<00:54, 35.26it/s, est. speed input: 46632.99 toks/s, output: 45.54 toks/s]
Processed prompts:  54%|█████▎    | 2193/4096 [00:48<00:53, 35.49it/s, est. speed input: 46453.78 toks/s, output: 45.37 toks/s]
Processed prompts:  54%|█████▍    | 2225/4096 [00:49<00:52, 35.37it/s, est. speed input: 46259.32 toks/s, output: 45.18 toks/s]
Processed prompts:  55%|█████▌    | 2257/4096 [00:50<00:52, 35.28it/s, est. speed input: 46071.19 toks/s, output: 44.99 toks/s]
Processed prompts:  56%|█████▌    | 2289/4096 [00:51<00:51, 35.20it/s, est. speed input: 45888.52 toks/s, output: 44.81 toks/s]
Processed prompts:  57%|█████▋    | 2321/4096 [00:51<00:50, 35.17it/s, est. speed input: 45714.33 toks/s, output: 44.64 toks/s]
Processed prompts:  57%|█████▋    | 2353/4096 [00:52<00:49, 35.15it/s, est. speed input: 45545.96 toks/s, output: 44.48 toks/s]
Processed prompts:  58%|█████▊    | 2385/4096 [00:53<00:48, 35.12it/s, est. speed input: 45382.26 toks/s, output: 44.32 toks/s]
Processed prompts:  59%|█████▉    | 2417/4096 [00:54<00:47, 35.11it/s, est. speed input: 45224.65 toks/s, output: 44.16 toks/s]
Processed prompts:  60%|█████▉    | 2449/4096 [00:55<00:46, 35.09it/s, est. speed input: 45071.24 toks/s, output: 44.01 toks/s]
Processed prompts:  61%|██████    | 2481/4096 [00:56<00:46, 35.06it/s, est. speed input: 44921.56 toks/s, output: 43.87 toks/s]
Processed prompts:  61%|██████▏   | 2513/4096 [00:57<00:45, 35.06it/s, est. speed input: 44778.25 toks/s, output: 43.73 toks/s]
Processed prompts:  62%|██████▏   | 2545/4096 [00:58<00:43, 35.35it/s, est. speed input: 44658.95 toks/s, output: 43.61 toks/s]
Processed prompts:  63%|██████▎   | 2577/4096 [00:59<00:42, 35.56it/s, est. speed input: 44542.85 toks/s, output: 43.50 toks/s]
Processed prompts:  64%|██████▎   | 2609/4096 [01:00<00:42, 35.38it/s, est. speed input: 44410.28 toks/s, output: 43.37 toks/s]
Processed prompts:  64%|██████▍   | 2641/4096 [01:01<00:40, 35.59it/s, est. speed input: 44301.54 toks/s, output: 43.26 toks/s]
Processed prompts:  65%|██████▌   | 2673/4096 [01:01<00:40, 35.41it/s, est. speed input: 44176.86 toks/s, output: 43.14 toks/s]
Processed prompts:  66%|██████▌   | 2705/4096 [01:02<00:39, 35.26it/s, est. speed input: 44054.18 toks/s, output: 43.02 toks/s]
Processed prompts:  67%|██████▋   | 2737/4096 [01:03<00:38, 35.47it/s, est. speed input: 43953.52 toks/s, output: 42.92 toks/s]
Processed prompts:  68%|██████▊   | 2769/4096 [01:04<00:37, 35.33it/s, est. speed input: 43839.10 toks/s, output: 42.81 toks/s]
Processed prompts:  68%|██████▊   | 2801/4096 [01:05<00:36, 35.24it/s, est. speed input: 43727.82 toks/s, output: 42.70 toks/s]
Processed prompts:  69%|██████▉   | 2833/4096 [01:06<00:35, 35.16it/s, est. speed input: 43619.32 toks/s, output: 42.60 toks/s]
Processed prompts:  70%|██████▉   | 2865/4096 [01:07<00:35, 35.10it/s, est. speed input: 43513.22 toks/s, output: 42.49 toks/s]
Processed prompts:  71%|███████   | 2897/4096 [01:08<00:33, 36.03it/s, est. speed input: 43462.06 toks/s, output: 42.44 toks/s]
Processed prompts:  72%|███████▏  | 2929/4096 [01:09<00:32, 35.71it/s, est. speed input: 43360.76 toks/s, output: 42.34 toks/s]
Processed prompts:  72%|███████▏  | 2961/4096 [01:10<00:32, 35.46it/s, est. speed input: 43261.00 toks/s, output: 42.25 toks/s]
Processed prompts:  73%|███████▎  | 2993/4096 [01:11<00:31, 35.31it/s, est. speed input: 43164.95 toks/s, output: 42.15 toks/s]
Processed prompts:  74%|███████▍  | 3025/4096 [01:11<00:30, 35.20it/s, est. speed input: 43071.16 toks/s, output: 42.06 toks/s]
Processed prompts:  75%|███████▍  | 3057/4096 [01:12<00:29, 35.11it/s, est. speed input: 42978.53 toks/s, output: 41.97 toks/s]
Processed prompts:  75%|███████▌  | 3089/4096 [01:13<00:28, 35.06it/s, est. speed input: 42889.06 toks/s, output: 41.88 toks/s]
Processed prompts:  76%|███████▌  | 3121/4096 [01:14<00:27, 35.01it/s, est. speed input: 42801.39 toks/s, output: 41.80 toks/s]
Processed prompts:  77%|███████▋  | 3153/4096 [01:15<00:26, 34.98it/s, est. speed input: 42715.96 toks/s, output: 41.71 toks/s]
Processed prompts:  78%|███████▊  | 3185/4096 [01:16<00:26, 34.97it/s, est. speed input: 42632.66 toks/s, output: 41.63 toks/s]
Processed prompts:  79%|███████▊  | 3217/4096 [01:17<00:25, 34.95it/s, est. speed input: 42551.37 toks/s, output: 41.55 toks/s]
Processed prompts:  79%|███████▉  | 3249/4096 [01:18<00:24, 34.93it/s, est. speed input: 42471.18 toks/s, output: 41.48 toks/s]
Processed prompts:  80%|████████  | 3281/4096 [01:19<00:23, 34.92it/s, est. speed input: 42393.46 toks/s, output: 41.40 toks/s]
Processed prompts:  81%|████████  | 3313/4096 [01:20<00:22, 34.92it/s, est. speed input: 42317.29 toks/s, output: 41.33 toks/s]
Processed prompts:  82%|████████▏ | 3345/4096 [01:21<00:21, 34.91it/s, est. speed input: 42242.98 toks/s, output: 41.25 toks/s]
Processed prompts:  82%|████████▏ | 3377/4096 [01:22<00:20, 34.90it/s, est. speed input: 42169.86 toks/s, output: 41.18 toks/s]
Processed prompts:  83%|████████▎ | 3409/4096 [01:22<00:19, 34.90it/s, est. speed input: 42098.88 toks/s, output: 41.11 toks/s]
Processed prompts:  84%|████████▍ | 3441/4096 [01:23<00:18, 34.89it/s, est. speed input: 42028.73 toks/s, output: 41.04 toks/s]
Processed prompts:  85%|████████▍ | 3473/4096 [01:24<00:17, 34.89it/s, est. speed input: 41960.35 toks/s, output: 40.98 toks/s]
Processed prompts:  86%|████████▌ | 3505/4096 [01:25<00:16, 34.88it/s, est. speed input: 41893.17 toks/s, output: 40.91 toks/s]
Processed prompts:  86%|████████▋ | 3537/4096 [01:26<00:15, 35.17it/s, est. speed input: 41840.22 toks/s, output: 40.86 toks/s]
Processed prompts:  87%|████████▋ | 3569/4096 [01:27<00:15, 35.06it/s, est. speed input: 41775.08 toks/s, output: 40.80 toks/s]
Processed prompts:  88%|████████▊ | 3601/4096 [01:28<00:14, 35.00it/s, est. speed input: 41711.69 toks/s, output: 40.73 toks/s]
Processed prompts:  89%|████████▊ | 3633/4096 [01:29<00:13, 34.95it/s, est. speed input: 41649.77 toks/s, output: 40.67 toks/s]
Processed prompts:  89%|████████▉ | 3665/4096 [01:30<00:12, 35.22it/s, est. speed input: 41601.16 toks/s, output: 40.63 toks/s]
Processed prompts:  90%|█████████ | 3697/4096 [01:31<00:11, 35.10it/s, est. speed input: 41541.02 toks/s, output: 40.57 toks/s]
Processed prompts:  91%|█████████ | 3729/4096 [01:32<00:10, 35.01it/s, est. speed input: 41482.16 toks/s, output: 40.51 toks/s]
Processed prompts:  92%|█████████▏| 3761/4096 [01:32<00:09, 34.98it/s, est. speed input: 41425.48 toks/s, output: 40.45 toks/s]
Processed prompts:  93%|█████████▎| 3793/4096 [01:33<00:08, 34.97it/s, est. speed input: 41370.53 toks/s, output: 40.40 toks/s]
Processed prompts:  93%|█████████▎| 3825/4096 [01:34<00:07, 34.97it/s, est. speed input: 41316.99 toks/s, output: 40.35 toks/s]
Processed prompts:  94%|█████████▍| 3857/4096 [01:35<00:06, 34.95it/s, est. speed input: 41263.62 toks/s, output: 40.30 toks/s]
Processed prompts:  95%|█████████▍| 3889/4096 [01:36<00:05, 34.96it/s, est. speed input: 41211.95 toks/s, output: 40.25 toks/s]
Processed prompts:  96%|█████████▌| 3921/4096 [01:37<00:04, 35.57it/s, est. speed input: 41183.20 toks/s, output: 40.22 toks/s]
Processed prompts:  97%|█████████▋| 3953/4096 [01:38<00:04, 35.39it/s, est. speed input: 41133.33 toks/s, output: 40.17 toks/s]
Processed prompts:  97%|█████████▋| 3985/4096 [01:39<00:03, 35.55it/s, est. speed input: 41094.53 toks/s, output: 40.13 toks/s]
Processed prompts:  98%|█████████▊| 4017/4096 [01:40<00:02, 35.36it/s, est. speed input: 41045.85 toks/s, output: 40.08 toks/s]
Processed prompts:  99%|█████████▉| 4049/4096 [01:41<00:01, 35.57it/s, est. speed input: 41009.77 toks/s, output: 40.05 toks/s]
Processed prompts: 100%|█████████▉| 4081/4096 [01:41<00:00, 42.10it/s, est. speed input: 41156.90 toks/s, output: 40.19 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:41<00:00, 42.10it/s, est. speed input: 41308.01 toks/s, output: 40.34 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:41<00:00, 40.34it/s, est. speed input: 41308.01 toks/s, output: 40.34 toks/s]
[rank0]:[W125 19:38:54.444293491 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 196.3s

测试结果:
  Requests/s:   35.43
  Tokens/s:     36319.20
  Total Reqs:   4096
  Elapsed:      115.60s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     36283.77

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:40:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=372966) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372966) WARNING 01-25 19:40:26 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     def forward(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     raise e
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/tmp/torchinductor_root/mg/cmgpwljzo6ba4mma7n4yhaoccaaovsui6woecf6rfef3pw3qqgh2.py", line 1090, in call
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     torch.cuda.synchronize()
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=372966) ERROR 01-25 19:40:38 [core.py:866] 


─── STDERR ───
[2026-01-25 19:40:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:40:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:40:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:40:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=372966) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=372966) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.73it/s]
(EngineCore_DP0 pid=372966) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
(EngineCore_DP0 pid=372966) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.72it/s]
(EngineCore_DP0 pid=372966) 
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=372966) [2026-01-25 19:40:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=372966) [rank0]:W0125 19:40:35.774000 372966 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=372966) [rank0]:W0125 19:40:35.898000 372966 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=372966) [rank0]:W0125 19:40:37.325000 372966 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=372966) [rank0]:W0125 19:40:37.526000 372966 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=372966) Process EngineCore_DP0:
(EngineCore_DP0 pid=372966) Traceback (most recent call last):
(EngineCore_DP0 pid=372966)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=372966)     self.run()
(EngineCore_DP0 pid=372966)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=372966)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=372966)     raise e
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372966)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372966)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372966)     super().__init__(
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372966)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372966)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=372966)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=372966)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=372966)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=372966)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=372966)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=372966)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372966)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=372966)     self.model_runner.profile_run()
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=372966)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=372966)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=372966)     return func(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=372966)     outputs = self.model(
(EngineCore_DP0 pid=372966)               ^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=372966)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372966)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372966)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=372966)     hidden_states = self.model(
(EngineCore_DP0 pid=372966)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=372966)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=372966)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=372966)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=372966)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=372966)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=372966)     def forward(
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=372966)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=372966)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=372966)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=372966)     raise e
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=372966)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=372966)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=372966)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=372966)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=372966)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=372966)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=372966)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=372966)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=372966)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=372966)     return compiled_fn(full_args)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=372966)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=372966)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=372966)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=372966)                             ^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=372966)     outs = compiled_fn(args)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=372966)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=372966)     return self.current_callable(inputs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=372966)     out = model(new_inputs)
(EngineCore_DP0 pid=372966)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/tmp/torchinductor_root/mg/cmgpwljzo6ba4mma7n4yhaoccaaovsui6woecf6rfef3pw3qqgh2.py", line 1090, in call
(EngineCore_DP0 pid=372966)     triton_poi_fused_mul_quant_slide_int8_silu_slice_1.run(buf15, buf16, triton_poi_fused_mul_quant_slide_int8_silu_slice_1_xnumel, stream=stream0)
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1272, in run
(EngineCore_DP0 pid=372966)     self.autotune_to_one_config(*args, **kwargs)
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1048, in autotune_to_one_config
(EngineCore_DP0 pid=372966)     timings = self.benchmark_all_configs(*args, **kwargs)
(EngineCore_DP0 pid=372966)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 1023, in benchmark_all_configs
(EngineCore_DP0 pid=372966)     launcher: self.bench(launcher, *args, **kwargs)
(EngineCore_DP0 pid=372966)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/triton_heuristics.py", line 891, in bench
(EngineCore_DP0 pid=372966)     return benchmarker.benchmark_gpu(kernel_call, rep=40)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 39, in wrapper
(EngineCore_DP0 pid=372966)     return fn(self, *args, **kwargs)
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/runtime/benchmarking.py", line 247, in benchmark_gpu
(EngineCore_DP0 pid=372966)     torch.cuda.synchronize()
(EngineCore_DP0 pid=372966)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 1083, in synchronize
(EngineCore_DP0 pid=372966)     return torch._C._cuda_synchronize()
(EngineCore_DP0 pid=372966)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372966) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=372966) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=372966) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=372966) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=372966) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=372966) 
[rank0]:[W125 19:40:39.789161584 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,20.7743,10657.2165,6.1615
1024,1024,1,128,128,21.7853,22329.8846,5.8755
2048,1024,2,256,128,31.5749,32364.2379,8.1077
4096,1024,4,512,128,33.8894,34736.6018,15.1080
8192,1024,8,1024,128,34.9832,35857.7556,29.2712
16384,1024,16,2048,128,35.6156,36505.9660,57.5029
32768,1024,32,4096,128,35.4334,36319.2028,115.5973
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:40:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=373807) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=373807) WARNING 01-25 19:49:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.76 requests/s, 11162.02 total tokens/s, 21.76 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 19:40:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:40:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:40:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:40:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:40:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:40:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:40:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:40:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:40:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:40:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=373807) [2026-01-25 19:40:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=373807) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=373807) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [04:51<04:51, 291.15s/it]
(EngineCore_DP0 pid=373807) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [08:20<00:00, 243.32s/it]
(EngineCore_DP0 pid=373807) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [08:20<00:00, 250.50s/it]
(EngineCore_DP0 pid=373807) 
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:20] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:20] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=373807) [2026-01-25 19:49:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=373807) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.37it/s]
(EngineCore_DP0 pid=373807) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.94it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.92it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  45%|████▍     | 57/128 [00:00<00:00, 559.85it/s]
Adding requests:  91%|█████████▏| 117/128 [00:00<00:00, 579.29it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 574.11it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:24,  5.19it/s, est. speed input: 2658.91 toks/s, output: 5.19 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:08, 13.79it/s, est. speed input: 6280.76 toks/s, output: 12.27 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 17.76it/s, est. speed input: 7911.81 toks/s, output: 15.45 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 19.76it/s, est. speed input: 8790.40 toks/s, output: 17.17 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 20.87it/s, est. speed input: 9331.88 toks/s, output: 18.23 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 21.62it/s, est. speed input: 9718.15 toks/s, output: 18.98 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 22.00it/s, est. speed input: 9981.96 toks/s, output: 19.50 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 22.48it/s, est. speed input: 10221.55 toks/s, output: 19.96 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 22.73it/s, est. speed input: 10400.97 toks/s, output: 20.31 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 22.90it/s, est. speed input: 10544.22 toks/s, output: 20.59 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.18it/s, est. speed input: 10684.57 toks/s, output: 20.87 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:04, 22.84it/s, est. speed input: 10738.26 toks/s, output: 20.97 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:04, 22.69it/s, est. speed input: 10791.44 toks/s, output: 21.08 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 23.01it/s, est. speed input: 10885.09 toks/s, output: 21.26 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:03, 22.92it/s, est. speed input: 10933.53 toks/s, output: 21.35 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 23.25it/s, est. speed input: 11014.20 toks/s, output: 21.51 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 23.18it/s, est. speed input: 11058.96 toks/s, output: 21.60 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 22.96it/s, est. speed input: 11083.26 toks/s, output: 21.65 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 23.20it/s, est. speed input: 11137.48 toks/s, output: 21.75 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:03, 23.28it/s, est. speed input: 11180.19 toks/s, output: 21.84 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 23.24it/s, est. speed input: 11211.32 toks/s, output: 21.90 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 23.21it/s, est. speed input: 11239.80 toks/s, output: 21.95 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:02, 22.72it/s, est. speed input: 11232.95 toks/s, output: 21.94 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 22.70it/s, est. speed input: 11248.07 toks/s, output: 21.97 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 23.01it/s, est. speed input: 11282.95 toks/s, output: 22.04 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.28it/s, est. speed input: 11318.55 toks/s, output: 22.11 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.25it/s, est. speed input: 11338.56 toks/s, output: 22.15 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 23.40it/s, est. speed input: 11366.94 toks/s, output: 22.20 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 22.96it/s, est. speed input: 11362.92 toks/s, output: 22.19 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 23.05it/s, est. speed input: 11380.91 toks/s, output: 22.23 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 23.03it/s, est. speed input: 11393.41 toks/s, output: 22.25 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.28it/s, est. speed input: 11417.96 toks/s, output: 22.30 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.31it/s, est. speed input: 11434.51 toks/s, output: 22.33 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.04it/s, est. speed input: 11436.10 toks/s, output: 22.34 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 23.17it/s, est. speed input: 11452.11 toks/s, output: 22.37 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 23.25it/s, est. speed input: 11467.20 toks/s, output: 22.40 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 23.20it/s, est. speed input: 11476.53 toks/s, output: 22.41 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 23.41it/s, est. speed input: 11495.87 toks/s, output: 22.45 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 23.54it/s, est. speed input: 11513.27 toks/s, output: 22.49 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 23.58it/s, est. speed input: 11528.01 toks/s, output: 22.52 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 23.71it/s, est. speed input: 11545.83 toks/s, output: 22.55 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.81it/s, est. speed input: 11563.27 toks/s, output: 22.58 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.80it/s, est. speed input: 11576.88 toks/s, output: 22.61 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.80it/s, est. speed input: 11581.56 toks/s, output: 22.62 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.62it/s, est. speed input: 11581.56 toks/s, output: 22.62 toks/s]
[rank0]:[W125 19:49:53.690655703 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 552.8s

测试结果:
  Requests/s:   21.76
  Tokens/s:     11162.02
  Total Reqs:   128
  Elapsed:      5.88s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     11140.26

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:50:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=381706) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=381706) WARNING 01-25 19:50:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.03 requests/s, 22580.71 total tokens/s, 22.03 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 19:50:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:50:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:50:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:50:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:50:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:50:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:50:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:50:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:50:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:50:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:50:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:50:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=381706) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=381706) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.36it/s]
(EngineCore_DP0 pid=381706) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]
(EngineCore_DP0 pid=381706) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]
(EngineCore_DP0 pid=381706) 
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=381706) [2026-01-25 19:50:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=381706) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 11.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 11.25it/s]
(EngineCore_DP0 pid=381706) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.70it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 246.23it/s]
Adding requests:  41%|████▏     | 53/128 [00:00<00:00, 262.55it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 270.04it/s]
Adding requests:  85%|████████▌ | 109/128 [00:00<00:00, 269.68it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 269.95it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 65.44it/s, est. speed input: 67015.15 toks/s, output: 65.44 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 32.39it/s, est. speed input: 36084.12 toks/s, output: 35.24 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:03, 28.40it/s, est. speed input: 32004.51 toks/s, output: 31.25 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:03, 26.52it/s, est. speed input: 30158.42 toks/s, output: 29.45 toks/s]
Processed prompts:  21%|██        | 27/128 [00:00<00:03, 25.53it/s, est. speed input: 29210.35 toks/s, output: 28.53 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:03, 24.88it/s, est. speed input: 28548.14 toks/s, output: 27.88 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:03, 24.40it/s, est. speed input: 28031.84 toks/s, output: 27.37 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:03, 24.06it/s, est. speed input: 27618.45 toks/s, output: 26.97 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:03, 23.60it/s, est. speed input: 27204.06 toks/s, output: 26.57 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:03, 23.42it/s, est. speed input: 26904.10 toks/s, output: 26.27 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:03, 23.18it/s, est. speed input: 26616.14 toks/s, output: 25.99 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:01<00:03, 23.06it/s, est. speed input: 26383.00 toks/s, output: 25.76 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:01<00:03, 23.06it/s, est. speed input: 26203.89 toks/s, output: 25.59 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:03, 23.04it/s, est. speed input: 26040.56 toks/s, output: 25.43 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 23.08it/s, est. speed input: 25908.07 toks/s, output: 25.30 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:02, 23.15it/s, est. speed input: 25798.26 toks/s, output: 25.19 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:02<00:02, 23.15it/s, est. speed input: 25689.57 toks/s, output: 25.09 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:02<00:02, 23.18it/s, est. speed input: 25598.49 toks/s, output: 25.00 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:02, 23.17it/s, est. speed input: 25510.13 toks/s, output: 24.91 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:02<00:02, 23.07it/s, est. speed input: 25413.57 toks/s, output: 24.82 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 23.03it/s, est. speed input: 25330.49 toks/s, output: 24.74 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:03<00:02, 23.07it/s, est. speed input: 25263.81 toks/s, output: 24.67 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:02, 23.07it/s, est. speed input: 25199.45 toks/s, output: 24.61 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:03<00:01, 23.13it/s, est. speed input: 25147.96 toks/s, output: 24.56 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:03<00:01, 23.18it/s, est. speed input: 25100.75 toks/s, output: 24.51 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:03<00:01, 23.13it/s, est. speed input: 25046.33 toks/s, output: 24.46 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:03<00:01, 23.15it/s, est. speed input: 25002.52 toks/s, output: 24.42 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:01, 23.14it/s, est. speed input: 24959.20 toks/s, output: 24.37 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 23.11it/s, est. speed input: 24915.28 toks/s, output: 24.33 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:04<00:01, 23.07it/s, est. speed input: 24871.58 toks/s, output: 24.29 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:04<00:00, 23.11it/s, est. speed input: 24838.74 toks/s, output: 24.26 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:00, 23.12it/s, est. speed input: 24805.62 toks/s, output: 24.22 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:04<00:00, 23.15it/s, est. speed input: 24776.84 toks/s, output: 24.20 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:04<00:00, 23.14it/s, est. speed input: 24746.65 toks/s, output: 24.17 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:04<00:00, 22.98it/s, est. speed input: 24702.79 toks/s, output: 24.12 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:04<00:00, 22.72it/s, est. speed input: 24647.93 toks/s, output: 24.07 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:05<00:00, 22.64it/s, est. speed input: 24604.67 toks/s, output: 24.03 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:05<00:00, 22.81it/s, est. speed input: 24583.92 toks/s, output: 24.01 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.81it/s, est. speed input: 24569.62 toks/s, output: 23.99 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.99it/s, est. speed input: 24569.62 toks/s, output: 23.99 toks/s]
[rank0]:[W125 19:50:45.545369470 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 52.1s

测试结果:
  Requests/s:   22.03
  Tokens/s:     22580.71
  Total Reqs:   128
  Elapsed:      5.81s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     22558.68

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:50:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=382682) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=382682) WARNING 01-25 19:51:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.83 requests/s, 26473.93 total tokens/s, 25.83 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 19:50:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:50:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:50:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:50:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:50:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:50:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:50:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:50:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:51:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:51:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:51:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:51:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:51:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:51:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:51:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:51:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=382682) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=382682) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.40it/s]
(EngineCore_DP0 pid=382682) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=382682) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=382682) 
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=382682) [2026-01-25 19:51:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=382682) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 11.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.94it/s]
(EngineCore_DP0 pid=382682) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 10.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 10.85it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 27/256 [00:00<00:00, 263.40it/s]
Adding requests:  21%|██        | 54/256 [00:00<00:00, 266.59it/s]
Adding requests:  33%|███▎      | 85/256 [00:00<00:00, 283.28it/s]
Adding requests:  45%|████▍     | 114/256 [00:00<00:00, 284.26it/s]
Adding requests:  57%|█████▋    | 145/256 [00:00<00:00, 291.43it/s]
Adding requests:  69%|██████▉   | 177/256 [00:00<00:00, 297.98it/s]
Adding requests:  81%|████████  | 207/256 [00:00<00:00, 295.92it/s]
Adding requests:  93%|█████████▎| 237/256 [00:00<00:00, 295.54it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 290.53it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 213.35it/s, est. speed input: 218512.70 toks/s, output: 213.36 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:00<00:05, 41.80it/s, est. speed input: 48970.17 toks/s, output: 47.82 toks/s]   
Processed prompts:  22%|██▏       | 57/256 [00:01<00:05, 36.81it/s, est. speed input: 43272.19 toks/s, output: 42.26 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:01<00:05, 32.63it/s, est. speed input: 39569.63 toks/s, output: 38.64 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:06, 30.99it/s, est. speed input: 37960.29 toks/s, output: 37.07 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:02<00:05, 31.27it/s, est. speed input: 37606.11 toks/s, output: 36.72 toks/s]
Processed prompts:  31%|███       | 79/256 [00:02<00:05, 30.11it/s, est. speed input: 36819.33 toks/s, output: 35.96 toks/s]
Processed prompts:  32%|███▏      | 83/256 [00:02<00:05, 29.10it/s, est. speed input: 36128.80 toks/s, output: 35.28 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:02<00:05, 28.33it/s, est. speed input: 35545.72 toks/s, output: 34.71 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:06, 26.00it/s, est. speed input: 34637.53 toks/s, output: 33.83 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:06, 25.95it/s, est. speed input: 34187.61 toks/s, output: 33.39 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:06, 25.95it/s, est. speed input: 33790.87 toks/s, output: 33.00 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:03<00:05, 25.90it/s, est. speed input: 33424.52 toks/s, output: 32.64 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:03<00:05, 25.92it/s, est. speed input: 33103.98 toks/s, output: 32.33 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:03<00:05, 25.91it/s, est. speed input: 32806.20 toks/s, output: 32.04 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:03<00:05, 25.89it/s, est. speed input: 32532.26 toks/s, output: 31.77 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:03<00:05, 25.90it/s, est. speed input: 32286.54 toks/s, output: 31.53 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:03<00:05, 25.92it/s, est. speed input: 32060.04 toks/s, output: 31.31 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:04<00:05, 25.85it/s, est. speed input: 31840.15 toks/s, output: 31.09 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:04<00:04, 25.84it/s, est. speed input: 31640.36 toks/s, output: 30.90 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:04<00:04, 25.85it/s, est. speed input: 31458.05 toks/s, output: 30.72 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:04<00:04, 25.84it/s, est. speed input: 31285.48 toks/s, output: 30.55 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:04<00:04, 25.84it/s, est. speed input: 31126.05 toks/s, output: 30.40 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:04<00:04, 25.88it/s, est. speed input: 30981.24 toks/s, output: 30.26 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:04<00:04, 25.88it/s, est. speed input: 30842.69 toks/s, output: 30.12 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:05<00:03, 25.82it/s, est. speed input: 30704.05 toks/s, output: 29.98 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:05<00:03, 25.84it/s, est. speed input: 30582.41 toks/s, output: 29.87 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:05<00:03, 25.81it/s, est. speed input: 30461.34 toks/s, output: 29.75 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:05<00:03, 25.79it/s, est. speed input: 30347.72 toks/s, output: 29.64 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:05<00:03, 25.83it/s, est. speed input: 30245.50 toks/s, output: 29.54 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:05<00:03, 25.85it/s, est. speed input: 30147.93 toks/s, output: 29.44 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:06<00:03, 25.84it/s, est. speed input: 30053.79 toks/s, output: 29.35 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:06<00:02, 25.85it/s, est. speed input: 29964.88 toks/s, output: 29.26 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:06<00:02, 25.87it/s, est. speed input: 29882.22 toks/s, output: 29.18 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:06<00:02, 25.80it/s, est. speed input: 29795.20 toks/s, output: 29.10 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:06<00:02, 25.75it/s, est. speed input: 29712.57 toks/s, output: 29.02 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:06<00:02, 25.79it/s, est. speed input: 29639.72 toks/s, output: 28.94 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:06<00:01, 27.16it/s, est. speed input: 29679.33 toks/s, output: 28.98 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:07<00:01, 26.74it/s, est. speed input: 29608.11 toks/s, output: 28.91 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:07<00:01, 26.45it/s, est. speed input: 29540.48 toks/s, output: 28.85 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:07<00:01, 26.27it/s, est. speed input: 29476.77 toks/s, output: 28.79 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:07<00:01, 26.19it/s, est. speed input: 29418.64 toks/s, output: 28.73 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:07<00:01, 26.02it/s, est. speed input: 29355.11 toks/s, output: 28.67 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:07<00:01, 25.96it/s, est. speed input: 29297.83 toks/s, output: 28.61 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:08<00:01, 25.89it/s, est. speed input: 29240.90 toks/s, output: 28.56 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:08<00:00, 25.84it/s, est. speed input: 29186.10 toks/s, output: 28.50 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:08<00:00, 25.83it/s, est. speed input: 29134.92 toks/s, output: 28.45 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:08<00:00, 25.80it/s, est. speed input: 29084.09 toks/s, output: 28.40 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:08<00:00, 25.82it/s, est. speed input: 29038.05 toks/s, output: 28.36 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:08<00:00, 25.80it/s, est. speed input: 28991.12 toks/s, output: 28.31 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:08<00:00, 25.82it/s, est. speed input: 28947.68 toks/s, output: 28.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 25.82it/s, est. speed input: 29033.61 toks/s, output: 28.35 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 28.35it/s, est. speed input: 29033.61 toks/s, output: 28.35 toks/s]
[rank0]:[W125 19:51:42.763824815 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 57.3s

测试结果:
  Requests/s:   25.83
  Tokens/s:     26473.93
  Total Reqs:   256
  Elapsed:      9.91s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     26448.11

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:51:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=383745) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=383745) WARNING 01-25 19:52:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.52 requests/s, 28213.06 total tokens/s, 27.52 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 19:51:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:51:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:51:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:51:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:51:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:51:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:51:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:51:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:51:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:52:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:52:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:52:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:52:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:52:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:52:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:52:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:52:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:52:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=383745) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=383745) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.36it/s]
(EngineCore_DP0 pid=383745) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=383745) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.39it/s]
(EngineCore_DP0 pid=383745) 
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=383745) [2026-01-25 19:52:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=383745) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 11.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.60it/s]
(EngineCore_DP0 pid=383745) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.13it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 26/512 [00:00<00:01, 259.84it/s]
Adding requests:  11%|█         | 56/512 [00:00<00:01, 282.79it/s]
Adding requests:  17%|█▋        | 85/512 [00:00<00:01, 282.79it/s]
Adding requests:  22%|██▏       | 114/512 [00:00<00:01, 276.24it/s]
Adding requests:  28%|██▊       | 142/512 [00:00<00:01, 274.63it/s]
Adding requests:  34%|███▎      | 172/512 [00:00<00:01, 281.17it/s]
Adding requests:  40%|███▉      | 203/512 [00:00<00:01, 289.38it/s]
Adding requests:  46%|████▌     | 235/512 [00:00<00:00, 298.22it/s]
Adding requests:  52%|█████▏    | 265/512 [00:00<00:00, 295.66it/s]
Adding requests:  58%|█████▊    | 295/512 [00:01<00:00, 293.05it/s]
Adding requests:  64%|██████▎   | 326/512 [00:01<00:00, 295.29it/s]
Adding requests:  70%|███████   | 359/512 [00:01<00:00, 305.36it/s]
Adding requests:  76%|███████▋  | 391/512 [00:01<00:00, 308.73it/s]
Adding requests:  82%|████████▏ | 422/512 [00:01<00:00, 301.74it/s]
Adding requests:  88%|████████▊ | 453/512 [00:01<00:00, 295.63it/s]
Adding requests:  95%|█████████▍| 485/512 [00:01<00:00, 300.91it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 295.16it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:00<00:02, 222.56it/s, est. speed input: 227920.82 toks/s, output: 222.56 toks/s]
Processed prompts:  14%|█▍        | 73/512 [00:00<00:06, 65.63it/s, est. speed input: 78590.61 toks/s, output: 76.75 toks/s]   
Processed prompts:  17%|█▋        | 85/512 [00:01<00:08, 49.84it/s, est. speed input: 62717.90 toks/s, output: 61.25 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:01<00:09, 43.54it/s, est. speed input: 56733.14 toks/s, output: 55.40 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:01<00:11, 36.99it/s, est. speed input: 51501.18 toks/s, output: 50.29 toks/s]
Processed prompts:  20%|██        | 104/512 [00:02<00:11, 36.53it/s, est. speed input: 50374.08 toks/s, output: 49.19 toks/s]
Processed prompts:  21%|██        | 108/512 [00:02<00:11, 34.75it/s, est. speed input: 48938.01 toks/s, output: 47.79 toks/s]
Processed prompts:  22%|██▏       | 112/512 [00:02<00:12, 33.18it/s, est. speed input: 47688.51 toks/s, output: 46.57 toks/s]
Processed prompts:  23%|██▎       | 116/512 [00:02<00:12, 31.84it/s, est. speed input: 46578.70 toks/s, output: 45.49 toks/s]
Processed prompts:  23%|██▎       | 120/512 [00:02<00:12, 30.78it/s, est. speed input: 45599.19 toks/s, output: 44.53 toks/s]
Processed prompts:  24%|██▍       | 124/512 [00:02<00:12, 29.89it/s, est. speed input: 44700.73 toks/s, output: 43.65 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:02<00:14, 27.32it/s, est. speed input: 43546.08 toks/s, output: 42.53 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:03<00:15, 25.38it/s, est. speed input: 42492.62 toks/s, output: 41.50 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:03<00:14, 26.02it/s, est. speed input: 41863.34 toks/s, output: 40.88 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:14, 26.49it/s, est. speed input: 41290.96 toks/s, output: 40.32 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:03<00:13, 26.74it/s, est. speed input: 40746.11 toks/s, output: 39.79 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:03<00:13, 26.96it/s, est. speed input: 40251.43 toks/s, output: 39.31 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:03<00:13, 27.16it/s, est. speed input: 39802.59 toks/s, output: 38.87 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:13, 27.22it/s, est. speed input: 39373.37 toks/s, output: 38.45 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:12, 27.35it/s, est. speed input: 38987.64 toks/s, output: 38.07 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:12, 27.40it/s, est. speed input: 38621.46 toks/s, output: 37.72 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:04<00:12, 27.38it/s, est. speed input: 38271.69 toks/s, output: 37.37 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:04<00:12, 27.34it/s, est. speed input: 37940.01 toks/s, output: 37.05 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:04<00:12, 27.43it/s, est. speed input: 37645.80 toks/s, output: 36.76 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:04<00:12, 27.44it/s, est. speed input: 37361.50 toks/s, output: 36.49 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:12, 27.45it/s, est. speed input: 37093.32 toks/s, output: 36.22 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:11, 27.45it/s, est. speed input: 36840.77 toks/s, output: 35.98 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:05<00:11, 27.46it/s, est. speed input: 36602.95 toks/s, output: 35.74 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:05<00:11, 27.46it/s, est. speed input: 36376.73 toks/s, output: 35.52 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:05<00:11, 27.49it/s, est. speed input: 36164.87 toks/s, output: 35.32 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:05<00:10, 29.12it/s, est. speed input: 36132.86 toks/s, output: 35.29 toks/s]
Processed prompts:  40%|████      | 206/512 [00:05<00:10, 28.55it/s, est. speed input: 35928.96 toks/s, output: 35.09 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:10, 28.22it/s, est. speed input: 35740.81 toks/s, output: 34.90 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:10, 28.00it/s, est. speed input: 35561.91 toks/s, output: 34.73 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:06<00:10, 27.86it/s, est. speed input: 35392.45 toks/s, output: 34.56 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:10, 27.74it/s, est. speed input: 35228.48 toks/s, output: 34.40 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:06<00:10, 27.62it/s, est. speed input: 35068.24 toks/s, output: 34.25 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:06<00:10, 27.56it/s, est. speed input: 34917.21 toks/s, output: 34.10 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:06<00:10, 27.51it/s, est. speed input: 34771.70 toks/s, output: 33.96 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:09, 27.55it/s, est. speed input: 34638.59 toks/s, output: 33.83 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:07<00:09, 27.54it/s, est. speed input: 34507.93 toks/s, output: 33.70 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:07<00:09, 27.47it/s, est. speed input: 34377.27 toks/s, output: 33.57 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:07<00:09, 27.42it/s, est. speed input: 34251.29 toks/s, output: 33.45 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:07<00:09, 27.40it/s, est. speed input: 34131.51 toks/s, output: 33.33 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:07<00:09, 27.40it/s, est. speed input: 34017.37 toks/s, output: 33.22 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:07<00:09, 27.38it/s, est. speed input: 33905.67 toks/s, output: 33.11 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:08<00:08, 27.37it/s, est. speed input: 33798.93 toks/s, output: 33.01 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:08<00:08, 27.39it/s, est. speed input: 33697.72 toks/s, output: 32.91 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:08<00:08, 27.42it/s, est. speed input: 33600.80 toks/s, output: 32.81 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:08<00:08, 27.39it/s, est. speed input: 33504.23 toks/s, output: 32.72 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:08<00:08, 27.45it/s, est. speed input: 33415.68 toks/s, output: 32.63 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:08<00:08, 27.43it/s, est. speed input: 33326.63 toks/s, output: 32.55 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:08<00:08, 27.45it/s, est. speed input: 33242.30 toks/s, output: 32.46 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:09<00:07, 27.43it/s, est. speed input: 33158.87 toks/s, output: 32.38 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:09<00:07, 27.43it/s, est. speed input: 33078.54 toks/s, output: 32.30 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:09<00:07, 27.45it/s, est. speed input: 33001.92 toks/s, output: 32.23 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:09<00:07, 29.28it/s, est. speed input: 33032.75 toks/s, output: 32.26 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:09<00:07, 28.66it/s, est. speed input: 32955.56 toks/s, output: 32.18 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:09<00:07, 28.27it/s, est. speed input: 32882.25 toks/s, output: 32.11 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:09<00:06, 28.00it/s, est. speed input: 32811.30 toks/s, output: 32.04 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:10<00:06, 27.78it/s, est. speed input: 32739.99 toks/s, output: 31.97 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:10<00:06, 27.66it/s, est. speed input: 32672.96 toks/s, output: 31.91 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:10<00:06, 27.61it/s, est. speed input: 32609.26 toks/s, output: 31.84 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:10<00:06, 27.53it/s, est. speed input: 32545.26 toks/s, output: 31.78 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:10<00:06, 27.48it/s, est. speed input: 32482.98 toks/s, output: 31.72 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:10<00:06, 27.45it/s, est. speed input: 32423.21 toks/s, output: 31.66 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:10<00:06, 27.43it/s, est. speed input: 32364.85 toks/s, output: 31.61 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:11<00:05, 27.45it/s, est. speed input: 32309.47 toks/s, output: 31.55 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:11<00:05, 27.42it/s, est. speed input: 32253.38 toks/s, output: 31.50 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:11<00:05, 27.40it/s, est. speed input: 32198.79 toks/s, output: 31.44 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:11<00:05, 27.43it/s, est. speed input: 32148.01 toks/s, output: 31.39 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:11<00:05, 27.47it/s, est. speed input: 32099.31 toks/s, output: 31.35 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:11<00:05, 27.44it/s, est. speed input: 32049.02 toks/s, output: 31.30 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:11<00:05, 27.41it/s, est. speed input: 31999.36 toks/s, output: 31.25 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:12<00:04, 27.43it/s, est. speed input: 31952.75 toks/s, output: 31.20 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:12<00:04, 27.41it/s, est. speed input: 31905.83 toks/s, output: 31.16 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:12<00:04, 27.41it/s, est. speed input: 31860.95 toks/s, output: 31.11 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:12<00:04, 27.44it/s, est. speed input: 31818.22 toks/s, output: 31.07 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:12<00:04, 27.43it/s, est. speed input: 31775.09 toks/s, output: 31.03 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:12<00:04, 27.36it/s, est. speed input: 31730.31 toks/s, output: 30.99 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:12<00:04, 27.40it/s, est. speed input: 31690.26 toks/s, output: 30.95 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:13<00:03, 27.38it/s, est. speed input: 31648.96 toks/s, output: 30.91 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:13<00:03, 27.45it/s, est. speed input: 31612.05 toks/s, output: 30.87 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:13<00:03, 27.41it/s, est. speed input: 31572.64 toks/s, output: 30.83 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:13<00:03, 27.41it/s, est. speed input: 31534.80 toks/s, output: 30.80 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:13<00:03, 27.42it/s, est. speed input: 31498.48 toks/s, output: 30.76 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:13<00:03, 27.42it/s, est. speed input: 31462.46 toks/s, output: 30.73 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:14<00:02, 27.39it/s, est. speed input: 31425.80 toks/s, output: 30.69 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:14<00:02, 29.21it/s, est. speed input: 31458.30 toks/s, output: 30.72 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:14<00:02, 28.64it/s, est. speed input: 31423.52 toks/s, output: 30.69 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:14<00:02, 28.31it/s, est. speed input: 31391.34 toks/s, output: 30.66 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:14<00:02, 28.00it/s, est. speed input: 31356.67 toks/s, output: 30.62 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:14<00:02, 27.86it/s, est. speed input: 31325.58 toks/s, output: 30.59 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:14<00:02, 27.68it/s, est. speed input: 31292.20 toks/s, output: 30.56 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:15<00:01, 27.59it/s, est. speed input: 31260.28 toks/s, output: 30.53 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:15<00:01, 27.54it/s, est. speed input: 31229.67 toks/s, output: 30.50 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:15<00:01, 27.48it/s, est. speed input: 31198.88 toks/s, output: 30.47 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:15<00:01, 27.51it/s, est. speed input: 31170.90 toks/s, output: 30.44 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:15<00:01, 27.49it/s, est. speed input: 31142.26 toks/s, output: 30.41 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:15<00:01, 27.48it/s, est. speed input: 31114.19 toks/s, output: 30.38 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:15<00:01, 27.46it/s, est. speed input: 31086.12 toks/s, output: 30.36 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:16<00:00, 27.47it/s, est. speed input: 31059.55 toks/s, output: 30.33 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:16<00:00, 27.43it/s, est. speed input: 31031.73 toks/s, output: 30.30 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:16<00:00, 27.48it/s, est. speed input: 31007.03 toks/s, output: 30.28 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:16<00:00, 27.47it/s, est. speed input: 30981.56 toks/s, output: 30.26 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:16<00:00, 27.44it/s, est. speed input: 30955.57 toks/s, output: 30.23 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:16<00:00, 27.43it/s, est. speed input: 30930.17 toks/s, output: 30.21 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:16<00:00, 29.40it/s, est. speed input: 30965.55 toks/s, output: 30.24 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:16<00:00, 29.40it/s, est. speed input: 31086.70 toks/s, output: 30.36 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:16<00:00, 30.36it/s, est. speed input: 31086.70 toks/s, output: 30.36 toks/s]
[rank0]:[W125 19:52:50.112837397 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 68.3s

测试结果:
  Requests/s:   27.52
  Tokens/s:     28213.06
  Total Reqs:   512
  Elapsed:      18.60s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     28185.53

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:53:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=384967) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=384967) WARNING 01-25 19:53:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.37 requests/s, 29080.64 total tokens/s, 28.37 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 19:53:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:53:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:53:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:53:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:53:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:53:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:53:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:53:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:53:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:53:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:53:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:53:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:53:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:53:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:53:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:53:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:53:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=384967) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=384967) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.39it/s]
(EngineCore_DP0 pid=384967) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.41it/s]
(EngineCore_DP0 pid=384967) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=384967) 
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=384967) [2026-01-25 19:53:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=384967) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 10.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00, 11.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 11.23it/s]
(EngineCore_DP0 pid=384967) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 10.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.40it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 27/1024 [00:00<00:03, 265.75it/s]
Adding requests:   6%|▌         | 57/1024 [00:00<00:03, 285.63it/s]
Adding requests:   9%|▊         | 88/1024 [00:00<00:03, 292.35it/s]
Adding requests:  12%|█▏        | 118/1024 [00:00<00:03, 294.09it/s]
Adding requests:  14%|█▍        | 148/1024 [00:00<00:02, 293.04it/s]
Adding requests:  17%|█▋        | 178/1024 [00:00<00:02, 293.76it/s]
Adding requests:  21%|██        | 210/1024 [00:00<00:02, 299.71it/s]
Adding requests:  23%|██▎       | 240/1024 [00:00<00:02, 296.37it/s]
Adding requests:  26%|██▋       | 270/1024 [00:00<00:02, 297.06it/s]
Adding requests:  29%|██▉       | 301/1024 [00:01<00:02, 298.12it/s]
Adding requests:  32%|███▏      | 331/1024 [00:01<00:02, 295.44it/s]
Adding requests:  35%|███▌      | 361/1024 [00:01<00:02, 293.17it/s]
Adding requests:  38%|███▊      | 391/1024 [00:01<00:02, 292.44it/s]
Adding requests:  41%|████      | 421/1024 [00:01<00:02, 293.91it/s]
Adding requests:  44%|████▍     | 451/1024 [00:01<00:01, 291.57it/s]
Adding requests:  47%|████▋     | 482/1024 [00:01<00:01, 294.56it/s]
Adding requests:  50%|█████     | 513/1024 [00:01<00:01, 298.92it/s]
Adding requests:  53%|█████▎    | 543/1024 [00:01<00:01, 295.28it/s]
Adding requests:  56%|█████▌    | 573/1024 [00:01<00:01, 294.52it/s]
Adding requests:  59%|█████▉    | 603/1024 [00:02<00:01, 289.16it/s]
Adding requests:  62%|██████▏   | 635/1024 [00:02<00:01, 296.71it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:02<00:01, 292.08it/s]
Adding requests:  68%|██████▊   | 696/1024 [00:02<00:01, 293.68it/s]
Adding requests:  71%|███████   | 726/1024 [00:02<00:01, 288.38it/s]
Adding requests:  74%|███████▍  | 756/1024 [00:02<00:00, 291.18it/s]
Adding requests:  77%|███████▋  | 789/1024 [00:02<00:00, 299.02it/s]
Adding requests:  80%|███████▉  | 819/1024 [00:02<00:00, 292.84it/s]
Adding requests:  83%|████████▎ | 852/1024 [00:02<00:00, 301.97it/s]
Adding requests:  86%|████████▌ | 883/1024 [00:02<00:00, 300.00it/s]
Adding requests:  89%|████████▉ | 914/1024 [00:03<00:00, 296.92it/s]
Adding requests:  92%|█████████▏| 944/1024 [00:03<00:00, 293.60it/s]
Adding requests:  95%|█████████▌| 974/1024 [00:03<00:00, 294.89it/s]
Adding requests:  98%|█████████▊| 1004/1024 [00:03<00:00, 289.55it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 293.47it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:00<00:02, 406.95it/s, est. speed input: 416752.61 toks/s, output: 406.96 toks/s]
Processed prompts:  14%|█▎        | 139/1024 [00:01<00:12, 69.37it/s, est. speed input: 86153.24 toks/s, output: 84.13 toks/s]  
Processed prompts:  15%|█▌        | 158/1024 [00:02<00:15, 57.30it/s, est. speed input: 72987.38 toks/s, output: 71.28 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:02<00:18, 45.54it/s, est. speed input: 62569.69 toks/s, output: 61.10 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:03<00:19, 42.30it/s, est. speed input: 59483.45 toks/s, output: 58.09 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:03<00:21, 39.33it/s, est. speed input: 56911.20 toks/s, output: 55.58 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:03<00:22, 36.78it/s, est. speed input: 54742.49 toks/s, output: 53.46 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:03<00:23, 35.60it/s, est. speed input: 53288.18 toks/s, output: 52.04 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:04<00:24, 33.65it/s, est. speed input: 51642.04 toks/s, output: 50.43 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:04<00:25, 32.20it/s, est. speed input: 50211.34 toks/s, output: 49.03 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:04<00:25, 31.06it/s, est. speed input: 48931.83 toks/s, output: 47.78 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:05<00:26, 30.30it/s, est. speed input: 47815.73 toks/s, output: 46.69 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:05<00:26, 29.73it/s, est. speed input: 46816.14 toks/s, output: 45.72 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:05<00:26, 29.38it/s, est. speed input: 45929.75 toks/s, output: 44.85 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:05<00:26, 29.06it/s, est. speed input: 45110.90 toks/s, output: 44.05 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:06<00:26, 28.87it/s, est. speed input: 44377.33 toks/s, output: 43.34 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:06<00:26, 28.72it/s, est. speed input: 43704.17 toks/s, output: 42.68 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:06<00:25, 28.64it/s, est. speed input: 43092.60 toks/s, output: 42.08 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:06<00:25, 28.62it/s, est. speed input: 42538.04 toks/s, output: 41.54 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:07<00:25, 28.56it/s, est. speed input: 42017.82 toks/s, output: 41.03 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:07<00:24, 29.45it/s, est. speed input: 41700.13 toks/s, output: 40.72 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:07<00:24, 29.11it/s, est. speed input: 41240.22 toks/s, output: 40.27 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:08<00:24, 28.87it/s, est. speed input: 40813.18 toks/s, output: 39.86 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:08<00:24, 28.69it/s, est. speed input: 40411.93 toks/s, output: 39.46 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:08<00:24, 28.56it/s, est. speed input: 40036.79 toks/s, output: 39.10 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:08<00:23, 28.51it/s, est. speed input: 39689.85 toks/s, output: 38.76 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:09<00:23, 28.46it/s, est. speed input: 39363.33 toks/s, output: 38.44 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:09<00:23, 28.41it/s, est. speed input: 39054.42 toks/s, output: 38.14 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:09<00:23, 28.38it/s, est. speed input: 38762.50 toks/s, output: 37.85 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:10<00:22, 28.37it/s, est. speed input: 38489.55 toks/s, output: 37.59 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:10<00:22, 28.34it/s, est. speed input: 38228.42 toks/s, output: 37.33 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:10<00:22, 28.30it/s, est. speed input: 37979.38 toks/s, output: 37.09 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:10<00:21, 28.31it/s, est. speed input: 37746.75 toks/s, output: 36.86 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:11<00:21, 28.33it/s, est. speed input: 37528.16 toks/s, output: 36.65 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:11<00:21, 28.30it/s, est. speed input: 37314.60 toks/s, output: 36.44 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:11<00:21, 28.29it/s, est. speed input: 37113.77 toks/s, output: 36.24 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:12<00:20, 29.27it/s, est. speed input: 37018.75 toks/s, output: 36.15 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:12<00:20, 28.96it/s, est. speed input: 36833.14 toks/s, output: 35.97 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:12<00:19, 28.73it/s, est. speed input: 36653.39 toks/s, output: 35.79 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:12<00:19, 28.59it/s, est. speed input: 36483.79 toks/s, output: 35.63 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:13<00:19, 28.53it/s, est. speed input: 36324.64 toks/s, output: 35.47 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:13<00:19, 28.47it/s, est. speed input: 36171.35 toks/s, output: 35.32 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:13<00:19, 28.43it/s, est. speed input: 36023.27 toks/s, output: 35.18 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:13<00:18, 28.37it/s, est. speed input: 35879.60 toks/s, output: 35.04 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:14<00:18, 28.40it/s, est. speed input: 35746.89 toks/s, output: 34.91 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:14<00:18, 28.38it/s, est. speed input: 35616.00 toks/s, output: 34.78 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:14<00:17, 28.36it/s, est. speed input: 35489.91 toks/s, output: 34.66 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:15<00:17, 28.34it/s, est. speed input: 35367.95 toks/s, output: 34.54 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:15<00:17, 28.38it/s, est. speed input: 35254.76 toks/s, output: 34.43 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:15<00:17, 28.35it/s, est. speed input: 35140.79 toks/s, output: 34.32 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:15<00:16, 28.32it/s, est. speed input: 35030.41 toks/s, output: 34.21 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:16<00:16, 28.31it/s, est. speed input: 34925.04 toks/s, output: 34.11 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:16<00:16, 28.33it/s, est. speed input: 34824.75 toks/s, output: 34.01 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:16<00:16, 28.33it/s, est. speed input: 34727.14 toks/s, output: 33.91 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:17<00:15, 28.32it/s, est. speed input: 34632.00 toks/s, output: 33.82 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:17<00:15, 28.30it/s, est. speed input: 34539.31 toks/s, output: 33.73 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:17<00:15, 28.32it/s, est. speed input: 34451.19 toks/s, output: 33.64 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:17<00:14, 28.32it/s, est. speed input: 34365.81 toks/s, output: 33.56 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:18<00:14, 28.30it/s, est. speed input: 34281.00 toks/s, output: 33.48 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:18<00:14, 28.31it/s, est. speed input: 34200.83 toks/s, output: 33.40 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:18<00:14, 28.34it/s, est. speed input: 34124.00 toks/s, output: 33.32 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:19<00:13, 28.31it/s, est. speed input: 34047.08 toks/s, output: 33.25 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:19<00:13, 28.32it/s, est. speed input: 33973.38 toks/s, output: 33.18 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:19<00:13, 28.33it/s, est. speed input: 33902.76 toks/s, output: 33.11 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:19<00:12, 28.32it/s, est. speed input: 33832.43 toks/s, output: 33.04 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:20<00:12, 28.28it/s, est. speed input: 33762.88 toks/s, output: 32.97 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:20<00:12, 28.31it/s, est. speed input: 33697.91 toks/s, output: 32.91 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:20<00:12, 28.32it/s, est. speed input: 33634.43 toks/s, output: 32.85 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:21<00:11, 28.31it/s, est. speed input: 33571.91 toks/s, output: 32.79 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:21<00:11, 28.30it/s, est. speed input: 33510.58 toks/s, output: 32.73 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:21<00:11, 28.34it/s, est. speed input: 33453.09 toks/s, output: 32.67 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:21<00:10, 28.32it/s, est. speed input: 33394.85 toks/s, output: 32.61 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:22<00:10, 28.32it/s, est. speed input: 33339.25 toks/s, output: 32.56 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:22<00:10, 28.33it/s, est. speed input: 33284.95 toks/s, output: 32.50 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:22<00:10, 28.34it/s, est. speed input: 33232.51 toks/s, output: 32.45 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:23<00:09, 28.31it/s, est. speed input: 33179.40 toks/s, output: 32.40 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:23<00:09, 28.25it/s, est. speed input: 33125.77 toks/s, output: 32.35 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:23<00:09, 28.25it/s, est. speed input: 33075.25 toks/s, output: 32.30 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:23<00:08, 28.25it/s, est. speed input: 33025.95 toks/s, output: 32.25 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:24<00:08, 28.21it/s, est. speed input: 32976.36 toks/s, output: 32.20 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:24<00:08, 29.16it/s, est. speed input: 32970.26 toks/s, output: 32.20 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:24<00:07, 28.86it/s, est. speed input: 32922.97 toks/s, output: 32.15 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:24<00:07, 28.70it/s, est. speed input: 32878.73 toks/s, output: 32.11 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:25<00:07, 28.55it/s, est. speed input: 32833.92 toks/s, output: 32.06 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:25<00:07, 28.46it/s, est. speed input: 32790.56 toks/s, output: 32.02 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:25<00:06, 28.38it/s, est. speed input: 32747.50 toks/s, output: 31.98 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:26<00:06, 28.35it/s, est. speed input: 32706.33 toks/s, output: 31.94 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:26<00:06, 28.30it/s, est. speed input: 32665.04 toks/s, output: 31.90 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:26<00:06, 28.29it/s, est. speed input: 32625.54 toks/s, output: 31.86 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:26<00:05, 28.28it/s, est. speed input: 32586.99 toks/s, output: 31.82 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:27<00:05, 28.25it/s, est. speed input: 32548.19 toks/s, output: 31.79 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:27<00:05, 28.24it/s, est. speed input: 32510.38 toks/s, output: 31.75 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:27<00:05, 28.24it/s, est. speed input: 32473.71 toks/s, output: 31.71 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:28<00:04, 28.25it/s, est. speed input: 32438.20 toks/s, output: 31.68 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:28<00:04, 28.24it/s, est. speed input: 32402.96 toks/s, output: 31.64 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:28<00:04, 28.27it/s, est. speed input: 32369.58 toks/s, output: 31.61 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:28<00:03, 28.24it/s, est. speed input: 32335.00 toks/s, output: 31.58 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:29<00:03, 28.20it/s, est. speed input: 32300.39 toks/s, output: 31.54 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:29<00:03, 28.21it/s, est. speed input: 32267.81 toks/s, output: 31.51 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:29<00:03, 28.23it/s, est. speed input: 32236.27 toks/s, output: 31.48 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:30<00:02, 28.23it/s, est. speed input: 32205.00 toks/s, output: 31.45 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:30<00:02, 28.23it/s, est. speed input: 32174.33 toks/s, output: 31.42 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:30<00:02, 28.24it/s, est. speed input: 32144.49 toks/s, output: 31.39 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:30<00:01, 28.23it/s, est. speed input: 32114.61 toks/s, output: 31.36 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:31<00:01, 28.24it/s, est. speed input: 32085.66 toks/s, output: 31.33 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:31<00:01, 28.20it/s, est. speed input: 32055.78 toks/s, output: 31.30 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:31<00:01, 28.19it/s, est. speed input: 32027.26 toks/s, output: 31.28 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:32<00:00, 28.13it/s, est. speed input: 31997.29 toks/s, output: 31.25 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:32<00:00, 28.13it/s, est. speed input: 31969.03 toks/s, output: 31.22 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:32<00:00, 29.17it/s, est. speed input: 31974.80 toks/s, output: 31.23 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:32<00:00, 29.17it/s, est. speed input: 32162.98 toks/s, output: 31.41 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:32<00:00, 31.41it/s, est. speed input: 32162.98 toks/s, output: 31.41 toks/s]
[rank0]:[W125 19:54:22.692210175 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 91.6s

测试结果:
  Requests/s:   28.37
  Tokens/s:     29080.64
  Total Reqs:   1024
  Elapsed:      36.09s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     29052.27

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:54:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=386564) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=386564) WARNING 01-25 19:55:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.71 requests/s, 29428.57 total tokens/s, 28.71 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 19:54:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:54:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:54:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:54:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:54:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:54:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:54:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:54:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:54:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:54:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:54:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:54:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:54:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:54:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:54:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:54:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:54:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=386564) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=386564) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.40it/s]
(EngineCore_DP0 pid=386564) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.42it/s]
(EngineCore_DP0 pid=386564) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.41it/s]
(EngineCore_DP0 pid=386564) 
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=386564) [2026-01-25 19:54:56] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=386564) [rank0]:W0125 19:55:13.619000 386564 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=386564) [rank0]:W0125 19:55:13.729000 386564 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=386564) [rank0]:W0125 19:55:15.307000 386564 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=386564) [rank0]:W0125 19:55:15.504000 386564 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=386564) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 10.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 10.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 11.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 10.75it/s]
(EngineCore_DP0 pid=386564) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  9.77it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 11.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.19it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 26/2048 [00:00<00:08, 246.37it/s]
Adding requests:   3%|▎         | 53/2048 [00:00<00:07, 253.69it/s]
Adding requests:   4%|▍         | 82/2048 [00:00<00:07, 265.98it/s]
Adding requests:   5%|▌         | 109/2048 [00:00<00:07, 266.80it/s]
Adding requests:   7%|▋         | 136/2048 [00:00<00:07, 265.26it/s]
Adding requests:   8%|▊         | 166/2048 [00:00<00:06, 275.29it/s]
Adding requests:  10%|▉         | 196/2048 [00:00<00:06, 282.84it/s]
Adding requests:  11%|█         | 225/2048 [00:00<00:06, 280.83it/s]
Adding requests:  12%|█▏        | 254/2048 [00:00<00:06, 276.32it/s]
Adding requests:  14%|█▍        | 282/2048 [00:01<00:06, 274.01it/s]
Adding requests:  15%|█▌        | 313/2048 [00:01<00:06, 282.95it/s]
Adding requests:  17%|█▋        | 345/2048 [00:01<00:05, 293.00it/s]
Adding requests:  18%|█▊        | 377/2048 [00:01<00:05, 297.53it/s]
Adding requests:  20%|█▉        | 408/2048 [00:01<00:05, 298.54it/s]
Adding requests:  21%|██▏       | 438/2048 [00:01<00:05, 295.26it/s]
Adding requests:  23%|██▎       | 468/2048 [00:01<00:05, 294.45it/s]
Adding requests:  24%|██▍       | 499/2048 [00:01<00:05, 296.24it/s]
Adding requests:  26%|██▌       | 531/2048 [00:01<00:05, 303.12it/s]
Adding requests:  27%|██▋       | 562/2048 [00:01<00:04, 303.79it/s]
Adding requests:  29%|██▉       | 593/2048 [00:02<00:04, 291.45it/s]
Adding requests:  30%|███       | 623/2048 [00:02<00:04, 289.35it/s]
Adding requests:  32%|███▏      | 653/2048 [00:02<00:04, 284.38it/s]
Adding requests:  33%|███▎      | 683/2048 [00:02<00:04, 285.66it/s]
Adding requests:  35%|███▍      | 712/2048 [00:02<00:04, 285.10it/s]
Adding requests:  36%|███▌      | 741/2048 [00:02<00:04, 279.43it/s]
Adding requests:  38%|███▊      | 769/2048 [00:02<00:04, 276.44it/s]
Adding requests:  39%|███▉      | 798/2048 [00:02<00:04, 279.08it/s]
Adding requests:  40%|████      | 827/2048 [00:02<00:04, 280.58it/s]
Adding requests:  42%|████▏     | 856/2048 [00:03<00:04, 280.03it/s]
Adding requests:  43%|████▎     | 887/2048 [00:03<00:04, 286.34it/s]
Adding requests:  45%|████▍     | 917/2048 [00:03<00:03, 286.92it/s]
Adding requests:  46%|████▌     | 946/2048 [00:03<00:03, 283.97it/s]
Adding requests:  48%|████▊     | 977/2048 [00:03<00:03, 291.07it/s]
Adding requests:  49%|████▉     | 1007/2048 [00:03<00:03, 291.67it/s]
Adding requests:  51%|█████     | 1037/2048 [00:03<00:03, 292.85it/s]
Adding requests:  52%|█████▏    | 1067/2048 [00:03<00:03, 288.87it/s]
Adding requests:  54%|█████▎    | 1096/2048 [00:03<00:03, 282.79it/s]
Adding requests:  55%|█████▍    | 1125/2048 [00:03<00:03, 284.84it/s]
Adding requests:  56%|█████▋    | 1154/2048 [00:04<00:03, 280.84it/s]
Adding requests:  58%|█████▊    | 1183/2048 [00:04<00:03, 282.88it/s]
Adding requests:  59%|█████▉    | 1214/2048 [00:04<00:02, 290.80it/s]
Adding requests:  61%|██████    | 1244/2048 [00:04<00:02, 290.64it/s]
Adding requests:  62%|██████▏   | 1274/2048 [00:04<00:02, 285.08it/s]
Adding requests:  64%|██████▎   | 1304/2048 [00:04<00:02, 286.40it/s]
Adding requests:  65%|██████▌   | 1333/2048 [00:04<00:02, 283.23it/s]
Adding requests:  67%|██████▋   | 1364/2048 [00:04<00:02, 290.11it/s]
Adding requests:  68%|██████▊   | 1396/2048 [00:04<00:02, 295.80it/s]
Adding requests:  70%|██████▉   | 1426/2048 [00:04<00:02, 294.63it/s]
Adding requests:  71%|███████   | 1456/2048 [00:05<00:02, 293.87it/s]
Adding requests:  73%|███████▎  | 1486/2048 [00:05<00:01, 295.35it/s]
Adding requests:  74%|███████▍  | 1518/2048 [00:05<00:01, 300.48it/s]
Adding requests:  76%|███████▌  | 1550/2048 [00:05<00:01, 303.97it/s]
Adding requests:  77%|███████▋  | 1581/2048 [00:05<00:01, 301.94it/s]
Adding requests:  79%|███████▉  | 1613/2048 [00:05<00:01, 304.19it/s]
Adding requests:  80%|████████  | 1644/2048 [00:05<00:01, 296.37it/s]
Adding requests:  82%|████████▏ | 1675/2048 [00:05<00:01, 298.59it/s]
Adding requests:  83%|████████▎ | 1709/2048 [00:05<00:01, 307.87it/s]
Adding requests:  85%|████████▍ | 1740/2048 [00:06<00:01, 302.42it/s]
Adding requests:  87%|████████▋ | 1773/2048 [00:06<00:00, 309.18it/s]
Adding requests:  88%|████████▊ | 1804/2048 [00:06<00:00, 302.37it/s]
Adding requests:  90%|████████▉ | 1835/2048 [00:06<00:00, 299.88it/s]
Adding requests:  91%|█████████ | 1867/2048 [00:06<00:00, 305.32it/s]
Adding requests:  93%|█████████▎| 1900/2048 [00:06<00:00, 309.96it/s]
Adding requests:  94%|█████████▍| 1933/2048 [00:06<00:00, 314.75it/s]
Adding requests:  96%|█████████▌| 1965/2048 [00:06<00:00, 305.84it/s]
Adding requests:  97%|█████████▋| 1996/2048 [00:06<00:00, 297.68it/s]
Adding requests:  99%|█████████▉| 2026/2048 [00:06<00:00, 283.21it/s]
Adding requests: 100%|██████████| 2048/2048 [00:07<00:00, 290.33it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:00<00:01, 957.68it/s, est. speed input: 980780.05 toks/s, output: 957.71 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:03<00:26, 66.78it/s, est. speed input: 84081.95 toks/s, output: 82.11 toks/s]   
Processed prompts:  16%|█▌        | 332/2048 [00:04<00:29, 58.21it/s, est. speed input: 73731.85 toks/s, output: 72.00 toks/s]
Processed prompts:  17%|█▋        | 357/2048 [00:05<00:35, 47.12it/s, est. speed input: 63916.55 toks/s, output: 62.42 toks/s]
Processed prompts:  18%|█▊        | 373/2048 [00:06<00:38, 43.78it/s, est. speed input: 60866.61 toks/s, output: 59.44 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:06<00:41, 39.59it/s, est. speed input: 57874.72 toks/s, output: 56.52 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:07<00:44, 37.08it/s, est. speed input: 55715.04 toks/s, output: 54.41 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:07<00:46, 34.98it/s, est. speed input: 53850.92 toks/s, output: 52.59 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:08<00:47, 33.86it/s, est. speed input: 52447.20 toks/s, output: 51.22 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:09<00:49, 32.48it/s, est. speed input: 51033.96 toks/s, output: 49.84 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:09<00:50, 31.47it/s, est. speed input: 49791.60 toks/s, output: 48.62 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:10<00:50, 30.71it/s, est. speed input: 48681.57 toks/s, output: 47.54 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:10<00:51, 30.12it/s, est. speed input: 47674.25 toks/s, output: 46.56 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:11<00:51, 29.75it/s, est. speed input: 46780.22 toks/s, output: 45.68 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:11<00:51, 29.42it/s, est. speed input: 45954.38 toks/s, output: 44.88 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:12<00:51, 29.23it/s, est. speed input: 45214.48 toks/s, output: 44.15 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:12<00:51, 29.12it/s, est. speed input: 44542.53 toks/s, output: 43.50 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:13<00:50, 29.03it/s, est. speed input: 43923.30 toks/s, output: 42.89 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:14<00:50, 28.87it/s, est. speed input: 43333.18 toks/s, output: 42.32 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:14<00:49, 28.83it/s, est. speed input: 42803.05 toks/s, output: 41.80 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:15<00:49, 28.82it/s, est. speed input: 42314.13 toks/s, output: 41.32 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:15<00:48, 28.74it/s, est. speed input: 41848.23 toks/s, output: 40.87 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:16<00:48, 28.73it/s, est. speed input: 41421.24 toks/s, output: 40.45 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:16<00:47, 28.72it/s, est. speed input: 41022.29 toks/s, output: 40.06 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:17<00:47, 28.63it/s, est. speed input: 40636.52 toks/s, output: 39.68 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:17<00:46, 28.66it/s, est. speed input: 40288.03 toks/s, output: 39.34 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:18<00:46, 28.68it/s, est. speed input: 39960.49 toks/s, output: 39.02 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:19<00:45, 28.64it/s, est. speed input: 39644.88 toks/s, output: 38.72 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:19<00:45, 28.60it/s, est. speed input: 39346.65 toks/s, output: 38.42 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:20<00:44, 28.65it/s, est. speed input: 39073.53 toks/s, output: 38.16 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:20<00:43, 29.12it/s, est. speed input: 38867.31 toks/s, output: 37.96 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:21<00:42, 28.99it/s, est. speed input: 38618.66 toks/s, output: 37.71 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:21<00:42, 28.80it/s, est. speed input: 38371.91 toks/s, output: 37.47 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:22<00:42, 28.77it/s, est. speed input: 38147.62 toks/s, output: 37.25 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:22<00:41, 28.68it/s, est. speed input: 37927.77 toks/s, output: 37.04 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:23<00:41, 28.70it/s, est. speed input: 37726.97 toks/s, output: 36.84 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:24<00:40, 28.58it/s, est. speed input: 37521.07 toks/s, output: 36.64 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:24<00:40, 28.58it/s, est. speed input: 37333.48 toks/s, output: 36.46 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:25<00:39, 28.58it/s, est. speed input: 37154.20 toks/s, output: 36.28 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:25<00:39, 28.62it/s, est. speed input: 36986.17 toks/s, output: 36.12 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:26<00:38, 28.56it/s, est. speed input: 36817.98 toks/s, output: 35.96 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:26<00:38, 28.49it/s, est. speed input: 36653.28 toks/s, output: 35.79 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:27<00:37, 28.47it/s, est. speed input: 36498.69 toks/s, output: 35.64 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:28<00:37, 28.42it/s, est. speed input: 36347.14 toks/s, output: 35.50 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:28<00:36, 28.46it/s, est. speed input: 36207.21 toks/s, output: 35.36 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:29<00:35, 28.44it/s, est. speed input: 36069.50 toks/s, output: 35.22 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:29<00:35, 28.51it/s, est. speed input: 35943.33 toks/s, output: 35.10 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:30<00:34, 28.52it/s, est. speed input: 35818.73 toks/s, output: 34.98 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:30<00:34, 28.48it/s, est. speed input: 35695.42 toks/s, output: 34.86 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:31<00:33, 28.44it/s, est. speed input: 35575.17 toks/s, output: 34.74 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:31<00:33, 28.39it/s, est. speed input: 35457.89 toks/s, output: 34.63 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:32<00:32, 28.49it/s, est. speed input: 35354.60 toks/s, output: 34.53 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:33<00:31, 28.49it/s, est. speed input: 35249.18 toks/s, output: 34.42 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:33<00:31, 28.54it/s, est. speed input: 35151.10 toks/s, output: 34.33 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:34<00:30, 28.49it/s, est. speed input: 35050.50 toks/s, output: 34.23 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:34<00:30, 28.46it/s, est. speed input: 34953.52 toks/s, output: 34.13 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:35<00:29, 28.92it/s, est. speed input: 34890.72 toks/s, output: 34.07 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:35<00:28, 28.84it/s, est. speed input: 34804.21 toks/s, output: 33.99 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:36<00:27, 29.21it/s, est. speed input: 34745.93 toks/s, output: 33.93 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:36<00:27, 29.03it/s, est. speed input: 34663.52 toks/s, output: 33.85 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:37<00:27, 28.87it/s, est. speed input: 34581.93 toks/s, output: 33.77 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:38<00:26, 28.68it/s, est. speed input: 34497.80 toks/s, output: 33.69 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:38<00:26, 28.59it/s, est. speed input: 34418.46 toks/s, output: 33.61 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:39<00:25, 28.53it/s, est. speed input: 34341.25 toks/s, output: 33.54 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:39<00:24, 28.99it/s, est. speed input: 34294.42 toks/s, output: 33.49 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:40<00:24, 28.86it/s, est. speed input: 34224.48 toks/s, output: 33.42 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:40<00:23, 28.73it/s, est. speed input: 34153.92 toks/s, output: 33.35 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:41<00:23, 28.60it/s, est. speed input: 34083.44 toks/s, output: 33.28 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:41<00:22, 28.52it/s, est. speed input: 34014.88 toks/s, output: 33.22 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:42<00:22, 28.45it/s, est. speed input: 33947.77 toks/s, output: 33.15 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:43<00:21, 28.42it/s, est. speed input: 33883.74 toks/s, output: 33.09 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:43<00:21, 28.38it/s, est. speed input: 33819.71 toks/s, output: 33.03 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:44<00:20, 28.89it/s, est. speed input: 33784.43 toks/s, output: 32.99 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:44<00:19, 28.79it/s, est. speed input: 33727.73 toks/s, output: 32.94 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:45<00:19, 28.69it/s, est. speed input: 33670.60 toks/s, output: 32.88 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:45<00:18, 28.57it/s, est. speed input: 33613.03 toks/s, output: 32.83 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:46<00:18, 29.02it/s, est. speed input: 33581.14 toks/s, output: 32.79 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:46<00:17, 28.82it/s, est. speed input: 33526.67 toks/s, output: 32.74 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:47<00:16, 29.19it/s, est. speed input: 33496.45 toks/s, output: 32.71 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:48<00:16, 28.89it/s, est. speed input: 33442.06 toks/s, output: 32.66 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:48<00:16, 28.69it/s, est. speed input: 33389.49 toks/s, output: 32.61 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:49<00:15, 28.58it/s, est. speed input: 33338.89 toks/s, output: 32.56 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:49<00:14, 28.99it/s, est. speed input: 33310.94 toks/s, output: 32.53 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:50<00:14, 28.80it/s, est. speed input: 33263.03 toks/s, output: 32.48 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:50<00:13, 28.67it/s, est. speed input: 33216.38 toks/s, output: 32.44 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:51<00:13, 28.58it/s, est. speed input: 33170.72 toks/s, output: 32.39 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:51<00:12, 28.59it/s, est. speed input: 33128.94 toks/s, output: 32.35 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:52<00:12, 28.50it/s, est. speed input: 33084.24 toks/s, output: 32.31 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:53<00:11, 28.48it/s, est. speed input: 33042.23 toks/s, output: 32.27 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:53<00:11, 28.90it/s, est. speed input: 33018.32 toks/s, output: 32.24 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:54<00:10, 29.24it/s, est. speed input: 32996.58 toks/s, output: 32.22 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:54<00:09, 28.88it/s, est. speed input: 32952.12 toks/s, output: 32.18 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:55<00:09, 28.72it/s, est. speed input: 32912.12 toks/s, output: 32.14 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:55<00:08, 28.55it/s, est. speed input: 32870.94 toks/s, output: 32.10 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:56<00:08, 28.49it/s, est. speed input: 32832.35 toks/s, output: 32.06 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:57<00:07, 28.39it/s, est. speed input: 32792.60 toks/s, output: 32.02 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:57<00:07, 28.36it/s, est. speed input: 32755.21 toks/s, output: 31.99 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:58<00:06, 28.32it/s, est. speed input: 32717.39 toks/s, output: 31.95 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:58<00:06, 28.27it/s, est. speed input: 32679.86 toks/s, output: 31.91 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:59<00:05, 28.76it/s, est. speed input: 32661.91 toks/s, output: 31.90 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:59<00:04, 28.66it/s, est. speed input: 32628.49 toks/s, output: 31.86 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:00<00:04, 28.55it/s, est. speed input: 32594.46 toks/s, output: 31.83 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:00<00:03, 28.47it/s, est. speed input: 32560.79 toks/s, output: 31.80 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:01<00:03, 28.40it/s, est. speed input: 32527.30 toks/s, output: 31.76 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:02<00:02, 28.35it/s, est. speed input: 32494.11 toks/s, output: 31.73 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:02<00:02, 28.82it/s, est. speed input: 32478.69 toks/s, output: 31.72 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:03<00:01, 28.64it/s, est. speed input: 32446.82 toks/s, output: 31.69 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:03<00:01, 28.55it/s, est. speed input: 32416.41 toks/s, output: 31.66 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:04<00:00, 29.03it/s, est. speed input: 32404.27 toks/s, output: 31.64 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:04<00:00, 29.03it/s, est. speed input: 32627.10 toks/s, output: 31.86 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:04<00:00, 31.86it/s, est. speed input: 32627.10 toks/s, output: 31.86 toks/s]
[rank0]:[W125 19:56:36.352518187 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 134.7s

测试结果:
  Requests/s:   28.71
  Tokens/s:     29428.57
  Total Reqs:   2048
  Elapsed:      71.33s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     29399.86

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:57:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=388855) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=388855) WARNING 01-25 19:57:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.55 requests/s, 29262.12 total tokens/s, 28.55 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 19:57:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:57:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:57:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:57:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:57:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:57:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:57:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:57:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:57:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:57:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:57:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 19:57:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 19:57:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:57:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:57:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:57:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:57:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=388855) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=388855) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.38it/s]
(EngineCore_DP0 pid=388855) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=388855) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=388855) 
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=388855) [2026-01-25 19:57:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=388855) [rank0]:W0125 19:57:42.935000 388855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=388855) [rank0]:W0125 19:57:43.054000 388855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=388855) [rank0]:W0125 19:57:44.467000 388855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=388855) [rank0]:W0125 19:57:44.662000 388855 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=388855) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 10.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 11.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00, 11.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00, 11.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:00<00:00, 11.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:00<00:00, 11.15it/s]
(EngineCore_DP0 pid=388855) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  9.33it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 10.64it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 11.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 11.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.99it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:16, 248.70it/s]
Adding requests:   1%|▏         | 52/4096 [00:00<00:16, 251.30it/s]
Adding requests:   2%|▏         | 81/4096 [00:00<00:15, 266.27it/s]
Adding requests:   3%|▎         | 110/4096 [00:00<00:14, 272.73it/s]
Adding requests:   3%|▎         | 138/4096 [00:00<00:14, 270.12it/s]
Adding requests:   4%|▍         | 168/4096 [00:00<00:14, 278.76it/s]
Adding requests:   5%|▍         | 197/4096 [00:00<00:13, 282.12it/s]
Adding requests:   6%|▌         | 226/4096 [00:00<00:13, 284.22it/s]
Adding requests:   6%|▌         | 255/4096 [00:00<00:13, 282.29it/s]
Adding requests:   7%|▋         | 284/4096 [00:01<00:13, 283.89it/s]
Adding requests:   8%|▊         | 316/4096 [00:01<00:12, 294.79it/s]
Adding requests:   8%|▊         | 347/4096 [00:01<00:12, 296.86it/s]
Adding requests:   9%|▉         | 378/4096 [00:01<00:12, 297.55it/s]
Adding requests:  10%|█         | 411/4096 [00:01<00:12, 303.66it/s]
Adding requests:  11%|█         | 442/4096 [00:01<00:12, 298.31it/s]
Adding requests:  12%|█▏        | 472/4096 [00:01<00:12, 296.83it/s]
Adding requests:  12%|█▏        | 506/4096 [00:01<00:11, 307.49it/s]
Adding requests:  13%|█▎        | 538/4096 [00:01<00:11, 310.29it/s]
Adding requests:  14%|█▍        | 571/4096 [00:01<00:11, 313.25it/s]
Adding requests:  15%|█▍        | 603/4096 [00:02<00:11, 303.38it/s]
Adding requests:  15%|█▌        | 634/4096 [00:02<00:11, 300.21it/s]
Adding requests:  16%|█▌        | 665/4096 [00:02<00:12, 285.37it/s]
Adding requests:  17%|█▋        | 694/4096 [00:02<00:11, 286.50it/s]
Adding requests:  18%|█▊        | 723/4096 [00:02<00:11, 285.79it/s]
Adding requests:  18%|█▊        | 753/4096 [00:02<00:11, 288.92it/s]
Adding requests:  19%|█▉        | 782/4096 [00:02<00:11, 285.48it/s]
Adding requests:  20%|█▉        | 811/4096 [00:02<00:11, 278.95it/s]
Adding requests:  21%|██        | 842/4096 [00:02<00:11, 285.87it/s]
Adding requests:  21%|██▏       | 873/4096 [00:03<00:11, 291.44it/s]
Adding requests:  22%|██▏       | 904/4096 [00:03<00:10, 295.30it/s]
Adding requests:  23%|██▎       | 934/4096 [00:03<00:11, 287.29it/s]
Adding requests:  24%|██▎       | 965/4096 [00:03<00:10, 292.38it/s]
Adding requests:  24%|██▍       | 995/4096 [00:03<00:10, 287.64it/s]
Adding requests:  25%|██▌       | 1025/4096 [00:03<00:10, 290.50it/s]
Adding requests:  26%|██▌       | 1055/4096 [00:03<00:10, 280.40it/s]
Adding requests:  26%|██▋       | 1084/4096 [00:03<00:10, 278.89it/s]
Adding requests:  27%|██▋       | 1112/4096 [00:03<00:10, 276.23it/s]
Adding requests:  28%|██▊       | 1142/4096 [00:03<00:10, 282.09it/s]
Adding requests:  29%|██▊       | 1171/4096 [00:04<00:10, 279.57it/s]
Adding requests:  29%|██▉       | 1201/4096 [00:04<00:10, 285.17it/s]
Adding requests:  30%|███       | 1234/4096 [00:04<00:09, 297.71it/s]
Adding requests:  31%|███       | 1265/4096 [00:04<00:09, 298.80it/s]
Adding requests:  32%|███▏      | 1295/4096 [00:04<00:09, 295.99it/s]
Adding requests:  32%|███▏      | 1328/4096 [00:04<00:09, 303.00it/s]
Adding requests:  33%|███▎      | 1359/4096 [00:04<00:08, 304.89it/s]
Adding requests:  34%|███▍      | 1390/4096 [00:04<00:09, 296.18it/s]
Adding requests:  35%|███▍      | 1420/4096 [00:04<00:09, 283.88it/s]
Adding requests:  35%|███▌      | 1450/4096 [00:05<00:09, 285.93it/s]
Adding requests:  36%|███▌      | 1482/4096 [00:05<00:08, 294.01it/s]
Adding requests:  37%|███▋      | 1513/4096 [00:05<00:08, 298.40it/s]
Adding requests:  38%|███▊      | 1543/4096 [00:05<00:08, 295.79it/s]
Adding requests:  38%|███▊      | 1573/4096 [00:05<00:08, 285.13it/s]
Adding requests:  39%|███▉      | 1602/4096 [00:05<00:08, 281.91it/s]
Adding requests:  40%|███▉      | 1631/4096 [00:05<00:08, 277.89it/s]
Adding requests:  41%|████      | 1659/4096 [00:05<00:08, 274.27it/s]
Adding requests:  41%|████      | 1689/4096 [00:05<00:08, 281.03it/s]
Adding requests:  42%|████▏     | 1719/4096 [00:05<00:08, 285.77it/s]
Adding requests:  43%|████▎     | 1751/4096 [00:06<00:07, 293.66it/s]
Adding requests:  43%|████▎     | 1781/4096 [00:06<00:08, 286.61it/s]
Adding requests:  44%|████▍     | 1810/4096 [00:06<00:08, 280.82it/s]
Adding requests:  45%|████▍     | 1840/4096 [00:06<00:07, 284.58it/s]
Adding requests:  46%|████▌     | 1869/4096 [00:06<00:07, 285.75it/s]
Adding requests:  46%|████▋     | 1898/4096 [00:06<00:07, 284.86it/s]
Adding requests:  47%|████▋     | 1930/4096 [00:06<00:07, 294.43it/s]
Adding requests:  48%|████▊     | 1960/4096 [00:06<00:07, 295.79it/s]
Adding requests:  49%|████▊     | 1990/4096 [00:06<00:07, 291.54it/s]
Adding requests:  49%|████▉     | 2020/4096 [00:07<00:07, 277.35it/s]
Adding requests:  50%|█████     | 2051/4096 [00:07<00:07, 284.26it/s]
Adding requests:  51%|█████     | 2080/4096 [00:07<00:07, 282.52it/s]
Adding requests:  52%|█████▏    | 2113/4096 [00:07<00:06, 294.57it/s]
Adding requests:  52%|█████▏    | 2144/4096 [00:07<00:06, 297.42it/s]
Adding requests:  53%|█████▎    | 2174/4096 [00:07<00:06, 295.15it/s]
Adding requests:  54%|█████▍    | 2204/4096 [00:07<00:06, 294.96it/s]
Adding requests:  55%|█████▍    | 2235/4096 [00:07<00:06, 298.02it/s]
Adding requests:  55%|█████▌    | 2265/4096 [00:07<00:06, 296.56it/s]
Adding requests:  56%|█████▌    | 2297/4096 [00:07<00:05, 303.04it/s]
Adding requests:  57%|█████▋    | 2328/4096 [00:08<00:06, 292.37it/s]
Adding requests:  58%|█████▊    | 2360/4096 [00:08<00:05, 299.95it/s]
Adding requests:  58%|█████▊    | 2392/4096 [00:08<00:05, 304.45it/s]
Adding requests:  59%|█████▉    | 2423/4096 [00:08<00:05, 306.05it/s]
Adding requests:  60%|█████▉    | 2454/4096 [00:08<00:05, 307.19it/s]
Adding requests:  61%|██████    | 2485/4096 [00:08<00:05, 300.86it/s]
Adding requests:  61%|██████▏   | 2516/4096 [00:08<00:05, 299.19it/s]
Adding requests:  62%|██████▏   | 2547/4096 [00:08<00:05, 300.83it/s]
Adding requests:  63%|██████▎   | 2578/4096 [00:08<00:05, 303.22it/s]
Adding requests:  64%|██████▎   | 2609/4096 [00:08<00:05, 296.32it/s]
Adding requests:  64%|██████▍   | 2639/4096 [00:09<00:05, 282.59it/s]
Adding requests:  65%|██████▌   | 2670/4096 [00:09<00:04, 289.19it/s]
Adding requests:  66%|██████▌   | 2700/4096 [00:09<00:04, 291.66it/s]
Adding requests:  67%|██████▋   | 2731/4096 [00:09<00:04, 296.40it/s]
Adding requests:  68%|██████▊   | 2765/4096 [00:09<00:04, 305.61it/s]
Adding requests:  68%|██████▊   | 2798/4096 [00:09<00:04, 309.96it/s]
Adding requests:  69%|██████▉   | 2830/4096 [00:09<00:04, 311.36it/s]
Adding requests:  70%|██████▉   | 2862/4096 [00:09<00:04, 304.78it/s]
Adding requests:  71%|███████   | 2893/4096 [00:09<00:03, 300.79it/s]
Adding requests:  71%|███████▏  | 2924/4096 [00:10<00:03, 303.01it/s]
Adding requests:  72%|███████▏  | 2955/4096 [00:10<00:03, 304.18it/s]
Adding requests:  73%|███████▎  | 2986/4096 [00:10<00:03, 293.56it/s]
Adding requests:  74%|███████▎  | 3018/4096 [00:10<00:03, 298.29it/s]
Adding requests:  74%|███████▍  | 3049/4096 [00:10<00:03, 300.44it/s]
Adding requests:  75%|███████▌  | 3082/4096 [00:10<00:03, 307.80it/s]
Adding requests:  76%|███████▌  | 3115/4096 [00:10<00:03, 313.55it/s]
Adding requests:  77%|███████▋  | 3148/4096 [00:10<00:02, 317.17it/s]
Adding requests:  78%|███████▊  | 3180/4096 [00:10<00:03, 303.73it/s]
Adding requests:  78%|███████▊  | 3211/4096 [00:10<00:02, 296.23it/s]
Adding requests:  79%|███████▉  | 3241/4096 [00:11<00:02, 293.70it/s]
Adding requests:  80%|███████▉  | 3271/4096 [00:11<00:02, 288.26it/s]
Adding requests:  81%|████████  | 3300/4096 [00:11<00:02, 288.32it/s]
Adding requests:  81%|████████▏ | 3330/4096 [00:11<00:02, 289.37it/s]
Adding requests:  82%|████████▏ | 3362/4096 [00:11<00:02, 297.84it/s]
Adding requests:  83%|████████▎ | 3396/4096 [00:11<00:02, 308.37it/s]
Adding requests:  84%|████████▎ | 3427/4096 [00:11<00:02, 303.83it/s]
Adding requests:  84%|████████▍ | 3458/4096 [00:11<00:02, 298.96it/s]
Adding requests:  85%|████████▌ | 3488/4096 [00:11<00:02, 290.53it/s]
Adding requests:  86%|████████▌ | 3520/4096 [00:12<00:01, 297.34it/s]
Adding requests:  87%|████████▋ | 3551/4096 [00:12<00:01, 298.57it/s]
Adding requests:  87%|████████▋ | 3581/4096 [00:12<00:01, 295.19it/s]
Adding requests:  88%|████████▊ | 3612/4096 [00:12<00:01, 297.68it/s]
Adding requests:  89%|████████▉ | 3644/4096 [00:12<00:01, 302.80it/s]
Adding requests:  90%|████████▉ | 3675/4096 [00:12<00:01, 290.00it/s]
Adding requests:  90%|█████████ | 3705/4096 [00:12<00:01, 289.96it/s]
Adding requests:  91%|█████████ | 3736/4096 [00:12<00:01, 295.70it/s]
Adding requests:  92%|█████████▏| 3766/4096 [00:12<00:01, 289.67it/s]
Adding requests:  93%|█████████▎| 3796/4096 [00:12<00:01, 283.76it/s]
Adding requests:  93%|█████████▎| 3825/4096 [00:13<00:00, 277.78it/s]
Adding requests:  94%|█████████▍| 3854/4096 [00:13<00:00, 280.99it/s]
Adding requests:  95%|█████████▍| 3883/4096 [00:13<00:00, 281.83it/s]
Adding requests:  96%|█████████▌| 3912/4096 [00:13<00:00, 276.44it/s]
Adding requests:  96%|█████████▌| 3941/4096 [00:13<00:00, 280.07it/s]
Adding requests:  97%|█████████▋| 3971/4096 [00:13<00:00, 285.19it/s]
Adding requests:  98%|█████████▊| 4000/4096 [00:13<00:00, 284.78it/s]
Adding requests:  98%|█████████▊| 4029/4096 [00:13<00:00, 285.46it/s]
Adding requests:  99%|█████████▉| 4059/4096 [00:13<00:00, 289.56it/s]
Adding requests: 100%|█████████▉| 4088/4096 [00:13<00:00, 288.59it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 292.13it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 401/4096 [00:00<00:09, 407.21it/s, est. speed input: 416996.51 toks/s, output: 407.21 toks/s]
Processed prompts:  11%|█         | 442/4096 [00:02<00:20, 181.62it/s, est. speed input: 218998.62 toks/s, output: 213.87 toks/s]
Processed prompts:  11%|█▏        | 465/4096 [00:03<00:34, 105.45it/s, est. speed input: 149713.15 toks/s, output: 146.20 toks/s]
Processed prompts:  12%|█▏        | 497/4096 [00:04<00:48, 74.22it/s, est. speed input: 118223.52 toks/s, output: 115.45 toks/s] 
Processed prompts:  13%|█▎        | 529/4096 [00:05<01:01, 57.62it/s, est. speed input: 99961.60 toks/s, output: 97.62 toks/s]  
Processed prompts:  14%|█▎        | 561/4096 [00:06<01:14, 47.55it/s, est. speed input: 87773.92 toks/s, output: 85.72 toks/s]
Processed prompts:  14%|█▍        | 593/4096 [00:07<01:24, 41.38it/s, est. speed input: 79283.14 toks/s, output: 77.42 toks/s]
Processed prompts:  15%|█▌        | 625/4096 [00:08<01:33, 37.22it/s, est. speed input: 72856.71 toks/s, output: 71.15 toks/s]
Processed prompts:  16%|█▌        | 657/4096 [00:09<01:39, 34.49it/s, est. speed input: 67910.58 toks/s, output: 66.32 toks/s]
Processed prompts:  17%|█▋        | 689/4096 [00:11<01:44, 32.67it/s, est. speed input: 63988.68 toks/s, output: 62.49 toks/s]
Processed prompts:  18%|█▊        | 721/4096 [00:12<01:47, 31.35it/s, est. speed input: 60750.10 toks/s, output: 59.33 toks/s]
Processed prompts:  18%|█▊        | 753/4096 [00:13<01:49, 30.53it/s, est. speed input: 58104.52 toks/s, output: 56.74 toks/s]
Processed prompts:  19%|█▉        | 785/4096 [00:14<01:49, 30.19it/s, est. speed input: 55980.78 toks/s, output: 54.67 toks/s]
Processed prompts:  20%|█▉        | 817/4096 [00:15<01:50, 29.64it/s, est. speed input: 54021.80 toks/s, output: 52.76 toks/s]
Processed prompts:  21%|██        | 849/4096 [00:16<01:51, 29.25it/s, est. speed input: 52325.79 toks/s, output: 51.10 toks/s]
Processed prompts:  22%|██▏       | 881/4096 [00:17<01:50, 28.99it/s, est. speed input: 50848.63 toks/s, output: 49.66 toks/s]
Processed prompts:  22%|██▏       | 913/4096 [00:18<01:50, 28.87it/s, est. speed input: 49567.64 toks/s, output: 48.41 toks/s]
Processed prompts:  23%|██▎       | 945/4096 [00:19<01:49, 28.72it/s, est. speed input: 48410.97 toks/s, output: 47.28 toks/s]
Processed prompts:  24%|██▍       | 977/4096 [00:21<01:49, 28.61it/s, est. speed input: 47375.48 toks/s, output: 46.27 toks/s]
Processed prompts:  25%|██▍       | 1009/4096 [00:22<01:48, 28.53it/s, est. speed input: 46443.82 toks/s, output: 45.36 toks/s]
Processed prompts:  25%|██▌       | 1041/4096 [00:23<01:47, 28.46it/s, est. speed input: 45599.10 toks/s, output: 44.53 toks/s]
Processed prompts:  26%|██▌       | 1073/4096 [00:24<01:46, 28.42it/s, est. speed input: 44834.79 toks/s, output: 43.78 toks/s]
Processed prompts:  27%|██▋       | 1105/4096 [00:25<01:45, 28.39it/s, est. speed input: 44136.37 toks/s, output: 43.10 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:26<01:44, 28.36it/s, est. speed input: 43496.28 toks/s, output: 42.48 toks/s]
Processed prompts:  29%|██▊       | 1169/4096 [00:27<01:43, 28.35it/s, est. speed input: 42909.64 toks/s, output: 41.90 toks/s]
Processed prompts:  29%|██▉       | 1201/4096 [00:28<01:41, 28.63it/s, est. speed input: 42423.59 toks/s, output: 41.43 toks/s]
Processed prompts:  30%|███       | 1233/4096 [00:30<01:39, 28.80it/s, est. speed input: 41968.06 toks/s, output: 40.98 toks/s]
Processed prompts:  31%|███       | 1265/4096 [00:31<01:38, 28.69it/s, est. speed input: 41504.66 toks/s, output: 40.53 toks/s]
Processed prompts:  32%|███▏      | 1297/4096 [00:32<01:37, 28.58it/s, est. speed input: 41067.61 toks/s, output: 40.11 toks/s]
Processed prompts:  32%|███▏      | 1329/4096 [00:33<01:36, 28.77it/s, est. speed input: 40703.50 toks/s, output: 39.75 toks/s]
Processed prompts:  33%|███▎      | 1361/4096 [00:34<01:35, 28.61it/s, est. speed input: 40317.51 toks/s, output: 39.37 toks/s]
Processed prompts:  34%|███▍      | 1393/4096 [00:35<01:34, 28.50it/s, est. speed input: 39954.93 toks/s, output: 39.02 toks/s]
Processed prompts:  35%|███▍      | 1425/4096 [00:36<01:33, 28.42it/s, est. speed input: 39615.59 toks/s, output: 38.69 toks/s]
Processed prompts:  36%|███▌      | 1457/4096 [00:37<01:32, 28.65it/s, est. speed input: 39335.59 toks/s, output: 38.41 toks/s]
Processed prompts:  36%|███▋      | 1489/4096 [00:39<01:31, 28.56it/s, est. speed input: 39037.47 toks/s, output: 38.12 toks/s]
Processed prompts:  37%|███▋      | 1521/4096 [00:40<01:29, 28.75it/s, est. speed input: 38788.28 toks/s, output: 37.88 toks/s]
Processed prompts:  38%|███▊      | 1553/4096 [00:41<01:27, 28.91it/s, est. speed input: 38554.77 toks/s, output: 37.65 toks/s]
Processed prompts:  39%|███▊      | 1585/4096 [00:42<01:27, 28.75it/s, est. speed input: 38303.01 toks/s, output: 37.41 toks/s]
Processed prompts:  39%|███▉      | 1617/4096 [00:43<01:25, 28.88it/s, est. speed input: 38090.11 toks/s, output: 37.20 toks/s]
Processed prompts:  40%|████      | 1649/4096 [00:44<01:25, 28.74it/s, est. speed input: 37863.33 toks/s, output: 36.98 toks/s]
Processed prompts:  41%|████      | 1681/4096 [00:45<01:24, 28.62it/s, est. speed input: 37644.64 toks/s, output: 36.76 toks/s]
Processed prompts:  42%|████▏     | 1713/4096 [00:46<01:22, 28.77it/s, est. speed input: 37461.52 toks/s, output: 36.58 toks/s]
Processed prompts:  43%|████▎     | 1745/4096 [00:47<01:21, 28.88it/s, est. speed input: 37287.21 toks/s, output: 36.41 toks/s]
Processed prompts:  43%|████▎     | 1777/4096 [00:49<01:20, 28.67it/s, est. speed input: 37092.20 toks/s, output: 36.22 toks/s]
Processed prompts:  44%|████▍     | 1809/4096 [00:50<01:20, 28.58it/s, est. speed input: 36911.33 toks/s, output: 36.05 toks/s]
Processed prompts:  45%|████▍     | 1841/4096 [00:51<01:19, 28.49it/s, est. speed input: 36736.09 toks/s, output: 35.88 toks/s]
Processed prompts:  46%|████▌     | 1873/4096 [00:52<01:17, 28.66it/s, est. speed input: 36589.43 toks/s, output: 35.73 toks/s]
Processed prompts:  47%|████▋     | 1905/4096 [00:53<01:16, 28.51it/s, est. speed input: 36425.00 toks/s, output: 35.57 toks/s]
Processed prompts:  47%|████▋     | 1937/4096 [00:54<01:15, 28.44it/s, est. speed input: 36270.56 toks/s, output: 35.42 toks/s]
Processed prompts:  48%|████▊     | 1969/4096 [00:55<01:14, 28.63it/s, est. speed input: 36142.19 toks/s, output: 35.30 toks/s]
Processed prompts:  49%|████▉     | 2001/4096 [00:56<01:13, 28.58it/s, est. speed input: 36003.90 toks/s, output: 35.16 toks/s]
Processed prompts:  50%|████▉     | 2033/4096 [00:58<01:12, 28.51it/s, est. speed input: 35868.27 toks/s, output: 35.03 toks/s]
Processed prompts:  50%|█████     | 2065/4096 [00:59<01:10, 28.66it/s, est. speed input: 35754.00 toks/s, output: 34.92 toks/s]
Processed prompts:  51%|█████     | 2097/4096 [01:00<01:10, 28.49it/s, est. speed input: 35621.93 toks/s, output: 34.79 toks/s]
Processed prompts:  52%|█████▏    | 2129/4096 [01:01<01:09, 28.43it/s, est. speed input: 35499.04 toks/s, output: 34.67 toks/s]
Processed prompts:  53%|█████▎    | 2161/4096 [01:02<01:08, 28.39it/s, est. speed input: 35381.25 toks/s, output: 34.55 toks/s]
Processed prompts:  54%|█████▎    | 2193/4096 [01:03<01:06, 28.58it/s, est. speed input: 35283.13 toks/s, output: 34.46 toks/s]
Processed prompts:  54%|█████▍    | 2225/4096 [01:04<01:05, 28.42it/s, est. speed input: 35167.91 toks/s, output: 34.34 toks/s]
Processed prompts:  55%|█████▌    | 2257/4096 [01:05<01:04, 28.37it/s, est. speed input: 35061.10 toks/s, output: 34.24 toks/s]
Processed prompts:  56%|█████▌    | 2289/4096 [01:07<01:03, 28.35it/s, est. speed input: 34958.32 toks/s, output: 34.14 toks/s]
Processed prompts:  57%|█████▋    | 2321/4096 [01:08<01:02, 28.33it/s, est. speed input: 34858.88 toks/s, output: 34.04 toks/s]
Processed prompts:  57%|█████▋    | 2353/4096 [01:09<01:01, 28.32it/s, est. speed input: 34762.90 toks/s, output: 33.95 toks/s]
Processed prompts:  58%|█████▊    | 2385/4096 [01:10<01:00, 28.31it/s, est. speed input: 34669.80 toks/s, output: 33.86 toks/s]
Processed prompts:  59%|█████▉    | 2417/4096 [01:11<00:59, 28.30it/s, est. speed input: 34579.59 toks/s, output: 33.77 toks/s]
Processed prompts:  60%|█████▉    | 2449/4096 [01:12<00:58, 28.31it/s, est. speed input: 34493.07 toks/s, output: 33.68 toks/s]
Processed prompts:  61%|██████    | 2481/4096 [01:13<00:57, 28.31it/s, est. speed input: 34409.00 toks/s, output: 33.60 toks/s]
Processed prompts:  61%|██████▏   | 2513/4096 [01:14<00:55, 28.32it/s, est. speed input: 34327.53 toks/s, output: 33.52 toks/s]
Processed prompts:  62%|██████▏   | 2545/4096 [01:16<00:54, 28.51it/s, est. speed input: 34260.09 toks/s, output: 33.46 toks/s]
Processed prompts:  63%|██████▎   | 2577/4096 [01:17<00:53, 28.64it/s, est. speed input: 34193.73 toks/s, output: 33.39 toks/s]
Processed prompts:  64%|██████▎   | 2609/4096 [01:18<00:52, 28.48it/s, est. speed input: 34114.97 toks/s, output: 33.32 toks/s]
Processed prompts:  64%|██████▍   | 2641/4096 [01:19<00:51, 28.43it/s, est. speed input: 34042.06 toks/s, output: 33.24 toks/s]
Processed prompts:  65%|██████▌   | 2673/4096 [01:20<00:50, 28.39it/s, est. speed input: 33971.31 toks/s, output: 33.18 toks/s]
Processed prompts:  66%|██████▌   | 2705/4096 [01:21<00:49, 28.38it/s, est. speed input: 33902.78 toks/s, output: 33.11 toks/s]
Processed prompts:  67%|██████▋   | 2737/4096 [01:22<00:47, 28.54it/s, est. speed input: 33845.39 toks/s, output: 33.05 toks/s]
Processed prompts:  68%|██████▊   | 2769/4096 [01:23<00:46, 28.46it/s, est. speed input: 33779.53 toks/s, output: 32.99 toks/s]
Processed prompts:  68%|██████▊   | 2801/4096 [01:25<00:45, 28.40it/s, est. speed input: 33715.38 toks/s, output: 32.93 toks/s]
Processed prompts:  69%|██████▉   | 2833/4096 [01:26<00:44, 28.38it/s, est. speed input: 33653.46 toks/s, output: 32.86 toks/s]
Processed prompts:  70%|██████▉   | 2865/4096 [01:27<00:43, 28.35it/s, est. speed input: 33592.63 toks/s, output: 32.81 toks/s]
Processed prompts:  71%|███████   | 2897/4096 [01:28<00:41, 29.08it/s, est. speed input: 33570.11 toks/s, output: 32.78 toks/s]
Processed prompts:  72%|███████▏  | 2929/4096 [01:29<00:40, 28.85it/s, est. speed input: 33512.64 toks/s, output: 32.73 toks/s]
Processed prompts:  72%|███████▏  | 2961/4096 [01:30<00:39, 28.68it/s, est. speed input: 33455.82 toks/s, output: 32.67 toks/s]
Processed prompts:  73%|███████▎  | 2993/4096 [01:31<00:38, 28.56it/s, est. speed input: 33400.54 toks/s, output: 32.62 toks/s]
Processed prompts:  74%|███████▍  | 3025/4096 [01:32<00:37, 28.49it/s, est. speed input: 33346.94 toks/s, output: 32.57 toks/s]
Processed prompts:  75%|███████▍  | 3057/4096 [01:34<00:36, 28.44it/s, est. speed input: 33294.86 toks/s, output: 32.51 toks/s]
Processed prompts:  75%|███████▌  | 3089/4096 [01:35<00:35, 28.41it/s, est. speed input: 33243.92 toks/s, output: 32.46 toks/s]
Processed prompts:  76%|███████▌  | 3121/4096 [01:36<00:34, 28.39it/s, est. speed input: 33194.68 toks/s, output: 32.42 toks/s]
Processed prompts:  77%|███████▋  | 3153/4096 [01:37<00:33, 28.37it/s, est. speed input: 33145.89 toks/s, output: 32.37 toks/s]
Processed prompts:  78%|███████▊  | 3185/4096 [01:38<00:32, 28.35it/s, est. speed input: 33098.24 toks/s, output: 32.32 toks/s]
Processed prompts:  79%|███████▊  | 3217/4096 [01:39<00:31, 28.33it/s, est. speed input: 33051.31 toks/s, output: 32.28 toks/s]
Processed prompts:  79%|███████▉  | 3249/4096 [01:40<00:29, 28.33it/s, est. speed input: 33005.85 toks/s, output: 32.23 toks/s]
Processed prompts:  80%|████████  | 3281/4096 [01:41<00:28, 28.31it/s, est. speed input: 32960.99 toks/s, output: 32.19 toks/s]
Processed prompts:  81%|████████  | 3313/4096 [01:43<00:27, 28.31it/s, est. speed input: 32917.14 toks/s, output: 32.15 toks/s]
Processed prompts:  82%|████████▏ | 3345/4096 [01:44<00:26, 28.29it/s, est. speed input: 32873.99 toks/s, output: 32.10 toks/s]
Processed prompts:  82%|████████▏ | 3377/4096 [01:45<00:25, 28.30it/s, est. speed input: 32832.24 toks/s, output: 32.06 toks/s]
Processed prompts:  83%|████████▎ | 3409/4096 [01:46<00:24, 28.29it/s, est. speed input: 32790.91 toks/s, output: 32.02 toks/s]
Processed prompts:  84%|████████▍ | 3441/4096 [01:47<00:23, 28.27it/s, est. speed input: 32750.03 toks/s, output: 31.98 toks/s]
Processed prompts:  85%|████████▍ | 3473/4096 [01:48<00:22, 28.27it/s, est. speed input: 32710.38 toks/s, output: 31.94 toks/s]
Processed prompts:  86%|████████▌ | 3505/4096 [01:49<00:20, 28.28it/s, est. speed input: 32672.08 toks/s, output: 31.91 toks/s]
Processed prompts:  86%|████████▋ | 3537/4096 [01:50<00:19, 28.50it/s, est. speed input: 32642.76 toks/s, output: 31.88 toks/s]
Processed prompts:  87%|████████▋ | 3569/4096 [01:52<00:18, 28.38it/s, est. speed input: 32603.51 toks/s, output: 31.84 toks/s]
Processed prompts:  88%|████████▊ | 3601/4096 [01:53<00:17, 28.37it/s, est. speed input: 32567.82 toks/s, output: 31.80 toks/s]
Processed prompts:  89%|████████▊ | 3633/4096 [01:54<00:16, 28.35it/s, est. speed input: 32532.38 toks/s, output: 31.77 toks/s]
Processed prompts:  89%|████████▉ | 3665/4096 [01:55<00:15, 28.54it/s, est. speed input: 32505.32 toks/s, output: 31.74 toks/s]
Processed prompts:  90%|█████████ | 3697/4096 [01:56<00:14, 28.44it/s, est. speed input: 32469.94 toks/s, output: 31.71 toks/s]
Processed prompts:  91%|█████████ | 3729/4096 [01:57<00:12, 28.40it/s, est. speed input: 32436.70 toks/s, output: 31.68 toks/s]
Processed prompts:  92%|█████████▏| 3761/4096 [01:58<00:11, 28.38it/s, est. speed input: 32404.14 toks/s, output: 31.64 toks/s]
Processed prompts:  93%|█████████▎| 3793/4096 [01:59<00:10, 28.36it/s, est. speed input: 32372.05 toks/s, output: 31.61 toks/s]
Processed prompts:  93%|█████████▎| 3825/4096 [02:01<00:09, 28.34it/s, est. speed input: 32340.26 toks/s, output: 31.58 toks/s]
Processed prompts:  94%|█████████▍| 3857/4096 [02:02<00:08, 28.33it/s, est. speed input: 32309.11 toks/s, output: 31.55 toks/s]
Processed prompts:  95%|█████████▍| 3889/4096 [02:03<00:07, 28.32it/s, est. speed input: 32278.62 toks/s, output: 31.52 toks/s]
Processed prompts:  96%|█████████▌| 3921/4096 [02:04<00:06, 28.80it/s, est. speed input: 32265.15 toks/s, output: 31.51 toks/s]
Processed prompts:  97%|█████████▋| 3953/4096 [02:05<00:04, 28.64it/s, est. speed input: 32235.31 toks/s, output: 31.48 toks/s]
Processed prompts:  97%|█████████▋| 3985/4096 [02:06<00:03, 28.73it/s, est. speed input: 32212.54 toks/s, output: 31.46 toks/s]
Processed prompts:  98%|█████████▊| 4017/4096 [02:07<00:02, 28.56it/s, est. speed input: 32182.69 toks/s, output: 31.43 toks/s]
Processed prompts:  99%|█████████▉| 4049/4096 [02:08<00:01, 28.70it/s, est. speed input: 32161.74 toks/s, output: 31.41 toks/s]
Processed prompts: 100%|█████████▉| 4081/4096 [02:09<00:00, 34.01it/s, est. speed input: 32282.02 toks/s, output: 31.53 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:09<00:00, 34.01it/s, est. speed input: 32400.58 toks/s, output: 31.64 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:09<00:00, 31.64it/s, est. speed input: 32400.58 toks/s, output: 31.64 toks/s]
[rank0]:[W125 20:00:19.854285200 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 222.5s

测试结果:
  Requests/s:   28.55
  Tokens/s:     29262.12
  Total Reqs:   4096
  Elapsed:      143.48s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     29233.57

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:01:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=392609) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=392609) WARNING 01-25 20:01:52 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     def forward(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     raise e
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/tmp/torchinductor_root/ho/chodei5cy5pcgbjjv7twirsgbagsxcmbr4o64xswdqxkoqqbodju.py", line 1093, in call
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) ERROR 01-25 20:02:04 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-25 20:01:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:01:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:01:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:01:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:01:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:01:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:01:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:01:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:01:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:01:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:01:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:01:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:01:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=392609) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=392609) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.35it/s]
(EngineCore_DP0 pid=392609) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=392609) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.38it/s]
(EngineCore_DP0 pid=392609) 
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=392609) [2026-01-25 20:01:43] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=392609) [rank0]:W0125 20:02:01.553000 392609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=392609) [rank0]:W0125 20:02:01.669000 392609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=392609) [rank0]:W0125 20:02:03.054000 392609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=392609) [rank0]:W0125 20:02:03.247000 392609 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=392609) Process EngineCore_DP0:
(EngineCore_DP0 pid=392609) Traceback (most recent call last):
(EngineCore_DP0 pid=392609)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=392609)     self.run()
(EngineCore_DP0 pid=392609)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=392609)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=392609)     raise e
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=392609)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=392609)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=392609)     super().__init__(
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=392609)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=392609)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=392609)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=392609)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=392609)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=392609)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=392609)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=392609)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392609)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=392609)     self.model_runner.profile_run()
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=392609)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=392609)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=392609)     return func(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=392609)     outputs = self.model(
(EngineCore_DP0 pid=392609)               ^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=392609)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392609)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392609)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=392609)     hidden_states = self.model(
(EngineCore_DP0 pid=392609)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=392609)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=392609)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=392609)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=392609)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=392609)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=392609)     def forward(
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=392609)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=392609)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=392609)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=392609)     raise e
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=392609)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=392609)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=392609)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=392609)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=392609)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=392609)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=392609)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=392609)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=392609)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=392609)     return compiled_fn(full_args)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=392609)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=392609)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=392609)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=392609)                             ^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=392609)     outs = compiled_fn(args)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=392609)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=392609)     return self.current_callable(inputs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=392609)     out = model(new_inputs)
(EngineCore_DP0 pid=392609)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/tmp/torchinductor_root/ho/chodei5cy5pcgbjjv7twirsgbagsxcmbr4o64xswdqxkoqqbodju.py", line 1093, in call
(EngineCore_DP0 pid=392609)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=392609)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=392609)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=392609)     return fn(input, L)
(EngineCore_DP0 pid=392609)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=392609)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=392609)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=392609)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=392609)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=392609)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=392609)     self._init_handles()
(EngineCore_DP0 pid=392609)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=392609)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=392609)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=392609) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W125 20:02:04.247787760 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,21.7583,11162.0216,5.8828
1024,1024,1,128,128,22.0300,22580.7114,5.8103
2048,1024,2,256,128,25.8282,26473.9345,9.9116
4096,1024,4,512,128,27.5249,28213.0583,18.6013
8192,1024,8,1024,128,28.3714,29080.6436,36.0927
16384,1024,16,2048,128,28.7108,29428.5713,71.3320
32768,1024,32,4096,128,28.5484,29262.1155,143.4756
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:02:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=393437) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=393437) WARNING 01-25 20:11:57 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.12 requests/s, 11348.92 total tokens/s, 22.12 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:02:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:02:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:02:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:02:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:02:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:02:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:02:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:02:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:02:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:02:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:02:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:02:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:02:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:02:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:02:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:02:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:02:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=393437) [2026-01-25 20:02:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=393437) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=393437) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [05:36<05:36, 336.38s/it]
(EngineCore_DP0 pid=393437) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [09:24<00:00, 272.84s/it]
(EngineCore_DP0 pid=393437) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [09:24<00:00, 282.37s/it]
(EngineCore_DP0 pid=393437) 
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=393437) [2026-01-25 20:11:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=393437) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.43it/s]
(EngineCore_DP0 pid=393437) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.25it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  37%|███▋      | 47/128 [00:00<00:00, 464.44it/s]
Adding requests:  74%|███████▍  | 95/128 [00:00<00:00, 469.31it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 470.06it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:17,  7.22it/s, est. speed input: 3696.68 toks/s, output: 7.22 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:07, 15.84it/s, est. speed input: 7445.47 toks/s, output: 14.54 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 19.40it/s, est. speed input: 8966.33 toks/s, output: 17.51 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 20.75it/s, est. speed input: 9638.19 toks/s, output: 18.82 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 21.65it/s, est. speed input: 10083.73 toks/s, output: 19.69 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 22.24it/s, est. speed input: 10393.67 toks/s, output: 20.30 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 22.82it/s, est. speed input: 10656.50 toks/s, output: 20.81 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 23.34it/s, est. speed input: 10879.28 toks/s, output: 21.25 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 23.52it/s, est. speed input: 11027.43 toks/s, output: 21.54 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 23.47it/s, est. speed input: 11120.25 toks/s, output: 21.72 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.64it/s, est. speed input: 11224.74 toks/s, output: 21.92 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:03, 23.88it/s, est. speed input: 11328.31 toks/s, output: 22.13 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 24.03it/s, est. speed input: 11413.42 toks/s, output: 22.29 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 23.96it/s, est. speed input: 11468.21 toks/s, output: 22.40 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 24.11it/s, est. speed input: 11535.79 toks/s, output: 22.53 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 24.08it/s, est. speed input: 11582.52 toks/s, output: 22.62 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 23.67it/s, est. speed input: 11586.71 toks/s, output: 22.63 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 23.30it/s, est. speed input: 11582.91 toks/s, output: 22.62 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 23.53it/s, est. speed input: 11621.15 toks/s, output: 22.70 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:02, 23.80it/s, est. speed input: 11664.78 toks/s, output: 22.78 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 23.88it/s, est. speed input: 11695.29 toks/s, output: 22.84 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 23.58it/s, est. speed input: 11696.76 toks/s, output: 22.85 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:02<00:02, 23.82it/s, est. speed input: 11730.55 toks/s, output: 22.91 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 23.94it/s, est. speed input: 11757.38 toks/s, output: 22.96 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 23.79it/s, est. speed input: 11767.51 toks/s, output: 22.98 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.22it/s, est. speed input: 11746.64 toks/s, output: 22.94 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.30it/s, est. speed input: 11756.97 toks/s, output: 22.96 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:01, 23.09it/s, est. speed input: 11750.25 toks/s, output: 22.95 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 22.81it/s, est. speed input: 11736.30 toks/s, output: 22.92 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 22.79it/s, est. speed input: 11733.13 toks/s, output: 22.92 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:03<00:01, 23.33it/s, est. speed input: 11760.81 toks/s, output: 22.97 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.67it/s, est. speed input: 11784.51 toks/s, output: 23.02 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.55it/s, est. speed input: 11788.36 toks/s, output: 23.02 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.73it/s, est. speed input: 11805.32 toks/s, output: 23.06 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 23.52it/s, est. speed input: 11805.09 toks/s, output: 23.06 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 23.27it/s, est. speed input: 11800.03 toks/s, output: 23.05 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 23.56it/s, est. speed input: 11816.43 toks/s, output: 23.08 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 23.79it/s, est. speed input: 11832.85 toks/s, output: 23.11 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:04<00:00, 23.84it/s, est. speed input: 11843.79 toks/s, output: 23.13 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 24.01it/s, est. speed input: 11859.78 toks/s, output: 23.16 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 23.76it/s, est. speed input: 11860.18 toks/s, output: 23.16 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.89it/s, est. speed input: 11872.23 toks/s, output: 23.19 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.99it/s, est. speed input: 11884.22 toks/s, output: 23.21 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.99it/s, est. speed input: 11889.13 toks/s, output: 23.22 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.22it/s, est. speed input: 11889.13 toks/s, output: 23.22 toks/s]
[rank0]:[W125 20:12:20.317901297 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 615.3s

测试结果:
  Requests/s:   22.12
  Tokens/s:     11348.92
  Total Reqs:   128
  Elapsed:      5.79s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     11326.80

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:12:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=402202) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=402202) WARNING 01-25 20:12:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.71 requests/s, 21230.35 total tokens/s, 20.71 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:12:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:12:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:12:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:12:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:12:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:12:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:12:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:12:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:12:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:12:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:12:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:12:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:12:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:12:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:12:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:12:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:12:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=402202) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=402202) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=402202) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
(EngineCore_DP0 pid=402202) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.30it/s]
(EngineCore_DP0 pid=402202) 
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=402202) [2026-01-25 20:12:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=402202) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.64it/s]
(EngineCore_DP0 pid=402202) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.63it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.62it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 237.75it/s]
Adding requests:  38%|███▊      | 49/128 [00:00<00:00, 243.03it/s]
Adding requests:  59%|█████▉    | 76/128 [00:00<00:00, 250.24it/s]
Adding requests:  80%|████████  | 103/128 [00:00<00:00, 255.43it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 255.43it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 63.84it/s, est. speed input: 65388.21 toks/s, output: 63.84 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:03, 30.80it/s, est. speed input: 34385.71 toks/s, output: 33.58 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 27.22it/s, est. speed input: 30815.83 toks/s, output: 30.09 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:04, 25.28it/s, est. speed input: 28901.42 toks/s, output: 28.22 toks/s]
Processed prompts:  20%|██        | 26/128 [00:00<00:04, 24.25it/s, est. speed input: 27911.26 toks/s, output: 27.26 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:04, 23.51it/s, est. speed input: 27185.09 toks/s, output: 26.55 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:04, 22.98it/s, est. speed input: 26622.16 toks/s, output: 26.00 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:04, 22.51it/s, est. speed input: 26139.54 toks/s, output: 25.53 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:04, 22.25it/s, est. speed input: 25770.71 toks/s, output: 25.17 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:03, 22.06it/s, est. speed input: 25464.35 toks/s, output: 24.87 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:03, 21.85it/s, est. speed input: 25183.84 toks/s, output: 24.59 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:01<00:03, 21.77it/s, est. speed input: 24961.54 toks/s, output: 24.38 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:03, 21.74it/s, est. speed input: 24774.24 toks/s, output: 24.19 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:03, 21.73it/s, est. speed input: 24614.82 toks/s, output: 24.04 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:03, 21.75it/s, est. speed input: 24479.35 toks/s, output: 23.91 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:02<00:03, 21.74it/s, est. speed input: 24355.26 toks/s, output: 23.78 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:02<00:03, 21.74it/s, est. speed input: 24244.44 toks/s, output: 23.68 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:02, 21.70it/s, est. speed input: 24138.22 toks/s, output: 23.57 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:02<00:02, 21.68it/s, est. speed input: 24043.79 toks/s, output: 23.48 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:02, 21.68it/s, est. speed input: 23958.71 toks/s, output: 23.40 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:02, 21.63it/s, est. speed input: 23874.59 toks/s, output: 23.31 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:02, 21.53it/s, est. speed input: 23787.31 toks/s, output: 23.23 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:03<00:02, 21.56it/s, est. speed input: 23721.50 toks/s, output: 23.17 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:02, 21.48it/s, est. speed input: 23646.15 toks/s, output: 23.09 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:03<00:01, 21.43it/s, est. speed input: 23577.88 toks/s, output: 23.03 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:03<00:01, 21.43it/s, est. speed input: 23519.25 toks/s, output: 22.97 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:01, 21.50it/s, est. speed input: 23472.48 toks/s, output: 22.92 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:01, 21.57it/s, est. speed input: 23431.99 toks/s, output: 22.88 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:04<00:01, 21.62it/s, est. speed input: 23394.20 toks/s, output: 22.85 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 21.54it/s, est. speed input: 23346.21 toks/s, output: 22.80 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:04<00:01, 21.48it/s, est. speed input: 23300.19 toks/s, output: 22.75 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:04<00:00, 21.56it/s, est. speed input: 23270.17 toks/s, output: 22.72 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:04<00:00, 21.60it/s, est. speed input: 23240.05 toks/s, output: 22.70 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:04<00:00, 21.63it/s, est. speed input: 23211.33 toks/s, output: 22.67 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:05<00:00, 21.63it/s, est. speed input: 23182.89 toks/s, output: 22.64 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 21.62it/s, est. speed input: 23154.67 toks/s, output: 22.61 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 21.65it/s, est. speed input: 23131.51 toks/s, output: 22.59 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:05<00:00, 21.63it/s, est. speed input: 23105.94 toks/s, output: 22.56 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.69it/s, est. speed input: 23087.02 toks/s, output: 22.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.69it/s, est. speed input: 23087.02 toks/s, output: 22.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.54it/s, est. speed input: 23087.02 toks/s, output: 22.55 toks/s]
[rank0]:[W125 20:13:14.546207423 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 53.3s

测试结果:
  Requests/s:   20.71
  Tokens/s:     21230.35
  Total Reqs:   128
  Elapsed:      6.18s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     21209.64

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:13:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=403198) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=403198) WARNING 01-25 20:13:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.43 requests/s, 25038.76 total tokens/s, 24.43 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 20:13:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:13:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:13:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:13:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:13:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:13:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:13:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:13:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:13:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:13:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:13:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:13:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:13:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:13:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:13:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:13:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:13:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.32it/s]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=403198) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=403198) 
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=403198) [2026-01-25 20:13:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=403198) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  9.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.10it/s]
(EngineCore_DP0 pid=403198) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 11.07it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 28/256 [00:00<00:00, 274.10it/s]
Adding requests:  22%|██▏       | 57/256 [00:00<00:00, 277.01it/s]
Adding requests:  34%|███▍      | 87/256 [00:00<00:00, 286.43it/s]
Adding requests:  45%|████▌     | 116/256 [00:00<00:00, 285.75it/s]
Adding requests:  57%|█████▋    | 145/256 [00:00<00:00, 280.24it/s]
Adding requests:  68%|██████▊   | 175/256 [00:00<00:00, 284.68it/s]
Adding requests:  80%|████████  | 206/256 [00:00<00:00, 292.22it/s]
Adding requests:  93%|█████████▎| 237/256 [00:00<00:00, 295.71it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 288.77it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 150.04it/s, est. speed input: 153653.95 toks/s, output: 150.04 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:00<00:05, 42.81it/s, est. speed input: 50312.52 toks/s, output: 49.13 toks/s]   
Processed prompts:  19%|█▉        | 48/256 [00:01<00:05, 35.89it/s, est. speed input: 43100.43 toks/s, output: 42.09 toks/s]
Processed prompts:  21%|██        | 54/256 [00:01<00:06, 32.61it/s, est. speed input: 39921.41 toks/s, output: 38.99 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:01<00:06, 32.22it/s, est. speed input: 39037.72 toks/s, output: 38.12 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:01<00:06, 30.39it/s, est. speed input: 37704.83 toks/s, output: 36.82 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:01<00:06, 28.89it/s, est. speed input: 36595.46 toks/s, output: 35.74 toks/s]
Processed prompts:  28%|██▊       | 71/256 [00:02<00:06, 27.71it/s, est. speed input: 35667.12 toks/s, output: 34.83 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:02<00:07, 25.13it/s, est. speed input: 34410.95 toks/s, output: 33.60 toks/s]
Processed prompts:  30%|███       | 78/256 [00:02<00:07, 24.91it/s, est. speed input: 33751.43 toks/s, output: 32.96 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:02<00:07, 24.75it/s, est. speed input: 33180.63 toks/s, output: 32.40 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:02<00:06, 24.68it/s, est. speed input: 32689.56 toks/s, output: 31.92 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:06, 24.68it/s, est. speed input: 32270.13 toks/s, output: 31.51 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:03<00:06, 24.64it/s, est. speed input: 31884.38 toks/s, output: 31.14 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:06, 24.64it/s, est. speed input: 31544.57 toks/s, output: 30.81 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:03<00:06, 24.57it/s, est. speed input: 31223.35 toks/s, output: 30.49 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:03<00:06, 24.51it/s, est. speed input: 30929.76 toks/s, output: 30.20 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:03<00:05, 24.50it/s, est. speed input: 30668.21 toks/s, output: 29.95 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:03<00:05, 24.48it/s, est. speed input: 30428.65 toks/s, output: 29.72 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:04<00:05, 24.44it/s, est. speed input: 30201.84 toks/s, output: 29.49 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:04<00:05, 24.43it/s, est. speed input: 29996.72 toks/s, output: 29.29 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:04<00:05, 24.39it/s, est. speed input: 29803.19 toks/s, output: 29.10 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:04<00:05, 24.40it/s, est. speed input: 29628.06 toks/s, output: 28.93 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:04<00:04, 24.42it/s, est. speed input: 29467.00 toks/s, output: 28.78 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:04<00:04, 24.45it/s, est. speed input: 29319.41 toks/s, output: 28.63 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:04<00:04, 24.47it/s, est. speed input: 29181.03 toks/s, output: 28.50 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:05<00:04, 24.47it/s, est. speed input: 29050.55 toks/s, output: 28.37 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:05<00:04, 24.44it/s, est. speed input: 28924.08 toks/s, output: 28.25 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:05<00:04, 24.42it/s, est. speed input: 28805.50 toks/s, output: 28.13 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:05<00:04, 24.38it/s, est. speed input: 28690.25 toks/s, output: 28.02 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:05<00:03, 24.40it/s, est. speed input: 28586.89 toks/s, output: 27.92 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:05<00:03, 24.36it/s, est. speed input: 28483.91 toks/s, output: 27.82 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:06<00:03, 24.41it/s, est. speed input: 28394.10 toks/s, output: 27.73 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:06<00:03, 24.53it/s, est. speed input: 28317.32 toks/s, output: 27.65 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:06<00:03, 24.51it/s, est. speed input: 28234.99 toks/s, output: 27.57 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:06<00:03, 24.51it/s, est. speed input: 28157.42 toks/s, output: 27.50 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:06<00:02, 24.42it/s, est. speed input: 28075.89 toks/s, output: 27.42 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:06<00:02, 24.38it/s, est. speed input: 27999.88 toks/s, output: 27.34 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:07<00:02, 24.35it/s, est. speed input: 27927.49 toks/s, output: 27.27 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:07<00:02, 24.40it/s, est. speed input: 27863.59 toks/s, output: 27.21 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:07<00:02, 25.80it/s, est. speed input: 27911.32 toks/s, output: 27.26 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:07<00:01, 25.41it/s, est. speed input: 27851.61 toks/s, output: 27.20 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:07<00:01, 25.06it/s, est. speed input: 27788.29 toks/s, output: 27.14 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:07<00:01, 24.83it/s, est. speed input: 27727.72 toks/s, output: 27.08 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:08<00:01, 24.69it/s, est. speed input: 27671.60 toks/s, output: 27.02 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:08<00:01, 24.60it/s, est. speed input: 27618.05 toks/s, output: 26.97 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:08<00:01, 24.56it/s, est. speed input: 27568.26 toks/s, output: 26.92 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:08<00:01, 24.54it/s, est. speed input: 27520.22 toks/s, output: 26.88 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:08<00:00, 24.45it/s, est. speed input: 27469.26 toks/s, output: 26.83 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:08<00:00, 24.38it/s, est. speed input: 27420.06 toks/s, output: 26.78 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:09<00:00, 24.34it/s, est. speed input: 27372.84 toks/s, output: 26.73 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:09<00:00, 24.33it/s, est. speed input: 27328.64 toks/s, output: 26.69 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:09<00:00, 24.36it/s, est. speed input: 27288.22 toks/s, output: 26.65 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:09<00:00, 24.42it/s, est. speed input: 27251.62 toks/s, output: 26.61 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 24.42it/s, est. speed input: 27329.81 toks/s, output: 26.69 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 26.69it/s, est. speed input: 27329.81 toks/s, output: 26.69 toks/s]
[rank0]:[W125 20:14:12.229756415 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 58.7s

测试结果:
  Requests/s:   24.43
  Tokens/s:     25038.76
  Total Reqs:   256
  Elapsed:      10.48s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     25014.33

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:14:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=404280) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=404280) WARNING 01-25 20:14:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.02 requests/s, 26666.60 total tokens/s, 26.02 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 20:14:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:14:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:14:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:14:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:14:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:14:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:14:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:14:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:14:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=404280) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=404280) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.32it/s]
(EngineCore_DP0 pid=404280) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.35it/s]
(EngineCore_DP0 pid=404280) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
(EngineCore_DP0 pid=404280) 
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=404280) [2026-01-25 20:14:36] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=404280) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 11.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.78it/s]
(EngineCore_DP0 pid=404280) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 10.81it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 25/512 [00:00<00:01, 248.08it/s]
Adding requests:  10%|█         | 53/512 [00:00<00:01, 264.92it/s]
Adding requests:  16%|█▌        | 83/512 [00:00<00:01, 279.18it/s]
Adding requests:  22%|██▏       | 111/512 [00:00<00:01, 278.98it/s]
Adding requests:  27%|██▋       | 139/512 [00:00<00:01, 271.37it/s]
Adding requests:  33%|███▎      | 167/512 [00:00<00:01, 270.53it/s]
Adding requests:  39%|███▊      | 198/512 [00:00<00:01, 279.53it/s]
Adding requests:  45%|████▍     | 229/512 [00:00<00:00, 286.25it/s]
Adding requests:  50%|█████     | 258/512 [00:00<00:00, 286.76it/s]
Adding requests:  56%|█████▋    | 289/512 [00:01<00:00, 292.61it/s]
Adding requests:  62%|██████▏   | 319/512 [00:01<00:00, 293.38it/s]
Adding requests:  68%|██████▊   | 349/512 [00:01<00:00, 292.22it/s]
Adding requests:  74%|███████▍  | 379/512 [00:01<00:00, 292.03it/s]
Adding requests:  80%|████████  | 410/512 [00:01<00:00, 295.35it/s]
Adding requests:  86%|████████▌ | 441/512 [00:01<00:00, 297.92it/s]
Adding requests:  92%|█████████▏| 472/512 [00:01<00:00, 298.19it/s]
Adding requests:  98%|█████████▊| 504/512 [00:01<00:00, 301.77it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 289.49it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:00<00:01, 298.95it/s, est. speed input: 306159.65 toks/s, output: 298.96 toks/s]
Processed prompts:  15%|█▍        | 76/512 [00:01<00:08, 52.51it/s, est. speed input: 63231.15 toks/s, output: 61.75 toks/s]   
Processed prompts:  18%|█▊        | 90/512 [00:01<00:10, 39.83it/s, est. speed input: 49915.21 toks/s, output: 48.74 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:02<00:11, 37.34it/s, est. speed input: 47051.88 toks/s, output: 45.95 toks/s]
Processed prompts:  21%|██        | 106/512 [00:02<00:12, 33.70it/s, est. speed input: 44087.71 toks/s, output: 43.05 toks/s]
Processed prompts:  22%|██▏       | 111/512 [00:02<00:11, 33.53it/s, est. speed input: 43457.34 toks/s, output: 42.44 toks/s]
Processed prompts:  23%|██▎       | 116/512 [00:02<00:11, 33.35it/s, est. speed input: 42894.42 toks/s, output: 41.89 toks/s]
Processed prompts:  23%|██▎       | 120/512 [00:02<00:12, 31.86it/s, est. speed input: 42037.23 toks/s, output: 41.05 toks/s]
Processed prompts:  24%|██▍       | 124/512 [00:03<00:12, 30.56it/s, est. speed input: 41270.87 toks/s, output: 40.30 toks/s]
Processed prompts:  25%|██▌       | 128/512 [00:03<00:13, 29.46it/s, est. speed input: 40576.33 toks/s, output: 39.63 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:03<00:13, 28.56it/s, est. speed input: 39939.79 toks/s, output: 39.00 toks/s]
Processed prompts:  26%|██▋       | 135/512 [00:03<00:14, 26.15it/s, est. speed input: 39076.72 toks/s, output: 38.16 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:15, 24.28it/s, est. speed input: 38277.07 toks/s, output: 37.38 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:03<00:14, 24.74it/s, est. speed input: 37803.04 toks/s, output: 36.92 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:03<00:14, 25.15it/s, est. speed input: 37382.72 toks/s, output: 36.51 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:04<00:14, 25.39it/s, est. speed input: 36983.13 toks/s, output: 36.12 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:14, 25.52it/s, est. speed input: 36604.52 toks/s, output: 35.75 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:13, 25.65it/s, est. speed input: 36257.47 toks/s, output: 35.41 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:13, 25.74it/s, est. speed input: 35934.99 toks/s, output: 35.09 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:04<00:13, 25.83it/s, est. speed input: 35635.70 toks/s, output: 34.80 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:04<00:13, 25.85it/s, est. speed input: 35350.80 toks/s, output: 34.52 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:05<00:13, 25.88it/s, est. speed input: 35084.12 toks/s, output: 34.26 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:05<00:12, 25.94it/s, est. speed input: 34837.91 toks/s, output: 34.02 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:12, 25.95it/s, est. speed input: 34602.84 toks/s, output: 33.79 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:12, 25.93it/s, est. speed input: 34377.44 toks/s, output: 33.57 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:05<00:12, 25.98it/s, est. speed input: 34171.06 toks/s, output: 33.37 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:05<00:12, 25.98it/s, est. speed input: 33971.85 toks/s, output: 33.18 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:06<00:12, 25.97it/s, est. speed input: 33781.42 toks/s, output: 32.99 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:06<00:11, 27.52it/s, est. speed input: 33760.41 toks/s, output: 32.97 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:11, 27.07it/s, est. speed input: 33587.87 toks/s, output: 32.80 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:11, 26.72it/s, est. speed input: 33419.30 toks/s, output: 32.64 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:11, 26.46it/s, est. speed input: 33257.25 toks/s, output: 32.48 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:06<00:11, 26.37it/s, est. speed input: 33110.02 toks/s, output: 32.33 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:11, 26.20it/s, est. speed input: 32960.05 toks/s, output: 32.19 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:10, 26.15it/s, est. speed input: 32823.17 toks/s, output: 32.05 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:10, 26.11it/s, est. speed input: 32690.73 toks/s, output: 31.92 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:10, 26.09it/s, est. speed input: 32565.00 toks/s, output: 31.80 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:10, 26.05it/s, est. speed input: 32442.39 toks/s, output: 31.68 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:07<00:10, 26.02it/s, est. speed input: 32324.31 toks/s, output: 31.57 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:07<00:10, 25.99it/s, est. speed input: 32210.41 toks/s, output: 31.46 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:07<00:10, 26.00it/s, est. speed input: 32102.74 toks/s, output: 31.35 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:09, 26.00it/s, est. speed input: 31999.03 toks/s, output: 31.25 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:09, 25.98it/s, est. speed input: 31897.99 toks/s, output: 31.15 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:08<00:09, 25.99it/s, est. speed input: 31801.71 toks/s, output: 31.06 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:08<00:09, 25.97it/s, est. speed input: 31707.54 toks/s, output: 30.96 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:08<00:09, 25.96it/s, est. speed input: 31617.10 toks/s, output: 30.88 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:08<00:09, 25.94it/s, est. speed input: 31528.17 toks/s, output: 30.79 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:09, 25.92it/s, est. speed input: 31442.00 toks/s, output: 30.71 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:08, 25.91it/s, est. speed input: 31359.61 toks/s, output: 30.62 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:08, 25.96it/s, est. speed input: 31283.17 toks/s, output: 30.55 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:09<00:08, 25.97it/s, est. speed input: 31207.42 toks/s, output: 30.48 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:09<00:08, 25.98it/s, est. speed input: 31134.69 toks/s, output: 30.40 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:09<00:08, 25.95it/s, est. speed input: 31062.03 toks/s, output: 30.33 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:09<00:08, 25.88it/s, est. speed input: 30988.04 toks/s, output: 30.26 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:07, 27.64it/s, est. speed input: 31020.37 toks/s, output: 30.29 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:07, 27.15it/s, est. speed input: 30955.45 toks/s, output: 30.23 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:10<00:07, 26.72it/s, est. speed input: 30887.63 toks/s, output: 30.16 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:10<00:07, 26.49it/s, est. speed input: 30824.80 toks/s, output: 30.10 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:10<00:07, 26.30it/s, est. speed input: 30762.22 toks/s, output: 30.04 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:10<00:07, 26.21it/s, est. speed input: 30703.93 toks/s, output: 29.98 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:06, 26.13it/s, est. speed input: 30646.07 toks/s, output: 29.93 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:11<00:06, 26.10it/s, est. speed input: 30590.92 toks/s, output: 29.87 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:11<00:06, 26.03it/s, est. speed input: 30535.16 toks/s, output: 29.82 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:11<00:06, 25.97it/s, est. speed input: 30479.85 toks/s, output: 29.77 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:11<00:06, 25.99it/s, est. speed input: 30429.53 toks/s, output: 29.72 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:11<00:06, 25.97it/s, est. speed input: 30378.62 toks/s, output: 29.67 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:11<00:06, 25.91it/s, est. speed input: 30326.78 toks/s, output: 29.62 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:12<00:05, 25.93it/s, est. speed input: 30279.47 toks/s, output: 29.57 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:12<00:05, 25.94it/s, est. speed input: 30233.05 toks/s, output: 29.52 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:12<00:05, 25.93it/s, est. speed input: 30186.98 toks/s, output: 29.48 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:12<00:05, 25.96it/s, est. speed input: 30144.03 toks/s, output: 29.44 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:12<00:05, 25.94it/s, est. speed input: 30099.95 toks/s, output: 29.39 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:12<00:05, 25.93it/s, est. speed input: 30056.99 toks/s, output: 29.35 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:13<00:05, 25.91it/s, est. speed input: 30014.54 toks/s, output: 29.31 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:13<00:04, 25.92it/s, est. speed input: 29974.26 toks/s, output: 29.27 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:13<00:04, 25.89it/s, est. speed input: 29933.42 toks/s, output: 29.23 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:13<00:04, 25.92it/s, est. speed input: 29895.61 toks/s, output: 29.19 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:13<00:04, 25.92it/s, est. speed input: 29857.63 toks/s, output: 29.16 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:13<00:04, 25.89it/s, est. speed input: 29819.26 toks/s, output: 29.12 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:13<00:04, 25.87it/s, est. speed input: 29781.75 toks/s, output: 29.08 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:14<00:03, 25.89it/s, est. speed input: 29746.70 toks/s, output: 29.05 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:14<00:03, 25.91it/s, est. speed input: 29712.22 toks/s, output: 29.02 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:14<00:03, 25.90it/s, est. speed input: 29678.06 toks/s, output: 28.98 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:14<00:03, 25.93it/s, est. speed input: 29645.56 toks/s, output: 28.95 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:14<00:03, 25.89it/s, est. speed input: 29611.76 toks/s, output: 28.92 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:14<00:03, 25.86it/s, est. speed input: 29578.35 toks/s, output: 28.89 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:15<00:02, 27.56it/s, est. speed input: 29609.01 toks/s, output: 28.92 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:15<00:02, 27.03it/s, est. speed input: 29577.22 toks/s, output: 28.88 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:15<00:02, 26.71it/s, est. speed input: 29547.59 toks/s, output: 28.86 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:15<00:02, 26.46it/s, est. speed input: 29517.15 toks/s, output: 28.83 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:15<00:02, 26.31it/s, est. speed input: 29488.18 toks/s, output: 28.80 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:15<00:02, 26.16it/s, est. speed input: 29458.38 toks/s, output: 28.77 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:15<00:02, 26.06it/s, est. speed input: 29429.08 toks/s, output: 28.74 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:16<00:01, 25.99it/s, est. speed input: 29400.24 toks/s, output: 28.71 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:16<00:01, 25.98it/s, est. speed input: 29373.50 toks/s, output: 28.69 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:16<00:01, 25.93it/s, est. speed input: 29345.75 toks/s, output: 28.66 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:16<00:01, 25.95it/s, est. speed input: 29320.49 toks/s, output: 28.63 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:16<00:01, 25.93it/s, est. speed input: 29294.57 toks/s, output: 28.61 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:16<00:01, 25.91it/s, est. speed input: 29268.55 toks/s, output: 28.58 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:17<00:01, 25.91it/s, est. speed input: 29243.85 toks/s, output: 28.56 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:17<00:00, 25.89it/s, est. speed input: 29218.91 toks/s, output: 28.53 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:17<00:00, 25.90it/s, est. speed input: 29195.04 toks/s, output: 28.51 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:17<00:00, 25.88it/s, est. speed input: 29170.84 toks/s, output: 28.49 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:17<00:00, 25.88it/s, est. speed input: 29147.30 toks/s, output: 28.46 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:17<00:00, 25.89it/s, est. speed input: 29124.53 toks/s, output: 28.44 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:17<00:00, 27.79it/s, est. speed input: 29159.34 toks/s, output: 28.48 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:17<00:00, 27.79it/s, est. speed input: 29273.39 toks/s, output: 28.59 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:17<00:00, 28.59it/s, est. speed input: 29273.39 toks/s, output: 28.59 toks/s]
[rank0]:[W125 20:15:22.291674769 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 70.0s

测试结果:
  Requests/s:   26.02
  Tokens/s:     26666.60
  Total Reqs:   512
  Elapsed:      19.68s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     26640.59

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:15:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=405536) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=405536) WARNING 01-25 20:15:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.77 requests/s, 27434.81 total tokens/s, 26.77 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 20:15:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:15:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:15:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:15:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:15:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:15:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:15:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:15:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:15:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:15:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:15:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:15:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:15:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:15:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:15:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:15:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:15:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:48] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=405536) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=405536) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=405536) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=405536) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=405536) 
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=405536) [2026-01-25 20:15:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=405536) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 10.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00, 11.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 10.94it/s]
(EngineCore_DP0 pid=405536) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  9.78it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00, 11.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.37it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 25/1024 [00:00<00:04, 246.65it/s]
Adding requests:   5%|▌         | 52/1024 [00:00<00:03, 258.33it/s]
Adding requests:   8%|▊         | 82/1024 [00:00<00:03, 276.51it/s]
Adding requests:  11%|█         | 111/1024 [00:00<00:03, 279.63it/s]
Adding requests:  14%|█▎        | 140/1024 [00:00<00:03, 279.79it/s]
Adding requests:  17%|█▋        | 170/1024 [00:00<00:03, 282.81it/s]
Adding requests:  20%|█▉        | 202/1024 [00:00<00:02, 293.94it/s]
Adding requests:  23%|██▎       | 232/1024 [00:00<00:02, 294.01it/s]
Adding requests:  26%|██▌       | 262/1024 [00:00<00:02, 284.37it/s]
Adding requests:  28%|██▊       | 291/1024 [00:01<00:02, 284.67it/s]
Adding requests:  31%|███▏      | 322/1024 [00:01<00:02, 289.97it/s]
Adding requests:  34%|███▍      | 352/1024 [00:01<00:02, 286.99it/s]
Adding requests:  37%|███▋      | 381/1024 [00:01<00:02, 287.79it/s]
Adding requests:  40%|████      | 410/1024 [00:01<00:02, 285.98it/s]
Adding requests:  43%|████▎     | 439/1024 [00:01<00:02, 285.07it/s]
Adding requests:  46%|████▌     | 469/1024 [00:01<00:01, 287.56it/s]
Adding requests:  49%|████▉     | 501/1024 [00:01<00:01, 296.38it/s]
Adding requests:  52%|█████▏    | 532/1024 [00:01<00:01, 298.56it/s]
Adding requests:  55%|█████▍    | 562/1024 [00:01<00:01, 293.23it/s]
Adding requests:  58%|█████▊    | 592/1024 [00:02<00:01, 288.04it/s]
Adding requests:  61%|██████    | 623/1024 [00:02<00:01, 290.91it/s]
Adding requests:  64%|██████▍   | 653/1024 [00:02<00:01, 289.54it/s]
Adding requests:  67%|██████▋   | 682/1024 [00:02<00:01, 287.53it/s]
Adding requests:  70%|██████▉   | 713/1024 [00:02<00:01, 292.85it/s]
Adding requests:  73%|███████▎  | 743/1024 [00:02<00:00, 286.31it/s]
Adding requests:  75%|███████▌  | 772/1024 [00:02<00:00, 285.09it/s]
Adding requests:  78%|███████▊  | 803/1024 [00:02<00:00, 290.25it/s]
Adding requests:  82%|████████▏ | 836/1024 [00:02<00:00, 299.48it/s]
Adding requests:  85%|████████▍ | 867/1024 [00:02<00:00, 300.03it/s]
Adding requests:  88%|████████▊ | 900/1024 [00:03<00:00, 307.37it/s]
Adding requests:  91%|█████████ | 931/1024 [00:03<00:00, 295.79it/s]
Adding requests:  94%|█████████▍| 961/1024 [00:03<00:00, 294.45it/s]
Adding requests:  97%|█████████▋| 991/1024 [00:03<00:00, 294.69it/s]
Adding requests: 100%|█████████▉| 1022/1024 [00:03<00:00, 296.90it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 290.03it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:00<00:01, 806.94it/s, est. speed input: 826460.31 toks/s, output: 806.98 toks/s]
Processed prompts:  17%|█▋        | 171/1024 [00:03<00:18, 47.11it/s, est. speed input: 56664.96 toks/s, output: 55.34 toks/s]  
Processed prompts:  20%|██        | 206/1024 [00:04<00:19, 41.12it/s, est. speed input: 49596.58 toks/s, output: 48.43 toks/s]
Processed prompts:  22%|██▏       | 227/1024 [00:05<00:22, 36.20it/s, est. speed input: 45158.94 toks/s, output: 44.10 toks/s]
Processed prompts:  24%|██▎       | 241/1024 [00:05<00:20, 37.46it/s, est. speed input: 45315.70 toks/s, output: 44.25 toks/s]
Processed prompts:  25%|██▍       | 252/1024 [00:06<00:23, 32.66it/s, est. speed input: 42694.04 toks/s, output: 41.69 toks/s]
Processed prompts:  25%|██▌       | 260/1024 [00:06<00:24, 31.79it/s, est. speed input: 41984.22 toks/s, output: 41.00 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:06<00:25, 29.71it/s, est. speed input: 41025.21 toks/s, output: 40.06 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:06<00:25, 29.10it/s, est. speed input: 40436.69 toks/s, output: 39.49 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:07<00:25, 28.59it/s, est. speed input: 39902.06 toks/s, output: 38.97 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:07<00:26, 28.16it/s, est. speed input: 39408.94 toks/s, output: 38.49 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:07<00:26, 27.80it/s, est. speed input: 38951.88 toks/s, output: 38.04 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:08<00:25, 28.32it/s, est. speed input: 38676.67 toks/s, output: 37.77 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:08<00:25, 27.96it/s, est. speed input: 38289.66 toks/s, output: 37.39 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:08<00:25, 27.62it/s, est. speed input: 37916.60 toks/s, output: 37.03 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:08<00:25, 27.33it/s, est. speed input: 37561.03 toks/s, output: 36.68 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:09<00:25, 27.18it/s, est. speed input: 37236.73 toks/s, output: 36.36 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:09<00:25, 27.07it/s, est. speed input: 36932.13 toks/s, output: 36.07 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:09<00:24, 26.95it/s, est. speed input: 36640.35 toks/s, output: 35.78 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:10<00:24, 26.90it/s, est. speed input: 36370.93 toks/s, output: 35.52 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:10<00:24, 26.88it/s, est. speed input: 36117.81 toks/s, output: 35.27 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:10<00:24, 26.84it/s, est. speed input: 35875.67 toks/s, output: 35.03 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:11<00:23, 26.79it/s, est. speed input: 35644.64 toks/s, output: 34.81 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:11<00:23, 26.81it/s, est. speed input: 35431.62 toks/s, output: 34.60 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:11<00:23, 26.83it/s, est. speed input: 35229.34 toks/s, output: 34.40 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:11<00:22, 26.75it/s, est. speed input: 35028.17 toks/s, output: 34.21 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:12<00:22, 26.74it/s, est. speed input: 34841.16 toks/s, output: 34.02 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:12<00:22, 26.74it/s, est. speed input: 34663.83 toks/s, output: 33.85 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:12<00:21, 27.65it/s, est. speed input: 34582.93 toks/s, output: 33.77 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:13<00:21, 27.39it/s, est. speed input: 34420.67 toks/s, output: 33.61 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:13<00:21, 27.17it/s, est. speed input: 34262.03 toks/s, output: 33.46 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:13<00:20, 27.07it/s, est. speed input: 34115.61 toks/s, output: 33.32 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:14<00:20, 26.94it/s, est. speed input: 33968.84 toks/s, output: 33.17 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:14<00:20, 26.85it/s, est. speed input: 33828.79 toks/s, output: 33.04 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:14<00:20, 26.83it/s, est. speed input: 33698.64 toks/s, output: 32.91 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:14<00:19, 26.79it/s, est. speed input: 33571.18 toks/s, output: 32.78 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:15<00:19, 26.75it/s, est. speed input: 33447.82 toks/s, output: 32.66 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:15<00:19, 26.75it/s, est. speed input: 33331.18 toks/s, output: 32.55 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:15<00:19, 26.72it/s, est. speed input: 33216.87 toks/s, output: 32.44 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:16<00:18, 26.73it/s, est. speed input: 33109.12 toks/s, output: 32.33 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:16<00:18, 26.73it/s, est. speed input: 33004.32 toks/s, output: 32.23 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:16<00:18, 26.72it/s, est. speed input: 32903.15 toks/s, output: 32.13 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:17<00:17, 26.72it/s, est. speed input: 32806.06 toks/s, output: 32.04 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:17<00:17, 26.69it/s, est. speed input: 32709.44 toks/s, output: 31.94 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:17<00:17, 26.69it/s, est. speed input: 32618.39 toks/s, output: 31.85 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:17<00:16, 26.71it/s, est. speed input: 32531.40 toks/s, output: 31.77 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:18<00:16, 26.66it/s, est. speed input: 32443.21 toks/s, output: 31.68 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:18<00:16, 26.65it/s, est. speed input: 32359.46 toks/s, output: 31.60 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:18<00:16, 26.65it/s, est. speed input: 32278.48 toks/s, output: 31.52 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:19<00:15, 26.65it/s, est. speed input: 32200.10 toks/s, output: 31.45 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:19<00:15, 26.64it/s, est. speed input: 32123.58 toks/s, output: 31.37 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:19<00:15, 26.65it/s, est. speed input: 32050.90 toks/s, output: 31.30 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:20<00:14, 26.68it/s, est. speed input: 31980.93 toks/s, output: 31.23 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:20<00:14, 26.65it/s, est. speed input: 31910.48 toks/s, output: 31.16 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:20<00:14, 26.63it/s, est. speed input: 31842.06 toks/s, output: 31.10 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:20<00:14, 26.61it/s, est. speed input: 31775.73 toks/s, output: 31.03 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:21<00:13, 26.65it/s, est. speed input: 31713.62 toks/s, output: 30.97 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:21<00:13, 26.63it/s, est. speed input: 31651.22 toks/s, output: 30.91 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:21<00:13, 26.62it/s, est. speed input: 31590.03 toks/s, output: 30.85 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:22<00:12, 26.63it/s, est. speed input: 31532.03 toks/s, output: 30.79 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:22<00:12, 26.66it/s, est. speed input: 31476.47 toks/s, output: 30.74 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:22<00:12, 26.60it/s, est. speed input: 31418.26 toks/s, output: 30.68 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:23<00:11, 26.60it/s, est. speed input: 31363.90 toks/s, output: 30.63 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:23<00:11, 26.61it/s, est. speed input: 31311.18 toks/s, output: 30.58 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:23<00:11, 26.57it/s, est. speed input: 31257.75 toks/s, output: 30.53 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:23<00:11, 26.56it/s, est. speed input: 31206.29 toks/s, output: 30.47 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:24<00:10, 26.57it/s, est. speed input: 31156.84 toks/s, output: 30.43 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:24<00:10, 26.58it/s, est. speed input: 31108.71 toks/s, output: 30.38 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:24<00:10, 26.59it/s, est. speed input: 31062.25 toks/s, output: 30.33 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:25<00:09, 26.61it/s, est. speed input: 31017.35 toks/s, output: 30.29 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:25<00:09, 26.58it/s, est. speed input: 30971.42 toks/s, output: 30.25 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:25<00:09, 26.60it/s, est. speed input: 30928.46 toks/s, output: 30.20 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:26<00:08, 27.47it/s, est. speed input: 30923.61 toks/s, output: 30.20 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:26<00:08, 27.20it/s, est. speed input: 30881.51 toks/s, output: 30.16 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:26<00:08, 27.02it/s, est. speed input: 30840.57 toks/s, output: 30.12 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:26<00:07, 26.88it/s, est. speed input: 30799.52 toks/s, output: 30.08 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:27<00:07, 26.82it/s, est. speed input: 30761.51 toks/s, output: 30.04 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:27<00:07, 26.71it/s, est. speed input: 30721.28 toks/s, output: 30.00 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:27<00:07, 26.70it/s, est. speed input: 30684.61 toks/s, output: 29.97 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:28<00:06, 26.64it/s, est. speed input: 30646.27 toks/s, output: 29.93 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:28<00:06, 26.62it/s, est. speed input: 30610.19 toks/s, output: 29.89 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:28<00:06, 26.61it/s, est. speed input: 30574.71 toks/s, output: 29.86 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:29<00:05, 26.64it/s, est. speed input: 30541.41 toks/s, output: 29.83 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:29<00:05, 26.64it/s, est. speed input: 30508.00 toks/s, output: 29.79 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:29<00:05, 26.62it/s, est. speed input: 30474.38 toks/s, output: 29.76 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:29<00:05, 26.59it/s, est. speed input: 30441.03 toks/s, output: 29.73 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:30<00:04, 26.60it/s, est. speed input: 30409.53 toks/s, output: 29.70 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:30<00:04, 26.55it/s, est. speed input: 30376.23 toks/s, output: 29.66 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:30<00:04, 26.53it/s, est. speed input: 30344.51 toks/s, output: 29.63 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:31<00:03, 26.54it/s, est. speed input: 30314.18 toks/s, output: 29.60 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:31<00:03, 26.51it/s, est. speed input: 30282.92 toks/s, output: 29.57 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:31<00:03, 26.53it/s, est. speed input: 30253.78 toks/s, output: 29.54 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:32<00:02, 26.56it/s, est. speed input: 30225.80 toks/s, output: 29.52 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:32<00:02, 26.55it/s, est. speed input: 30197.21 toks/s, output: 29.49 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:32<00:02, 26.50it/s, est. speed input: 30167.83 toks/s, output: 29.46 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:32<00:02, 26.50it/s, est. speed input: 30139.93 toks/s, output: 29.43 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:33<00:01, 26.54it/s, est. speed input: 30113.98 toks/s, output: 29.41 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:33<00:01, 26.52it/s, est. speed input: 30086.99 toks/s, output: 29.38 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:33<00:01, 26.54it/s, est. speed input: 30061.54 toks/s, output: 29.36 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:34<00:00, 26.55it/s, est. speed input: 30036.50 toks/s, output: 29.33 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:34<00:00, 26.59it/s, est. speed input: 30012.74 toks/s, output: 29.31 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:34<00:00, 27.56it/s, est. speed input: 30019.10 toks/s, output: 29.32 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:34<00:00, 27.56it/s, est. speed input: 30195.80 toks/s, output: 29.49 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:34<00:00, 29.49it/s, est. speed input: 30195.80 toks/s, output: 29.49 toks/s]
[rank0]:[W125 20:16:56.717213191 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 93.5s

测试结果:
  Requests/s:   26.77
  Tokens/s:     27434.81
  Total Reqs:   1024
  Elapsed:      38.26s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     27408.05

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:17:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=407154) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=407154) WARNING 01-25 20:17:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.20 requests/s, 27876.81 total tokens/s, 27.20 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 20:17:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:17:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:17:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:17:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:17:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:17:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:17:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:17:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:17:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:17:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:17:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:17:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:17:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:17:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:17:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:17:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:17:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=407154) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=407154) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=407154) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=407154) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.32it/s]
(EngineCore_DP0 pid=407154) 
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=407154) [2026-01-25 20:17:31] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=407154) [rank0]:W0125 20:17:48.383000 407154 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=407154) [rank0]:W0125 20:17:48.503000 407154 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=407154) [rank0]:W0125 20:17:50.074000 407154 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=407154) [rank0]:W0125 20:17:50.260000 407154 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=407154) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 10.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 11.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 11.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 11.20it/s]
(EngineCore_DP0 pid=407154) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00, 10.75it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00, 11.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.08it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 27/2048 [00:00<00:07, 259.84it/s]
Adding requests:   3%|▎         | 57/2048 [00:00<00:07, 280.59it/s]
Adding requests:   4%|▍         | 86/2048 [00:00<00:07, 274.39it/s]
Adding requests:   6%|▌         | 114/2048 [00:00<00:07, 269.01it/s]
Adding requests:   7%|▋         | 142/2048 [00:00<00:07, 270.79it/s]
Adding requests:   8%|▊         | 170/2048 [00:00<00:06, 272.58it/s]
Adding requests:  10%|▉         | 202/2048 [00:00<00:06, 284.07it/s]
Adding requests:  11%|█▏        | 231/2048 [00:00<00:06, 284.95it/s]
Adding requests:  13%|█▎        | 260/2048 [00:00<00:06, 285.42it/s]
Adding requests:  14%|█▍        | 289/2048 [00:01<00:06, 285.25it/s]
Adding requests:  16%|█▌        | 320/2048 [00:01<00:05, 290.69it/s]
Adding requests:  17%|█▋        | 350/2048 [00:01<00:05, 292.89it/s]
Adding requests:  19%|█▊        | 380/2048 [00:01<00:05, 289.61it/s]
Adding requests:  20%|██        | 410/2048 [00:01<00:05, 291.72it/s]
Adding requests:  21%|██▏       | 440/2048 [00:01<00:05, 292.18it/s]
Adding requests:  23%|██▎       | 471/2048 [00:01<00:05, 296.55it/s]
Adding requests:  25%|██▍       | 504/2048 [00:01<00:05, 304.43it/s]
Adding requests:  26%|██▌       | 537/2048 [00:01<00:04, 311.53it/s]
Adding requests:  28%|██▊       | 569/2048 [00:01<00:04, 312.53it/s]
Adding requests:  29%|██▉       | 601/2048 [00:02<00:04, 303.34it/s]
Adding requests:  31%|███       | 632/2048 [00:02<00:04, 304.19it/s]
Adding requests:  32%|███▏      | 663/2048 [00:02<00:04, 300.47it/s]
Adding requests:  34%|███▍      | 695/2048 [00:02<00:04, 303.10it/s]
Adding requests:  35%|███▌      | 726/2048 [00:02<00:04, 294.20it/s]
Adding requests:  37%|███▋      | 756/2048 [00:02<00:04, 286.72it/s]
Adding requests:  38%|███▊      | 787/2048 [00:02<00:04, 292.87it/s]
Adding requests:  40%|███▉      | 817/2048 [00:02<00:04, 293.17it/s]
Adding requests:  42%|████▏     | 850/2048 [00:02<00:03, 301.69it/s]
Adding requests:  43%|████▎     | 882/2048 [00:03<00:03, 305.89it/s]
Adding requests:  45%|████▍     | 913/2048 [00:03<00:03, 292.95it/s]
Adding requests:  46%|████▌     | 943/2048 [00:03<00:03, 282.29it/s]
Adding requests:  48%|████▊     | 974/2048 [00:03<00:03, 288.27it/s]
Adding requests:  49%|████▉     | 1003/2048 [00:03<00:03, 278.34it/s]
Adding requests:  50%|█████     | 1031/2048 [00:03<00:03, 276.71it/s]
Adding requests:  52%|█████▏    | 1060/2048 [00:03<00:03, 280.28it/s]
Adding requests:  53%|█████▎    | 1089/2048 [00:03<00:03, 282.85it/s]
Adding requests:  55%|█████▍    | 1119/2048 [00:03<00:03, 287.30it/s]
Adding requests:  56%|█████▌    | 1150/2048 [00:03<00:03, 293.05it/s]
Adding requests:  58%|█████▊    | 1181/2048 [00:04<00:02, 296.74it/s]
Adding requests:  59%|█████▉    | 1212/2048 [00:04<00:02, 299.12it/s]
Adding requests:  61%|██████    | 1242/2048 [00:04<00:02, 294.91it/s]
Adding requests:  62%|██████▏   | 1272/2048 [00:04<00:02, 291.12it/s]
Adding requests:  64%|██████▎   | 1302/2048 [00:04<00:02, 288.57it/s]
Adding requests:  65%|██████▍   | 1331/2048 [00:04<00:02, 283.17it/s]
Adding requests:  67%|██████▋   | 1363/2048 [00:04<00:02, 293.38it/s]
Adding requests:  68%|██████▊   | 1393/2048 [00:04<00:02, 292.74it/s]
Adding requests:  69%|██████▉   | 1423/2048 [00:04<00:02, 294.06it/s]
Adding requests:  71%|███████   | 1455/2048 [00:04<00:01, 301.20it/s]
Adding requests:  73%|███████▎  | 1487/2048 [00:05<00:01, 305.76it/s]
Adding requests:  74%|███████▍  | 1519/2048 [00:05<00:01, 308.41it/s]
Adding requests:  76%|███████▌  | 1550/2048 [00:05<00:01, 302.63it/s]
Adding requests:  77%|███████▋  | 1581/2048 [00:05<00:01, 296.26it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:05<00:01, 290.49it/s]
Adding requests:  80%|████████  | 1641/2048 [00:05<00:01, 282.61it/s]
Adding requests:  82%|████████▏ | 1670/2048 [00:05<00:01, 283.44it/s]
Adding requests:  83%|████████▎ | 1700/2048 [00:05<00:01, 286.53it/s]
Adding requests:  84%|████████▍ | 1730/2048 [00:05<00:01, 289.28it/s]
Adding requests:  86%|████████▌ | 1762/2048 [00:06<00:00, 296.31it/s]
Adding requests:  88%|████████▊ | 1793/2048 [00:06<00:00, 299.77it/s]
Adding requests:  89%|████████▉ | 1824/2048 [00:06<00:00, 292.83it/s]
Adding requests:  91%|█████████ | 1854/2048 [00:06<00:00, 287.75it/s]
Adding requests:  92%|█████████▏| 1886/2048 [00:06<00:00, 295.96it/s]
Adding requests:  94%|█████████▎| 1916/2048 [00:06<00:00, 290.22it/s]
Adding requests:  95%|█████████▌| 1947/2048 [00:06<00:00, 295.37it/s]
Adding requests:  97%|█████████▋| 1978/2048 [00:06<00:00, 298.72it/s]
Adding requests:  98%|█████████▊| 2008/2048 [00:06<00:00, 294.08it/s]
Adding requests: 100%|█████████▉| 2038/2048 [00:06<00:00, 289.15it/s]
Adding requests: 100%|██████████| 2048/2048 [00:07<00:00, 291.75it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:00<00:05, 310.56it/s, est. speed input: 318032.91 toks/s, output: 310.57 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:01<00:17, 104.43it/s, est. speed input: 128987.30 toks/s, output: 125.96 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:02<00:23, 77.99it/s, est. speed input: 104096.01 toks/s, output: 101.66 toks/s] 
Processed prompts:  13%|█▎        | 258/2048 [00:02<00:29, 61.36it/s, est. speed input: 89071.55 toks/s, output: 86.98 toks/s]  
Processed prompts:  13%|█▎        | 274/2048 [00:03<00:35, 50.48it/s, est. speed input: 78986.55 toks/s, output: 77.13 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:04<00:40, 43.23it/s, est. speed input: 71771.29 toks/s, output: 70.09 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:04<00:44, 38.91it/s, est. speed input: 66754.09 toks/s, output: 65.19 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:05<00:48, 35.33it/s, est. speed input: 62457.79 toks/s, output: 60.99 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:05<00:52, 32.87it/s, est. speed input: 59014.71 toks/s, output: 57.63 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:06<00:54, 31.19it/s, est. speed input: 56199.81 toks/s, output: 54.88 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:07<00:55, 30.01it/s, est. speed input: 53849.43 toks/s, output: 52.59 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:07<00:56, 29.19it/s, est. speed input: 51857.52 toks/s, output: 50.64 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:08<00:57, 28.60it/s, est. speed input: 50142.09 toks/s, output: 48.97 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:08<00:57, 28.19it/s, est. speed input: 48658.29 toks/s, output: 47.52 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:09<00:56, 28.32it/s, est. speed input: 47502.48 toks/s, output: 46.39 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:09<00:57, 27.98it/s, est. speed input: 46342.12 toks/s, output: 45.26 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:10<00:56, 27.78it/s, est. speed input: 45318.25 toks/s, output: 44.26 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:11<00:56, 27.63it/s, est. speed input: 44401.68 toks/s, output: 43.36 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:11<00:56, 27.50it/s, est. speed input: 43570.85 toks/s, output: 42.55 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:12<00:55, 27.43it/s, est. speed input: 42823.49 toks/s, output: 41.82 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:12<00:55, 27.36it/s, est. speed input: 42138.70 toks/s, output: 41.15 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:13<00:54, 27.34it/s, est. speed input: 41521.82 toks/s, output: 40.55 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:14<00:54, 27.31it/s, est. speed input: 40951.74 toks/s, output: 39.99 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:14<00:53, 27.29it/s, est. speed input: 40428.75 toks/s, output: 39.48 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:15<00:53, 27.25it/s, est. speed input: 39940.43 toks/s, output: 39.00 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:15<00:52, 27.23it/s, est. speed input: 39490.67 toks/s, output: 38.57 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:16<00:52, 27.24it/s, est. speed input: 39076.69 toks/s, output: 38.16 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:16<00:51, 27.20it/s, est. speed input: 38683.43 toks/s, output: 37.78 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:17<00:51, 27.20it/s, est. speed input: 38321.08 toks/s, output: 37.42 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:18<00:50, 27.22it/s, est. speed input: 37985.18 toks/s, output: 37.09 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:18<00:49, 27.18it/s, est. speed input: 37662.69 toks/s, output: 36.78 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:19<00:49, 27.16it/s, est. speed input: 37360.69 toks/s, output: 36.48 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:19<00:48, 27.14it/s, est. speed input: 37076.40 toks/s, output: 36.21 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:20<00:48, 27.17it/s, est. speed input: 36813.18 toks/s, output: 35.95 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:21<00:47, 27.15it/s, est. speed input: 36559.55 toks/s, output: 35.70 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:21<00:47, 27.12it/s, est. speed input: 36318.98 toks/s, output: 35.47 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:22<00:45, 27.53it/s, est. speed input: 36139.95 toks/s, output: 35.29 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:22<00:45, 27.39it/s, est. speed input: 35922.21 toks/s, output: 35.08 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:23<00:45, 27.32it/s, est. speed input: 35718.37 toks/s, output: 34.88 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:24<00:44, 27.26it/s, est. speed input: 35523.85 toks/s, output: 34.69 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:24<00:44, 27.20it/s, est. speed input: 35336.26 toks/s, output: 34.51 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:25<00:43, 27.16it/s, est. speed input: 35157.63 toks/s, output: 34.33 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:25<00:42, 27.17it/s, est. speed input: 34990.53 toks/s, output: 34.17 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:26<00:42, 27.15it/s, est. speed input: 34828.84 toks/s, output: 34.01 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:26<00:41, 27.09it/s, est. speed input: 34669.51 toks/s, output: 33.86 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:27<00:41, 27.10it/s, est. speed input: 34522.73 toks/s, output: 33.71 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:28<00:40, 27.08it/s, est. speed input: 34378.57 toks/s, output: 33.57 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:28<00:40, 27.08it/s, est. speed input: 34241.96 toks/s, output: 33.44 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:29<00:39, 27.05it/s, est. speed input: 34108.69 toks/s, output: 33.31 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:29<00:38, 27.08it/s, est. speed input: 33984.05 toks/s, output: 33.19 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:30<00:38, 27.00it/s, est. speed input: 33857.09 toks/s, output: 33.06 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:31<00:37, 27.03it/s, est. speed input: 33741.55 toks/s, output: 32.95 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:31<00:37, 27.03it/s, est. speed input: 33627.92 toks/s, output: 32.84 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:32<00:36, 27.00it/s, est. speed input: 33516.78 toks/s, output: 32.73 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:32<00:36, 27.01it/s, est. speed input: 33411.74 toks/s, output: 32.63 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:33<00:35, 27.00it/s, est. speed input: 33309.07 toks/s, output: 32.53 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:34<00:34, 26.99it/s, est. speed input: 33210.45 toks/s, output: 32.43 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:34<00:34, 26.99it/s, est. speed input: 33115.36 toks/s, output: 32.34 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:35<00:33, 26.97it/s, est. speed input: 33021.70 toks/s, output: 32.25 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:35<00:33, 26.98it/s, est. speed input: 32933.01 toks/s, output: 32.16 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:36<00:32, 26.95it/s, est. speed input: 32845.06 toks/s, output: 32.08 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:37<00:31, 26.97it/s, est. speed input: 32762.13 toks/s, output: 31.99 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:37<00:30, 27.44it/s, est. speed input: 32710.47 toks/s, output: 31.94 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:38<00:30, 27.29it/s, est. speed input: 32631.25 toks/s, output: 31.87 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:38<00:29, 27.60it/s, est. speed input: 32578.94 toks/s, output: 31.82 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:39<00:29, 27.43it/s, est. speed input: 32505.52 toks/s, output: 31.74 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:39<00:28, 27.25it/s, est. speed input: 32430.42 toks/s, output: 31.67 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:40<00:28, 27.18it/s, est. speed input: 32360.98 toks/s, output: 31.60 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:41<00:27, 27.07it/s, est. speed input: 32289.65 toks/s, output: 31.53 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:41<00:27, 27.04it/s, est. speed input: 32223.55 toks/s, output: 31.47 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:42<00:26, 27.40it/s, est. speed input: 32179.75 toks/s, output: 31.43 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:42<00:25, 27.26it/s, est. speed input: 32116.14 toks/s, output: 31.36 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:43<00:25, 27.13it/s, est. speed input: 32052.80 toks/s, output: 31.30 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:44<00:24, 27.10it/s, est. speed input: 31993.82 toks/s, output: 31.24 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:44<00:24, 27.00it/s, est. speed input: 31932.80 toks/s, output: 31.18 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:45<00:23, 26.99it/s, est. speed input: 31876.15 toks/s, output: 31.13 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:45<00:23, 26.98it/s, est. speed input: 31820.87 toks/s, output: 31.08 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:46<00:22, 26.95it/s, est. speed input: 31765.95 toks/s, output: 31.02 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:47<00:21, 27.38it/s, est. speed input: 31734.30 toks/s, output: 30.99 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:47<00:21, 27.24it/s, est. speed input: 31682.13 toks/s, output: 30.94 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:48<00:20, 27.14it/s, est. speed input: 31631.51 toks/s, output: 30.89 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:48<00:20, 27.06it/s, est. speed input: 31581.22 toks/s, output: 30.84 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:49<00:19, 27.49it/s, est. speed input: 31554.50 toks/s, output: 30.81 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:49<00:18, 27.30it/s, est. speed input: 31506.27 toks/s, output: 30.77 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:50<00:17, 27.62it/s, est. speed input: 31479.44 toks/s, output: 30.74 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:51<00:17, 27.39it/s, est. speed input: 31432.99 toks/s, output: 30.70 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:51<00:16, 27.23it/s, est. speed input: 31387.94 toks/s, output: 30.65 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:52<00:16, 27.09it/s, est. speed input: 31342.64 toks/s, output: 30.61 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:52<00:15, 27.44it/s, est. speed input: 31317.34 toks/s, output: 30.58 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:53<00:15, 27.24it/s, est. speed input: 31273.74 toks/s, output: 30.54 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:54<00:14, 27.09it/s, est. speed input: 31230.92 toks/s, output: 30.50 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:54<00:14, 27.02it/s, est. speed input: 31190.40 toks/s, output: 30.46 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:55<00:13, 26.94it/s, est. speed input: 31149.26 toks/s, output: 30.42 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:55<00:12, 26.94it/s, est. speed input: 31111.55 toks/s, output: 30.38 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:56<00:12, 26.88it/s, est. speed input: 31071.81 toks/s, output: 30.34 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:57<00:11, 27.29it/s, est. speed input: 31051.10 toks/s, output: 30.32 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:57<00:10, 27.60it/s, est. speed input: 31031.24 toks/s, output: 30.30 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:58<00:10, 27.30it/s, est. speed input: 30992.61 toks/s, output: 30.27 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:58<00:09, 27.19it/s, est. speed input: 30958.08 toks/s, output: 30.23 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:59<00:09, 27.03it/s, est. speed input: 30921.08 toks/s, output: 30.20 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:00<00:08, 26.98it/s, est. speed input: 30887.10 toks/s, output: 30.16 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:00<00:08, 26.92it/s, est. speed input: 30852.96 toks/s, output: 30.13 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:01<00:07, 26.86it/s, est. speed input: 30819.01 toks/s, output: 30.10 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:01<00:07, 26.84it/s, est. speed input: 30786.10 toks/s, output: 30.06 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:02<00:06, 26.82it/s, est. speed input: 30753.92 toks/s, output: 30.03 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:02<00:05, 27.24it/s, est. speed input: 30737.86 toks/s, output: 30.02 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:03<00:05, 27.06it/s, est. speed input: 30705.02 toks/s, output: 29.99 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:04<00:04, 27.01it/s, est. speed input: 30675.62 toks/s, output: 29.96 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:04<00:04, 26.92it/s, est. speed input: 30645.05 toks/s, output: 29.93 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:05<00:03, 26.85it/s, est. speed input: 30614.72 toks/s, output: 29.90 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:05<00:02, 26.82it/s, est. speed input: 30585.49 toks/s, output: 29.87 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:06<00:02, 27.20it/s, est. speed input: 30570.11 toks/s, output: 29.85 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:07<00:01, 27.05it/s, est. speed input: 30541.50 toks/s, output: 29.83 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:07<00:01, 26.93it/s, est. speed input: 30512.77 toks/s, output: 29.80 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:08<00:00, 27.44it/s, est. speed input: 30503.62 toks/s, output: 29.79 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:08<00:00, 27.44it/s, est. speed input: 30713.41 toks/s, output: 29.99 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:08<00:00, 29.99it/s, est. speed input: 30713.41 toks/s, output: 29.99 toks/s]
[rank0]:[W125 20:19:15.156829466 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 139.5s

测试结果:
  Requests/s:   27.20
  Tokens/s:     27876.81
  Total Reqs:   2048
  Elapsed:      75.30s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     27849.61

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:19:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=409511) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=409511) WARNING 01-25 20:20:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 27.07 requests/s, 27743.75 total tokens/s, 27.07 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 20:19:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:19:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:19:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:19:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:19:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:19:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:19:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:19:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:19:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:20:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:20:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:20:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:20:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:20:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:20:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:20:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:20:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:20:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=409511) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=409511) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.31it/s]
(EngineCore_DP0 pid=409511) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
(EngineCore_DP0 pid=409511) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.31it/s]
(EngineCore_DP0 pid=409511) 
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=409511) [2026-01-25 20:20:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=409511) [rank0]:W0125 20:20:21.969000 409511 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=409511) [rank0]:W0125 20:20:22.094000 409511 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=409511) [rank0]:W0125 20:20:23.475000 409511 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=409511) [rank0]:W0125 20:20:23.668000 409511 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=409511) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:00, 10.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00, 10.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00, 10.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00, 11.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:00<00:00, 11.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.94it/s]
(EngineCore_DP0 pid=409511) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  9.94it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 11.15it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 11.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 11.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 11.41it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 26/4096 [00:00<00:15, 259.43it/s]
Adding requests:   1%|▏         | 55/4096 [00:00<00:14, 277.17it/s]
Adding requests:   2%|▏         | 84/4096 [00:00<00:14, 281.00it/s]
Adding requests:   3%|▎         | 114/4096 [00:00<00:13, 285.43it/s]
Adding requests:   3%|▎         | 143/4096 [00:00<00:13, 286.95it/s]
Adding requests:   4%|▍         | 172/4096 [00:00<00:13, 287.32it/s]
Adding requests:   5%|▍         | 203/4096 [00:00<00:13, 293.29it/s]
Adding requests:   6%|▌         | 233/4096 [00:00<00:13, 287.45it/s]
Adding requests:   6%|▋         | 263/4096 [00:00<00:13, 289.28it/s]
Adding requests:   7%|▋         | 293/4096 [00:01<00:13, 289.50it/s]
Adding requests:   8%|▊         | 325/4096 [00:01<00:12, 295.31it/s]
Adding requests:   9%|▊         | 358/4096 [00:01<00:12, 302.85it/s]
Adding requests:  10%|▉         | 390/4096 [00:01<00:12, 306.78it/s]
Adding requests:  10%|█         | 421/4096 [00:01<00:12, 302.96it/s]
Adding requests:  11%|█         | 452/4096 [00:01<00:12, 300.42it/s]
Adding requests:  12%|█▏        | 485/4096 [00:01<00:11, 308.24it/s]
Adding requests:  13%|█▎        | 518/4096 [00:01<00:11, 313.89it/s]
Adding requests:  13%|█▎        | 550/4096 [00:01<00:11, 305.15it/s]
Adding requests:  14%|█▍        | 581/4096 [00:01<00:11, 305.87it/s]
Adding requests:  15%|█▍        | 612/4096 [00:02<00:11, 300.78it/s]
Adding requests:  16%|█▌        | 643/4096 [00:02<00:11, 302.31it/s]
Adding requests:  16%|█▋        | 674/4096 [00:02<00:11, 295.28it/s]
Adding requests:  17%|█▋        | 707/4096 [00:02<00:11, 303.42it/s]
Adding requests:  18%|█▊        | 738/4096 [00:02<00:11, 299.48it/s]
Adding requests:  19%|█▉        | 768/4096 [00:02<00:11, 296.62it/s]
Adding requests:  20%|█▉        | 800/4096 [00:02<00:10, 301.87it/s]
Adding requests:  20%|██        | 832/4096 [00:02<00:10, 306.79it/s]
Adding requests:  21%|██        | 863/4096 [00:02<00:10, 299.24it/s]
Adding requests:  22%|██▏       | 893/4096 [00:03<00:10, 296.80it/s]
Adding requests:  23%|██▎       | 923/4096 [00:03<00:11, 283.64it/s]
Adding requests:  23%|██▎       | 953/4096 [00:03<00:10, 286.25it/s]
Adding requests:  24%|██▍       | 983/4096 [00:03<00:10, 289.01it/s]
Adding requests:  25%|██▍       | 1012/4096 [00:03<00:10, 288.80it/s]
Adding requests:  25%|██▌       | 1041/4096 [00:03<00:10, 287.71it/s]
Adding requests:  26%|██▌       | 1071/4096 [00:03<00:10, 290.53it/s]
Adding requests:  27%|██▋       | 1101/4096 [00:03<00:10, 282.79it/s]
Adding requests:  28%|██▊       | 1132/4096 [00:03<00:10, 288.42it/s]
Adding requests:  28%|██▊       | 1161/4096 [00:03<00:10, 279.17it/s]
Adding requests:  29%|██▉       | 1192/4096 [00:04<00:10, 285.28it/s]
Adding requests:  30%|██▉       | 1225/4096 [00:04<00:09, 296.09it/s]
Adding requests:  31%|███       | 1256/4096 [00:04<00:09, 299.93it/s]
Adding requests:  31%|███▏      | 1287/4096 [00:04<00:09, 297.79it/s]
Adding requests:  32%|███▏      | 1318/4096 [00:04<00:09, 300.11it/s]
Adding requests:  33%|███▎      | 1350/4096 [00:04<00:08, 305.24it/s]
Adding requests:  34%|███▎      | 1381/4096 [00:04<00:08, 305.52it/s]
Adding requests:  34%|███▍      | 1412/4096 [00:04<00:09, 297.93it/s]
Adding requests:  35%|███▌      | 1443/4096 [00:04<00:08, 299.88it/s]
Adding requests:  36%|███▌      | 1474/4096 [00:04<00:09, 291.14it/s]
Adding requests:  37%|███▋      | 1505/4096 [00:05<00:08, 294.24it/s]
Adding requests:  37%|███▋      | 1535/4096 [00:05<00:08, 294.72it/s]
Adding requests:  38%|███▊      | 1565/4096 [00:05<00:08, 288.19it/s]
Adding requests:  39%|███▉      | 1594/4096 [00:05<00:08, 281.62it/s]
Adding requests:  40%|███▉      | 1623/4096 [00:05<00:08, 275.41it/s]
Adding requests:  40%|████      | 1651/4096 [00:05<00:08, 273.45it/s]
Adding requests:  41%|████      | 1679/4096 [00:05<00:08, 273.95it/s]
Adding requests:  42%|████▏     | 1711/4096 [00:05<00:08, 285.64it/s]
Adding requests:  43%|████▎     | 1741/4096 [00:05<00:08, 289.45it/s]
Adding requests:  43%|████▎     | 1772/4096 [00:06<00:07, 294.81it/s]
Adding requests:  44%|████▍     | 1802/4096 [00:06<00:07, 289.78it/s]
Adding requests:  45%|████▍     | 1832/4096 [00:06<00:07, 284.85it/s]
Adding requests:  45%|████▌     | 1861/4096 [00:06<00:07, 283.10it/s]
Adding requests:  46%|████▌     | 1891/4096 [00:06<00:07, 286.44it/s]
Adding requests:  47%|████▋     | 1923/4096 [00:06<00:07, 293.35it/s]
Adding requests:  48%|████▊     | 1956/4096 [00:06<00:07, 302.29it/s]
Adding requests:  49%|████▊     | 1987/4096 [00:06<00:06, 302.01it/s]
Adding requests:  49%|████▉     | 2018/4096 [00:06<00:07, 295.51it/s]
Adding requests:  50%|█████     | 2048/4096 [00:06<00:06, 296.51it/s]
Adding requests:  51%|█████     | 2078/4096 [00:07<00:07, 284.95it/s]
Adding requests:  51%|█████▏    | 2108/4096 [00:07<00:06, 287.14it/s]
Adding requests:  52%|█████▏    | 2137/4096 [00:07<00:06, 282.46it/s]
Adding requests:  53%|█████▎    | 2166/4096 [00:07<00:06, 282.47it/s]
Adding requests:  54%|█████▎    | 2196/4096 [00:07<00:06, 285.59it/s]
Adding requests:  54%|█████▍    | 2225/4096 [00:07<00:06, 282.22it/s]
Adding requests:  55%|█████▌    | 2254/4096 [00:07<00:06, 283.96it/s]
Adding requests:  56%|█████▌    | 2285/4096 [00:07<00:06, 289.79it/s]
Adding requests:  57%|█████▋    | 2315/4096 [00:07<00:06, 288.13it/s]
Adding requests:  57%|█████▋    | 2345/4096 [00:08<00:06, 289.06it/s]
Adding requests:  58%|█████▊    | 2376/4096 [00:08<00:05, 292.51it/s]
Adding requests:  59%|█████▉    | 2409/4096 [00:08<00:05, 302.55it/s]
Adding requests:  60%|█████▉    | 2440/4096 [00:08<00:05, 303.06it/s]
Adding requests:  60%|██████    | 2472/4096 [00:08<00:05, 307.92it/s]
Adding requests:  61%|██████    | 2504/4096 [00:08<00:05, 309.85it/s]
Adding requests:  62%|██████▏   | 2536/4096 [00:08<00:05, 311.83it/s]
Adding requests:  63%|██████▎   | 2570/4096 [00:08<00:04, 318.17it/s]
Adding requests:  64%|██████▎   | 2603/4096 [00:08<00:04, 319.63it/s]
Adding requests:  64%|██████▍   | 2635/4096 [00:08<00:04, 310.48it/s]
Adding requests:  65%|██████▌   | 2667/4096 [00:09<00:04, 297.54it/s]
Adding requests:  66%|██████▌   | 2697/4096 [00:09<00:04, 288.35it/s]
Adding requests:  67%|██████▋   | 2726/4096 [00:09<00:04, 284.08it/s]
Adding requests:  67%|██████▋   | 2755/4096 [00:09<00:04, 285.04it/s]
Adding requests:  68%|██████▊   | 2785/4096 [00:09<00:04, 288.53it/s]
Adding requests:  69%|██████▉   | 2818/4096 [00:09<00:04, 299.97it/s]
Adding requests:  70%|██████▉   | 2849/4096 [00:09<00:04, 299.56it/s]
Adding requests:  70%|███████   | 2880/4096 [00:09<00:04, 290.51it/s]
Adding requests:  71%|███████   | 2912/4096 [00:09<00:03, 296.39it/s]
Adding requests:  72%|███████▏  | 2944/4096 [00:10<00:03, 301.33it/s]
Adding requests:  73%|███████▎  | 2975/4096 [00:10<00:03, 294.79it/s]
Adding requests:  73%|███████▎  | 3007/4096 [00:10<00:03, 299.84it/s]
Adding requests:  74%|███████▍  | 3038/4096 [00:10<00:03, 302.52it/s]
Adding requests:  75%|███████▍  | 3071/4096 [00:10<00:03, 308.74it/s]
Adding requests:  76%|███████▌  | 3103/4096 [00:10<00:03, 311.21it/s]
Adding requests:  77%|███████▋  | 3137/4096 [00:10<00:03, 316.07it/s]
Adding requests:  77%|███████▋  | 3169/4096 [00:10<00:03, 305.52it/s]
Adding requests:  78%|███████▊  | 3200/4096 [00:10<00:02, 304.83it/s]
Adding requests:  79%|███████▉  | 3233/4096 [00:10<00:02, 310.63it/s]
Adding requests:  80%|███████▉  | 3265/4096 [00:11<00:02, 308.92it/s]
Adding requests:  80%|████████  | 3296/4096 [00:11<00:02, 298.13it/s]
Adding requests:  81%|████████  | 3326/4096 [00:11<00:02, 297.26it/s]
Adding requests:  82%|████████▏ | 3357/4096 [00:11<00:02, 299.59it/s]
Adding requests:  83%|████████▎ | 3388/4096 [00:11<00:02, 301.09it/s]
Adding requests:  83%|████████▎ | 3419/4096 [00:11<00:02, 298.69it/s]
Adding requests:  84%|████████▍ | 3451/4096 [00:11<00:02, 304.83it/s]
Adding requests:  85%|████████▌ | 3482/4096 [00:11<00:02, 303.60it/s]
Adding requests:  86%|████████▌ | 3513/4096 [00:11<00:01, 298.86it/s]
Adding requests:  87%|████████▋ | 3547/4096 [00:11<00:01, 308.94it/s]
Adding requests:  87%|████████▋ | 3579/4096 [00:12<00:01, 311.43it/s]
Adding requests:  88%|████████▊ | 3611/4096 [00:12<00:01, 307.50it/s]
Adding requests:  89%|████████▉ | 3642/4096 [00:12<00:01, 303.29it/s]
Adding requests:  90%|████████▉ | 3673/4096 [00:12<00:01, 284.33it/s]
Adding requests:  90%|█████████ | 3702/4096 [00:12<00:01, 281.12it/s]
Adding requests:  91%|█████████ | 3731/4096 [00:12<00:01, 280.59it/s]
Adding requests:  92%|█████████▏| 3760/4096 [00:12<00:01, 279.01it/s]
Adding requests:  92%|█████████▏| 3788/4096 [00:12<00:01, 277.01it/s]
Adding requests:  93%|█████████▎| 3817/4096 [00:12<00:01, 277.92it/s]
Adding requests:  94%|█████████▍| 3848/4096 [00:13<00:00, 287.08it/s]
Adding requests:  95%|█████████▍| 3881/4096 [00:13<00:00, 297.45it/s]
Adding requests:  95%|█████████▌| 3911/4096 [00:13<00:00, 284.85it/s]
Adding requests:  96%|█████████▌| 3942/4096 [00:13<00:00, 288.13it/s]
Adding requests:  97%|█████████▋| 3972/4096 [00:13<00:00, 290.81it/s]
Adding requests:  98%|█████████▊| 4002/4096 [00:13<00:00, 286.60it/s]
Adding requests:  98%|█████████▊| 4033/4096 [00:13<00:00, 291.31it/s]
Adding requests:  99%|█████████▉| 4063/4096 [00:13<00:00, 288.15it/s]
Adding requests: 100%|█████████▉| 4092/4096 [00:13<00:00, 280.03it/s]
Adding requests: 100%|██████████| 4096/4096 [00:13<00:00, 294.37it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 369/4096 [00:00<00:07, 508.34it/s, est. speed input: 520563.45 toks/s, output: 508.35 toks/s]
Processed prompts:  10%|█         | 420/4096 [00:01<00:19, 184.16it/s, est. speed input: 226680.45 toks/s, output: 221.37 toks/s]
Processed prompts:  11%|█         | 444/4096 [00:03<00:35, 103.69it/s, est. speed input: 149499.53 toks/s, output: 146.00 toks/s]
Processed prompts:  11%|█▏        | 465/4096 [00:04<00:53, 67.65it/s, est. speed input: 112922.73 toks/s, output: 110.28 toks/s] 
Processed prompts:  12%|█▏        | 497/4096 [00:05<01:08, 52.52it/s, est. speed input: 94415.33 toks/s, output: 92.20 toks/s]  
Processed prompts:  13%|█▎        | 529/4096 [00:06<01:21, 43.71it/s, est. speed input: 82522.31 toks/s, output: 80.59 toks/s]
Processed prompts:  14%|█▎        | 561/4096 [00:07<01:32, 38.23it/s, est. speed input: 74225.85 toks/s, output: 72.49 toks/s]
Processed prompts:  14%|█▍        | 593/4096 [00:08<01:41, 34.65it/s, est. speed input: 68087.43 toks/s, output: 66.49 toks/s]
Processed prompts:  15%|█▌        | 625/4096 [00:10<01:47, 32.29it/s, est. speed input: 63388.07 toks/s, output: 61.90 toks/s]
Processed prompts:  16%|█▌        | 657/4096 [00:11<01:51, 30.72it/s, est. speed input: 59687.28 toks/s, output: 58.29 toks/s]
Processed prompts:  17%|█▋        | 689/4096 [00:12<01:55, 29.63it/s, est. speed input: 56671.08 toks/s, output: 55.34 toks/s]
Processed prompts:  18%|█▊        | 721/4096 [00:13<01:56, 28.86it/s, est. speed input: 54169.64 toks/s, output: 52.90 toks/s]
Processed prompts:  18%|█▊        | 753/4096 [00:14<01:58, 28.32it/s, est. speed input: 52060.72 toks/s, output: 50.84 toks/s]
Processed prompts:  19%|█▉        | 785/4096 [00:15<01:57, 28.22it/s, est. speed input: 50381.68 toks/s, output: 49.20 toks/s]
Processed prompts:  20%|█▉        | 817/4096 [00:17<01:57, 27.87it/s, est. speed input: 48819.03 toks/s, output: 47.67 toks/s]
Processed prompts:  21%|██        | 849/4096 [00:18<01:57, 27.62it/s, est. speed input: 47455.34 toks/s, output: 46.34 toks/s]
Processed prompts:  22%|██▏       | 881/4096 [00:19<01:57, 27.45it/s, est. speed input: 46257.44 toks/s, output: 45.17 toks/s]
Processed prompts:  22%|██▏       | 913/4096 [00:20<01:56, 27.32it/s, est. speed input: 45194.58 toks/s, output: 44.14 toks/s]
Processed prompts:  23%|██▎       | 945/4096 [00:21<01:55, 27.24it/s, est. speed input: 44247.12 toks/s, output: 43.21 toks/s]
Processed prompts:  24%|██▍       | 977/4096 [00:23<01:54, 27.17it/s, est. speed input: 43394.82 toks/s, output: 42.38 toks/s]
Processed prompts:  25%|██▍       | 1009/4096 [00:24<01:53, 27.12it/s, est. speed input: 42624.97 toks/s, output: 41.63 toks/s]
Processed prompts:  25%|██▌       | 1041/4096 [00:25<01:52, 27.07it/s, est. speed input: 41923.69 toks/s, output: 40.94 toks/s]
Processed prompts:  26%|██▌       | 1073/4096 [00:26<01:51, 27.04it/s, est. speed input: 41285.36 toks/s, output: 40.32 toks/s]
Processed prompts:  27%|██▋       | 1105/4096 [00:27<01:50, 27.04it/s, est. speed input: 40706.48 toks/s, output: 39.75 toks/s]
Processed prompts:  28%|██▊       | 1137/4096 [00:28<01:49, 27.01it/s, est. speed input: 40168.94 toks/s, output: 39.23 toks/s]
Processed prompts:  29%|██▊       | 1169/4096 [00:30<01:48, 26.98it/s, est. speed input: 39671.53 toks/s, output: 38.74 toks/s]
Processed prompts:  29%|██▉       | 1201/4096 [00:31<01:46, 27.20it/s, est. speed input: 39255.89 toks/s, output: 38.34 toks/s]
Processed prompts:  30%|███       | 1233/4096 [00:32<01:44, 27.34it/s, est. speed input: 38866.86 toks/s, output: 37.96 toks/s]
Processed prompts:  31%|███       | 1265/4096 [00:33<01:44, 27.22it/s, est. speed input: 38469.35 toks/s, output: 37.57 toks/s]
Processed prompts:  32%|███▏      | 1297/4096 [00:34<01:43, 27.13it/s, est. speed input: 38098.12 toks/s, output: 37.21 toks/s]
Processed prompts:  32%|███▏      | 1329/4096 [00:36<01:41, 27.31it/s, est. speed input: 37787.64 toks/s, output: 36.90 toks/s]
Processed prompts:  33%|███▎      | 1361/4096 [00:37<01:40, 27.18it/s, est. speed input: 37459.02 toks/s, output: 36.58 toks/s]
Processed prompts:  34%|███▍      | 1393/4096 [00:38<01:39, 27.08it/s, est. speed input: 37150.16 toks/s, output: 36.28 toks/s]
Processed prompts:  35%|███▍      | 1425/4096 [00:39<01:38, 27.00it/s, est. speed input: 36857.23 toks/s, output: 35.99 toks/s]
Processed prompts:  36%|███▌      | 1457/4096 [00:40<01:37, 27.19it/s, est. speed input: 36614.88 toks/s, output: 35.76 toks/s]
Processed prompts:  36%|███▋      | 1489/4096 [00:41<01:36, 27.10it/s, est. speed input: 36357.38 toks/s, output: 35.51 toks/s]
Processed prompts:  37%|███▋      | 1521/4096 [00:43<01:34, 27.27it/s, est. speed input: 36142.34 toks/s, output: 35.30 toks/s]
Processed prompts:  38%|███▊      | 1553/4096 [00:44<01:32, 27.39it/s, est. speed input: 35937.69 toks/s, output: 35.10 toks/s]
Processed prompts:  39%|███▊      | 1585/4096 [00:45<01:32, 27.21it/s, est. speed input: 35715.36 toks/s, output: 34.88 toks/s]
Processed prompts:  39%|███▉      | 1617/4096 [00:46<01:30, 27.40it/s, est. speed input: 35537.59 toks/s, output: 34.70 toks/s]
Processed prompts:  40%|████      | 1649/4096 [00:47<01:29, 27.24it/s, est. speed input: 35337.70 toks/s, output: 34.51 toks/s]
Processed prompts:  41%|████      | 1681/4096 [00:48<01:29, 27.11it/s, est. speed input: 35145.92 toks/s, output: 34.32 toks/s]
Processed prompts:  42%|████▏     | 1713/4096 [00:50<01:27, 27.25it/s, est. speed input: 34986.38 toks/s, output: 34.17 toks/s]
Processed prompts:  43%|████▎     | 1745/4096 [00:51<01:25, 27.38it/s, est. speed input: 34836.45 toks/s, output: 34.02 toks/s]
Processed prompts:  43%|████▎     | 1777/4096 [00:52<01:25, 27.17it/s, est. speed input: 34665.39 toks/s, output: 33.85 toks/s]
Processed prompts:  44%|████▍     | 1809/4096 [00:53<01:24, 27.06it/s, est. speed input: 34505.15 toks/s, output: 33.70 toks/s]
Processed prompts:  45%|████▍     | 1841/4096 [00:54<01:23, 26.97it/s, est. speed input: 34350.54 toks/s, output: 33.55 toks/s]
Processed prompts:  46%|████▌     | 1873/4096 [00:56<01:21, 27.19it/s, est. speed input: 34227.47 toks/s, output: 33.43 toks/s]
Processed prompts:  47%|████▋     | 1905/4096 [00:57<01:20, 27.12it/s, est. speed input: 34090.36 toks/s, output: 33.29 toks/s]
Processed prompts:  47%|████▋     | 1937/4096 [00:58<01:19, 27.06it/s, est. speed input: 33957.22 toks/s, output: 33.16 toks/s]
Processed prompts:  48%|████▊     | 1969/4096 [00:59<01:18, 27.27it/s, est. speed input: 33850.34 toks/s, output: 33.06 toks/s]
Processed prompts:  49%|████▉     | 2001/4096 [01:00<01:17, 27.17it/s, est. speed input: 33727.97 toks/s, output: 32.94 toks/s]
Processed prompts:  50%|████▉     | 2033/4096 [01:01<01:16, 27.09it/s, est. speed input: 33609.09 toks/s, output: 32.82 toks/s]
Processed prompts:  50%|█████     | 2065/4096 [01:03<01:14, 27.30it/s, est. speed input: 33515.49 toks/s, output: 32.73 toks/s]
Processed prompts:  51%|█████     | 2097/4096 [01:04<01:13, 27.18it/s, est. speed input: 33405.33 toks/s, output: 32.62 toks/s]
Processed prompts:  52%|█████▏    | 2129/4096 [01:05<01:12, 27.09it/s, est. speed input: 33298.26 toks/s, output: 32.52 toks/s]
Processed prompts:  53%|█████▎    | 2161/4096 [01:06<01:11, 27.02it/s, est. speed input: 33194.69 toks/s, output: 32.42 toks/s]
Processed prompts:  54%|█████▎    | 2193/4096 [01:07<01:09, 27.19it/s, est. speed input: 33110.59 toks/s, output: 32.33 toks/s]
Processed prompts:  54%|█████▍    | 2225/4096 [01:09<01:09, 27.07it/s, est. speed input: 33012.52 toks/s, output: 32.24 toks/s]
Processed prompts:  55%|█████▌    | 2257/4096 [01:10<01:08, 27.00it/s, est. speed input: 32918.10 toks/s, output: 32.15 toks/s]
Processed prompts:  56%|█████▌    | 2289/4096 [01:11<01:07, 26.94it/s, est. speed input: 32826.91 toks/s, output: 32.06 toks/s]
Processed prompts:  57%|█████▋    | 2321/4096 [01:12<01:05, 26.91it/s, est. speed input: 32739.09 toks/s, output: 31.97 toks/s]
Processed prompts:  57%|█████▋    | 2353/4096 [01:13<01:04, 26.88it/s, est. speed input: 32653.88 toks/s, output: 31.89 toks/s]
Processed prompts:  58%|█████▊    | 2385/4096 [01:14<01:03, 26.87it/s, est. speed input: 32571.37 toks/s, output: 31.81 toks/s]
Processed prompts:  59%|█████▉    | 2417/4096 [01:16<01:02, 26.87it/s, est. speed input: 32492.41 toks/s, output: 31.73 toks/s]
Processed prompts:  60%|█████▉    | 2449/4096 [01:17<01:01, 26.86it/s, est. speed input: 32415.42 toks/s, output: 31.66 toks/s]
Processed prompts:  61%|██████    | 2481/4096 [01:18<01:00, 26.85it/s, est. speed input: 32340.28 toks/s, output: 31.58 toks/s]
Processed prompts:  61%|██████▏   | 2513/4096 [01:19<00:58, 26.84it/s, est. speed input: 32267.10 toks/s, output: 31.51 toks/s]
Processed prompts:  62%|██████▏   | 2545/4096 [01:20<00:57, 27.07it/s, est. speed input: 32210.20 toks/s, output: 31.46 toks/s]
Processed prompts:  63%|██████▎   | 2577/4096 [01:22<00:55, 27.22it/s, est. speed input: 32153.94 toks/s, output: 31.40 toks/s]
Processed prompts:  64%|██████▎   | 2609/4096 [01:23<00:54, 27.09it/s, est. speed input: 32086.38 toks/s, output: 31.33 toks/s]
Processed prompts:  64%|██████▍   | 2641/4096 [01:24<00:53, 27.01it/s, est. speed input: 32021.03 toks/s, output: 31.27 toks/s]
Processed prompts:  65%|██████▌   | 2673/4096 [01:25<00:52, 26.95it/s, est. speed input: 31957.55 toks/s, output: 31.21 toks/s]
Processed prompts:  66%|██████▌   | 2705/4096 [01:26<00:51, 26.91it/s, est. speed input: 31895.55 toks/s, output: 31.15 toks/s]
Processed prompts:  67%|██████▋   | 2737/4096 [01:28<00:50, 27.10it/s, est. speed input: 31846.93 toks/s, output: 31.10 toks/s]
Processed prompts:  68%|██████▊   | 2769/4096 [01:29<00:49, 26.98it/s, est. speed input: 31786.62 toks/s, output: 31.04 toks/s]
Processed prompts:  68%|██████▊   | 2801/4096 [01:30<00:48, 26.91it/s, est. speed input: 31728.41 toks/s, output: 30.98 toks/s]
Processed prompts:  69%|██████▉   | 2833/4096 [01:31<00:47, 26.85it/s, est. speed input: 31671.38 toks/s, output: 30.93 toks/s]
Processed prompts:  70%|██████▉   | 2865/4096 [01:32<00:45, 26.83it/s, est. speed input: 31616.58 toks/s, output: 30.88 toks/s]
Processed prompts:  71%|███████   | 2897/4096 [01:33<00:43, 27.50it/s, est. speed input: 31596.53 toks/s, output: 30.86 toks/s]
Processed prompts:  72%|███████▏  | 2929/4096 [01:35<00:42, 27.26it/s, est. speed input: 31543.20 toks/s, output: 30.80 toks/s]
Processed prompts:  72%|███████▏  | 2961/4096 [01:36<00:41, 27.10it/s, est. speed input: 31491.37 toks/s, output: 30.75 toks/s]
Processed prompts:  73%|███████▎  | 2993/4096 [01:37<00:40, 27.00it/s, est. speed input: 31441.39 toks/s, output: 30.70 toks/s]
Processed prompts:  74%|███████▍  | 3025/4096 [01:38<00:39, 26.91it/s, est. speed input: 31391.67 toks/s, output: 30.66 toks/s]
Processed prompts:  75%|███████▍  | 3057/4096 [01:39<00:38, 26.84it/s, est. speed input: 31342.56 toks/s, output: 30.61 toks/s]
Processed prompts:  75%|███████▌  | 3089/4096 [01:41<00:37, 26.81it/s, est. speed input: 31295.79 toks/s, output: 30.56 toks/s]
Processed prompts:  76%|███████▌  | 3121/4096 [01:42<00:36, 26.77it/s, est. speed input: 31249.18 toks/s, output: 30.52 toks/s]
Processed prompts:  77%|███████▋  | 3153/4096 [01:43<00:35, 26.75it/s, est. speed input: 31204.05 toks/s, output: 30.47 toks/s]
Processed prompts:  78%|███████▊  | 3185/4096 [01:44<00:34, 26.74it/s, est. speed input: 31160.02 toks/s, output: 30.43 toks/s]
Processed prompts:  79%|███████▊  | 3217/4096 [01:45<00:32, 26.73it/s, est. speed input: 31116.64 toks/s, output: 30.39 toks/s]
Processed prompts:  79%|███████▉  | 3249/4096 [01:47<00:31, 26.72it/s, est. speed input: 31074.52 toks/s, output: 30.35 toks/s]
Processed prompts:  80%|████████  | 3281/4096 [01:48<00:30, 26.72it/s, est. speed input: 31033.38 toks/s, output: 30.31 toks/s]
Processed prompts:  81%|████████  | 3313/4096 [01:49<00:29, 26.71it/s, est. speed input: 30992.62 toks/s, output: 30.27 toks/s]
Processed prompts:  82%|████████▏ | 3345/4096 [01:50<00:28, 26.70it/s, est. speed input: 30952.89 toks/s, output: 30.23 toks/s]
Processed prompts:  82%|████████▏ | 3377/4096 [01:51<00:26, 26.71it/s, est. speed input: 30914.54 toks/s, output: 30.19 toks/s]
Processed prompts:  83%|████████▎ | 3409/4096 [01:53<00:25, 26.71it/s, est. speed input: 30876.69 toks/s, output: 30.15 toks/s]
Processed prompts:  84%|████████▍ | 3441/4096 [01:54<00:24, 26.69it/s, est. speed input: 30839.04 toks/s, output: 30.12 toks/s]
Processed prompts:  85%|████████▍ | 3473/4096 [01:55<00:23, 26.71it/s, est. speed input: 30803.26 toks/s, output: 30.08 toks/s]
Processed prompts:  86%|████████▌ | 3505/4096 [01:56<00:22, 26.71it/s, est. speed input: 30768.03 toks/s, output: 30.05 toks/s]
Processed prompts:  86%|████████▋ | 3537/4096 [01:57<00:20, 26.96it/s, est. speed input: 30742.79 toks/s, output: 30.02 toks/s]
Processed prompts:  87%|████████▋ | 3569/4096 [01:59<00:19, 26.87it/s, est. speed input: 30708.23 toks/s, output: 29.99 toks/s]
Processed prompts:  88%|████████▊ | 3601/4096 [02:00<00:18, 26.81it/s, est. speed input: 30674.40 toks/s, output: 29.96 toks/s]
Processed prompts:  89%|████████▊ | 3633/4096 [02:01<00:17, 26.77it/s, est. speed input: 30641.05 toks/s, output: 29.92 toks/s]
Processed prompts:  89%|████████▉ | 3665/4096 [02:02<00:15, 26.97it/s, est. speed input: 30617.00 toks/s, output: 29.90 toks/s]
Processed prompts:  90%|█████████ | 3697/4096 [02:03<00:14, 26.87it/s, est. speed input: 30584.50 toks/s, output: 29.87 toks/s]
Processed prompts:  91%|█████████ | 3729/4096 [02:04<00:13, 26.81it/s, est. speed input: 30553.09 toks/s, output: 29.84 toks/s]
Processed prompts:  92%|█████████▏| 3761/4096 [02:06<00:12, 26.77it/s, est. speed input: 30522.38 toks/s, output: 29.81 toks/s]
Processed prompts:  93%|█████████▎| 3793/4096 [02:07<00:11, 26.73it/s, est. speed input: 30491.89 toks/s, output: 29.78 toks/s]
Processed prompts:  93%|█████████▎| 3825/4096 [02:08<00:10, 26.71it/s, est. speed input: 30462.05 toks/s, output: 29.75 toks/s]
Processed prompts:  94%|█████████▍| 3857/4096 [02:09<00:08, 26.69it/s, est. speed input: 30432.46 toks/s, output: 29.72 toks/s]
Processed prompts:  95%|█████████▍| 3889/4096 [02:10<00:07, 26.68it/s, est. speed input: 30403.67 toks/s, output: 29.69 toks/s]
Processed prompts:  96%|█████████▌| 3921/4096 [02:12<00:06, 27.11it/s, est. speed input: 30390.45 toks/s, output: 29.68 toks/s]
Processed prompts:  97%|█████████▋| 3953/4096 [02:13<00:05, 26.96it/s, est. speed input: 30362.15 toks/s, output: 29.65 toks/s]
Processed prompts:  97%|█████████▋| 3985/4096 [02:14<00:04, 27.12it/s, est. speed input: 30343.12 toks/s, output: 29.63 toks/s]
Processed prompts:  98%|█████████▊| 4017/4096 [02:15<00:02, 26.97it/s, est. speed input: 30315.81 toks/s, output: 29.61 toks/s]
Processed prompts:  99%|█████████▉| 4049/4096 [02:16<00:01, 27.14it/s, est. speed input: 30297.86 toks/s, output: 29.59 toks/s]
Processed prompts: 100%|█████████▉| 4081/4096 [02:17<00:00, 32.18it/s, est. speed input: 30412.19 toks/s, output: 29.70 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:17<00:00, 32.18it/s, est. speed input: 30523.86 toks/s, output: 29.81 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:17<00:00, 29.81it/s, est. speed input: 30523.86 toks/s, output: 29.81 toks/s]
[rank0]:[W125 20:23:06.748487344 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 230.7s

测试结果:
  Requests/s:   27.07
  Tokens/s:     27743.75
  Total Reqs:   4096
  Elapsed:      151.33s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     27716.68

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:24:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=413325) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=413325) WARNING 01-25 20:24:33 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     def forward(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     raise e
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/tmp/torchinductor_root/ie/ciemksipb2utubwo6wdej2lrgrjtv5bidk3nxdd4qcpvjvpboent.py", line 1093, in call
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 8)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) ERROR 01-25 20:24:44 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-25 20:24:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:24:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:24:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:24:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:24:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:24:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:24:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:24:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:24:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:24:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:24:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:24:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=413325) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=413325) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=413325) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.34it/s]
(EngineCore_DP0 pid=413325) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.33it/s]
(EngineCore_DP0 pid=413325) 
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=413325) [2026-01-25 20:24:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=413325) [rank0]:W0125 20:24:41.980000 413325 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=413325) [rank0]:W0125 20:24:42.091000 413325 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=413325) [rank0]:W0125 20:24:43.509000 413325 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=413325) [rank0]:W0125 20:24:43.692000 413325 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=413325) Process EngineCore_DP0:
(EngineCore_DP0 pid=413325) Traceback (most recent call last):
(EngineCore_DP0 pid=413325)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=413325)     self.run()
(EngineCore_DP0 pid=413325)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=413325)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=413325)     raise e
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=413325)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=413325)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=413325)     super().__init__(
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=413325)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=413325)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=413325)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=413325)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=413325)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=413325)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=413325)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=413325)     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=413325)     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=413325)     self.model_runner.profile_run()
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=413325)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=413325)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=413325)     return func(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=413325)     outputs = self.model(
(EngineCore_DP0 pid=413325)               ^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=413325)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=413325)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=413325)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=413325)     hidden_states = self.model(
(EngineCore_DP0 pid=413325)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=413325)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=413325)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=413325)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=413325)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=413325)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=413325)     def forward(
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=413325)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=413325)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=413325)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=413325)     raise e
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=413325)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=413325)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=413325)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=413325)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=413325)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=413325)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=413325)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=413325)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=413325)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=413325)     return compiled_fn(full_args)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=413325)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=413325)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=413325)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=413325)                             ^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=413325)     outs = compiled_fn(args)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=413325)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=413325)     return self.current_callable(inputs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=413325)     out = model(new_inputs)
(EngineCore_DP0 pid=413325)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/tmp/torchinductor_root/ie/ciemksipb2utubwo6wdej2lrgrjtv5bidk3nxdd4qcpvjvpboent.py", line 1093, in call
(EngineCore_DP0 pid=413325)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 8)
(EngineCore_DP0 pid=413325)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=413325)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=413325)     return fn(input, L)
(EngineCore_DP0 pid=413325)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=413325)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=413325)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=413325)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=413325)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=413325)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=413325)     self._init_handles()
(EngineCore_DP0 pid=413325)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=413325)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=413325)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=413325) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W125 20:24:45.517863540 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,22.1227,11348.9226,5.7859
1024,1024,1,128,128,20.7125,21230.3495,6.1798
2048,1024,2,256,128,24.4281,25038.7629,10.4798
4096,1024,4,512,128,26.0162,26666.6041,19.6800
8192,1024,8,1024,128,26.7657,27434.8134,38.2580
16384,1024,16,2048,128,27.1969,27876.8113,75.3027
32768,1024,32,4096,128,27.0671,27743.7515,151.3278
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:24:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=414106) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=414106) WARNING 01-25 20:35:38 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.55 requests/s, 11055.08 total tokens/s, 21.55 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:24:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:24:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:24:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:24:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:24:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:24:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:24:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:24:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:25:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:25:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:25:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:25:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:25:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:25:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:25:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:25:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:25:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=414106) [2026-01-25 20:25:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=414106) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=414106) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [06:07<06:07, 367.85s/it]
(EngineCore_DP0 pid=414106) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [10:25<00:00, 302.80s/it]
(EngineCore_DP0 pid=414106) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [10:25<00:00, 312.55s/it]
(EngineCore_DP0 pid=414106) 
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=414106) [2026-01-25 20:35:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=414106) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.41it/s]
(EngineCore_DP0 pid=414106) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 10.05it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 48/128 [00:00<00:00, 473.75it/s]
Adding requests:  76%|███████▌  | 97/128 [00:00<00:00, 481.01it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 479.99it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:20,  6.31it/s, est. speed input: 3233.74 toks/s, output: 6.31 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:08, 15.47it/s, est. speed input: 7142.82 toks/s, output: 13.95 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:06, 18.70it/s, est. speed input: 8570.42 toks/s, output: 16.74 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 20.14it/s, est. speed input: 9271.35 toks/s, output: 18.11 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 21.43it/s, est. speed input: 9822.26 toks/s, output: 19.18 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 21.98it/s, est. speed input: 10141.78 toks/s, output: 19.81 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:04, 22.32it/s, est. speed input: 10371.05 toks/s, output: 20.26 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:04, 22.90it/s, est. speed input: 10606.11 toks/s, output: 20.71 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:04, 23.11it/s, est. speed input: 10763.63 toks/s, output: 21.02 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:04, 23.41it/s, est. speed input: 10912.86 toks/s, output: 21.31 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:04, 23.61it/s, est. speed input: 11035.81 toks/s, output: 21.55 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:04, 23.40it/s, est. speed input: 11094.19 toks/s, output: 21.67 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:03, 23.25it/s, est. speed input: 11143.33 toks/s, output: 21.76 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:03, 23.49it/s, est. speed input: 11223.90 toks/s, output: 21.92 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:01<00:03, 22.70it/s, est. speed input: 11191.49 toks/s, output: 21.86 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:03, 22.41it/s, est. speed input: 11188.76 toks/s, output: 21.85 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:03, 22.29it/s, est. speed input: 11193.81 toks/s, output: 21.86 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:03, 22.52it/s, est. speed input: 11227.71 toks/s, output: 21.93 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:03, 22.71it/s, est. speed input: 11260.83 toks/s, output: 21.99 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:03, 22.44it/s, est. speed input: 11255.96 toks/s, output: 21.98 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:02, 22.67it/s, est. speed input: 11285.56 toks/s, output: 22.04 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:02<00:02, 22.49it/s, est. speed input: 11286.73 toks/s, output: 22.04 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:02, 22.70it/s, est. speed input: 11312.18 toks/s, output: 22.09 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:02, 22.84it/s, est. speed input: 11334.57 toks/s, output: 22.14 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:02, 22.96it/s, est. speed input: 11356.86 toks/s, output: 22.18 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 23.02it/s, est. speed input: 11376.17 toks/s, output: 22.22 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:02, 23.15it/s, est. speed input: 11398.83 toks/s, output: 22.26 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:02, 22.38it/s, est. speed input: 11369.10 toks/s, output: 22.21 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 22.44it/s, est. speed input: 11375.34 toks/s, output: 22.22 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 22.72it/s, est. speed input: 11395.21 toks/s, output: 22.26 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 23.01it/s, est. speed input: 11418.19 toks/s, output: 22.30 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 23.09it/s, est. speed input: 11433.69 toks/s, output: 22.33 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 23.23it/s, est. speed input: 11452.10 toks/s, output: 22.37 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 23.25it/s, est. speed input: 11465.74 toks/s, output: 22.39 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 23.33it/s, est. speed input: 11481.75 toks/s, output: 22.43 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:00, 23.20it/s, est. speed input: 11488.68 toks/s, output: 22.44 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:04<00:00, 23.48it/s, est. speed input: 11511.31 toks/s, output: 22.48 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 23.66it/s, est. speed input: 11531.77 toks/s, output: 22.52 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 23.61it/s, est. speed input: 11544.29 toks/s, output: 22.55 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 23.29it/s, est. speed input: 11544.58 toks/s, output: 22.55 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 22.99it/s, est. speed input: 11541.75 toks/s, output: 22.54 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 23.00it/s, est. speed input: 11547.57 toks/s, output: 22.55 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:05<00:00, 23.04it/s, est. speed input: 11554.41 toks/s, output: 22.57 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 23.04it/s, est. speed input: 11554.93 toks/s, output: 22.57 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.57it/s, est. speed input: 11554.93 toks/s, output: 22.57 toks/s]
[rank0]:[W125 20:36:02.135970600 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 676.8s

测试结果:
  Requests/s:   21.55
  Tokens/s:     11055.08
  Total Reqs:   128
  Elapsed:      5.94s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     11033.53

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:36:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=423746) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=423746) WARNING 01-25 20:36:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.05 requests/s, 20556.28 total tokens/s, 20.05 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-25 20:36:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:36:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:36:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:36:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:36:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:36:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:36:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:36:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:36:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:36:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:36:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:36:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:36:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:36:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=423746) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=423746) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=423746) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=423746) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=423746) 
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=423746) [2026-01-25 20:36:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=423746) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.04it/s]
(EngineCore_DP0 pid=423746) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  9.16it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 241.10it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 252.55it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 269.72it/s]
Adding requests:  86%|████████▌ | 110/128 [00:00<00:00, 273.21it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 269.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:02, 57.94it/s, est. speed input: 59333.71 toks/s, output: 57.94 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:03, 30.06it/s, est. speed input: 33553.16 toks/s, output: 32.77 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:04, 26.29it/s, est. speed input: 29814.88 toks/s, output: 29.12 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:04, 24.64it/s, est. speed input: 28235.57 toks/s, output: 27.57 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:00<00:04, 23.49it/s, est. speed input: 27146.56 toks/s, output: 26.51 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:04, 22.59it/s, est. speed input: 26299.45 toks/s, output: 25.68 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:04, 22.11it/s, est. speed input: 25726.45 toks/s, output: 25.12 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:04, 21.76it/s, est. speed input: 25267.31 toks/s, output: 24.67 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:04, 21.50it/s, est. speed input: 24892.04 toks/s, output: 24.31 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:04, 21.33it/s, est. speed input: 24586.92 toks/s, output: 24.01 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:01<00:04, 21.18it/s, est. speed input: 24321.98 toks/s, output: 23.75 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:03, 21.06it/s, est. speed input: 24092.22 toks/s, output: 23.53 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:03, 21.00it/s, est. speed input: 23900.48 toks/s, output: 23.34 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:03, 20.91it/s, est. speed input: 23723.97 toks/s, output: 23.17 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:03, 20.94it/s, est. speed input: 23588.60 toks/s, output: 23.04 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 20.88it/s, est. speed input: 23452.09 toks/s, output: 22.90 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:02<00:03, 20.91it/s, est. speed input: 23344.74 toks/s, output: 22.80 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:02<00:03, 20.82it/s, est. speed input: 23228.71 toks/s, output: 22.68 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:02<00:02, 20.78it/s, est. speed input: 23125.77 toks/s, output: 22.58 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:02, 20.70it/s, est. speed input: 23024.68 toks/s, output: 22.48 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:02, 20.75it/s, est. speed input: 22951.11 toks/s, output: 22.41 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 20.83it/s, est. speed input: 22890.07 toks/s, output: 22.35 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:03<00:02, 20.76it/s, est. speed input: 22816.23 toks/s, output: 22.28 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:02, 20.80it/s, est. speed input: 22759.35 toks/s, output: 22.23 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:03<00:02, 20.80it/s, est. speed input: 22703.85 toks/s, output: 22.17 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:03<00:01, 20.76it/s, est. speed input: 22647.53 toks/s, output: 22.12 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:01, 20.72it/s, est. speed input: 22592.93 toks/s, output: 22.06 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 20.68it/s, est. speed input: 22541.18 toks/s, output: 22.01 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:04<00:01, 20.76it/s, est. speed input: 22504.63 toks/s, output: 21.98 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 20.73it/s, est. speed input: 22461.19 toks/s, output: 21.93 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:04<00:01, 20.76it/s, est. speed input: 22426.36 toks/s, output: 21.90 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:04<00:01, 20.80it/s, est. speed input: 22395.47 toks/s, output: 21.87 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:00, 20.83it/s, est. speed input: 22366.93 toks/s, output: 21.84 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:00, 20.90it/s, est. speed input: 22344.11 toks/s, output: 21.82 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 20.89it/s, est. speed input: 22317.27 toks/s, output: 21.79 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 20.86it/s, est. speed input: 22290.00 toks/s, output: 21.77 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:05<00:00, 20.73it/s, est. speed input: 22253.28 toks/s, output: 21.73 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:05<00:00, 20.79it/s, est. speed input: 22232.82 toks/s, output: 21.71 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:05<00:00, 20.83it/s, est. speed input: 22212.55 toks/s, output: 21.69 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 20.83it/s, est. speed input: 22195.64 toks/s, output: 21.68 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.67it/s, est. speed input: 22195.64 toks/s, output: 21.68 toks/s]
[rank0]:[W125 20:36:56.559213275 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 53.5s

测试结果:
  Requests/s:   20.05
  Tokens/s:     20556.28
  Total Reqs:   128
  Elapsed:      6.38s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     20536.23

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:37:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=424737) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=424737) WARNING 01-25 20:37:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.29 requests/s, 23875.82 total tokens/s, 23.29 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-25 20:37:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:37:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:37:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:37:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:37:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:37:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:37:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:37:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:37:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:37:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:37:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:37:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:37:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:37:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=424737) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=424737) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=424737) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
(EngineCore_DP0 pid=424737) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.27it/s]
(EngineCore_DP0 pid=424737) 
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=424737) [2026-01-25 20:37:18] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=424737) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00, 11.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00, 10.60it/s]
(EngineCore_DP0 pid=424737) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 10.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00, 10.92it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 27/256 [00:00<00:00, 264.59it/s]
Adding requests:  21%|██        | 54/256 [00:00<00:00, 261.90it/s]
Adding requests:  33%|███▎      | 85/256 [00:00<00:00, 281.70it/s]
Adding requests:  45%|████▍     | 114/256 [00:00<00:00, 275.12it/s]
Adding requests:  56%|█████▋    | 144/256 [00:00<00:00, 282.23it/s]
Adding requests:  69%|██████▉   | 176/256 [00:00<00:00, 293.28it/s]
Adding requests:  81%|████████▏ | 208/256 [00:00<00:00, 299.11it/s]
Adding requests:  94%|█████████▍| 240/256 [00:00<00:00, 303.53it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 290.95it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:00<00:01, 167.47it/s, est. speed input: 171511.49 toks/s, output: 167.48 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:00<00:05, 41.70it/s, est. speed input: 48919.78 toks/s, output: 47.77 toks/s]   
Processed prompts:  19%|█▉        | 48/256 [00:01<00:06, 32.58it/s, est. speed input: 39485.20 toks/s, output: 38.56 toks/s]
Processed prompts:  21%|██        | 54/256 [00:01<00:06, 30.05it/s, est. speed input: 36819.84 toks/s, output: 35.96 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:01<00:06, 29.85it/s, est. speed input: 36096.01 toks/s, output: 35.25 toks/s]
Processed prompts:  25%|██▍       | 63/256 [00:01<00:06, 28.38it/s, est. speed input: 34972.95 toks/s, output: 34.15 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:02<00:06, 27.15it/s, est. speed input: 34032.63 toks/s, output: 33.23 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:02<00:07, 24.62it/s, est. speed input: 32763.32 toks/s, output: 32.00 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:02<00:07, 24.28it/s, est. speed input: 32122.44 toks/s, output: 31.37 toks/s]
Processed prompts:  30%|███       | 78/256 [00:02<00:07, 23.99it/s, est. speed input: 31554.90 toks/s, output: 30.82 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:02<00:07, 23.79it/s, est. speed input: 31065.72 toks/s, output: 30.34 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:02<00:07, 23.64it/s, est. speed input: 30634.44 toks/s, output: 29.92 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:07, 23.58it/s, est. speed input: 30261.64 toks/s, output: 29.55 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:03<00:06, 23.45it/s, est. speed input: 29908.89 toks/s, output: 29.21 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:06, 23.40it/s, est. speed input: 29602.32 toks/s, output: 28.91 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:03<00:06, 23.37it/s, est. speed input: 29325.11 toks/s, output: 28.64 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:03<00:06, 23.40it/s, est. speed input: 29083.26 toks/s, output: 28.40 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:03<00:06, 23.35it/s, est. speed input: 28850.32 toks/s, output: 28.17 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:04<00:06, 23.38it/s, est. speed input: 28646.85 toks/s, output: 27.98 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:04<00:05, 23.27it/s, est. speed input: 28440.15 toks/s, output: 27.77 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:04<00:05, 23.26it/s, est. speed input: 28258.29 toks/s, output: 27.60 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:04<00:05, 23.26it/s, est. speed input: 28092.11 toks/s, output: 27.43 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:04<00:05, 23.30it/s, est. speed input: 27944.02 toks/s, output: 27.29 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:04<00:05, 23.29it/s, est. speed input: 27800.26 toks/s, output: 27.15 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:05<00:05, 23.33it/s, est. speed input: 27672.71 toks/s, output: 27.02 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:05<00:04, 23.31it/s, est. speed input: 27547.60 toks/s, output: 26.90 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:05<00:04, 23.31it/s, est. speed input: 27431.37 toks/s, output: 26.79 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:05<00:04, 23.32it/s, est. speed input: 27323.48 toks/s, output: 26.68 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:05<00:04, 23.33it/s, est. speed input: 27222.98 toks/s, output: 26.58 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:05<00:04, 23.35it/s, est. speed input: 27128.96 toks/s, output: 26.49 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:06<00:04, 23.29it/s, est. speed input: 27033.37 toks/s, output: 26.40 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:06<00:03, 23.29it/s, est. speed input: 26946.14 toks/s, output: 26.31 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:06<00:03, 23.28it/s, est. speed input: 26863.67 toks/s, output: 26.23 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:06<00:03, 23.28it/s, est. speed input: 26785.06 toks/s, output: 26.16 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:06<00:03, 23.28it/s, est. speed input: 26710.94 toks/s, output: 26.08 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:06<00:03, 23.31it/s, est. speed input: 26643.59 toks/s, output: 26.02 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:07<00:03, 23.29it/s, est. speed input: 26574.96 toks/s, output: 25.95 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:07<00:02, 23.29it/s, est. speed input: 26510.97 toks/s, output: 25.89 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:07<00:02, 23.25it/s, est. speed input: 26446.56 toks/s, output: 25.83 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:07<00:02, 23.28it/s, est. speed input: 26390.41 toks/s, output: 25.77 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:07<00:02, 24.57it/s, est. speed input: 26435.59 toks/s, output: 25.82 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:07<00:02, 24.19it/s, est. speed input: 26381.67 toks/s, output: 25.76 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:08<00:01, 23.97it/s, est. speed input: 26332.77 toks/s, output: 25.72 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:08<00:01, 23.72it/s, est. speed input: 26277.99 toks/s, output: 25.66 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:08<00:01, 23.61it/s, est. speed input: 26230.86 toks/s, output: 25.62 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:08<00:01, 23.49it/s, est. speed input: 26182.25 toks/s, output: 25.57 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:08<00:01, 23.41it/s, est. speed input: 26135.40 toks/s, output: 25.52 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:09<00:01, 23.34it/s, est. speed input: 26089.65 toks/s, output: 25.48 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:09<00:00, 23.31it/s, est. speed input: 26046.35 toks/s, output: 25.44 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:09<00:00, 23.29it/s, est. speed input: 26005.54 toks/s, output: 25.40 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:09<00:00, 23.30it/s, est. speed input: 25967.56 toks/s, output: 25.36 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:09<00:00, 23.28it/s, est. speed input: 25929.07 toks/s, output: 25.32 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:09<00:00, 23.26it/s, est. speed input: 25891.34 toks/s, output: 25.28 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:10<00:00, 23.28it/s, est. speed input: 25857.15 toks/s, output: 25.25 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 23.28it/s, est. speed input: 25931.97 toks/s, output: 25.32 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 25.32it/s, est. speed input: 25931.97 toks/s, output: 25.32 toks/s]
[rank0]:[W125 20:37:55.147646195 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 59.6s

测试结果:
  Requests/s:   23.29
  Tokens/s:     23875.82
  Total Reqs:   256
  Elapsed:      10.99s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     23852.53

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:38:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=425839) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=425839) WARNING 01-25 20:38:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.84 requests/s, 25462.42 total tokens/s, 24.84 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-25 20:38:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:38:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:38:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:38:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:38:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:38:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:38:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:38:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:38:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:38:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:38:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:38:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:38:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:38:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:38:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:38:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:38:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=425839) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=425839) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.28it/s]
(EngineCore_DP0 pid=425839) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
(EngineCore_DP0 pid=425839) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.24it/s]
(EngineCore_DP0 pid=425839) 
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=425839) [2026-01-25 20:38:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=425839) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 11.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00, 10.47it/s]
(EngineCore_DP0 pid=425839) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  9.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.28it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00, 11.12it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 27/512 [00:00<00:01, 255.23it/s]
Adding requests:  10%|█         | 53/512 [00:00<00:01, 250.69it/s]
Adding requests:  16%|█▌        | 80/512 [00:00<00:01, 258.30it/s]
Adding requests:  21%|██        | 107/512 [00:00<00:01, 262.47it/s]
Adding requests:  27%|██▋       | 136/512 [00:00<00:01, 268.35it/s]
Adding requests:  33%|███▎      | 167/512 [00:00<00:01, 278.88it/s]
Adding requests:  39%|███▉      | 199/512 [00:00<00:01, 289.39it/s]
Adding requests:  45%|████▌     | 231/512 [00:00<00:00, 296.79it/s]
Adding requests:  51%|█████     | 261/512 [00:00<00:00, 292.94it/s]
Adding requests:  57%|█████▋    | 291/512 [00:01<00:00, 290.86it/s]
Adding requests:  63%|██████▎   | 323/512 [00:01<00:00, 297.67it/s]
Adding requests:  69%|██████▉   | 355/512 [00:01<00:00, 302.86it/s]
Adding requests:  75%|███████▌  | 386/512 [00:01<00:00, 301.32it/s]
Adding requests:  81%|████████▏ | 417/512 [00:01<00:00, 296.48it/s]
Adding requests:  87%|████████▋ | 447/512 [00:01<00:00, 289.78it/s]
Adding requests:  94%|█████████▍| 481/512 [00:01<00:00, 302.83it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 299.41it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 289.49it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:00<00:02, 196.04it/s, est. speed input: 200758.75 toks/s, output: 196.04 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:01<00:08, 53.84it/s, est. speed input: 64994.30 toks/s, output: 63.47 toks/s]   
Processed prompts:  15%|█▍        | 76/512 [00:01<00:09, 46.48it/s, est. speed input: 57121.11 toks/s, output: 55.78 toks/s]
Processed prompts:  16%|█▌        | 83/512 [00:01<00:11, 38.71it/s, est. speed input: 50467.63 toks/s, output: 49.28 toks/s]
Processed prompts:  17%|█▋        | 88/512 [00:01<00:11, 37.25it/s, est. speed input: 48806.14 toks/s, output: 47.66 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:02<00:11, 35.95it/s, est. speed input: 47432.68 toks/s, output: 46.32 toks/s]
Processed prompts:  19%|█▉        | 97/512 [00:02<00:12, 33.37it/s, est. speed input: 45783.71 toks/s, output: 44.71 toks/s]
Processed prompts:  20%|█▉        | 101/512 [00:02<00:13, 31.28it/s, est. speed input: 44382.04 toks/s, output: 43.34 toks/s]
Processed prompts:  21%|██        | 105/512 [00:02<00:13, 29.61it/s, est. speed input: 43159.44 toks/s, output: 42.15 toks/s]
Processed prompts:  21%|██        | 108/512 [00:02<00:15, 26.59it/s, est. speed input: 41680.54 toks/s, output: 40.70 toks/s]
Processed prompts:  22%|██▏       | 111/512 [00:02<00:16, 24.36it/s, est. speed input: 40384.82 toks/s, output: 39.44 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:02<00:17, 22.73it/s, est. speed input: 39232.19 toks/s, output: 38.31 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:16, 23.32it/s, est. speed input: 38516.26 toks/s, output: 37.61 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:03<00:16, 23.73it/s, est. speed input: 37869.09 toks/s, output: 36.98 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:03<00:16, 24.07it/s, est. speed input: 37294.39 toks/s, output: 36.42 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:03<00:15, 24.29it/s, est. speed input: 36765.58 toks/s, output: 35.90 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:03<00:15, 24.41it/s, est. speed input: 36272.90 toks/s, output: 35.42 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:15, 24.52it/s, est. speed input: 35826.41 toks/s, output: 34.99 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:15, 24.60it/s, est. speed input: 35415.85 toks/s, output: 34.59 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:04<00:14, 24.67it/s, est. speed input: 35039.75 toks/s, output: 34.22 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:04<00:14, 24.70it/s, est. speed input: 34686.99 toks/s, output: 33.87 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:14, 24.71it/s, est. speed input: 34357.09 toks/s, output: 33.55 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:14, 24.72it/s, est. speed input: 34050.86 toks/s, output: 33.25 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:14, 24.75it/s, est. speed input: 33767.67 toks/s, output: 32.98 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:13, 24.74it/s, est. speed input: 33497.15 toks/s, output: 32.71 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:05<00:13, 24.74it/s, est. speed input: 33244.98 toks/s, output: 32.47 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:05<00:13, 24.72it/s, est. speed input: 33005.94 toks/s, output: 32.23 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:05<00:13, 24.72it/s, est. speed input: 32781.66 toks/s, output: 32.01 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:13, 24.80it/s, est. speed input: 32580.34 toks/s, output: 31.82 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:13, 24.79it/s, est. speed input: 32381.69 toks/s, output: 31.62 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:06<00:12, 24.78it/s, est. speed input: 32194.10 toks/s, output: 31.44 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:06<00:12, 24.80it/s, est. speed input: 32019.21 toks/s, output: 31.27 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:06<00:12, 24.76it/s, est. speed input: 31847.15 toks/s, output: 31.10 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:06<00:11, 26.20it/s, est. speed input: 31830.83 toks/s, output: 31.08 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:11, 25.77it/s, est. speed input: 31675.79 toks/s, output: 30.93 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:11, 25.47it/s, est. speed input: 31526.79 toks/s, output: 30.79 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:11, 25.23it/s, est. speed input: 31382.31 toks/s, output: 30.65 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:07<00:11, 25.11it/s, est. speed input: 31248.19 toks/s, output: 30.52 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:07<00:11, 24.98it/s, est. speed input: 31115.33 toks/s, output: 30.39 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:11, 24.89it/s, est. speed input: 30989.05 toks/s, output: 30.26 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:11, 24.87it/s, est. speed input: 30871.16 toks/s, output: 30.15 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:11, 24.84it/s, est. speed input: 30757.02 toks/s, output: 30.04 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:11, 24.78it/s, est. speed input: 30644.37 toks/s, output: 29.93 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:10, 24.81it/s, est. speed input: 30541.91 toks/s, output: 29.83 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:08<00:10, 24.89it/s, est. speed input: 30448.26 toks/s, output: 29.73 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:08<00:10, 24.78it/s, est. speed input: 30345.41 toks/s, output: 29.63 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:10, 24.83it/s, est. speed input: 30255.78 toks/s, output: 29.55 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:10, 24.81it/s, est. speed input: 30165.72 toks/s, output: 29.46 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:08<00:10, 24.77it/s, est. speed input: 30076.42 toks/s, output: 29.37 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:09<00:09, 24.75it/s, est. speed input: 29991.53 toks/s, output: 29.29 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:09<00:09, 24.79it/s, est. speed input: 29912.88 toks/s, output: 29.21 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:09<00:09, 24.77it/s, est. speed input: 29834.08 toks/s, output: 29.13 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:09, 24.78it/s, est. speed input: 29759.07 toks/s, output: 29.06 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:09, 24.80it/s, est. speed input: 29687.79 toks/s, output: 28.99 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:09, 24.81it/s, est. speed input: 29618.15 toks/s, output: 28.92 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:08, 24.80it/s, est. speed input: 29549.89 toks/s, output: 28.86 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:10<00:08, 24.81it/s, est. speed input: 29485.06 toks/s, output: 28.79 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:10<00:08, 24.77it/s, est. speed input: 29419.04 toks/s, output: 28.73 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:08, 24.75it/s, est. speed input: 29355.91 toks/s, output: 28.67 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:07, 26.37it/s, est. speed input: 29385.98 toks/s, output: 28.70 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:07, 25.90it/s, est. speed input: 29327.73 toks/s, output: 28.64 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:10<00:07, 25.59it/s, est. speed input: 29271.81 toks/s, output: 28.59 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:11<00:07, 25.33it/s, est. speed input: 29214.48 toks/s, output: 28.53 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:07, 25.17it/s, est. speed input: 29160.15 toks/s, output: 28.48 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:07, 25.02it/s, est. speed input: 29105.04 toks/s, output: 28.42 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:07, 24.92it/s, est. speed input: 29051.82 toks/s, output: 28.37 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:11<00:07, 24.84it/s, est. speed input: 28999.47 toks/s, output: 28.32 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:11<00:07, 24.84it/s, est. speed input: 28951.26 toks/s, output: 28.27 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:12<00:06, 24.85it/s, est. speed input: 28905.25 toks/s, output: 28.23 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:06, 24.84it/s, est. speed input: 28859.31 toks/s, output: 28.18 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:06, 24.78it/s, est. speed input: 28812.18 toks/s, output: 28.14 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:12<00:06, 24.79it/s, est. speed input: 28768.30 toks/s, output: 28.09 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:12<00:06, 24.80it/s, est. speed input: 28726.06 toks/s, output: 28.05 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:12<00:06, 24.74it/s, est. speed input: 28681.60 toks/s, output: 28.01 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:13<00:05, 24.73it/s, est. speed input: 28639.88 toks/s, output: 27.97 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:05, 24.74it/s, est. speed input: 28599.74 toks/s, output: 27.93 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:05, 24.75it/s, est. speed input: 28560.88 toks/s, output: 27.89 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:13<00:05, 24.76it/s, est. speed input: 28522.80 toks/s, output: 27.85 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:13<00:05, 24.78it/s, est. speed input: 28486.68 toks/s, output: 27.82 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:13<00:05, 24.77it/s, est. speed input: 28449.95 toks/s, output: 27.78 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:14<00:04, 24.74it/s, est. speed input: 28413.27 toks/s, output: 27.75 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:04, 24.74it/s, est. speed input: 28378.03 toks/s, output: 27.71 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:04, 24.73it/s, est. speed input: 28343.67 toks/s, output: 27.68 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:14<00:04, 24.75it/s, est. speed input: 28310.90 toks/s, output: 27.65 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:14<00:04, 24.71it/s, est. speed input: 28276.34 toks/s, output: 27.61 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:14<00:04, 24.76it/s, est. speed input: 28246.15 toks/s, output: 27.58 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:03, 24.75it/s, est. speed input: 28214.48 toks/s, output: 27.55 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:03, 24.70it/s, est. speed input: 28182.12 toks/s, output: 27.52 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:15<00:03, 24.68it/s, est. speed input: 28150.67 toks/s, output: 27.49 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:15<00:03, 24.70it/s, est. speed input: 28121.43 toks/s, output: 27.46 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:15<00:03, 24.73it/s, est. speed input: 28093.29 toks/s, output: 27.43 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:15<00:02, 26.31it/s, est. speed input: 28122.62 toks/s, output: 27.46 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:15<00:02, 25.86it/s, est. speed input: 28095.96 toks/s, output: 27.44 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:16<00:02, 25.55it/s, est. speed input: 28069.35 toks/s, output: 27.41 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:16<00:02, 25.25it/s, est. speed input: 28040.44 toks/s, output: 27.38 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:16<00:02, 25.06it/s, est. speed input: 28012.63 toks/s, output: 27.36 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:16<00:02, 24.96it/s, est. speed input: 27986.54 toks/s, output: 27.33 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:16<00:02, 24.85it/s, est. speed input: 27959.41 toks/s, output: 27.30 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:16<00:02, 24.90it/s, est. speed input: 27937.08 toks/s, output: 27.28 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:17<00:01, 24.82it/s, est. speed input: 27911.51 toks/s, output: 27.26 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:17<00:01, 24.75it/s, est. speed input: 27885.82 toks/s, output: 27.23 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:17<00:01, 24.74it/s, est. speed input: 27861.85 toks/s, output: 27.21 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:17<00:01, 24.72it/s, est. speed input: 27837.79 toks/s, output: 27.19 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:17<00:01, 24.69it/s, est. speed input: 27813.90 toks/s, output: 27.16 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:17<00:01, 24.74it/s, est. speed input: 27792.50 toks/s, output: 27.14 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:18<00:00, 24.77it/s, est. speed input: 27771.57 toks/s, output: 27.12 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:18<00:00, 24.73it/s, est. speed input: 27748.83 toks/s, output: 27.10 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:18<00:00, 24.70it/s, est. speed input: 27726.71 toks/s, output: 27.08 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:18<00:00, 24.74it/s, est. speed input: 27706.71 toks/s, output: 27.06 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:18<00:00, 24.70it/s, est. speed input: 27684.86 toks/s, output: 27.04 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:18<00:00, 26.52it/s, est. speed input: 27718.79 toks/s, output: 27.07 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:18<00:00, 26.52it/s, est. speed input: 27827.27 toks/s, output: 27.18 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:18<00:00, 27.17it/s, est. speed input: 27827.27 toks/s, output: 27.18 toks/s]
[rank0]:[W125 20:39:07.497274139 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 71.3s

测试结果:
  Requests/s:   24.84
  Tokens/s:     25462.42
  Total Reqs:   512
  Elapsed:      20.61s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     25437.58

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:39:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=427118) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=427118) WARNING 01-25 20:39:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.54 requests/s, 26174.54 total tokens/s, 25.54 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-25 20:39:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:39:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:39:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:39:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:39:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:39:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:39:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:39:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:39:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:39:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:39:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:39:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:39:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:39:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=427118) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=427118) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=427118) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
(EngineCore_DP0 pid=427118) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
(EngineCore_DP0 pid=427118) 
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=427118) [2026-01-25 20:39:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=427118) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00, 10.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00, 11.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00, 10.71it/s]
(EngineCore_DP0 pid=427118) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00, 11.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, 11.37it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 27/1024 [00:00<00:03, 262.12it/s]
Adding requests:   6%|▌         | 58/1024 [00:00<00:03, 288.44it/s]
Adding requests:   9%|▊         | 88/1024 [00:00<00:03, 289.96it/s]
Adding requests:  12%|█▏        | 118/1024 [00:00<00:03, 290.90it/s]
Adding requests:  14%|█▍        | 148/1024 [00:00<00:03, 291.98it/s]
Adding requests:  17%|█▋        | 179/1024 [00:00<00:02, 295.76it/s]
Adding requests:  21%|██        | 210/1024 [00:00<00:02, 299.43it/s]
Adding requests:  23%|██▎       | 240/1024 [00:00<00:02, 298.78it/s]
Adding requests:  26%|██▋       | 270/1024 [00:00<00:02, 293.95it/s]
Adding requests:  29%|██▉       | 301/1024 [00:01<00:02, 297.88it/s]
Adding requests:  32%|███▏      | 332/1024 [00:01<00:02, 299.87it/s]
Adding requests:  36%|███▌      | 364/1024 [00:01<00:02, 305.77it/s]
Adding requests:  39%|███▊      | 396/1024 [00:01<00:02, 309.68it/s]
Adding requests:  42%|████▏     | 427/1024 [00:01<00:01, 309.50it/s]
Adding requests:  45%|████▍     | 458/1024 [00:01<00:01, 302.08it/s]
Adding requests:  48%|████▊     | 489/1024 [00:01<00:01, 302.85it/s]
Adding requests:  51%|█████     | 520/1024 [00:01<00:01, 303.85it/s]
Adding requests:  54%|█████▍    | 551/1024 [00:01<00:01, 297.98it/s]
Adding requests:  57%|█████▋    | 581/1024 [00:01<00:01, 295.02it/s]
Adding requests:  60%|█████▉    | 611/1024 [00:02<00:01, 289.91it/s]
Adding requests:  63%|██████▎   | 641/1024 [00:02<00:01, 288.36it/s]
Adding requests:  65%|██████▌   | 670/1024 [00:02<00:01, 283.17it/s]
Adding requests:  69%|██████▊   | 702/1024 [00:02<00:01, 292.50it/s]
Adding requests:  71%|███████▏  | 732/1024 [00:02<00:01, 288.93it/s]
Adding requests:  75%|███████▍  | 763/1024 [00:02<00:00, 293.19it/s]
Adding requests:  78%|███████▊  | 795/1024 [00:02<00:00, 300.50it/s]
Adding requests:  81%|████████  | 826/1024 [00:02<00:00, 298.68it/s]
Adding requests:  84%|████████▎ | 856/1024 [00:02<00:00, 298.84it/s]
Adding requests:  87%|████████▋ | 886/1024 [00:02<00:00, 296.15it/s]
Adding requests:  89%|████████▉ | 916/1024 [00:03<00:00, 286.29it/s]
Adding requests:  92%|█████████▏| 945/1024 [00:03<00:00, 282.50it/s]
Adding requests:  95%|█████████▌| 977/1024 [00:03<00:00, 291.52it/s]
Adding requests:  98%|█████████▊| 1007/1024 [00:03<00:00, 292.36it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 295.28it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:00<00:03, 261.23it/s, est. speed input: 267523.46 toks/s, output: 261.24 toks/s]
Processed prompts:  11%|█▏        | 117/1024 [00:01<00:11, 76.48it/s, est. speed input: 93588.24 toks/s, output: 91.39 toks/s]  
Processed prompts:  13%|█▎        | 130/1024 [00:01<00:17, 52.55it/s, est. speed input: 69966.61 toks/s, output: 68.33 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:02<00:19, 46.16it/s, est. speed input: 63768.51 toks/s, output: 62.27 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:02<00:21, 41.01it/s, est. speed input: 59143.85 toks/s, output: 57.76 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:02<00:23, 36.95it/s, est. speed input: 55535.06 toks/s, output: 54.23 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:03<00:25, 33.85it/s, est. speed input: 52636.58 toks/s, output: 51.40 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:03<00:27, 31.50it/s, est. speed input: 50238.34 toks/s, output: 49.06 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:03<00:28, 29.84it/s, est. speed input: 48265.40 toks/s, output: 47.13 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:04<00:29, 28.64it/s, est. speed input: 46594.73 toks/s, output: 45.50 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:04<00:29, 27.75it/s, est. speed input: 45148.38 toks/s, output: 44.09 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:04<00:29, 27.99it/s, est. speed input: 44204.19 toks/s, output: 43.17 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:04<00:29, 27.26it/s, est. speed input: 43075.39 toks/s, output: 42.07 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:05<00:30, 26.77it/s, est. speed input: 42085.43 toks/s, output: 41.10 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:05<00:30, 26.40it/s, est. speed input: 41197.82 toks/s, output: 40.23 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:05<00:30, 26.17it/s, est. speed input: 40410.61 toks/s, output: 39.46 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:06<00:30, 25.99it/s, est. speed input: 39697.48 toks/s, output: 38.77 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:06<00:29, 25.86it/s, est. speed input: 39052.53 toks/s, output: 38.14 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:06<00:29, 25.77it/s, est. speed input: 38465.60 toks/s, output: 37.56 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:07<00:29, 25.73it/s, est. speed input: 37933.58 toks/s, output: 37.04 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:07<00:29, 25.69it/s, est. speed input: 37445.38 toks/s, output: 36.57 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:07<00:28, 25.63it/s, est. speed input: 36989.90 toks/s, output: 36.12 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:28, 25.63it/s, est. speed input: 36576.93 toks/s, output: 35.72 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:28, 25.64it/s, est. speed input: 36195.72 toks/s, output: 35.35 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:08<00:27, 26.45it/s, est. speed input: 35972.65 toks/s, output: 35.13 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:27, 26.18it/s, est. speed input: 35632.81 toks/s, output: 34.80 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:27, 26.00it/s, est. speed input: 35316.42 toks/s, output: 34.49 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:09<00:26, 25.83it/s, est. speed input: 35015.00 toks/s, output: 34.19 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:09<00:26, 25.74it/s, est. speed input: 34736.29 toks/s, output: 33.92 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:10<00:26, 25.68it/s, est. speed input: 34474.94 toks/s, output: 33.67 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:10<00:26, 25.64it/s, est. speed input: 34229.50 toks/s, output: 33.43 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:10<00:25, 25.61it/s, est. speed input: 33996.51 toks/s, output: 33.20 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:11<00:25, 25.61it/s, est. speed input: 33780.19 toks/s, output: 32.99 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:11<00:25, 25.58it/s, est. speed input: 33571.84 toks/s, output: 32.78 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:11<00:24, 25.55it/s, est. speed input: 33373.40 toks/s, output: 32.59 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:12<00:24, 25.54it/s, est. speed input: 33186.73 toks/s, output: 32.41 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:12<00:24, 25.55it/s, est. speed input: 33011.69 toks/s, output: 32.24 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:12<00:24, 25.50it/s, est. speed input: 32838.12 toks/s, output: 32.07 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:13<00:23, 25.53it/s, est. speed input: 32680.00 toks/s, output: 31.91 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:13<00:23, 25.50it/s, est. speed input: 32524.15 toks/s, output: 31.76 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:13<00:22, 26.38it/s, est. speed input: 32459.83 toks/s, output: 31.70 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:14<00:22, 26.11it/s, est. speed input: 32317.66 toks/s, output: 31.56 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:14<00:22, 25.94it/s, est. speed input: 32183.00 toks/s, output: 31.43 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:14<00:21, 25.81it/s, est. speed input: 32053.56 toks/s, output: 31.30 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:14<00:21, 25.69it/s, est. speed input: 31926.34 toks/s, output: 31.18 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:15<00:21, 25.64it/s, est. speed input: 31807.65 toks/s, output: 31.06 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:15<00:21, 25.61it/s, est. speed input: 31693.93 toks/s, output: 30.95 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:15<00:20, 25.53it/s, est. speed input: 31579.73 toks/s, output: 30.84 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:16<00:20, 25.56it/s, est. speed input: 31476.98 toks/s, output: 30.74 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:16<00:20, 25.54it/s, est. speed input: 31374.86 toks/s, output: 30.64 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:16<00:19, 25.53it/s, est. speed input: 31277.10 toks/s, output: 30.54 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:17<00:19, 25.47it/s, est. speed input: 31178.64 toks/s, output: 30.45 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:17<00:19, 25.46it/s, est. speed input: 31085.94 toks/s, output: 30.36 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:17<00:19, 25.49it/s, est. speed input: 30999.59 toks/s, output: 30.27 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:18<00:18, 25.46it/s, est. speed input: 30912.86 toks/s, output: 30.19 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:18<00:18, 25.45it/s, est. speed input: 30829.48 toks/s, output: 30.11 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:18<00:18, 25.45it/s, est. speed input: 30749.41 toks/s, output: 30.03 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:19<00:17, 25.47it/s, est. speed input: 30672.88 toks/s, output: 29.95 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:19<00:17, 25.42it/s, est. speed input: 30595.50 toks/s, output: 29.88 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:19<00:17, 25.43it/s, est. speed input: 30522.68 toks/s, output: 29.81 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:19<00:16, 25.45it/s, est. speed input: 30453.28 toks/s, output: 29.74 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:20<00:16, 25.43it/s, est. speed input: 30384.37 toks/s, output: 29.67 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:20<00:16, 25.42it/s, est. speed input: 30317.46 toks/s, output: 29.61 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:20<00:15, 25.43it/s, est. speed input: 30253.14 toks/s, output: 29.54 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:21<00:15, 25.43it/s, est. speed input: 30191.00 toks/s, output: 29.48 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:21<00:15, 25.40it/s, est. speed input: 30128.84 toks/s, output: 29.42 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:21<00:15, 25.41it/s, est. speed input: 30069.81 toks/s, output: 29.37 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:22<00:14, 25.43it/s, est. speed input: 30013.72 toks/s, output: 29.31 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:22<00:14, 25.39it/s, est. speed input: 29955.98 toks/s, output: 29.25 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:22<00:14, 25.41it/s, est. speed input: 29902.50 toks/s, output: 29.20 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:23<00:13, 25.41it/s, est. speed input: 29849.66 toks/s, output: 29.15 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:23<00:13, 25.39it/s, est. speed input: 29797.24 toks/s, output: 29.10 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:23<00:13, 25.42it/s, est. speed input: 29748.15 toks/s, output: 29.05 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:24<00:12, 25.39it/s, est. speed input: 29698.24 toks/s, output: 29.00 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:24<00:12, 25.41it/s, est. speed input: 29651.10 toks/s, output: 28.96 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:24<00:12, 25.38it/s, est. speed input: 29603.26 toks/s, output: 28.91 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:25<00:11, 25.37it/s, est. speed input: 29557.57 toks/s, output: 28.86 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:25<00:11, 25.39it/s, est. speed input: 29514.07 toks/s, output: 28.82 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:25<00:11, 25.40it/s, est. speed input: 29471.09 toks/s, output: 28.78 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:25<00:10, 25.40it/s, est. speed input: 29429.10 toks/s, output: 28.74 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:26<00:10, 25.37it/s, est. speed input: 29386.85 toks/s, output: 28.70 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:26<00:10, 25.37it/s, est. speed input: 29346.35 toks/s, output: 28.66 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:26<00:10, 25.37it/s, est. speed input: 29306.77 toks/s, output: 28.62 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:27<00:09, 25.37it/s, est. speed input: 29268.27 toks/s, output: 28.58 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:27<00:09, 26.25it/s, est. speed input: 29268.08 toks/s, output: 28.58 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:27<00:08, 25.97it/s, est. speed input: 29230.62 toks/s, output: 28.55 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:28<00:08, 25.79it/s, est. speed input: 29194.29 toks/s, output: 28.51 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:28<00:08, 25.66it/s, est. speed input: 29158.52 toks/s, output: 28.48 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:28<00:08, 25.55it/s, est. speed input: 29122.53 toks/s, output: 28.44 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:29<00:07, 25.52it/s, est. speed input: 29089.40 toks/s, output: 28.41 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:29<00:07, 25.46it/s, est. speed input: 29055.58 toks/s, output: 28.37 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:29<00:07, 25.40it/s, est. speed input: 29021.49 toks/s, output: 28.34 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:30<00:06, 25.36it/s, est. speed input: 28988.42 toks/s, output: 28.31 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:30<00:06, 25.37it/s, est. speed input: 28957.37 toks/s, output: 28.28 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:30<00:06, 25.37it/s, est. speed input: 28926.67 toks/s, output: 28.25 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:30<00:05, 25.32it/s, est. speed input: 28894.80 toks/s, output: 28.22 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:31<00:05, 25.34it/s, est. speed input: 28865.58 toks/s, output: 28.19 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:31<00:05, 25.35it/s, est. speed input: 28836.64 toks/s, output: 28.16 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:31<00:04, 25.31it/s, est. speed input: 28806.80 toks/s, output: 28.13 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:32<00:04, 25.32it/s, est. speed input: 28778.98 toks/s, output: 28.10 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:32<00:04, 25.32it/s, est. speed input: 28751.06 toks/s, output: 28.08 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:32<00:04, 25.30it/s, est. speed input: 28723.37 toks/s, output: 28.05 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:33<00:03, 25.31it/s, est. speed input: 28697.01 toks/s, output: 28.02 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:33<00:03, 25.28it/s, est. speed input: 28669.73 toks/s, output: 28.00 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:33<00:03, 25.28it/s, est. speed input: 28643.66 toks/s, output: 27.97 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:34<00:02, 25.31it/s, est. speed input: 28619.17 toks/s, output: 27.95 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:34<00:02, 25.29it/s, est. speed input: 28593.53 toks/s, output: 27.92 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:34<00:02, 25.27it/s, est. speed input: 28568.47 toks/s, output: 27.90 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:35<00:01, 25.29it/s, est. speed input: 28544.95 toks/s, output: 27.88 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:35<00:01, 25.28it/s, est. speed input: 28521.01 toks/s, output: 27.85 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:35<00:01, 25.27it/s, est. speed input: 28497.18 toks/s, output: 27.83 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:36<00:00, 25.26it/s, est. speed input: 28473.82 toks/s, output: 27.81 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:36<00:00, 25.28it/s, est. speed input: 28451.83 toks/s, output: 27.78 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:36<00:00, 26.19it/s, est. speed input: 28458.15 toks/s, output: 27.79 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 26.19it/s, est. speed input: 28625.67 toks/s, output: 27.95 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 27.95it/s, est. speed input: 28625.67 toks/s, output: 27.95 toks/s]
[rank0]:[W125 20:40:42.094246594 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 95.6s

测试结果:
  Requests/s:   25.54
  Tokens/s:     26174.54
  Total Reqs:   1024
  Elapsed:      40.10s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     26149.01

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:41:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=428756) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=428756) WARNING 01-25 20:41:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.84 requests/s, 26483.18 total tokens/s, 25.84 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-25 20:41:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:41:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:41:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:41:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:41:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:41:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:41:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:41:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:41:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:41:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:41:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:41:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:41:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:41:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:15] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=428756) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=428756) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.28it/s]
(EngineCore_DP0 pid=428756) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
(EngineCore_DP0 pid=428756) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.26it/s]
(EngineCore_DP0 pid=428756) 
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=428756) [2026-01-25 20:41:17] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=428756) [rank0]:W0125 20:41:34.243000 428756 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=428756) [rank0]:W0125 20:41:34.359000 428756 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=428756) [rank0]:W0125 20:41:35.910000 428756 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=428756) [rank0]:W0125 20:41:36.102000 428756 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=428756) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 10.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00, 11.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00, 11.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 11.05it/s]
(EngineCore_DP0 pid=428756) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  9.79it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 10.57it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 11.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 10.90it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 26/2048 [00:00<00:08, 250.69it/s]
Adding requests:   3%|▎         | 53/2048 [00:00<00:07, 261.02it/s]
Adding requests:   4%|▍         | 82/2048 [00:00<00:07, 270.24it/s]
Adding requests:   5%|▌         | 110/2048 [00:00<00:07, 269.98it/s]
Adding requests:   7%|▋         | 138/2048 [00:00<00:06, 273.24it/s]
Adding requests:   8%|▊         | 170/2048 [00:00<00:06, 287.60it/s]
Adding requests:  10%|▉         | 203/2048 [00:00<00:06, 298.67it/s]
Adding requests:  11%|█▏        | 235/2048 [00:00<00:05, 304.98it/s]
Adding requests:  13%|█▎        | 266/2048 [00:00<00:05, 304.77it/s]
Adding requests:  15%|█▍        | 297/2048 [00:01<00:05, 298.78it/s]
Adding requests:  16%|█▌        | 327/2048 [00:01<00:05, 295.99it/s]
Adding requests:  17%|█▋        | 358/2048 [00:01<00:05, 298.61it/s]
Adding requests:  19%|█▉        | 388/2048 [00:01<00:05, 298.63it/s]
Adding requests:  21%|██        | 421/2048 [00:01<00:05, 305.61it/s]
Adding requests:  22%|██▏       | 452/2048 [00:01<00:05, 302.51it/s]
Adding requests:  24%|██▎       | 485/2048 [00:01<00:05, 308.64it/s]
Adding requests:  25%|██▌       | 517/2048 [00:01<00:04, 311.10it/s]
Adding requests:  27%|██▋       | 549/2048 [00:01<00:04, 308.39it/s]
Adding requests:  28%|██▊       | 580/2048 [00:01<00:04, 308.31it/s]
Adding requests:  30%|██▉       | 611/2048 [00:02<00:04, 300.09it/s]
Adding requests:  31%|███▏      | 642/2048 [00:02<00:04, 295.94it/s]
Adding requests:  33%|███▎      | 672/2048 [00:02<00:04, 287.46it/s]
Adding requests:  34%|███▍      | 704/2048 [00:02<00:04, 294.61it/s]
Adding requests:  36%|███▌      | 734/2048 [00:02<00:04, 283.64it/s]
Adding requests:  37%|███▋      | 763/2048 [00:02<00:04, 279.46it/s]
Adding requests:  39%|███▊      | 793/2048 [00:02<00:04, 283.41it/s]
Adding requests:  40%|████      | 822/2048 [00:02<00:04, 282.38it/s]
Adding requests:  42%|████▏     | 851/2048 [00:02<00:04, 282.92it/s]
Adding requests:  43%|████▎     | 882/2048 [00:03<00:04, 289.36it/s]
Adding requests:  45%|████▍     | 912/2048 [00:03<00:03, 289.81it/s]
Adding requests:  46%|████▌     | 942/2048 [00:03<00:03, 281.09it/s]
Adding requests:  47%|████▋     | 971/2048 [00:03<00:03, 276.61it/s]
Adding requests:  49%|████▉     | 999/2048 [00:03<00:03, 269.59it/s]
Adding requests:  50%|█████     | 1027/2048 [00:03<00:03, 272.34it/s]
Adding requests:  52%|█████▏    | 1057/2048 [00:03<00:03, 278.80it/s]
Adding requests:  53%|█████▎    | 1086/2048 [00:03<00:03, 281.82it/s]
Adding requests:  55%|█████▍    | 1117/2048 [00:03<00:03, 287.66it/s]
Adding requests:  56%|█████▌    | 1147/2048 [00:03<00:03, 290.33it/s]
Adding requests:  58%|█████▊    | 1178/2048 [00:04<00:02, 293.82it/s]
Adding requests:  59%|█████▉    | 1208/2048 [00:04<00:02, 292.25it/s]
Adding requests:  60%|██████    | 1239/2048 [00:04<00:02, 294.90it/s]
Adding requests:  62%|██████▏   | 1269/2048 [00:04<00:02, 287.40it/s]
Adding requests:  63%|██████▎   | 1298/2048 [00:04<00:02, 281.55it/s]
Adding requests:  65%|██████▍   | 1327/2048 [00:04<00:02, 280.74it/s]
Adding requests:  66%|██████▋   | 1357/2048 [00:04<00:02, 285.59it/s]
Adding requests:  68%|██████▊   | 1388/2048 [00:04<00:02, 290.91it/s]
Adding requests:  69%|██████▉   | 1418/2048 [00:04<00:02, 288.80it/s]
Adding requests:  71%|███████   | 1448/2048 [00:05<00:02, 289.92it/s]
Adding requests:  72%|███████▏  | 1480/2048 [00:05<00:01, 297.88it/s]
Adding requests:  74%|███████▍  | 1514/2048 [00:05<00:01, 307.26it/s]
Adding requests:  75%|███████▌  | 1545/2048 [00:05<00:01, 305.35it/s]
Adding requests:  77%|███████▋  | 1576/2048 [00:05<00:01, 294.34it/s]
Adding requests:  78%|███████▊  | 1606/2048 [00:05<00:01, 295.46it/s]
Adding requests:  80%|███████▉  | 1636/2048 [00:05<00:01, 295.51it/s]
Adding requests:  81%|████████▏ | 1666/2048 [00:05<00:01, 291.58it/s]
Adding requests:  83%|████████▎ | 1699/2048 [00:05<00:01, 301.37it/s]
Adding requests:  85%|████████▍ | 1732/2048 [00:05<00:01, 308.21it/s]
Adding requests:  86%|████████▌ | 1765/2048 [00:06<00:00, 313.81it/s]
Adding requests:  88%|████████▊ | 1797/2048 [00:06<00:00, 312.02it/s]
Adding requests:  89%|████████▉ | 1830/2048 [00:06<00:00, 315.15it/s]
Adding requests:  91%|█████████ | 1862/2048 [00:06<00:00, 307.11it/s]
Adding requests:  92%|█████████▏| 1893/2048 [00:06<00:00, 300.28it/s]
Adding requests:  94%|█████████▍| 1924/2048 [00:06<00:00, 294.64it/s]
Adding requests:  95%|█████████▌| 1954/2048 [00:06<00:00, 293.83it/s]
Adding requests:  97%|█████████▋| 1985/2048 [00:06<00:00, 296.04it/s]
Adding requests:  98%|█████████▊| 2016/2048 [00:06<00:00, 296.52it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 301.70it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 293.33it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:00<00:05, 368.69it/s, est. speed input: 377557.91 toks/s, output: 368.69 toks/s]
Processed prompts:  10%|█         | 215/2048 [00:01<00:17, 104.84it/s, est. speed input: 130561.29 toks/s, output: 127.50 toks/s]
Processed prompts:  11%|█▏        | 232/2048 [00:02<00:23, 76.88it/s, est. speed input: 103296.36 toks/s, output: 100.88 toks/s] 
Processed prompts:  12%|█▏        | 243/2048 [00:02<00:31, 56.58it/s, est. speed input: 85234.82 toks/s, output: 83.24 toks/s]  
Processed prompts:  13%|█▎        | 258/2048 [00:03<00:38, 46.03it/s, est. speed input: 74746.65 toks/s, output: 72.99 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:04<00:44, 39.60it/s, est. speed input: 67574.52 toks/s, output: 65.99 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:04<00:49, 35.30it/s, est. speed input: 62251.38 toks/s, output: 60.79 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:05<00:52, 33.01it/s, est. speed input: 58559.08 toks/s, output: 57.19 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:05<00:56, 30.78it/s, est. speed input: 55234.24 toks/s, output: 53.94 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:06<00:58, 29.29it/s, est. speed input: 52543.47 toks/s, output: 51.31 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:07<00:59, 28.25it/s, est. speed input: 50308.91 toks/s, output: 49.13 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:07<01:00, 27.55it/s, est. speed input: 48435.55 toks/s, output: 47.30 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:08<01:01, 26.98it/s, est. speed input: 46803.89 toks/s, output: 45.71 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:09<01:01, 26.67it/s, est. speed input: 45426.40 toks/s, output: 44.36 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:09<01:01, 26.42it/s, est. speed input: 44214.11 toks/s, output: 43.18 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:10<01:00, 26.72it/s, est. speed input: 43301.16 toks/s, output: 42.29 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:10<01:00, 26.48it/s, est. speed input: 42349.60 toks/s, output: 41.36 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:11<01:00, 26.31it/s, est. speed input: 41501.54 toks/s, output: 40.53 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:12<00:59, 26.15it/s, est. speed input: 40728.53 toks/s, output: 39.77 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:12<00:59, 26.10it/s, est. speed input: 40044.39 toks/s, output: 39.11 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:13<00:58, 26.01it/s, est. speed input: 39412.16 toks/s, output: 38.49 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:13<00:58, 25.95it/s, est. speed input: 38837.51 toks/s, output: 37.93 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:14<00:57, 25.94it/s, est. speed input: 38316.60 toks/s, output: 37.42 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:15<00:57, 25.89it/s, est. speed input: 37830.63 toks/s, output: 36.94 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:15<00:56, 25.88it/s, est. speed input: 37385.72 toks/s, output: 36.51 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:16<00:56, 25.87it/s, est. speed input: 36974.81 toks/s, output: 36.11 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:17<00:55, 25.86it/s, est. speed input: 36593.10 toks/s, output: 35.74 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:17<00:55, 25.82it/s, est. speed input: 36233.87 toks/s, output: 35.38 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:18<00:54, 25.84it/s, est. speed input: 35905.20 toks/s, output: 35.06 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:18<00:53, 25.83it/s, est. speed input: 35594.74 toks/s, output: 34.76 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:19<00:53, 25.82it/s, est. speed input: 35303.08 toks/s, output: 34.48 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:20<00:52, 25.80it/s, est. speed input: 35027.76 toks/s, output: 34.21 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:20<00:52, 25.80it/s, est. speed input: 34771.79 toks/s, output: 33.96 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:21<00:51, 25.81it/s, est. speed input: 34530.40 toks/s, output: 33.72 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:22<00:50, 25.79it/s, est. speed input: 34300.14 toks/s, output: 33.50 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:22<00:50, 25.77it/s, est. speed input: 34081.34 toks/s, output: 33.28 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:23<00:49, 25.78it/s, est. speed input: 33877.92 toks/s, output: 33.08 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:23<00:48, 26.23it/s, est. speed input: 33733.53 toks/s, output: 32.94 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:24<00:47, 26.10it/s, est. speed input: 33548.15 toks/s, output: 32.76 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:25<00:47, 25.97it/s, est. speed input: 33368.42 toks/s, output: 32.59 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:25<00:46, 25.90it/s, est. speed input: 33198.14 toks/s, output: 32.42 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:26<00:46, 25.85it/s, est. speed input: 33036.85 toks/s, output: 32.26 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:26<00:45, 25.81it/s, est. speed input: 32882.50 toks/s, output: 32.11 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:27<00:45, 25.78it/s, est. speed input: 32734.81 toks/s, output: 31.97 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:28<00:44, 25.79it/s, est. speed input: 32595.79 toks/s, output: 31.83 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:28<00:44, 25.75it/s, est. speed input: 32459.70 toks/s, output: 31.70 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:29<00:43, 25.72it/s, est. speed input: 32328.58 toks/s, output: 31.57 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:30<00:42, 25.71it/s, est. speed input: 32203.57 toks/s, output: 31.45 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:30<00:42, 25.69it/s, est. speed input: 32083.14 toks/s, output: 31.33 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:31<00:41, 25.68it/s, est. speed input: 31967.42 toks/s, output: 31.22 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:31<00:41, 25.69it/s, est. speed input: 31857.38 toks/s, output: 31.11 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:32<00:40, 25.67it/s, est. speed input: 31749.93 toks/s, output: 31.01 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:33<00:39, 25.65it/s, est. speed input: 31646.01 toks/s, output: 30.90 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:33<00:39, 25.64it/s, est. speed input: 31545.58 toks/s, output: 30.81 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:34<00:38, 25.64it/s, est. speed input: 31449.90 toks/s, output: 30.71 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:35<00:37, 25.64it/s, est. speed input: 31357.27 toks/s, output: 30.62 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:35<00:37, 25.67it/s, est. speed input: 31270.02 toks/s, output: 30.54 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:36<00:36, 25.65it/s, est. speed input: 31183.26 toks/s, output: 30.45 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:36<00:36, 25.65it/s, est. speed input: 31100.32 toks/s, output: 30.37 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:37<00:35, 25.62it/s, est. speed input: 31018.06 toks/s, output: 30.29 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:38<00:34, 25.64it/s, est. speed input: 30941.44 toks/s, output: 30.22 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:38<00:34, 25.62it/s, est. speed input: 30864.37 toks/s, output: 30.14 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:39<00:33, 25.62it/s, est. speed input: 30791.52 toks/s, output: 30.07 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:40<00:32, 26.03it/s, est. speed input: 30745.62 toks/s, output: 30.02 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:40<00:32, 25.92it/s, est. speed input: 30677.10 toks/s, output: 29.96 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:41<00:31, 26.26it/s, est. speed input: 30634.73 toks/s, output: 29.92 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:41<00:30, 26.05it/s, est. speed input: 30568.75 toks/s, output: 29.85 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:42<00:30, 25.93it/s, est. speed input: 30505.48 toks/s, output: 29.79 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:43<00:29, 25.82it/s, est. speed input: 30442.73 toks/s, output: 29.73 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:43<00:29, 25.75it/s, est. speed input: 30382.12 toks/s, output: 29.67 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:44<00:28, 25.70it/s, est. speed input: 30322.93 toks/s, output: 29.61 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:44<00:27, 26.11it/s, est. speed input: 30289.45 toks/s, output: 29.58 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:45<00:27, 25.94it/s, est. speed input: 30232.91 toks/s, output: 29.52 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:46<00:26, 25.82it/s, est. speed input: 30177.48 toks/s, output: 29.47 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:46<00:26, 25.74it/s, est. speed input: 30124.20 toks/s, output: 29.42 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:47<00:25, 25.68it/s, est. speed input: 30071.88 toks/s, output: 29.37 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:48<00:24, 25.64it/s, est. speed input: 30020.76 toks/s, output: 29.32 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:48<00:24, 25.64it/s, est. speed input: 29972.55 toks/s, output: 29.27 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:49<00:23, 25.61it/s, est. speed input: 29924.30 toks/s, output: 29.22 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:49<00:22, 26.01it/s, est. speed input: 29897.24 toks/s, output: 29.20 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:50<00:22, 25.88it/s, est. speed input: 29851.28 toks/s, output: 29.15 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:51<00:21, 25.76it/s, est. speed input: 29805.26 toks/s, output: 29.11 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:51<00:21, 25.70it/s, est. speed input: 29761.16 toks/s, output: 29.06 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:52<00:20, 26.06it/s, est. speed input: 29736.88 toks/s, output: 29.04 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:53<00:19, 25.91it/s, est. speed input: 29694.97 toks/s, output: 29.00 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:53<00:18, 26.23it/s, est. speed input: 29672.30 toks/s, output: 28.98 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:54<00:18, 26.01it/s, est. speed input: 29631.17 toks/s, output: 28.94 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:54<00:17, 25.86it/s, est. speed input: 29591.07 toks/s, output: 28.90 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:55<00:17, 25.73it/s, est. speed input: 29550.89 toks/s, output: 28.86 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:56<00:16, 26.07it/s, est. speed input: 29529.66 toks/s, output: 28.84 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:56<00:15, 25.88it/s, est. speed input: 29491.31 toks/s, output: 28.80 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:57<00:15, 25.76it/s, est. speed input: 29454.21 toks/s, output: 28.76 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:57<00:14, 25.67it/s, est. speed input: 29417.65 toks/s, output: 28.73 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:58<00:14, 25.60it/s, est. speed input: 29381.57 toks/s, output: 28.69 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:59<00:13, 25.56it/s, est. speed input: 29346.56 toks/s, output: 28.66 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:59<00:13, 25.53it/s, est. speed input: 29312.02 toks/s, output: 28.63 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:00<00:12, 25.94it/s, est. speed input: 29295.15 toks/s, output: 28.61 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:01<00:11, 26.22it/s, est. speed input: 29278.00 toks/s, output: 28.59 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:01<00:11, 26.00it/s, est. speed input: 29245.84 toks/s, output: 28.56 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:02<00:10, 25.82it/s, est. speed input: 29213.20 toks/s, output: 28.53 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:02<00:09, 25.72it/s, est. speed input: 29182.16 toks/s, output: 28.50 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:03<00:09, 25.62it/s, est. speed input: 29150.77 toks/s, output: 28.47 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:04<00:08, 25.57it/s, est. speed input: 29120.41 toks/s, output: 28.44 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:04<00:08, 25.53it/s, est. speed input: 29090.77 toks/s, output: 28.41 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:05<00:07, 25.51it/s, est. speed input: 29061.67 toks/s, output: 28.38 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:06<00:06, 25.47it/s, est. speed input: 29032.29 toks/s, output: 28.35 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:06<00:06, 25.87it/s, est. speed input: 29018.78 toks/s, output: 28.34 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:07<00:05, 25.77it/s, est. speed input: 28992.07 toks/s, output: 28.31 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:07<00:04, 25.67it/s, est. speed input: 28964.78 toks/s, output: 28.29 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:08<00:04, 25.58it/s, est. speed input: 28937.47 toks/s, output: 28.26 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:09<00:03, 25.53it/s, est. speed input: 28910.96 toks/s, output: 28.23 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:09<00:03, 25.50it/s, est. speed input: 28884.94 toks/s, output: 28.21 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:10<00:02, 25.93it/s, est. speed input: 28874.49 toks/s, output: 28.20 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:11<00:01, 25.75it/s, est. speed input: 28848.38 toks/s, output: 28.17 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:11<00:01, 25.64it/s, est. speed input: 28823.31 toks/s, output: 28.15 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:12<00:00, 26.08it/s, est. speed input: 28815.31 toks/s, output: 28.14 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:12<00:00, 26.08it/s, est. speed input: 29013.47 toks/s, output: 28.33 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:12<00:00, 28.33it/s, est. speed input: 29013.47 toks/s, output: 28.33 toks/s]
[rank0]:[W125 20:43:05.018011763 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 142.9s

测试结果:
  Requests/s:   25.84
  Tokens/s:     26483.18
  Total Reqs:   2048
  Elapsed:      79.27s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     26457.34

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:43:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=431176) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=431176) WARNING 01-25 20:44:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 25.63 requests/s, 26267.30 total tokens/s, 25.63 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-25 20:43:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:43:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:43:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:43:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:43:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:43:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:43:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:43:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:43:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:43:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:43:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:43:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:43:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:43:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:43:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:43:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:43:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=431176) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=431176) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=431176) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=431176) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=431176) 
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=431176) [2026-01-25 20:43:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=431176) [rank0]:W0125 20:44:12.073000 431176 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=431176) [rank0]:W0125 20:44:12.191000 431176 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=431176) [rank0]:W0125 20:44:13.610000 431176 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=431176) [rank0]:W0125 20:44:13.805000 431176 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=431176) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  9.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00, 10.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00, 11.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00, 11.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00, 11.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00, 10.79it/s]
(EngineCore_DP0 pid=431176) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  8.99it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00, 10.63it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00, 10.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00, 10.55it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 248.23it/s]
Adding requests:   1%|▏         | 53/4096 [00:00<00:15, 262.47it/s]
Adding requests:   2%|▏         | 83/4096 [00:00<00:14, 277.86it/s]
Adding requests:   3%|▎         | 111/4096 [00:00<00:14, 277.13it/s]
Adding requests:   3%|▎         | 139/4096 [00:00<00:14, 273.50it/s]
Adding requests:   4%|▍         | 170/4096 [00:00<00:13, 284.78it/s]
Adding requests:   5%|▍         | 200/4096 [00:00<00:13, 288.35it/s]
Adding requests:   6%|▌         | 229/4096 [00:00<00:13, 286.71it/s]
Adding requests:   6%|▋         | 258/4096 [00:00<00:13, 285.62it/s]
Adding requests:   7%|▋         | 288/4096 [00:01<00:13, 289.92it/s]
Adding requests:   8%|▊         | 320/4096 [00:01<00:12, 296.57it/s]
Adding requests:   9%|▊         | 351/4096 [00:01<00:12, 299.53it/s]
Adding requests:   9%|▉         | 384/4096 [00:01<00:12, 304.89it/s]
Adding requests:  10%|█         | 417/4096 [00:01<00:11, 311.71it/s]
Adding requests:  11%|█         | 449/4096 [00:01<00:12, 303.86it/s]
Adding requests:  12%|█▏        | 480/4096 [00:01<00:11, 304.74it/s]
Adding requests:  12%|█▏        | 511/4096 [00:01<00:11, 301.08it/s]
Adding requests:  13%|█▎        | 543/4096 [00:01<00:11, 304.38it/s]
Adding requests:  14%|█▍        | 575/4096 [00:01<00:11, 305.59it/s]
Adding requests:  15%|█▍        | 606/4096 [00:02<00:11, 297.64it/s]
Adding requests:  16%|█▌        | 636/4096 [00:02<00:11, 296.45it/s]
Adding requests:  16%|█▋        | 666/4096 [00:02<00:11, 294.88it/s]
Adding requests:  17%|█▋        | 698/4096 [00:02<00:11, 300.56it/s]
Adding requests:  18%|█▊        | 729/4096 [00:02<00:11, 293.77it/s]
Adding requests:  19%|█▊        | 759/4096 [00:02<00:11, 291.00it/s]
Adding requests:  19%|█▉        | 790/4096 [00:02<00:11, 295.60it/s]
Adding requests:  20%|██        | 820/4096 [00:02<00:11, 287.92it/s]
Adding requests:  21%|██        | 852/4096 [00:02<00:10, 296.22it/s]
Adding requests:  22%|██▏       | 882/4096 [00:02<00:10, 296.70it/s]
Adding requests:  22%|██▏       | 913/4096 [00:03<00:10, 298.86it/s]
Adding requests:  23%|██▎       | 943/4096 [00:03<00:10, 293.71it/s]
Adding requests:  24%|██▍       | 973/4096 [00:03<00:10, 294.09it/s]
Adding requests:  24%|██▍       | 1003/4096 [00:03<00:10, 288.52it/s]
Adding requests:  25%|██▌       | 1032/4096 [00:03<00:10, 287.24it/s]
Adding requests:  26%|██▌       | 1061/4096 [00:03<00:10, 287.93it/s]
Adding requests:  27%|██▋       | 1090/4096 [00:03<00:10, 288.01it/s]
Adding requests:  27%|██▋       | 1119/4096 [00:03<00:10, 276.07it/s]
Adding requests:  28%|██▊       | 1149/4096 [00:03<00:10, 280.51it/s]
Adding requests:  29%|██▉       | 1178/4096 [00:04<00:10, 281.52it/s]
Adding requests:  30%|██▉       | 1210/4096 [00:04<00:09, 291.73it/s]
Adding requests:  30%|███       | 1241/4096 [00:04<00:09, 296.57it/s]
Adding requests:  31%|███       | 1272/4096 [00:04<00:09, 299.08it/s]
Adding requests:  32%|███▏      | 1302/4096 [00:04<00:09, 298.88it/s]
Adding requests:  33%|███▎      | 1332/4096 [00:04<00:09, 290.66it/s]
Adding requests:  33%|███▎      | 1362/4096 [00:04<00:09, 291.45it/s]
Adding requests:  34%|███▍      | 1392/4096 [00:04<00:09, 286.33it/s]
Adding requests:  35%|███▍      | 1421/4096 [00:04<00:09, 279.71it/s]
Adding requests:  35%|███▌      | 1450/4096 [00:04<00:09, 278.83it/s]
Adding requests:  36%|███▌      | 1480/4096 [00:05<00:09, 284.52it/s]
Adding requests:  37%|███▋      | 1512/4096 [00:05<00:08, 293.51it/s]
Adding requests:  38%|███▊      | 1544/4096 [00:05<00:08, 299.01it/s]
Adding requests:  38%|███▊      | 1574/4096 [00:05<00:08, 295.40it/s]
Adding requests:  39%|███▉      | 1604/4096 [00:05<00:08, 288.59it/s]
Adding requests:  40%|███▉      | 1633/4096 [00:05<00:08, 286.48it/s]
Adding requests:  41%|████      | 1662/4096 [00:05<00:08, 279.61it/s]
Adding requests:  41%|████▏     | 1692/4096 [00:05<00:08, 283.14it/s]
Adding requests:  42%|████▏     | 1721/4096 [00:05<00:08, 282.54it/s]
Adding requests:  43%|████▎     | 1752/4096 [00:06<00:08, 287.90it/s]
Adding requests:  44%|████▎     | 1783/4096 [00:06<00:07, 292.42it/s]
Adding requests:  44%|████▍     | 1813/4096 [00:06<00:07, 293.33it/s]
Adding requests:  45%|████▌     | 1845/4096 [00:06<00:07, 300.91it/s]
Adding requests:  46%|████▌     | 1876/4096 [00:06<00:07, 299.51it/s]
Adding requests:  47%|████▋     | 1907/4096 [00:06<00:07, 302.44it/s]
Adding requests:  47%|████▋     | 1939/4096 [00:06<00:07, 305.45it/s]
Adding requests:  48%|████▊     | 1970/4096 [00:06<00:07, 298.57it/s]
Adding requests:  49%|████▉     | 2000/4096 [00:06<00:07, 296.94it/s]
Adding requests:  50%|████▉     | 2030/4096 [00:06<00:07, 286.64it/s]
Adding requests:  50%|█████     | 2059/4096 [00:07<00:07, 285.37it/s]
Adding requests:  51%|█████     | 2088/4096 [00:07<00:07, 279.92it/s]
Adding requests:  52%|█████▏    | 2119/4096 [00:07<00:06, 285.88it/s]
Adding requests:  52%|█████▏    | 2150/4096 [00:07<00:06, 292.65it/s]
Adding requests:  53%|█████▎    | 2180/4096 [00:07<00:06, 290.32it/s]
Adding requests:  54%|█████▍    | 2210/4096 [00:07<00:06, 287.74it/s]
Adding requests:  55%|█████▍    | 2241/4096 [00:07<00:06, 293.24it/s]
Adding requests:  55%|█████▌    | 2273/4096 [00:07<00:06, 299.83it/s]
Adding requests:  56%|█████▋    | 2305/4096 [00:07<00:05, 304.19it/s]
Adding requests:  57%|█████▋    | 2336/4096 [00:08<00:06, 289.52it/s]
Adding requests:  58%|█████▊    | 2366/4096 [00:08<00:05, 291.40it/s]
Adding requests:  59%|█████▊    | 2400/4096 [00:08<00:05, 302.38it/s]
Adding requests:  59%|█████▉    | 2433/4096 [00:08<00:05, 307.74it/s]
Adding requests:  60%|██████    | 2464/4096 [00:08<00:05, 306.39it/s]
Adding requests:  61%|██████    | 2496/4096 [00:08<00:05, 308.15it/s]
Adding requests:  62%|██████▏   | 2529/4096 [00:08<00:04, 313.60it/s]
Adding requests:  63%|██████▎   | 2563/4096 [00:08<00:04, 319.34it/s]
Adding requests:  63%|██████▎   | 2595/4096 [00:08<00:04, 309.94it/s]
Adding requests:  64%|██████▍   | 2627/4096 [00:08<00:04, 299.52it/s]
Adding requests:  65%|██████▍   | 2658/4096 [00:09<00:04, 291.48it/s]
Adding requests:  66%|██████▌   | 2688/4096 [00:09<00:04, 292.66it/s]
Adding requests:  66%|██████▋   | 2718/4096 [00:09<00:04, 289.47it/s]
Adding requests:  67%|██████▋   | 2748/4096 [00:09<00:04, 289.61it/s]
Adding requests:  68%|██████▊   | 2777/4096 [00:09<00:04, 287.57it/s]
Adding requests:  69%|██████▊   | 2811/4096 [00:09<00:04, 300.48it/s]
Adding requests:  69%|██████▉   | 2844/4096 [00:09<00:04, 306.80it/s]
Adding requests:  70%|███████   | 2875/4096 [00:09<00:03, 305.77it/s]
Adding requests:  71%|███████   | 2906/4096 [00:09<00:03, 302.89it/s]
Adding requests:  72%|███████▏  | 2938/4096 [00:09<00:03, 307.56it/s]
Adding requests:  72%|███████▏  | 2969/4096 [00:10<00:03, 299.34it/s]
Adding requests:  73%|███████▎  | 3000/4096 [00:10<00:03, 301.57it/s]
Adding requests:  74%|███████▍  | 3032/4096 [00:10<00:03, 306.03it/s]
Adding requests:  75%|███████▍  | 3064/4096 [00:10<00:03, 307.68it/s]
Adding requests:  76%|███████▌  | 3095/4096 [00:10<00:03, 306.66it/s]
Adding requests:  76%|███████▋  | 3128/4096 [00:10<00:03, 312.86it/s]
Adding requests:  77%|███████▋  | 3160/4096 [00:10<00:03, 307.17it/s]
Adding requests:  78%|███████▊  | 3191/4096 [00:10<00:02, 302.01it/s]
Adding requests:  79%|███████▊  | 3222/4096 [00:10<00:02, 296.36it/s]
Adding requests:  79%|███████▉  | 3254/4096 [00:11<00:02, 299.54it/s]
Adding requests:  80%|████████  | 3284/4096 [00:11<00:02, 283.93it/s]
Adding requests:  81%|████████  | 3313/4096 [00:11<00:02, 281.25it/s]
Adding requests:  82%|████████▏ | 3344/4096 [00:11<00:02, 288.00it/s]
Adding requests:  82%|████████▏ | 3375/4096 [00:11<00:02, 292.11it/s]
Adding requests:  83%|████████▎ | 3405/4096 [00:11<00:02, 288.97it/s]
Adding requests:  84%|████████▍ | 3434/4096 [00:11<00:02, 286.10it/s]
Adding requests:  85%|████████▍ | 3464/4096 [00:11<00:02, 288.43it/s]
Adding requests:  85%|████████▌ | 3493/4096 [00:11<00:02, 288.58it/s]
Adding requests:  86%|████████▌ | 3527/4096 [00:11<00:01, 303.20it/s]
Adding requests:  87%|████████▋ | 3559/4096 [00:12<00:01, 305.71it/s]
Adding requests:  88%|████████▊ | 3590/4096 [00:12<00:01, 292.66it/s]
Adding requests:  88%|████████▊ | 3623/4096 [00:12<00:01, 300.97it/s]
Adding requests:  89%|████████▉ | 3655/4096 [00:12<00:01, 304.46it/s]
Adding requests:  90%|████████▉ | 3686/4096 [00:12<00:01, 291.24it/s]
Adding requests:  91%|█████████ | 3719/4096 [00:12<00:01, 301.72it/s]
Adding requests:  92%|█████████▏| 3750/4096 [00:12<00:01, 299.21it/s]
Adding requests:  92%|█████████▏| 3781/4096 [00:12<00:01, 287.65it/s]
Adding requests:  93%|█████████▎| 3810/4096 [00:12<00:01, 268.45it/s]
Adding requests:  94%|█████████▎| 3838/4096 [00:13<00:00, 270.87it/s]
Adding requests:  94%|█████████▍| 3866/4096 [00:13<00:00, 272.35it/s]
Adding requests:  95%|█████████▌| 3896/4096 [00:13<00:00, 279.50it/s]
Adding requests:  96%|█████████▌| 3925/4096 [00:13<00:00, 281.16it/s]
Adding requests:  97%|█████████▋| 3957/4096 [00:13<00:00, 289.18it/s]
Adding requests:  97%|█████████▋| 3987/4096 [00:13<00:00, 289.50it/s]
Adding requests:  98%|█████████▊| 4017/4096 [00:13<00:00, 282.87it/s]
Adding requests:  99%|█████████▉| 4046/4096 [00:13<00:00, 275.85it/s]
Adding requests: 100%|█████████▉| 4077/4096 [00:13<00:00, 283.05it/s]
Adding requests: 100%|██████████| 4096/4096 [00:13<00:00, 293.05it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 338/4096 [00:00<00:02, 1319.76it/s, est. speed input: 1351570.55 toks/s, output: 1319.79 toks/s]
Processed prompts:  11%|█▏        | 470/4096 [00:05<00:50, 72.24it/s, est. speed input: 92920.76 toks/s, output: 90.74 toks/s]      
Processed prompts:  13%|█▎        | 526/4096 [00:06<00:54, 65.23it/s, est. speed input: 83877.42 toks/s, output: 81.91 toks/s]
Processed prompts:  14%|█▎        | 559/4096 [00:07<01:04, 54.81it/s, est. speed input: 74683.43 toks/s, output: 72.93 toks/s]
Processed prompts:  14%|█▍        | 580/4096 [00:08<01:19, 44.27it/s, est. speed input: 66677.63 toks/s, output: 65.11 toks/s]
Processed prompts:  15%|█▍        | 594/4096 [00:10<01:40, 34.88it/s, est. speed input: 59915.00 toks/s, output: 58.51 toks/s]
Processed prompts:  15%|█▌        | 626/4096 [00:11<01:47, 32.22it/s, est. speed input: 56240.77 toks/s, output: 54.92 toks/s]
Processed prompts:  16%|█▌        | 658/4096 [00:12<01:53, 30.31it/s, est. speed input: 53292.85 toks/s, output: 52.04 toks/s]
Processed prompts:  17%|█▋        | 690/4096 [00:13<01:57, 28.95it/s, est. speed input: 50874.02 toks/s, output: 49.68 toks/s]
Processed prompts:  18%|█▊        | 722/4096 [00:15<02:00, 27.98it/s, est. speed input: 48850.62 toks/s, output: 47.71 toks/s]
Processed prompts:  18%|█▊        | 754/4096 [00:16<02:02, 27.30it/s, est. speed input: 47136.31 toks/s, output: 46.03 toks/s]
Processed prompts:  19%|█▉        | 786/4096 [00:17<02:02, 27.06it/s, est. speed input: 45760.16 toks/s, output: 44.69 toks/s]
Processed prompts:  20%|█▉        | 818/4096 [00:18<02:03, 26.63it/s, est. speed input: 44465.30 toks/s, output: 43.42 toks/s]
Processed prompts:  21%|██        | 850/4096 [00:20<02:03, 26.33it/s, est. speed input: 43332.35 toks/s, output: 42.32 toks/s]
Processed prompts:  22%|██▏       | 882/4096 [00:21<02:03, 26.11it/s, est. speed input: 42331.51 toks/s, output: 41.34 toks/s]
Processed prompts:  22%|██▏       | 914/4096 [00:22<02:02, 25.97it/s, est. speed input: 41442.26 toks/s, output: 40.47 toks/s]
Processed prompts:  23%|██▎       | 946/4096 [00:23<02:01, 25.86it/s, est. speed input: 40643.75 toks/s, output: 39.69 toks/s]
Processed prompts:  24%|██▍       | 978/4096 [00:25<02:00, 25.78it/s, est. speed input: 39923.36 toks/s, output: 38.99 toks/s]
Processed prompts:  25%|██▍       | 1010/4096 [00:26<02:00, 25.71it/s, est. speed input: 39268.35 toks/s, output: 38.35 toks/s]
Processed prompts:  25%|██▌       | 1042/4096 [00:27<01:59, 25.65it/s, est. speed input: 38672.34 toks/s, output: 37.77 toks/s]
Processed prompts:  26%|██▌       | 1074/4096 [00:28<01:57, 25.63it/s, est. speed input: 38130.87 toks/s, output: 37.24 toks/s]
Processed prompts:  27%|██▋       | 1106/4096 [00:30<01:56, 25.60it/s, est. speed input: 37631.88 toks/s, output: 36.75 toks/s]
Processed prompts:  28%|██▊       | 1138/4096 [00:31<01:55, 25.58it/s, est. speed input: 37172.60 toks/s, output: 36.30 toks/s]
Processed prompts:  29%|██▊       | 1170/4096 [00:32<01:54, 25.57it/s, est. speed input: 36749.02 toks/s, output: 35.89 toks/s]
Processed prompts:  29%|██▉       | 1202/4096 [00:33<01:52, 25.77it/s, est. speed input: 36393.02 toks/s, output: 35.54 toks/s]
Processed prompts:  30%|███       | 1234/4096 [00:35<01:50, 25.92it/s, est. speed input: 36064.40 toks/s, output: 35.22 toks/s]
Processed prompts:  31%|███       | 1266/4096 [00:36<01:49, 25.80it/s, est. speed input: 35720.58 toks/s, output: 34.88 toks/s]
Processed prompts:  32%|███▏      | 1298/4096 [00:37<01:48, 25.70it/s, est. speed input: 35397.79 toks/s, output: 34.57 toks/s]
Processed prompts:  32%|███▏      | 1330/4096 [00:38<01:46, 25.86it/s, est. speed input: 35129.21 toks/s, output: 34.31 toks/s]
Processed prompts:  33%|███▎      | 1362/4096 [00:40<01:46, 25.74it/s, est. speed input: 34845.45 toks/s, output: 34.03 toks/s]
Processed prompts:  34%|███▍      | 1394/4096 [00:41<01:45, 25.64it/s, est. speed input: 34576.65 toks/s, output: 33.77 toks/s]
Processed prompts:  35%|███▍      | 1426/4096 [00:42<01:44, 25.58it/s, est. speed input: 34324.58 toks/s, output: 33.52 toks/s]
Processed prompts:  36%|███▌      | 1458/4096 [00:43<01:42, 25.76it/s, est. speed input: 34114.96 toks/s, output: 33.32 toks/s]
Processed prompts:  36%|███▋      | 1490/4096 [00:45<01:41, 25.67it/s, est. speed input: 33890.05 toks/s, output: 33.10 toks/s]
Processed prompts:  37%|███▋      | 1522/4096 [00:46<01:39, 25.82it/s, est. speed input: 33703.50 toks/s, output: 32.91 toks/s]
Processed prompts:  38%|███▊      | 1554/4096 [00:47<01:38, 25.93it/s, est. speed input: 33525.75 toks/s, output: 32.74 toks/s]
Processed prompts:  39%|███▊      | 1586/4096 [00:48<01:37, 25.78it/s, est. speed input: 33332.83 toks/s, output: 32.55 toks/s]
Processed prompts:  40%|███▉      | 1618/4096 [00:49<01:35, 25.90it/s, est. speed input: 33173.55 toks/s, output: 32.40 toks/s]
Processed prompts:  40%|████      | 1650/4096 [00:51<01:34, 25.75it/s, est. speed input: 32997.14 toks/s, output: 32.22 toks/s]
Processed prompts:  41%|████      | 1682/4096 [00:52<01:34, 25.64it/s, est. speed input: 32828.69 toks/s, output: 32.06 toks/s]
Processed prompts:  42%|████▏     | 1714/4096 [00:53<01:32, 25.78it/s, est. speed input: 32689.52 toks/s, output: 31.92 toks/s]
Processed prompts:  43%|████▎     | 1746/4096 [00:54<01:30, 25.88it/s, est. speed input: 32556.82 toks/s, output: 31.79 toks/s]
Processed prompts:  43%|████▎     | 1778/4096 [00:56<01:30, 25.72it/s, est. speed input: 32409.23 toks/s, output: 31.65 toks/s]
Processed prompts:  44%|████▍     | 1810/4096 [00:57<01:29, 25.61it/s, est. speed input: 32267.19 toks/s, output: 31.51 toks/s]
Processed prompts:  45%|████▍     | 1842/4096 [00:58<01:28, 25.54it/s, est. speed input: 32132.33 toks/s, output: 31.38 toks/s]
Processed prompts:  46%|████▌     | 1874/4096 [00:59<01:26, 25.70it/s, est. speed input: 32021.19 toks/s, output: 31.27 toks/s]
Processed prompts:  47%|████▋     | 1906/4096 [01:01<01:25, 25.61it/s, est. speed input: 31897.17 toks/s, output: 31.15 toks/s]
Processed prompts:  47%|████▋     | 1938/4096 [01:02<01:24, 25.53it/s, est. speed input: 31777.02 toks/s, output: 31.03 toks/s]
Processed prompts:  48%|████▊     | 1970/4096 [01:03<01:22, 25.69it/s, est. speed input: 31679.10 toks/s, output: 30.94 toks/s]
Processed prompts:  49%|████▉     | 2002/4096 [01:04<01:21, 25.58it/s, est. speed input: 31567.15 toks/s, output: 30.83 toks/s]
Processed prompts:  50%|████▉     | 2034/4096 [01:06<01:20, 25.50it/s, est. speed input: 31459.65 toks/s, output: 30.72 toks/s]
Processed prompts:  50%|█████     | 2066/4096 [01:07<01:19, 25.67it/s, est. speed input: 31372.72 toks/s, output: 30.64 toks/s]
Processed prompts:  51%|█████     | 2098/4096 [01:08<01:18, 25.55it/s, est. speed input: 31271.90 toks/s, output: 30.54 toks/s]
Processed prompts:  52%|█████▏    | 2130/4096 [01:09<01:17, 25.48it/s, est. speed input: 31175.35 toks/s, output: 30.44 toks/s]
Processed prompts:  53%|█████▎    | 2162/4096 [01:11<01:16, 25.43it/s, est. speed input: 31081.74 toks/s, output: 30.35 toks/s]
Processed prompts:  54%|█████▎    | 2194/4096 [01:12<01:14, 25.61it/s, est. speed input: 31006.72 toks/s, output: 30.28 toks/s]
Processed prompts:  54%|█████▍    | 2226/4096 [01:13<01:13, 25.56it/s, est. speed input: 30922.60 toks/s, output: 30.20 toks/s]
Processed prompts:  55%|█████▌    | 2258/4096 [01:14<01:12, 25.52it/s, est. speed input: 30840.22 toks/s, output: 30.12 toks/s]
Processed prompts:  56%|█████▌    | 2290/4096 [01:16<01:10, 25.49it/s, est. speed input: 30760.85 toks/s, output: 30.04 toks/s]
Processed prompts:  57%|█████▋    | 2322/4096 [01:17<01:09, 25.48it/s, est. speed input: 30684.80 toks/s, output: 29.97 toks/s]
Processed prompts:  57%|█████▋    | 2354/4096 [01:18<01:08, 25.46it/s, est. speed input: 30610.45 toks/s, output: 29.89 toks/s]
Processed prompts:  58%|█████▊    | 2386/4096 [01:20<01:07, 25.44it/s, est. speed input: 30537.49 toks/s, output: 29.82 toks/s]
Processed prompts:  59%|█████▉    | 2418/4096 [01:21<01:05, 25.42it/s, est. speed input: 30467.24 toks/s, output: 29.75 toks/s]
Processed prompts:  60%|█████▉    | 2450/4096 [01:22<01:04, 25.42it/s, est. speed input: 30399.08 toks/s, output: 29.69 toks/s]
Processed prompts:  61%|██████    | 2482/4096 [01:23<01:03, 25.40it/s, est. speed input: 30332.52 toks/s, output: 29.62 toks/s]
Processed prompts:  61%|██████▏   | 2514/4096 [01:25<01:01, 25.61it/s, est. speed input: 30280.93 toks/s, output: 29.57 toks/s]
Processed prompts:  62%|██████▏   | 2546/4096 [01:26<01:00, 25.55it/s, est. speed input: 30218.79 toks/s, output: 29.51 toks/s]
Processed prompts:  63%|██████▎   | 2578/4096 [01:27<00:59, 25.71it/s, est. speed input: 30169.38 toks/s, output: 29.46 toks/s]
Processed prompts:  64%|██████▎   | 2610/4096 [01:28<00:58, 25.60it/s, est. speed input: 30109.68 toks/s, output: 29.40 toks/s]
Processed prompts:  65%|██████▍   | 2642/4096 [01:30<00:56, 25.52it/s, est. speed input: 30051.20 toks/s, output: 29.35 toks/s]
Processed prompts:  65%|██████▌   | 2674/4096 [01:31<00:55, 25.47it/s, est. speed input: 29994.76 toks/s, output: 29.29 toks/s]
Processed prompts:  66%|██████▌   | 2706/4096 [01:32<00:54, 25.43it/s, est. speed input: 29939.39 toks/s, output: 29.24 toks/s]
Processed prompts:  67%|██████▋   | 2738/4096 [01:33<00:53, 25.62it/s, est. speed input: 29896.79 toks/s, output: 29.20 toks/s]
Processed prompts:  68%|██████▊   | 2770/4096 [01:35<00:51, 25.53it/s, est. speed input: 29844.02 toks/s, output: 29.14 toks/s]
Processed prompts:  68%|██████▊   | 2802/4096 [01:36<00:50, 25.48it/s, est. speed input: 29793.25 toks/s, output: 29.09 toks/s]
Processed prompts:  69%|██████▉   | 2834/4096 [01:37<00:49, 25.43it/s, est. speed input: 29743.10 toks/s, output: 29.05 toks/s]
Processed prompts:  70%|██████▉   | 2866/4096 [01:38<00:48, 25.41it/s, est. speed input: 29695.13 toks/s, output: 29.00 toks/s]
Processed prompts:  71%|███████   | 2898/4096 [01:39<00:45, 26.13it/s, est. speed input: 29683.18 toks/s, output: 28.99 toks/s]
Processed prompts:  72%|███████▏  | 2930/4096 [01:41<00:45, 25.88it/s, est. speed input: 29636.27 toks/s, output: 28.94 toks/s]
Processed prompts:  72%|███████▏  | 2962/4096 [01:42<00:44, 25.71it/s, est. speed input: 29590.58 toks/s, output: 28.90 toks/s]
Processed prompts:  73%|███████▎  | 2994/4096 [01:43<00:43, 25.60it/s, est. speed input: 29546.44 toks/s, output: 28.85 toks/s]
Processed prompts:  74%|███████▍  | 3026/4096 [01:45<00:41, 25.51it/s, est. speed input: 29502.60 toks/s, output: 28.81 toks/s]
Processed prompts:  75%|███████▍  | 3058/4096 [01:46<00:40, 25.47it/s, est. speed input: 29460.63 toks/s, output: 28.77 toks/s]
Processed prompts:  75%|███████▌  | 3090/4096 [01:47<00:39, 25.42it/s, est. speed input: 29418.90 toks/s, output: 28.73 toks/s]
Processed prompts:  76%|███████▌  | 3122/4096 [01:48<00:38, 25.40it/s, est. speed input: 29379.00 toks/s, output: 28.69 toks/s]
Processed prompts:  77%|███████▋  | 3154/4096 [01:50<00:37, 25.36it/s, est. speed input: 29338.59 toks/s, output: 28.65 toks/s]
Processed prompts:  78%|███████▊  | 3186/4096 [01:51<00:35, 25.35it/s, est. speed input: 29299.76 toks/s, output: 28.61 toks/s]
Processed prompts:  79%|███████▊  | 3218/4096 [01:52<00:34, 25.35it/s, est. speed input: 29262.37 toks/s, output: 28.58 toks/s]
Processed prompts:  79%|███████▉  | 3250/4096 [01:53<00:33, 25.33it/s, est. speed input: 29225.05 toks/s, output: 28.54 toks/s]
Processed prompts:  80%|████████  | 3282/4096 [01:55<00:32, 25.33it/s, est. speed input: 29189.10 toks/s, output: 28.50 toks/s]
Processed prompts:  81%|████████  | 3314/4096 [01:56<00:30, 25.31it/s, est. speed input: 29152.93 toks/s, output: 28.47 toks/s]
Processed prompts:  82%|████████▏ | 3346/4096 [01:57<00:29, 25.31it/s, est. speed input: 29118.19 toks/s, output: 28.44 toks/s]
Processed prompts:  82%|████████▏ | 3378/4096 [01:58<00:28, 25.31it/s, est. speed input: 29084.15 toks/s, output: 28.40 toks/s]
Processed prompts:  83%|████████▎ | 3410/4096 [02:00<00:27, 25.31it/s, est. speed input: 29050.70 toks/s, output: 28.37 toks/s]
Processed prompts:  84%|████████▍ | 3442/4096 [02:01<00:25, 25.31it/s, est. speed input: 29018.04 toks/s, output: 28.34 toks/s]
Processed prompts:  85%|████████▍ | 3474/4096 [02:02<00:24, 25.31it/s, est. speed input: 28986.19 toks/s, output: 28.31 toks/s]
Processed prompts:  86%|████████▌ | 3506/4096 [02:03<00:23, 25.31it/s, est. speed input: 28954.71 toks/s, output: 28.28 toks/s]
Processed prompts:  86%|████████▋ | 3538/4096 [02:05<00:21, 25.52it/s, est. speed input: 28932.24 toks/s, output: 28.25 toks/s]
Processed prompts:  87%|████████▋ | 3570/4096 [02:06<00:20, 25.46it/s, est. speed input: 28902.05 toks/s, output: 28.22 toks/s]
Processed prompts:  88%|████████▊ | 3602/4096 [02:07<00:19, 25.40it/s, est. speed input: 28871.89 toks/s, output: 28.20 toks/s]
Processed prompts:  89%|████████▊ | 3634/4096 [02:09<00:18, 25.36it/s, est. speed input: 28842.66 toks/s, output: 28.17 toks/s]
Processed prompts:  90%|████████▉ | 3666/4096 [02:10<00:16, 25.55it/s, est. speed input: 28821.86 toks/s, output: 28.15 toks/s]
Processed prompts:  90%|█████████ | 3698/4096 [02:11<00:15, 25.48it/s, est. speed input: 28793.80 toks/s, output: 28.12 toks/s]
Processed prompts:  91%|█████████ | 3730/4096 [02:12<00:14, 25.42it/s, est. speed input: 28766.08 toks/s, output: 28.09 toks/s]
Processed prompts:  92%|█████████▏| 3762/4096 [02:14<00:13, 25.36it/s, est. speed input: 28738.31 toks/s, output: 28.06 toks/s]
Processed prompts:  93%|█████████▎| 3794/4096 [02:15<00:11, 25.34it/s, est. speed input: 28711.68 toks/s, output: 28.04 toks/s]
Processed prompts:  93%|█████████▎| 3826/4096 [02:16<00:10, 25.31it/s, est. speed input: 28685.19 toks/s, output: 28.01 toks/s]
Processed prompts:  94%|█████████▍| 3858/4096 [02:17<00:09, 25.31it/s, est. speed input: 28659.82 toks/s, output: 27.99 toks/s]
Processed prompts:  95%|█████████▍| 3890/4096 [02:19<00:08, 25.30it/s, est. speed input: 28634.38 toks/s, output: 27.96 toks/s]
Processed prompts:  96%|█████████▌| 3922/4096 [02:20<00:06, 25.76it/s, est. speed input: 28625.19 toks/s, output: 27.95 toks/s]
Processed prompts:  97%|█████████▋| 3954/4096 [02:21<00:05, 25.60it/s, est. speed input: 28600.36 toks/s, output: 27.93 toks/s]
Processed prompts:  97%|█████████▋| 3986/4096 [02:22<00:04, 25.72it/s, est. speed input: 28583.46 toks/s, output: 27.91 toks/s]
Processed prompts:  98%|█████████▊| 4018/4096 [02:24<00:03, 25.58it/s, est. speed input: 28559.58 toks/s, output: 27.89 toks/s]
Processed prompts:  99%|█████████▉| 4050/4096 [02:25<00:01, 25.71it/s, est. speed input: 28543.37 toks/s, output: 27.87 toks/s]
Processed prompts: 100%|█████████▉| 4082/4096 [02:25<00:00, 30.81it/s, est. speed input: 28658.68 toks/s, output: 27.99 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:25<00:00, 30.81it/s, est. speed input: 28756.88 toks/s, output: 28.08 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:25<00:00, 28.08it/s, est. speed input: 28756.88 toks/s, output: 28.08 toks/s]
[rank0]:[W125 20:47:05.517562285 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 239.6s

测试结果:
  Requests/s:   25.63
  Tokens/s:     26267.30
  Total Reqs:   4096
  Elapsed:      159.83s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     26241.67

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:48:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=435117) [INFO] Loading compress extension: cusparselt_compress_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=435117) WARNING 01-25 20:48:33 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     def forward(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     raise e
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/tmp/torchinductor_root/cy/ccy35bgbmruxc5pmbysp2nlvvnrxqz3ca4fajnwwlsxbt34m55dv.py", line 1093, in call
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) ERROR 01-25 20:48:44 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-25 20:48:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:48:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:48:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 20:48:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 20:48:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 20:48:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:48:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:48:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:48:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:48:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_A100_cc80_py312_cu129_x86_64.so
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=435117) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=435117) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.27it/s]
(EngineCore_DP0 pid=435117) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=435117) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.25it/s]
(EngineCore_DP0 pid=435117) 
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=435117) [2026-01-25 20:48:25] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=435117) [rank0]:W0125 20:48:42.462000 435117 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=435117) [rank0]:W0125 20:48:42.587000 435117 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=435117) [rank0]:W0125 20:48:43.994000 435117 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=435117) [rank0]:W0125 20:48:44.176000 435117 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=435117) Process EngineCore_DP0:
(EngineCore_DP0 pid=435117) Traceback (most recent call last):
(EngineCore_DP0 pid=435117)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=435117)     self.run()
(EngineCore_DP0 pid=435117)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=435117)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=435117)     raise e
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=435117)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=435117)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=435117)     super().__init__(
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=435117)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=435117)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=435117)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=435117)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=435117)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=435117)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=435117)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=435117)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435117)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=435117)     self.model_runner.profile_run()
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=435117)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=435117)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=435117)     return func(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=435117)     outputs = self.model(
(EngineCore_DP0 pid=435117)               ^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=435117)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435117)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435117)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=435117)     hidden_states = self.model(
(EngineCore_DP0 pid=435117)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=435117)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=435117)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=435117)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=435117)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=435117)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=435117)     def forward(
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=435117)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=435117)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=435117)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=435117)     raise e
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=435117)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=435117)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=435117)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=435117)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=435117)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=435117)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=435117)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=435117)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=435117)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=435117)     return compiled_fn(full_args)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=435117)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=435117)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=435117)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=435117)                             ^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=435117)     outs = compiled_fn(args)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=435117)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=435117)     return self.current_callable(inputs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=435117)     out = model(new_inputs)
(EngineCore_DP0 pid=435117)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/tmp/torchinductor_root/cy/ccy35bgbmruxc5pmbysp2nlvvnrxqz3ca4fajnwwlsxbt34m55dv.py", line 1093, in call
(EngineCore_DP0 pid=435117)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 10)
(EngineCore_DP0 pid=435117)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=435117)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=435117)     return fn(input, L)
(EngineCore_DP0 pid=435117)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/A100_cc80_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 321, in quant_slide_int8_triton
(EngineCore_DP0 pid=435117)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=435117)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=435117)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=435117)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=435117)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=435117)     self._init_handles()
(EngineCore_DP0 pid=435117)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=435117)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=435117)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=435117) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W125 20:48:45.016468946 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,21.5499,11055.0770,5.9397
1024,1024,1,128,128,20.0549,20556.2826,6.3825
2048,1024,2,256,128,23.2935,23875.8194,10.9902
4096,1024,4,512,128,24.8414,25462.4217,20.6108
8192,1024,8,1024,128,25.5361,26174.5421,40.1000
16384,1024,16,2048,128,25.8372,26483.1789,79.2654
32768,1024,32,4096,128,25.6266,26267.2967,159.8337
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败


============================================================
  Benchmark 完成!
============================================================


总计: 35 成功, 5 失败
============================================================
