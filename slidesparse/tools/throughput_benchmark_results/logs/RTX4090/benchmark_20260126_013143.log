======================================================================
SlideSparse vLLM Throughput Benchmark Log
Created: 2026-01-26 01:31:43
======================================================================

原始命令:
  /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --backend cublaslt,cusparselt --stage prefill --sparsity 2_4,2_6,2_8,2_10 --M 512,1024,2048,4096,8192,16384,32768,65536

命令行参数:
  --model: qwen2.5-7b-int8
  --backend: cublaslt,cusparselt
  --sparsity: 2_4,2_6,2_8,2_10
  --stage: prefill
  --M: 512,1024,2048,4096,8192,16384,32768,65536
  --N: None
  --inner-32: False
  --eager: False
  --gpu-id: 0
  --gpu-mem: 0.8
  --dry-run: False
  --list-models: False

硬件信息:
  GPU: RTX4090
  Compute Capability: cc89
  VRAM: 24.0 GB
  CUDA: 12.9
  Python: py312

Backend 环境变量 (初始状态):
  DISABLE_SLIDESPARSE: 未设置
  USE_CUBLASLT: 未设置
  USE_CUSPARSELT: 未设置
  SPARSITY: 未设置
  INNER_DTYPE_32: 未设置

======================================================================


============================================================
  Qwen2.5-7B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:31:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:31:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=9491) WARNING 01-26 01:32:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=9491) WARNING 01-26 01:32:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.13 requests/s, 8272.14 total tokens/s, 16.13 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 01:31:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:31:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:31:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:31:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:31:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:31:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:31:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:31:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:31:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:32:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:32:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:32:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:32:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:32:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:32:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=9491) [2026-01-26 01:32:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=9491) [2026-01-26 01:32:01] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=9491) [2026-01-26 01:32:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=9491) [2026-01-26 01:32:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=9491) [2026-01-26 01:32:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=9491) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=9491) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.42it/s]
(EngineCore_DP0 pid=9491) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.03it/s]
(EngineCore_DP0 pid=9491) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.07it/s]
(EngineCore_DP0 pid=9491) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=9491) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.71it/s]
(EngineCore_DP0 pid=9491) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.65it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  35%|███▌      | 45/128 [00:00<00:00, 446.72it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 465.61it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 465.11it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:03, 37.38it/s, est. speed input: 19141.01 toks/s, output: 37.38 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:05, 21.96it/s, est. speed input: 12078.51 toks/s, output: 23.58 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:05, 19.52it/s, est. speed input: 10872.92 toks/s, output: 21.23 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:06, 18.35it/s, est. speed input: 10274.38 toks/s, output: 20.07 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:06, 17.86it/s, est. speed input: 10019.44 toks/s, output: 19.57 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:06, 17.45it/s, est. speed input: 9819.32 toks/s, output: 19.18 toks/s] 
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 17.19it/s, est. speed input: 9671.17 toks/s, output: 18.89 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 16.88it/s, est. speed input: 9528.23 toks/s, output: 18.61 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 16.73it/s, est. speed input: 9425.86 toks/s, output: 18.41 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 16.60it/s, est. speed input: 9335.66 toks/s, output: 18.23 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 16.57it/s, est. speed input: 9268.81 toks/s, output: 18.10 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 16.55it/s, est. speed input: 9210.39 toks/s, output: 17.99 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 16.52it/s, est. speed input: 9159.43 toks/s, output: 17.89 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 16.45it/s, est. speed input: 9107.54 toks/s, output: 17.79 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 16.41it/s, est. speed input: 9062.81 toks/s, output: 17.70 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 16.36it/s, est. speed input: 9022.01 toks/s, output: 17.62 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 16.38it/s, est. speed input: 8989.59 toks/s, output: 17.56 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 16.33it/s, est. speed input: 8955.24 toks/s, output: 17.49 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 16.36it/s, est. speed input: 8929.51 toks/s, output: 17.44 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 16.38it/s, est. speed input: 8905.87 toks/s, output: 17.39 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 16.41it/s, est. speed input: 8885.78 toks/s, output: 17.35 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 16.37it/s, est. speed input: 8863.41 toks/s, output: 17.31 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 16.40it/s, est. speed input: 8845.74 toks/s, output: 17.28 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 16.35it/s, est. speed input: 8825.87 toks/s, output: 17.24 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 16.29it/s, est. speed input: 8804.30 toks/s, output: 17.20 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 16.26it/s, est. speed input: 8786.18 toks/s, output: 17.16 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 16.22it/s, est. speed input: 8767.38 toks/s, output: 17.12 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 16.28it/s, est. speed input: 8755.91 toks/s, output: 17.10 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 16.33it/s, est. speed input: 8744.96 toks/s, output: 17.08 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 16.36it/s, est. speed input: 8734.79 toks/s, output: 17.06 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 16.37it/s, est. speed input: 8724.68 toks/s, output: 17.04 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 16.30it/s, est. speed input: 8710.67 toks/s, output: 17.01 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 16.29it/s, est. speed input: 8700.09 toks/s, output: 16.99 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 16.36it/s, est. speed input: 8693.15 toks/s, output: 16.98 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 16.35it/s, est. speed input: 8684.39 toks/s, output: 16.96 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:03, 16.28it/s, est. speed input: 8672.84 toks/s, output: 16.94 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 16.34it/s, est. speed input: 8666.93 toks/s, output: 16.93 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 16.38it/s, est. speed input: 8661.39 toks/s, output: 16.92 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 16.40it/s, est. speed input: 8655.51 toks/s, output: 16.91 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 16.43it/s, est. speed input: 8650.58 toks/s, output: 16.90 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 16.40it/s, est. speed input: 8643.84 toks/s, output: 16.88 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 16.40it/s, est. speed input: 8638.10 toks/s, output: 16.87 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 16.40it/s, est. speed input: 8632.92 toks/s, output: 16.86 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:02, 16.32it/s, est. speed input: 8624.56 toks/s, output: 16.84 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 16.32it/s, est. speed input: 8619.11 toks/s, output: 16.83 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 16.34it/s, est. speed input: 8614.33 toks/s, output: 16.82 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 16.37it/s, est. speed input: 8610.38 toks/s, output: 16.82 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 16.34it/s, est. speed input: 8604.84 toks/s, output: 16.81 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 16.25it/s, est. speed input: 8596.96 toks/s, output: 16.79 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 16.33it/s, est. speed input: 8594.29 toks/s, output: 16.79 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 16.32it/s, est. speed input: 8589.52 toks/s, output: 16.78 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:01, 16.28it/s, est. speed input: 8584.09 toks/s, output: 16.77 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 16.22it/s, est. speed input: 8577.69 toks/s, output: 16.75 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 16.24it/s, est. speed input: 8573.45 toks/s, output: 16.74 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 16.30it/s, est. speed input: 8570.68 toks/s, output: 16.74 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 16.33it/s, est. speed input: 8567.55 toks/s, output: 16.73 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 16.26it/s, est. speed input: 8562.14 toks/s, output: 16.72 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 16.32it/s, est. speed input: 8559.98 toks/s, output: 16.72 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 16.36it/s, est. speed input: 8557.82 toks/s, output: 16.71 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:07<00:00, 16.39it/s, est. speed input: 8555.68 toks/s, output: 16.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.39it/s, est. speed input: 8554.24 toks/s, output: 16.71 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.71it/s, est. speed input: 8554.24 toks/s, output: 16.71 toks/s]
[rank0]:[W126 01:32:31.065384188 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 50.8s

测试结果:
  Requests/s:   16.13
  Tokens/s:     8272.14
  Total Reqs:   128
  Elapsed:      7.94s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     8256.02

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:32:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:32:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=10400) WARNING 01-26 01:32:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=10400) WARNING 01-26 01:33:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.92 requests/s, 16315.73 total tokens/s, 15.92 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 01:32:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:32:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:32:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:32:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:32:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:32:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:32:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:32:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:32:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:32:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:32:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:32:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:32:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:32:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=10400) [2026-01-26 01:32:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=10400) [2026-01-26 01:32:51] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=10400) [2026-01-26 01:32:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=10400) [2026-01-26 01:32:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=10400) [2026-01-26 01:32:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=10400) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=10400) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.25it/s]
(EngineCore_DP0 pid=10400) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.08it/s]
(EngineCore_DP0 pid=10400) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.10it/s]
(EngineCore_DP0 pid=10400) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=10400) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.09it/s]
(EngineCore_DP0 pid=10400) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.09it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 243.89it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 255.56it/s]
Adding requests:  61%|██████    | 78/128 [00:00<00:00, 256.04it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 256.75it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 255.64it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:02, 47.60it/s, est. speed input: 48754.84 toks/s, output: 47.61 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:04, 24.02it/s, est. speed input: 26930.54 toks/s, output: 26.30 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:05, 20.83it/s, est. speed input: 23835.87 toks/s, output: 23.28 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 19.09it/s, est. speed input: 22150.06 toks/s, output: 21.63 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:05, 17.96it/s, est. speed input: 21041.49 toks/s, output: 20.55 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 17.47it/s, est. speed input: 20527.54 toks/s, output: 20.05 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 17.15it/s, est. speed input: 20147.81 toks/s, output: 19.68 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 16.92it/s, est. speed input: 19841.41 toks/s, output: 19.38 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 16.74it/s, est. speed input: 19583.99 toks/s, output: 19.12 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 16.59it/s, est. speed input: 19359.28 toks/s, output: 18.91 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 16.50it/s, est. speed input: 19171.03 toks/s, output: 18.72 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 16.32it/s, est. speed input: 18978.29 toks/s, output: 18.53 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 16.31it/s, est. speed input: 18838.17 toks/s, output: 18.40 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 16.22it/s, est. speed input: 18694.67 toks/s, output: 18.26 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 16.24it/s, est. speed input: 18584.98 toks/s, output: 18.15 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 16.25it/s, est. speed input: 18486.83 toks/s, output: 18.05 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 16.23it/s, est. speed input: 18392.41 toks/s, output: 17.96 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 16.31it/s, est. speed input: 18322.43 toks/s, output: 17.89 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 16.30it/s, est. speed input: 18249.63 toks/s, output: 17.82 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 16.39it/s, est. speed input: 18196.38 toks/s, output: 17.77 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:02<00:00, 61.36it/s, est. speed input: 24341.80 toks/s, output: 23.77 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:03<00:01, 34.42it/s, est. speed input: 23418.93 toks/s, output: 22.87 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:01, 27.71it/s, est. speed input: 22906.20 toks/s, output: 22.37 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:03<00:01, 24.28it/s, est. speed input: 22532.51 toks/s, output: 22.00 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 21.98it/s, est. speed input: 22216.41 toks/s, output: 21.70 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 20.57it/s, est. speed input: 21983.19 toks/s, output: 21.47 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 19.55it/s, est. speed input: 21786.58 toks/s, output: 21.28 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 18.77it/s, est. speed input: 21605.45 toks/s, output: 21.10 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 18.03it/s, est. speed input: 21414.95 toks/s, output: 20.91 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 17.75it/s, est. speed input: 21312.22 toks/s, output: 20.81 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 17.50it/s, est. speed input: 21212.72 toks/s, output: 20.72 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:01, 17.17it/s, est. speed input: 21105.17 toks/s, output: 20.61 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:01, 16.95it/s, est. speed input: 21005.79 toks/s, output: 20.51 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:05<00:00, 16.87it/s, est. speed input: 20919.68 toks/s, output: 20.43 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 16.77it/s, est. speed input: 20833.59 toks/s, output: 20.35 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 16.71it/s, est. speed input: 20752.84 toks/s, output: 20.27 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 16.70it/s, est. speed input: 20677.45 toks/s, output: 20.19 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 16.52it/s, est. speed input: 20590.80 toks/s, output: 20.11 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 16.55it/s, est. speed input: 20521.13 toks/s, output: 20.04 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 16.57it/s, est. speed input: 20453.70 toks/s, output: 19.97 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 16.42it/s, est. speed input: 20376.19 toks/s, output: 19.90 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 16.42it/s, est. speed input: 20342.80 toks/s, output: 19.87 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.87it/s, est. speed input: 20342.80 toks/s, output: 19.87 toks/s]
[rank0]:[W126 01:33:21.254114223 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 49.1s

测试结果:
  Requests/s:   15.92
  Tokens/s:     16315.73
  Total Reqs:   128
  Elapsed:      8.04s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     16299.81

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:33:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:33:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=11346) WARNING 01-26 01:33:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=11346) WARNING 01-26 01:33:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.80 requests/s, 20297.87 total tokens/s, 19.80 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 01:33:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:33:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:33:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:33:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:33:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:33:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:33:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:33:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:33:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:33:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:33:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:33:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:33:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:33:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:33:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:33:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:33:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=11346) [2026-01-26 01:33:42] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=11346) [2026-01-26 01:33:42] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=11346) [2026-01-26 01:33:42] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=11346) [2026-01-26 01:33:42] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=11346) [2026-01-26 01:33:42] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=11346) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=11346) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.27it/s]
(EngineCore_DP0 pid=11346) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.07it/s]
(EngineCore_DP0 pid=11346) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.10it/s]
(EngineCore_DP0 pid=11346) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=11346) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.02it/s]
(EngineCore_DP0 pid=11346) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  6.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.63it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 24/256 [00:00<00:00, 236.31it/s]
Adding requests:  20%|█▉        | 51/256 [00:00<00:00, 251.74it/s]
Adding requests:  31%|███       | 79/256 [00:00<00:00, 261.92it/s]
Adding requests:  41%|████▏     | 106/256 [00:00<00:00, 262.98it/s]
Adding requests:  52%|█████▏    | 133/256 [00:00<00:00, 260.87it/s]
Adding requests:  63%|██████▎   | 161/256 [00:00<00:00, 264.79it/s]
Adding requests:  74%|███████▍  | 190/256 [00:00<00:00, 271.60it/s]
Adding requests:  85%|████████▌ | 218/256 [00:00<00:00, 267.21it/s]
Adding requests:  96%|█████████▌| 245/256 [00:00<00:00, 266.61it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 263.60it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:01, 140.52it/s, est. speed input: 143923.88 toks/s, output: 140.53 toks/s]
Processed prompts:  12%|█▏        | 31/256 [00:00<00:06, 33.71it/s, est. speed input: 39128.06 toks/s, output: 38.21 toks/s]   
Processed prompts:  15%|█▌        | 39/256 [00:01<00:07, 27.96it/s, est. speed input: 33020.68 toks/s, output: 32.25 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:08, 24.47it/s, est. speed input: 29886.72 toks/s, output: 29.19 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:08, 23.48it/s, est. speed input: 28804.69 toks/s, output: 28.13 toks/s]
Processed prompts:  20%|██        | 52/256 [00:01<00:09, 22.64it/s, est. speed input: 27945.34 toks/s, output: 27.29 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:02<00:09, 21.99it/s, est. speed input: 27251.15 toks/s, output: 26.61 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:09, 21.48it/s, est. speed input: 26676.82 toks/s, output: 26.05 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:09, 21.09it/s, est. speed input: 26190.93 toks/s, output: 25.58 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:09, 20.81it/s, est. speed input: 25778.89 toks/s, output: 25.17 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:08, 20.60it/s, est. speed input: 25421.29 toks/s, output: 24.83 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:08, 20.44it/s, est. speed input: 25107.08 toks/s, output: 24.52 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:08, 20.33it/s, est. speed input: 24831.67 toks/s, output: 24.25 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:08, 20.24it/s, est. speed input: 24585.54 toks/s, output: 24.01 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:08, 20.19it/s, est. speed input: 24368.21 toks/s, output: 23.80 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:08, 20.15it/s, est. speed input: 24170.75 toks/s, output: 23.60 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:04<00:07, 20.12it/s, est. speed input: 23993.52 toks/s, output: 23.43 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:07, 20.11it/s, est. speed input: 23834.65 toks/s, output: 23.28 toks/s]
Processed prompts:  41%|████      | 104/256 [00:04<00:07, 20.10it/s, est. speed input: 23689.23 toks/s, output: 23.13 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:07, 20.10it/s, est. speed input: 23558.00 toks/s, output: 23.01 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:07, 20.11it/s, est. speed input: 23438.40 toks/s, output: 22.89 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:05<00:06, 20.10it/s, est. speed input: 23325.47 toks/s, output: 22.78 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:05<00:06, 20.10it/s, est. speed input: 23223.18 toks/s, output: 22.68 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:06, 20.09it/s, est. speed input: 23125.28 toks/s, output: 22.58 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:05<00:06, 20.09it/s, est. speed input: 23035.88 toks/s, output: 22.50 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:06, 20.09it/s, est. speed input: 22952.99 toks/s, output: 22.41 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:05, 20.09it/s, est. speed input: 22875.25 toks/s, output: 22.34 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:06<00:05, 20.09it/s, est. speed input: 22801.94 toks/s, output: 22.27 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:05, 20.06it/s, est. speed input: 22730.33 toks/s, output: 22.20 toks/s]
Processed prompts:  57%|█████▋    | 147/256 [00:06<00:05, 21.79it/s, est. speed input: 22849.24 toks/s, output: 22.31 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:06<00:05, 19.50it/s, est. speed input: 22627.39 toks/s, output: 22.10 toks/s]
Processed prompts:  60%|█████▉    | 153/256 [00:06<00:04, 21.51it/s, est. speed input: 22743.22 toks/s, output: 22.21 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:07<00:05, 19.17it/s, est. speed input: 22532.68 toks/s, output: 22.00 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:07<00:04, 19.53it/s, est. speed input: 22483.62 toks/s, output: 21.96 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:07<00:04, 19.78it/s, est. speed input: 22438.89 toks/s, output: 21.91 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:07<00:04, 19.92it/s, est. speed input: 22394.98 toks/s, output: 21.87 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:07<00:04, 20.05it/s, est. speed input: 22355.49 toks/s, output: 21.83 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:08<00:03, 20.12it/s, est. speed input: 22316.97 toks/s, output: 21.79 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:08<00:03, 20.15it/s, est. speed input: 22277.98 toks/s, output: 21.76 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:08<00:03, 20.19it/s, est. speed input: 22242.83 toks/s, output: 21.72 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:08<00:03, 20.21it/s, est. speed input: 22208.85 toks/s, output: 21.69 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:08<00:03, 20.22it/s, est. speed input: 22176.16 toks/s, output: 21.66 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:09<00:02, 20.24it/s, est. speed input: 22145.27 toks/s, output: 21.63 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:09<00:02, 20.23it/s, est. speed input: 22114.16 toks/s, output: 21.60 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:09<00:02, 21.44it/s, est. speed input: 22172.30 toks/s, output: 21.65 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:09<00:02, 21.06it/s, est. speed input: 22142.08 toks/s, output: 21.62 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:09<00:02, 20.79it/s, est. speed input: 22112.28 toks/s, output: 21.59 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:10<00:01, 20.61it/s, est. speed input: 22084.19 toks/s, output: 21.57 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:10<00:01, 20.50it/s, est. speed input: 22057.85 toks/s, output: 21.54 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:10<00:01, 20.42it/s, est. speed input: 22032.61 toks/s, output: 21.52 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:10<00:01, 20.38it/s, est. speed input: 22009.52 toks/s, output: 21.49 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:10<00:01, 20.35it/s, est. speed input: 21986.89 toks/s, output: 21.47 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:11<00:00, 20.33it/s, est. speed input: 21964.64 toks/s, output: 21.45 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:11<00:00, 20.29it/s, est. speed input: 21942.25 toks/s, output: 21.43 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:11<00:00, 20.27it/s, est. speed input: 21920.88 toks/s, output: 21.41 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:11<00:00, 20.25it/s, est. speed input: 21899.93 toks/s, output: 21.39 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:11<00:00, 20.24it/s, est. speed input: 21879.71 toks/s, output: 21.37 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 21.45it/s, est. speed input: 21928.57 toks/s, output: 21.41 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 21.45it/s, est. speed input: 21928.57 toks/s, output: 21.41 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 21.41it/s, est. speed input: 21928.57 toks/s, output: 21.41 toks/s]
[rank0]:[W126 01:34:17.730977085 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 56.3s

测试结果:
  Requests/s:   19.80
  Tokens/s:     20297.87
  Total Reqs:   256
  Elapsed:      12.93s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     20278.07

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:34:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:34:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=12394) WARNING 01-26 01:34:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=12394) WARNING 01-26 01:34:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.17 requests/s, 20674.60 total tokens/s, 20.17 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 01:34:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:34:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:34:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:34:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:34:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:34:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:34:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:34:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:34:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:34:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:34:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:34:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:34:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:34:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:34:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:34:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:34:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=12394) [2026-01-26 01:34:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=12394) [2026-01-26 01:34:39] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=12394) [2026-01-26 01:34:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=12394) [2026-01-26 01:34:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=12394) [2026-01-26 01:34:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=12394) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=12394) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.47it/s]
(EngineCore_DP0 pid=12394) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.15it/s]
(EngineCore_DP0 pid=12394) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
(EngineCore_DP0 pid=12394) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=12394) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  7.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.18it/s]
(EngineCore_DP0 pid=12394) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  6.95it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.21it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 239.61it/s]
Adding requests:  10%|▉         | 50/512 [00:00<00:01, 244.80it/s]
Adding requests:  15%|█▌        | 77/512 [00:00<00:01, 252.78it/s]
Adding requests:  20%|██        | 103/512 [00:00<00:01, 254.20it/s]
Adding requests:  25%|██▌       | 129/512 [00:00<00:01, 253.70it/s]
Adding requests:  30%|███       | 156/512 [00:00<00:01, 258.59it/s]
Adding requests:  36%|███▌      | 182/512 [00:00<00:01, 257.21it/s]
Adding requests:  41%|████      | 209/512 [00:00<00:01, 260.01it/s]
Adding requests:  46%|████▌     | 236/512 [00:00<00:01, 260.84it/s]
Adding requests:  51%|█████▏    | 263/512 [00:01<00:00, 261.12it/s]
Adding requests:  57%|█████▋    | 290/512 [00:01<00:00, 261.02it/s]
Adding requests:  62%|██████▏   | 319/512 [00:01<00:00, 268.66it/s]
Adding requests:  68%|██████▊   | 346/512 [00:01<00:00, 261.13it/s]
Adding requests:  73%|███████▎  | 374/512 [00:01<00:00, 264.44it/s]
Adding requests:  79%|███████▊  | 402/512 [00:01<00:00, 266.39it/s]
Adding requests:  84%|████████▍ | 430/512 [00:01<00:00, 267.87it/s]
Adding requests:  89%|████████▉ | 457/512 [00:01<00:00, 264.77it/s]
Adding requests:  95%|█████████▌| 487/512 [00:01<00:00, 274.30it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 263.31it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 38/512 [00:00<00:03, 126.97it/s, est. speed input: 130035.01 toks/s, output: 126.98 toks/s]
Processed prompts:  10%|▉         | 51/512 [00:00<00:09, 48.56it/s, est. speed input: 57688.05 toks/s, output: 56.34 toks/s]   
Processed prompts:  11%|█▏        | 58/512 [00:01<00:12, 35.61it/s, est. speed input: 45355.88 toks/s, output: 44.29 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:01<00:13, 33.13it/s, est. speed input: 42678.97 toks/s, output: 41.68 toks/s]
Processed prompts:  13%|█▎        | 67/512 [00:01<00:14, 29.84it/s, est. speed input: 40032.87 toks/s, output: 39.09 toks/s]
Processed prompts:  14%|█▍        | 71/512 [00:01<00:16, 27.22it/s, est. speed input: 37942.50 toks/s, output: 37.05 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:02<00:18, 23.87it/s, est. speed input: 35774.71 toks/s, output: 34.94 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:19, 22.73it/s, est. speed input: 34421.00 toks/s, output: 33.61 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:19, 21.88it/s, est. speed input: 33283.90 toks/s, output: 32.50 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:02<00:20, 21.26it/s, est. speed input: 32309.70 toks/s, output: 31.55 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:20, 20.82it/s, est. speed input: 31473.92 toks/s, output: 30.74 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:20, 20.66it/s, est. speed input: 30799.35 toks/s, output: 30.08 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:20, 20.61it/s, est. speed input: 30220.78 toks/s, output: 29.51 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:19, 20.57it/s, est. speed input: 29706.20 toks/s, output: 29.01 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:19, 20.53it/s, est. speed input: 29244.48 toks/s, output: 28.56 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:19, 20.51it/s, est. speed input: 28829.89 toks/s, output: 28.15 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:19, 20.50it/s, est. speed input: 28454.80 toks/s, output: 27.79 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:19, 20.49it/s, est. speed input: 28113.24 toks/s, output: 27.45 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:19, 20.47it/s, est. speed input: 27800.70 toks/s, output: 27.15 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:18, 20.47it/s, est. speed input: 27515.23 toks/s, output: 26.87 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:18, 20.46it/s, est. speed input: 27251.51 toks/s, output: 26.61 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:18, 20.45it/s, est. speed input: 27007.92 toks/s, output: 26.37 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:18, 20.45it/s, est. speed input: 26782.07 toks/s, output: 26.15 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:18, 20.46it/s, est. speed input: 26574.58 toks/s, output: 25.95 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:17, 20.45it/s, est. speed input: 26379.99 toks/s, output: 25.76 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:17, 20.45it/s, est. speed input: 26197.66 toks/s, output: 25.58 toks/s]
Processed prompts:  30%|███       | 154/512 [00:06<00:17, 20.44it/s, est. speed input: 26026.89 toks/s, output: 25.42 toks/s]
Processed prompts:  31%|███       | 158/512 [00:06<00:17, 20.44it/s, est. speed input: 25868.07 toks/s, output: 25.26 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:06<00:17, 20.44it/s, est. speed input: 25717.55 toks/s, output: 25.11 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:16, 20.43it/s, est. speed input: 25575.52 toks/s, output: 24.98 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:16, 20.43it/s, est. speed input: 25442.16 toks/s, output: 24.85 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:07<00:16, 20.42it/s, est. speed input: 25315.58 toks/s, output: 24.72 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:07<00:16, 20.43it/s, est. speed input: 25196.94 toks/s, output: 24.61 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:07<00:16, 20.43it/s, est. speed input: 25084.13 toks/s, output: 24.50 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:07<00:15, 20.43it/s, est. speed input: 24977.49 toks/s, output: 24.39 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:15, 20.43it/s, est. speed input: 24875.46 toks/s, output: 24.29 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:08<00:15, 20.42it/s, est. speed input: 24778.02 toks/s, output: 24.20 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:08<00:15, 20.41it/s, est. speed input: 24685.23 toks/s, output: 24.11 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:08<00:14, 21.91it/s, est. speed input: 24727.96 toks/s, output: 24.15 toks/s]
Processed prompts:  40%|████      | 206/512 [00:08<00:14, 21.43it/s, est. speed input: 24640.03 toks/s, output: 24.06 toks/s]
Processed prompts:  41%|████      | 210/512 [00:08<00:14, 21.12it/s, est. speed input: 24556.40 toks/s, output: 23.98 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:14, 20.89it/s, est. speed input: 24475.49 toks/s, output: 23.90 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:09<00:14, 20.73it/s, est. speed input: 24398.05 toks/s, output: 23.83 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:09<00:14, 20.62it/s, est. speed input: 24323.81 toks/s, output: 23.75 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:09<00:13, 20.56it/s, est. speed input: 24253.55 toks/s, output: 23.69 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:09<00:13, 20.51it/s, est. speed input: 24185.30 toks/s, output: 23.62 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:13, 20.47it/s, est. speed input: 24120.14 toks/s, output: 23.55 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:10<00:13, 20.44it/s, est. speed input: 24056.91 toks/s, output: 23.49 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:10<00:13, 20.42it/s, est. speed input: 23996.33 toks/s, output: 23.43 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:10<00:13, 20.41it/s, est. speed input: 23938.26 toks/s, output: 23.38 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:10<00:12, 20.41it/s, est. speed input: 23882.64 toks/s, output: 23.32 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:10<00:12, 20.41it/s, est. speed input: 23828.81 toks/s, output: 23.27 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:11<00:12, 20.40it/s, est. speed input: 23776.72 toks/s, output: 23.22 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:11<00:12, 20.40it/s, est. speed input: 23726.36 toks/s, output: 23.17 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:11<00:12, 20.39it/s, est. speed input: 23677.53 toks/s, output: 23.12 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:11<00:11, 20.39it/s, est. speed input: 23630.85 toks/s, output: 23.08 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:11<00:11, 20.39it/s, est. speed input: 23585.41 toks/s, output: 23.03 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:12<00:11, 20.39it/s, est. speed input: 23541.46 toks/s, output: 22.99 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:12<00:11, 20.38it/s, est. speed input: 23498.33 toks/s, output: 22.95 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:12<00:11, 20.38it/s, est. speed input: 23457.01 toks/s, output: 22.91 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:12<00:10, 20.38it/s, est. speed input: 23416.84 toks/s, output: 22.87 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:12<00:10, 20.37it/s, est. speed input: 23377.65 toks/s, output: 22.83 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:13<00:10, 20.37it/s, est. speed input: 23339.75 toks/s, output: 22.79 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:13<00:10, 20.37it/s, est. speed input: 23303.24 toks/s, output: 22.76 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:13<00:10, 20.37it/s, est. speed input: 23267.51 toks/s, output: 22.72 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:13<00:09, 20.38it/s, est. speed input: 23233.20 toks/s, output: 22.69 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:13<00:09, 20.38it/s, est. speed input: 23200.04 toks/s, output: 22.66 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:14<00:09, 20.39it/s, est. speed input: 23167.86 toks/s, output: 22.62 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:14<00:09, 20.39it/s, est. speed input: 23136.48 toks/s, output: 22.59 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:14<00:09, 20.39it/s, est. speed input: 23105.61 toks/s, output: 22.56 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:14<00:08, 20.38it/s, est. speed input: 23075.54 toks/s, output: 22.53 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:14<00:08, 20.39it/s, est. speed input: 23046.72 toks/s, output: 22.51 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:15<00:08, 20.38it/s, est. speed input: 23018.05 toks/s, output: 22.48 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:15<00:08, 20.38it/s, est. speed input: 22990.34 toks/s, output: 22.45 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:15<00:08, 20.38it/s, est. speed input: 22963.23 toks/s, output: 22.42 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:15<00:07, 20.38it/s, est. speed input: 22936.87 toks/s, output: 22.40 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:15<00:07, 20.38it/s, est. speed input: 22911.31 toks/s, output: 22.37 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:16<00:07, 20.38it/s, est. speed input: 22886.36 toks/s, output: 22.35 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:16<00:07, 20.38it/s, est. speed input: 22861.80 toks/s, output: 22.33 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:16<00:07, 20.38it/s, est. speed input: 22838.04 toks/s, output: 22.30 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:16<00:06, 20.38it/s, est. speed input: 22814.94 toks/s, output: 22.28 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:16<00:06, 20.38it/s, est. speed input: 22792.00 toks/s, output: 22.26 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:16<00:06, 20.38it/s, est. speed input: 22769.74 toks/s, output: 22.24 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:17<00:06, 20.37it/s, est. speed input: 22747.86 toks/s, output: 22.21 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:17<00:06, 20.36it/s, est. speed input: 22726.03 toks/s, output: 22.19 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:17<00:05, 20.35it/s, est. speed input: 22704.75 toks/s, output: 22.17 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:17<00:05, 20.34it/s, est. speed input: 22683.64 toks/s, output: 22.15 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:17<00:05, 20.34it/s, est. speed input: 22663.39 toks/s, output: 22.13 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:18<00:05, 20.35it/s, est. speed input: 22643.74 toks/s, output: 22.11 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:18<00:05, 20.36it/s, est. speed input: 22624.73 toks/s, output: 22.09 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:18<00:05, 20.35it/s, est. speed input: 22605.82 toks/s, output: 22.08 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:18<00:04, 20.35it/s, est. speed input: 22587.21 toks/s, output: 22.06 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:18<00:04, 20.36it/s, est. speed input: 22569.44 toks/s, output: 22.04 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:19<00:04, 20.36it/s, est. speed input: 22552.00 toks/s, output: 22.02 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:19<00:04, 20.36it/s, est. speed input: 22534.71 toks/s, output: 22.01 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:19<00:04, 20.36it/s, est. speed input: 22517.74 toks/s, output: 21.99 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:19<00:00, 61.64it/s, est. speed input: 23804.69 toks/s, output: 23.25 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:20<00:01, 41.77it/s, est. speed input: 23746.65 toks/s, output: 23.19 toks/s]
Processed prompts:  92%|█████████▏| 472/512 [00:20<00:01, 38.89it/s, est. speed input: 23819.14 toks/s, output: 23.26 toks/s]
Processed prompts:  93%|█████████▎| 477/512 [00:20<00:00, 35.27it/s, est. speed input: 23840.18 toks/s, output: 23.28 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:20<00:01, 25.51it/s, est. speed input: 23636.83 toks/s, output: 23.08 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:21<00:01, 24.29it/s, est. speed input: 23610.66 toks/s, output: 23.06 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:21<00:00, 23.30it/s, est. speed input: 23585.13 toks/s, output: 23.03 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:21<00:00, 22.52it/s, est. speed input: 23560.01 toks/s, output: 23.01 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:21<00:00, 21.91it/s, est. speed input: 23535.06 toks/s, output: 22.98 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:21<00:00, 21.47it/s, est. speed input: 23510.78 toks/s, output: 22.96 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:22<00:00, 21.14it/s, est. speed input: 23486.59 toks/s, output: 22.94 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:22<00:00, 22.55it/s, est. speed input: 23515.25 toks/s, output: 22.96 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 22.55it/s, est. speed input: 23607.24 toks/s, output: 23.05 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 23.05it/s, est. speed input: 23607.24 toks/s, output: 23.05 toks/s]
[rank0]:[W126 01:35:25.402620264 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 68.1s

测试结果:
  Requests/s:   20.17
  Tokens/s:     20674.60
  Total Reqs:   512
  Elapsed:      25.38s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     20654.43

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:35:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:35:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=13657) WARNING 01-26 01:35:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=13657) WARNING 01-26 01:36:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.68 requests/s, 21195.19 total tokens/s, 20.68 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 01:35:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:35:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:35:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:35:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:35:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:35:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:35:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:35:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:35:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:35:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:35:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:35:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:35:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:35:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:35:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:35:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:35:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=13657) [2026-01-26 01:35:54] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=13657) [2026-01-26 01:35:54] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=13657) [2026-01-26 01:35:54] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=13657) [2026-01-26 01:35:54] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=13657) [2026-01-26 01:35:54] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=13657) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=13657) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.37it/s]
(EngineCore_DP0 pid=13657) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.12it/s]
(EngineCore_DP0 pid=13657) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.15it/s]
(EngineCore_DP0 pid=13657) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=13657) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  7.96it/s]
(EngineCore_DP0 pid=13657) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  6.81it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  7.86it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  8.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.16it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 25/1024 [00:00<00:04, 242.56it/s]
Adding requests:   5%|▍         | 51/1024 [00:00<00:03, 250.42it/s]
Adding requests:   8%|▊         | 78/1024 [00:00<00:03, 256.49it/s]
Adding requests:  10%|█         | 105/1024 [00:00<00:03, 260.21it/s]
Adding requests:  13%|█▎        | 132/1024 [00:00<00:03, 256.27it/s]
Adding requests:  16%|█▌        | 160/1024 [00:00<00:03, 261.22it/s]
Adding requests:  18%|█▊        | 188/1024 [00:00<00:03, 265.44it/s]
Adding requests:  21%|██        | 215/1024 [00:00<00:03, 266.44it/s]
Adding requests:  24%|██▎       | 242/1024 [00:00<00:02, 265.26it/s]
Adding requests:  26%|██▋       | 269/1024 [00:01<00:03, 247.33it/s]
Adding requests:  29%|██▉       | 297/1024 [00:01<00:02, 255.70it/s]
Adding requests:  32%|███▏      | 325/1024 [00:01<00:02, 260.61it/s]
Adding requests:  34%|███▍      | 353/1024 [00:01<00:02, 264.34it/s]
Adding requests:  37%|███▋      | 381/1024 [00:01<00:02, 268.75it/s]
Adding requests:  40%|███▉      | 408/1024 [00:01<00:02, 247.15it/s]
Adding requests:  42%|████▏     | 435/1024 [00:01<00:02, 251.97it/s]
Adding requests:  45%|████▌     | 463/1024 [00:01<00:02, 258.89it/s]
Adding requests:  48%|████▊     | 492/1024 [00:01<00:02, 265.45it/s]
Adding requests:  51%|█████     | 522/1024 [00:01<00:01, 274.88it/s]
Adding requests:  54%|█████▎    | 550/1024 [00:02<00:01, 267.18it/s]
Adding requests:  56%|█████▋    | 577/1024 [00:02<00:01, 267.97it/s]
Adding requests:  59%|█████▉    | 604/1024 [00:02<00:01, 261.06it/s]
Adding requests:  62%|██████▏   | 631/1024 [00:02<00:01, 262.14it/s]
Adding requests:  64%|██████▍   | 658/1024 [00:02<00:01, 258.50it/s]
Adding requests:  67%|██████▋   | 685/1024 [00:02<00:01, 259.06it/s]
Adding requests:  70%|██████▉   | 713/1024 [00:02<00:01, 262.71it/s]
Adding requests:  72%|███████▏  | 740/1024 [00:02<00:01, 257.64it/s]
Adding requests:  75%|███████▍  | 766/1024 [00:02<00:01, 257.19it/s]
Adding requests:  77%|███████▋  | 792/1024 [00:03<00:00, 256.15it/s]
Adding requests:  80%|███████▉  | 819/1024 [00:03<00:00, 257.22it/s]
Adding requests:  83%|████████▎ | 848/1024 [00:03<00:00, 266.53it/s]
Adding requests:  85%|████████▌ | 875/1024 [00:03<00:00, 264.88it/s]
Adding requests:  88%|████████▊ | 903/1024 [00:03<00:00, 268.69it/s]
Adding requests:  91%|█████████ | 930/1024 [00:03<00:00, 261.50it/s]
Adding requests:  94%|█████████▎| 958/1024 [00:03<00:00, 264.55it/s]
Adding requests:  96%|█████████▌| 985/1024 [00:03<00:00, 259.92it/s]
Adding requests:  99%|█████████▉| 1012/1024 [00:03<00:00, 256.81it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 260.31it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:00<00:01, 478.72it/s, est. speed input: 490305.93 toks/s, output: 478.75 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:02<00:21, 41.38it/s, est. speed input: 50819.40 toks/s, output: 49.63 toks/s]  
Processed prompts:  14%|█▍        | 143/1024 [00:03<00:23, 36.99it/s, est. speed input: 45383.41 toks/s, output: 44.32 toks/s]
Processed prompts:  15%|█▌        | 156/1024 [00:03<00:28, 30.80it/s, est. speed input: 39992.50 toks/s, output: 39.06 toks/s]
Processed prompts:  16%|█▌        | 165/1024 [00:04<00:29, 29.47it/s, est. speed input: 38590.18 toks/s, output: 37.69 toks/s]
Processed prompts:  17%|█▋        | 172/1024 [00:04<00:31, 27.16it/s, est. speed input: 36985.60 toks/s, output: 36.12 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:05<00:21, 38.77it/s, est. speed input: 40213.57 toks/s, output: 39.27 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:23, 34.36it/s, est. speed input: 38897.70 toks/s, output: 37.99 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:05<00:26, 30.85it/s, est. speed input: 37754.01 toks/s, output: 36.87 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:06<00:28, 28.13it/s, est. speed input: 36749.37 toks/s, output: 35.89 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:30, 26.09it/s, est. speed input: 35860.35 toks/s, output: 35.02 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:07<00:31, 24.58it/s, est. speed input: 35066.97 toks/s, output: 34.24 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:07<00:32, 23.48it/s, est. speed input: 34353.89 toks/s, output: 33.55 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:33, 22.70it/s, est. speed input: 33713.05 toks/s, output: 32.92 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:08<00:34, 22.12it/s, est. speed input: 33128.53 toks/s, output: 32.35 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:08<00:34, 21.73it/s, est. speed input: 32599.70 toks/s, output: 31.84 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:34, 21.44it/s, est. speed input: 32113.64 toks/s, output: 31.36 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:09<00:34, 21.24it/s, est. speed input: 31667.78 toks/s, output: 30.93 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:09<00:34, 21.10it/s, est. speed input: 31257.90 toks/s, output: 30.53 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:10<00:34, 20.99it/s, est. speed input: 30876.47 toks/s, output: 30.15 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:10<00:33, 20.91it/s, est. speed input: 30522.02 toks/s, output: 29.81 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:10<00:33, 20.86it/s, est. speed input: 30194.61 toks/s, output: 29.49 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:11<00:33, 20.83it/s, est. speed input: 29889.30 toks/s, output: 29.19 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:11<00:32, 20.80it/s, est. speed input: 29603.79 toks/s, output: 28.91 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:12<00:32, 20.79it/s, est. speed input: 29337.34 toks/s, output: 28.65 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:12<00:32, 20.78it/s, est. speed input: 29087.00 toks/s, output: 28.41 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:12<00:31, 20.76it/s, est. speed input: 28851.08 toks/s, output: 28.17 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:13<00:31, 20.75it/s, est. speed input: 28628.88 toks/s, output: 27.96 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:13<00:31, 20.74it/s, est. speed input: 28418.57 toks/s, output: 27.75 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:14<00:30, 20.74it/s, est. speed input: 28220.03 toks/s, output: 27.56 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:14<00:30, 20.72it/s, est. speed input: 28031.46 toks/s, output: 27.37 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:14<00:30, 20.72it/s, est. speed input: 27853.34 toks/s, output: 27.20 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:15<00:29, 20.72it/s, est. speed input: 27683.73 toks/s, output: 27.03 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:15<00:29, 20.71it/s, est. speed input: 27522.56 toks/s, output: 26.88 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:15<00:28, 20.71it/s, est. speed input: 27369.35 toks/s, output: 26.73 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:16<00:28, 20.71it/s, est. speed input: 27223.45 toks/s, output: 26.59 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:16<00:28, 20.70it/s, est. speed input: 27083.58 toks/s, output: 26.45 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:17<00:27, 20.71it/s, est. speed input: 26951.00 toks/s, output: 26.32 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:17<00:27, 20.69it/s, est. speed input: 26822.79 toks/s, output: 26.19 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:17<00:26, 20.70it/s, est. speed input: 26701.17 toks/s, output: 26.08 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:18<00:26, 20.70it/s, est. speed input: 26584.52 toks/s, output: 25.96 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:18<00:26, 20.69it/s, est. speed input: 26472.34 toks/s, output: 25.85 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:19<00:25, 20.69it/s, est. speed input: 26365.02 toks/s, output: 25.75 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:19<00:25, 20.70it/s, est. speed input: 26262.32 toks/s, output: 25.65 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:19<00:25, 20.69it/s, est. speed input: 26162.74 toks/s, output: 25.55 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:20<00:24, 20.69it/s, est. speed input: 26067.26 toks/s, output: 25.46 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:20<00:24, 20.68it/s, est. speed input: 25974.89 toks/s, output: 25.37 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:20<00:23, 20.68it/s, est. speed input: 25886.43 toks/s, output: 25.28 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:21<00:23, 20.67it/s, est. speed input: 25800.55 toks/s, output: 25.20 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:21<00:23, 20.68it/s, est. speed input: 25718.67 toks/s, output: 25.12 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:22<00:22, 20.69it/s, est. speed input: 25640.15 toks/s, output: 25.04 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:22<00:22, 20.70it/s, est. speed input: 25564.03 toks/s, output: 24.96 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:22<00:21, 20.69it/s, est. speed input: 25489.83 toks/s, output: 24.89 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:23<00:21, 20.69it/s, est. speed input: 25418.65 toks/s, output: 24.82 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:23<00:21, 20.69it/s, est. speed input: 25349.56 toks/s, output: 24.76 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:24<00:20, 20.70it/s, est. speed input: 25282.88 toks/s, output: 24.69 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:24<00:20, 20.69it/s, est. speed input: 25217.79 toks/s, output: 24.63 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:24<00:20, 20.69it/s, est. speed input: 25155.16 toks/s, output: 24.57 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:25<00:19, 20.70it/s, est. speed input: 25094.60 toks/s, output: 24.51 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:25<00:19, 20.69it/s, est. speed input: 25035.51 toks/s, output: 24.45 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:25<00:18, 20.70it/s, est. speed input: 24978.52 toks/s, output: 24.39 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:26<00:18, 20.69it/s, est. speed input: 24922.93 toks/s, output: 24.34 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:26<00:18, 20.70it/s, est. speed input: 24869.23 toks/s, output: 24.29 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:27<00:17, 20.70it/s, est. speed input: 24816.99 toks/s, output: 24.24 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:27<00:17, 20.69it/s, est. speed input: 24765.84 toks/s, output: 24.19 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:27<00:16, 20.70it/s, est. speed input: 24716.46 toks/s, output: 24.14 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:28<00:16, 20.71it/s, est. speed input: 24668.94 toks/s, output: 24.09 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:28<00:16, 20.69it/s, est. speed input: 24621.54 toks/s, output: 24.04 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:29<00:15, 20.69it/s, est. speed input: 24575.78 toks/s, output: 24.00 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:29<00:15, 20.69it/s, est. speed input: 24531.50 toks/s, output: 23.96 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:29<00:14, 20.69it/s, est. speed input: 24488.27 toks/s, output: 23.91 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:30<00:14, 20.71it/s, est. speed input: 24446.67 toks/s, output: 23.87 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:30<00:14, 20.71it/s, est. speed input: 24405.85 toks/s, output: 23.83 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:31<00:13, 20.71it/s, est. speed input: 24366.00 toks/s, output: 23.79 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:31<00:13, 20.71it/s, est. speed input: 24327.12 toks/s, output: 23.76 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:31<00:13, 20.71it/s, est. speed input: 24289.22 toks/s, output: 23.72 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:32<00:12, 20.70it/s, est. speed input: 24251.99 toks/s, output: 23.68 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:32<00:12, 20.71it/s, est. speed input: 24215.92 toks/s, output: 23.65 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:32<00:11, 20.70it/s, est. speed input: 24180.40 toks/s, output: 23.61 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:33<00:11, 21.35it/s, est. speed input: 24173.97 toks/s, output: 23.61 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:33<00:10, 21.15it/s, est. speed input: 24140.03 toks/s, output: 23.57 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:34<00:10, 21.02it/s, est. speed input: 24106.84 toks/s, output: 23.54 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:34<00:10, 20.93it/s, est. speed input: 24074.34 toks/s, output: 23.51 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:34<00:09, 20.86it/s, est. speed input: 24042.65 toks/s, output: 23.48 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:35<00:09, 20.81it/s, est. speed input: 24011.47 toks/s, output: 23.45 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:35<00:09, 20.78it/s, est. speed input: 23981.02 toks/s, output: 23.42 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:35<00:08, 20.76it/s, est. speed input: 23951.16 toks/s, output: 23.39 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:36<00:08, 20.74it/s, est. speed input: 23921.89 toks/s, output: 23.36 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:36<00:03, 38.19it/s, est. speed input: 24534.68 toks/s, output: 23.96 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:37<00:04, 33.04it/s, est. speed input: 24499.88 toks/s, output: 23.93 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:37<00:04, 29.39it/s, est. speed input: 24465.86 toks/s, output: 23.89 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:37<00:04, 26.81it/s, est. speed input: 24432.39 toks/s, output: 23.86 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:38<00:04, 24.98it/s, est. speed input: 24399.49 toks/s, output: 23.83 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:38<00:04, 23.70it/s, est. speed input: 24367.49 toks/s, output: 23.80 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:39<00:04, 22.80it/s, est. speed input: 24335.92 toks/s, output: 23.77 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:39<00:03, 22.17it/s, est. speed input: 24305.16 toks/s, output: 23.74 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:39<00:03, 21.73it/s, est. speed input: 24275.03 toks/s, output: 23.71 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:40<00:03, 21.41it/s, est. speed input: 24245.18 toks/s, output: 23.68 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:40<00:02, 21.18it/s, est. speed input: 24215.70 toks/s, output: 23.65 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:41<00:02, 21.03it/s, est. speed input: 24186.93 toks/s, output: 23.62 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:41<00:02, 20.91it/s, est. speed input: 24158.37 toks/s, output: 23.59 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:41<00:01, 20.84it/s, est. speed input: 24130.66 toks/s, output: 23.57 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:42<00:01, 20.79it/s, est. speed input: 24103.50 toks/s, output: 23.54 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:42<00:01, 20.75it/s, est. speed input: 24076.91 toks/s, output: 23.51 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:43<00:00, 20.73it/s, est. speed input: 24050.69 toks/s, output: 23.49 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:43<00:00, 21.42it/s, est. speed input: 24048.52 toks/s, output: 23.48 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:43<00:00, 21.42it/s, est. speed input: 24190.10 toks/s, output: 23.62 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:43<00:00, 23.62it/s, est. speed input: 24190.10 toks/s, output: 23.62 toks/s]
[rank0]:[W126 01:37:04.289432241 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 98.5s

测试结果:
  Requests/s:   20.68
  Tokens/s:     21195.19
  Total Reqs:   1024
  Elapsed:      49.52s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     21174.51

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:37:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:37:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=15324) WARNING 01-26 01:37:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=15324) WARNING 01-26 01:37:47 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.76 requests/s, 21276.61 total tokens/s, 20.76 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 01:37:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:37:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:37:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:37:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:37:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:37:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:37:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:37:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:37:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:37:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:37:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:37:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:37:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:37:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:37:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:37:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:37:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=15324) [2026-01-26 01:37:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=15324) [2026-01-26 01:37:37] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=15324) [2026-01-26 01:37:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=15324) [2026-01-26 01:37:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=15324) [2026-01-26 01:37:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=15324) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=15324) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.47it/s]
(EngineCore_DP0 pid=15324) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
(EngineCore_DP0 pid=15324) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.21it/s]
(EngineCore_DP0 pid=15324) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=15324) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  7.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  8.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.06it/s]
(EngineCore_DP0 pid=15324) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  6.78it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  7.66it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.02it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.17it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 22/2048 [00:00<00:09, 214.40it/s]
Adding requests:   2%|▏         | 48/2048 [00:00<00:08, 236.92it/s]
Adding requests:   4%|▎         | 74/2048 [00:00<00:08, 246.27it/s]
Adding requests:   5%|▍         | 101/2048 [00:00<00:07, 251.06it/s]
Adding requests:   6%|▌         | 127/2048 [00:00<00:07, 253.61it/s]
Adding requests:   8%|▊         | 154/2048 [00:00<00:07, 256.79it/s]
Adding requests:   9%|▉         | 183/2048 [00:00<00:06, 266.92it/s]
Adding requests:  10%|█         | 211/2048 [00:00<00:06, 270.18it/s]
Adding requests:  12%|█▏        | 239/2048 [00:00<00:06, 271.45it/s]
Adding requests:  13%|█▎        | 267/2048 [00:01<00:06, 271.85it/s]
Adding requests:  14%|█▍        | 295/2048 [00:01<00:06, 266.38it/s]
Adding requests:  16%|█▌        | 324/2048 [00:01<00:06, 270.91it/s]
Adding requests:  17%|█▋        | 353/2048 [00:01<00:06, 275.19it/s]
Adding requests:  19%|█▊        | 382/2048 [00:01<00:05, 278.08it/s]
Adding requests:  20%|██        | 412/2048 [00:01<00:05, 283.75it/s]
Adding requests:  22%|██▏       | 441/2048 [00:01<00:05, 283.82it/s]
Adding requests:  23%|██▎       | 470/2048 [00:01<00:05, 285.02it/s]
Adding requests:  24%|██▍       | 501/2048 [00:01<00:05, 289.36it/s]
Adding requests:  26%|██▌       | 532/2048 [00:01<00:05, 295.34it/s]
Adding requests:  27%|██▋       | 562/2048 [00:02<00:05, 292.85it/s]
Adding requests:  29%|██▉       | 592/2048 [00:02<00:05, 278.89it/s]
Adding requests:  30%|███       | 621/2048 [00:02<00:05, 277.42it/s]
Adding requests:  32%|███▏      | 649/2048 [00:02<00:05, 273.02it/s]
Adding requests:  33%|███▎      | 677/2048 [00:02<00:05, 268.62it/s]
Adding requests:  34%|███▍      | 706/2048 [00:02<00:04, 271.21it/s]
Adding requests:  36%|███▌      | 734/2048 [00:02<00:04, 268.17it/s]
Adding requests:  37%|███▋      | 762/2048 [00:02<00:04, 270.65it/s]
Adding requests:  39%|███▊      | 791/2048 [00:02<00:04, 275.00it/s]
Adding requests:  40%|███▉      | 819/2048 [00:03<00:04, 274.93it/s]
Adding requests:  41%|████▏     | 849/2048 [00:03<00:04, 280.37it/s]
Adding requests:  43%|████▎     | 878/2048 [00:03<00:04, 278.38it/s]
Adding requests:  44%|████▍     | 907/2048 [00:03<00:04, 278.53it/s]
Adding requests:  46%|████▌     | 935/2048 [00:03<00:04, 268.99it/s]
Adding requests:  47%|████▋     | 963/2048 [00:03<00:03, 271.88it/s]
Adding requests:  48%|████▊     | 991/2048 [00:03<00:03, 267.40it/s]
Adding requests:  50%|████▉     | 1018/2048 [00:03<00:03, 267.03it/s]
Adding requests:  51%|█████     | 1046/2048 [00:03<00:03, 267.64it/s]
Adding requests:  52%|█████▏    | 1074/2048 [00:03<00:03, 269.19it/s]
Adding requests:  54%|█████▍    | 1101/2048 [00:04<00:03, 268.49it/s]
Adding requests:  55%|█████▌    | 1130/2048 [00:04<00:03, 272.82it/s]
Adding requests:  57%|█████▋    | 1158/2048 [00:04<00:03, 265.78it/s]
Adding requests:  58%|█████▊    | 1186/2048 [00:04<00:03, 267.86it/s]
Adding requests:  59%|█████▉    | 1216/2048 [00:04<00:03, 275.61it/s]
Adding requests:  61%|██████    | 1244/2048 [00:04<00:02, 272.98it/s]
Adding requests:  62%|██████▏   | 1272/2048 [00:04<00:02, 270.06it/s]
Adding requests:  63%|██████▎   | 1300/2048 [00:04<00:02, 270.97it/s]
Adding requests:  65%|██████▍   | 1329/2048 [00:04<00:02, 273.39it/s]
Adding requests:  66%|██████▋   | 1357/2048 [00:04<00:02, 274.81it/s]
Adding requests:  68%|██████▊   | 1385/2048 [00:05<00:02, 275.03it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:05<00:02, 273.71it/s]
Adding requests:  70%|███████   | 1442/2048 [00:05<00:02, 275.76it/s]
Adding requests:  72%|███████▏  | 1470/2048 [00:05<00:02, 275.97it/s]
Adding requests:  73%|███████▎  | 1499/2048 [00:05<00:01, 278.92it/s]
Adding requests:  75%|███████▍  | 1528/2048 [00:05<00:01, 280.54it/s]
Adding requests:  76%|███████▌  | 1557/2048 [00:05<00:01, 274.12it/s]
Adding requests:  77%|███████▋  | 1585/2048 [00:05<00:01, 271.56it/s]
Adding requests:  79%|███████▉  | 1613/2048 [00:05<00:01, 271.69it/s]
Adding requests:  80%|████████  | 1641/2048 [00:06<00:01, 265.29it/s]
Adding requests:  81%|████████▏ | 1668/2048 [00:06<00:01, 262.27it/s]
Adding requests:  83%|████████▎ | 1696/2048 [00:06<00:01, 266.23it/s]
Adding requests:  84%|████████▍ | 1724/2048 [00:06<00:01, 268.59it/s]
Adding requests:  85%|████████▌ | 1751/2048 [00:06<00:01, 267.64it/s]
Adding requests:  87%|████████▋ | 1779/2048 [00:06<00:00, 270.72it/s]
Adding requests:  88%|████████▊ | 1807/2048 [00:06<00:00, 268.67it/s]
Adding requests:  90%|████████▉ | 1834/2048 [00:06<00:00, 257.03it/s]
Adding requests:  91%|█████████ | 1863/2048 [00:06<00:00, 263.66it/s]
Adding requests:  92%|█████████▏| 1892/2048 [00:06<00:00, 270.25it/s]
Adding requests:  94%|█████████▍| 1921/2048 [00:07<00:00, 274.24it/s]
Adding requests:  95%|█████████▌| 1951/2048 [00:07<00:00, 280.99it/s]
Adding requests:  97%|█████████▋| 1980/2048 [00:07<00:00, 279.17it/s]
Adding requests:  98%|█████████▊| 2008/2048 [00:07<00:00, 271.90it/s]
Adding requests:  99%|█████████▉| 2036/2048 [00:07<00:00, 266.46it/s]
Adding requests: 100%|██████████| 2048/2048 [00:07<00:00, 271.58it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:00<00:04, 393.52it/s, est. speed input: 402996.14 toks/s, output: 393.53 toks/s]
Processed prompts:   9%|▉         | 186/2048 [00:01<00:23, 79.71it/s, est. speed input: 100497.66 toks/s, output: 98.14 toks/s]  
Processed prompts:  10%|▉         | 204/2048 [00:02<00:31, 58.42it/s, est. speed input: 78582.93 toks/s, output: 76.74 toks/s] 
Processed prompts:  10%|█         | 215/2048 [00:03<00:42, 42.96it/s, est. speed input: 64352.63 toks/s, output: 62.84 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:04<00:54, 33.42it/s, est. speed input: 55307.52 toks/s, output: 54.01 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:04<01:01, 29.39it/s, est. speed input: 50082.62 toks/s, output: 48.91 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:05<01:07, 26.72it/s, est. speed input: 46250.37 toks/s, output: 45.17 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:06<01:11, 24.91it/s, est. speed input: 43316.81 toks/s, output: 42.30 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:07<01:14, 23.68it/s, est. speed input: 41002.49 toks/s, output: 40.04 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:08<01:16, 22.83it/s, est. speed input: 39127.97 toks/s, output: 38.21 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:08<01:17, 22.23it/s, est. speed input: 37577.87 toks/s, output: 36.70 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:09<01:18, 21.82it/s, est. speed input: 36275.91 toks/s, output: 35.43 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:10<01:18, 21.53it/s, est. speed input: 35164.46 toks/s, output: 34.34 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:11<01:18, 21.33it/s, est. speed input: 34209.33 toks/s, output: 33.41 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:11<01:18, 21.17it/s, est. speed input: 33372.07 toks/s, output: 32.59 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:12<01:18, 21.07it/s, est. speed input: 32639.09 toks/s, output: 31.87 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:13<01:17, 20.99it/s, est. speed input: 31988.57 toks/s, output: 31.24 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:14<01:17, 20.94it/s, est. speed input: 31409.03 toks/s, output: 30.67 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:14<01:16, 20.90it/s, est. speed input: 30888.70 toks/s, output: 30.16 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:15<01:15, 20.88it/s, est. speed input: 30420.72 toks/s, output: 29.71 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:16<01:15, 20.86it/s, est. speed input: 29994.83 toks/s, output: 29.29 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:17<01:14, 20.83it/s, est. speed input: 29604.79 toks/s, output: 28.91 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:17<01:13, 20.82it/s, est. speed input: 29249.16 toks/s, output: 28.56 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:18<01:12, 20.81it/s, est. speed input: 28922.52 toks/s, output: 28.24 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:19<01:12, 20.81it/s, est. speed input: 28621.93 toks/s, output: 27.95 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:20<01:11, 20.81it/s, est. speed input: 28344.77 toks/s, output: 27.68 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:21<01:10, 20.80it/s, est. speed input: 28086.90 toks/s, output: 27.43 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:21<01:09, 20.79it/s, est. speed input: 27846.84 toks/s, output: 27.19 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:22<01:09, 20.80it/s, est. speed input: 27624.29 toks/s, output: 26.98 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:23<01:08, 20.80it/s, est. speed input: 27416.06 toks/s, output: 26.77 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:24<01:07, 20.80it/s, est. speed input: 27221.54 toks/s, output: 26.58 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:24<00:42, 32.17it/s, est. speed input: 28158.40 toks/s, output: 27.50 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:25<00:47, 28.34it/s, est. speed input: 27950.73 toks/s, output: 27.30 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:26<00:51, 25.89it/s, est. speed input: 27754.92 toks/s, output: 27.10 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:26<00:54, 24.29it/s, est. speed input: 27570.96 toks/s, output: 26.92 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:27<00:56, 23.22it/s, est. speed input: 27398.18 toks/s, output: 26.76 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:28<00:57, 22.48it/s, est. speed input: 27233.33 toks/s, output: 26.60 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:29<00:58, 21.98it/s, est. speed input: 27077.86 toks/s, output: 26.44 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:29<00:57, 21.96it/s, est. speed input: 26964.71 toks/s, output: 26.33 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:30<00:57, 21.62it/s, est. speed input: 26823.81 toks/s, output: 26.20 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:31<00:57, 21.39it/s, est. speed input: 26689.99 toks/s, output: 26.06 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:32<00:57, 21.20it/s, est. speed input: 26560.53 toks/s, output: 25.94 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:32<00:56, 21.06it/s, est. speed input: 26435.34 toks/s, output: 25.82 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:33<00:56, 20.95it/s, est. speed input: 26315.41 toks/s, output: 25.70 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:34<00:55, 20.88it/s, est. speed input: 26200.67 toks/s, output: 25.59 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:35<00:55, 20.83it/s, est. speed input: 26091.22 toks/s, output: 25.48 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:36<00:54, 20.79it/s, est. speed input: 25986.43 toks/s, output: 25.38 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:36<00:53, 20.76it/s, est. speed input: 25885.84 toks/s, output: 25.28 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:37<00:53, 20.75it/s, est. speed input: 25789.79 toks/s, output: 25.19 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:38<00:52, 20.74it/s, est. speed input: 25697.93 toks/s, output: 25.10 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:39<00:51, 20.74it/s, est. speed input: 25609.38 toks/s, output: 25.01 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:39<00:50, 20.72it/s, est. speed input: 25523.51 toks/s, output: 24.93 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:40<00:50, 20.66it/s, est. speed input: 25437.19 toks/s, output: 24.84 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:41<00:49, 20.62it/s, est. speed input: 25354.04 toks/s, output: 24.76 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:42<00:48, 20.59it/s, est. speed input: 25273.77 toks/s, output: 24.68 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:42<00:48, 20.57it/s, est. speed input: 25196.25 toks/s, output: 24.61 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:43<00:47, 20.55it/s, est. speed input: 25121.79 toks/s, output: 24.53 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:44<00:46, 20.54it/s, est. speed input: 25049.99 toks/s, output: 24.46 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:45<00:45, 20.54it/s, est. speed input: 24980.78 toks/s, output: 24.40 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:46<00:45, 20.53it/s, est. speed input: 24913.61 toks/s, output: 24.33 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:46<00:44, 20.53it/s, est. speed input: 24849.06 toks/s, output: 24.27 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:47<00:43, 20.53it/s, est. speed input: 24786.34 toks/s, output: 24.21 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:48<00:42, 20.60it/s, est. speed input: 24730.28 toks/s, output: 24.15 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:49<00:41, 20.68it/s, est. speed input: 24677.68 toks/s, output: 24.10 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:49<00:40, 20.73it/s, est. speed input: 24626.48 toks/s, output: 24.05 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:50<00:39, 20.76it/s, est. speed input: 24576.85 toks/s, output: 24.00 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:51<00:39, 20.79it/s, est. speed input: 24528.67 toks/s, output: 23.95 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:52<00:38, 20.81it/s, est. speed input: 24482.06 toks/s, output: 23.91 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:53<00:37, 20.82it/s, est. speed input: 24436.62 toks/s, output: 23.86 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:53<00:36, 20.82it/s, est. speed input: 24392.38 toks/s, output: 23.82 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:54<00:36, 20.83it/s, est. speed input: 24349.30 toks/s, output: 23.78 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:55<00:35, 20.83it/s, est. speed input: 24307.37 toks/s, output: 23.74 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:55<00:20, 34.29it/s, est. speed input: 24796.55 toks/s, output: 24.22 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:56<00:23, 29.59it/s, est. speed input: 24750.40 toks/s, output: 24.17 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:57<00:25, 26.70it/s, est. speed input: 24706.16 toks/s, output: 24.13 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:57<00:26, 24.84it/s, est. speed input: 24662.75 toks/s, output: 24.08 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:58<00:27, 23.60it/s, est. speed input: 24620.67 toks/s, output: 24.04 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:59<00:27, 22.78it/s, est. speed input: 24579.90 toks/s, output: 24.00 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:00<00:27, 22.21it/s, est. speed input: 24540.07 toks/s, output: 23.96 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:00<00:27, 21.83it/s, est. speed input: 24501.37 toks/s, output: 23.93 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:01<00:26, 21.56it/s, est. speed input: 24463.37 toks/s, output: 23.89 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:02<00:26, 21.37it/s, est. speed input: 24426.48 toks/s, output: 23.85 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:03<00:25, 21.24it/s, est. speed input: 24390.34 toks/s, output: 23.82 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:03<00:24, 21.14it/s, est. speed input: 24354.95 toks/s, output: 23.78 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:04<00:24, 20.97it/s, est. speed input: 24315.46 toks/s, output: 23.75 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:05<00:23, 20.85it/s, est. speed input: 24276.84 toks/s, output: 23.71 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:06<00:23, 20.76it/s, est. speed input: 24239.19 toks/s, output: 23.67 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:07<00:22, 20.71it/s, est. speed input: 24202.70 toks/s, output: 23.64 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:07<00:21, 20.67it/s, est. speed input: 24166.85 toks/s, output: 23.60 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:08<00:20, 20.95it/s, est. speed input: 24145.00 toks/s, output: 23.58 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:09<00:19, 20.84it/s, est. speed input: 24110.54 toks/s, output: 23.55 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:10<00:19, 20.76it/s, est. speed input: 24077.14 toks/s, output: 23.51 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:10<00:18, 20.71it/s, est. speed input: 24044.46 toks/s, output: 23.48 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:11<00:17, 20.68it/s, est. speed input: 24012.37 toks/s, output: 23.45 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:12<00:16, 20.67it/s, est. speed input: 23981.90 toks/s, output: 23.42 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:13<00:16, 20.68it/s, est. speed input: 23952.39 toks/s, output: 23.39 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:14<00:15, 20.69it/s, est. speed input: 23923.69 toks/s, output: 23.36 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:14<00:14, 20.69it/s, est. speed input: 23895.49 toks/s, output: 23.34 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:15<00:13, 20.69it/s, est. speed input: 23867.97 toks/s, output: 23.31 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:16<00:13, 20.69it/s, est. speed input: 23840.80 toks/s, output: 23.28 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:17<00:12, 20.70it/s, est. speed input: 23814.38 toks/s, output: 23.26 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:17<00:11, 20.70it/s, est. speed input: 23788.45 toks/s, output: 23.23 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:18<00:10, 20.69it/s, est. speed input: 23762.84 toks/s, output: 23.21 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:19<00:09, 20.70it/s, est. speed input: 23737.89 toks/s, output: 23.18 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:20<00:09, 20.70it/s, est. speed input: 23713.54 toks/s, output: 23.16 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:20<00:08, 20.75it/s, est. speed input: 23691.16 toks/s, output: 23.14 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:21<00:07, 20.77it/s, est. speed input: 23669.06 toks/s, output: 23.11 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:22<00:06, 20.79it/s, est. speed input: 23647.38 toks/s, output: 23.09 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:23<00:06, 20.80it/s, est. speed input: 23625.98 toks/s, output: 23.07 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:24<00:05, 20.81it/s, est. speed input: 23605.03 toks/s, output: 23.05 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:24<00:04, 20.82it/s, est. speed input: 23584.46 toks/s, output: 23.03 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:25<00:03, 20.82it/s, est. speed input: 23564.24 toks/s, output: 23.01 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:26<00:02, 20.82it/s, est. speed input: 23544.27 toks/s, output: 22.99 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:26<00:00, 33.24it/s, est. speed input: 23842.88 toks/s, output: 23.28 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:27<00:00, 29.54it/s, est. speed input: 23832.67 toks/s, output: 23.27 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:27<00:00, 29.54it/s, est. speed input: 23996.58 toks/s, output: 23.43 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:27<00:00, 23.43it/s, est. speed input: 23996.58 toks/s, output: 23.43 toks/s]
[rank0]:[W126 01:39:34.324442140 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 150.1s

测试结果:
  Requests/s:   20.76
  Tokens/s:     21276.61
  Total Reqs:   2048
  Elapsed:      98.66s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     21255.85

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:40:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:40:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=17884) WARNING 01-26 01:40:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=17884) WARNING 01-26 01:40:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.91 requests/s, 21436.81 total tokens/s, 20.91 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 01:40:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:40:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:40:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:40:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:40:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:40:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:40:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:40:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:40:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:40:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:40:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:40:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:40:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:40:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:40:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:40:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:40:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=17884) [2026-01-26 01:40:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=17884) [2026-01-26 01:40:22] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=17884) [2026-01-26 01:40:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=17884) [2026-01-26 01:40:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=17884) [2026-01-26 01:40:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=17884) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=17884) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.48it/s]
(EngineCore_DP0 pid=17884) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.15it/s]
(EngineCore_DP0 pid=17884) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
(EngineCore_DP0 pid=17884) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=17884) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  7.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  8.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  8.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  8.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.42it/s]
(EngineCore_DP0 pid=17884) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.80it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  7.89it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  8.56it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  8.64it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.50it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/4096 [00:00<00:17, 236.11it/s]
Adding requests:   1%|          | 50/4096 [00:00<00:16, 245.14it/s]
Adding requests:   2%|▏         | 78/4096 [00:00<00:15, 256.35it/s]
Adding requests:   3%|▎         | 104/4096 [00:00<00:15, 257.45it/s]
Adding requests:   3%|▎         | 131/4096 [00:00<00:15, 259.74it/s]
Adding requests:   4%|▍         | 158/4096 [00:00<00:15, 261.80it/s]
Adding requests:   5%|▍         | 185/4096 [00:00<00:14, 262.97it/s]
Adding requests:   5%|▌         | 214/4096 [00:00<00:14, 269.45it/s]
Adding requests:   6%|▌         | 241/4096 [00:00<00:14, 269.51it/s]
Adding requests:   7%|▋         | 269/4096 [00:01<00:14, 269.62it/s]
Adding requests:   7%|▋         | 298/4096 [00:01<00:13, 272.27it/s]
Adding requests:   8%|▊         | 326/4096 [00:01<00:13, 271.24it/s]
Adding requests:   9%|▊         | 356/4096 [00:01<00:13, 278.64it/s]
Adding requests:   9%|▉         | 385/4096 [00:01<00:13, 280.85it/s]
Adding requests:  10%|█         | 414/4096 [00:01<00:13, 281.47it/s]
Adding requests:  11%|█         | 443/4096 [00:01<00:13, 275.30it/s]
Adding requests:  11%|█▏        | 471/4096 [00:01<00:13, 275.98it/s]
Adding requests:  12%|█▏        | 500/4096 [00:01<00:12, 279.79it/s]
Adding requests:  13%|█▎        | 531/4096 [00:01<00:12, 286.45it/s]
Adding requests:  14%|█▎        | 560/4096 [00:02<00:12, 286.83it/s]
Adding requests:  14%|█▍        | 589/4096 [00:02<00:12, 275.03it/s]
Adding requests:  15%|█▌        | 617/4096 [00:02<00:12, 273.36it/s]
Adding requests:  16%|█▌        | 645/4096 [00:02<00:12, 272.70it/s]
Adding requests:  16%|█▋        | 673/4096 [00:02<00:12, 269.36it/s]
Adding requests:  17%|█▋        | 703/4096 [00:02<00:12, 276.99it/s]
Adding requests:  18%|█▊        | 731/4096 [00:02<00:12, 269.86it/s]
Adding requests:  19%|█▊        | 759/4096 [00:02<00:12, 266.99it/s]
Adding requests:  19%|█▉        | 788/4096 [00:02<00:12, 271.00it/s]
Adding requests:  20%|█▉        | 816/4096 [00:03<00:12, 270.76it/s]
Adding requests:  21%|██        | 846/4096 [00:03<00:11, 278.89it/s]
Adding requests:  21%|██▏       | 875/4096 [00:03<00:11, 279.10it/s]
Adding requests:  22%|██▏       | 904/4096 [00:03<00:11, 282.25it/s]
Adding requests:  23%|██▎       | 933/4096 [00:03<00:11, 273.25it/s]
Adding requests:  23%|██▎       | 961/4096 [00:03<00:11, 274.71it/s]
Adding requests:  24%|██▍       | 989/4096 [00:03<00:11, 273.13it/s]
Adding requests:  25%|██▍       | 1017/4096 [00:03<00:11, 269.92it/s]
Adding requests:  26%|██▌       | 1045/4096 [00:03<00:11, 269.40it/s]
Adding requests:  26%|██▌       | 1073/4096 [00:03<00:11, 270.17it/s]
Adding requests:  27%|██▋       | 1101/4096 [00:04<00:11, 271.05it/s]
Adding requests:  28%|██▊       | 1129/4096 [00:04<00:11, 267.05it/s]
Adding requests:  28%|██▊       | 1156/4096 [00:04<00:11, 262.00it/s]
Adding requests:  29%|██▉       | 1184/4096 [00:04<00:10, 265.82it/s]
Adding requests:  30%|██▉       | 1213/4096 [00:04<00:10, 270.75it/s]
Adding requests:  30%|███       | 1242/4096 [00:04<00:10, 275.28it/s]
Adding requests:  31%|███       | 1270/4096 [00:04<00:10, 269.47it/s]
Adding requests:  32%|███▏      | 1297/4096 [00:04<00:10, 266.55it/s]
Adding requests:  32%|███▏      | 1324/4096 [00:04<00:10, 266.90it/s]
Adding requests:  33%|███▎      | 1351/4096 [00:04<00:10, 264.38it/s]
Adding requests:  34%|███▎      | 1379/4096 [00:05<00:10, 268.48it/s]
Adding requests:  34%|███▍      | 1406/4096 [00:05<00:10, 268.56it/s]
Adding requests:  35%|███▌      | 1434/4096 [00:05<00:09, 270.67it/s]
Adding requests:  36%|███▌      | 1463/4096 [00:05<00:09, 275.77it/s]
Adding requests:  36%|███▋      | 1492/4096 [00:05<00:09, 279.37it/s]
Adding requests:  37%|███▋      | 1520/4096 [00:05<00:09, 278.74it/s]
Adding requests:  38%|███▊      | 1548/4096 [00:05<00:09, 278.06it/s]
Adding requests:  38%|███▊      | 1576/4096 [00:05<00:09, 270.97it/s]
Adding requests:  39%|███▉      | 1604/4096 [00:05<00:09, 267.92it/s]
Adding requests:  40%|███▉      | 1631/4096 [00:06<00:09, 262.76it/s]
Adding requests:  40%|████      | 1658/4096 [00:06<00:09, 262.05it/s]
Adding requests:  41%|████      | 1686/4096 [00:06<00:09, 264.60it/s]
Adding requests:  42%|████▏     | 1714/4096 [00:06<00:08, 268.95it/s]
Adding requests:  43%|████▎     | 1742/4096 [00:06<00:08, 271.97it/s]
Adding requests:  43%|████▎     | 1772/4096 [00:06<00:08, 278.96it/s]
Adding requests:  44%|████▍     | 1800/4096 [00:06<00:08, 275.65it/s]
Adding requests:  45%|████▍     | 1828/4096 [00:06<00:08, 276.36it/s]
Adding requests:  45%|████▌     | 1856/4096 [00:06<00:08, 272.56it/s]
Adding requests:  46%|████▌     | 1884/4096 [00:06<00:08, 271.75it/s]
Adding requests:  47%|████▋     | 1912/4096 [00:07<00:08, 271.14it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:07<00:07, 277.32it/s]
Adding requests:  48%|████▊     | 1971/4096 [00:07<00:07, 278.36it/s]
Adding requests:  49%|████▉     | 1999/4096 [00:07<00:07, 277.28it/s]
Adding requests:  49%|████▉     | 2027/4096 [00:07<00:07, 269.85it/s]
Adding requests:  50%|█████     | 2055/4096 [00:07<00:07, 271.84it/s]
Adding requests:  51%|█████     | 2083/4096 [00:07<00:07, 265.08it/s]
Adding requests:  52%|█████▏    | 2112/4096 [00:07<00:07, 269.34it/s]
Adding requests:  52%|█████▏    | 2139/4096 [00:07<00:07, 267.13it/s]
Adding requests:  53%|█████▎    | 2166/4096 [00:08<00:07, 250.22it/s]
Adding requests:  54%|█████▎    | 2192/4096 [00:08<00:07, 249.16it/s]
Adding requests:  54%|█████▍    | 2220/4096 [00:08<00:07, 255.62it/s]
Adding requests:  55%|█████▍    | 2247/4096 [00:08<00:07, 258.64it/s]
Adding requests:  56%|█████▌    | 2277/4096 [00:08<00:06, 270.03it/s]
Adding requests:  56%|█████▋    | 2306/4096 [00:08<00:06, 274.05it/s]
Adding requests:  57%|█████▋    | 2334/4096 [00:08<00:06, 267.20it/s]
Adding requests:  58%|█████▊    | 2363/4096 [00:08<00:06, 273.13it/s]
Adding requests:  58%|█████▊    | 2393/4096 [00:08<00:06, 278.73it/s]
Adding requests:  59%|█████▉    | 2422/4096 [00:08<00:05, 280.75it/s]
Adding requests:  60%|█████▉    | 2451/4096 [00:09<00:05, 278.07it/s]
Adding requests:  61%|██████    | 2479/4096 [00:09<00:05, 277.69it/s]
Adding requests:  61%|██████▏   | 2509/4096 [00:09<00:05, 281.64it/s]
Adding requests:  62%|██████▏   | 2539/4096 [00:09<00:05, 286.78it/s]
Adding requests:  63%|██████▎   | 2571/4096 [00:09<00:05, 293.76it/s]
Adding requests:  64%|██████▎   | 2601/4096 [00:09<00:05, 288.15it/s]
Adding requests:  64%|██████▍   | 2630/4096 [00:09<00:05, 281.77it/s]
Adding requests:  65%|██████▍   | 2659/4096 [00:09<00:05, 279.11it/s]
Adding requests:  66%|██████▌   | 2687/4096 [00:09<00:05, 277.16it/s]
Adding requests:  66%|██████▋   | 2715/4096 [00:09<00:05, 274.34it/s]
Adding requests:  67%|██████▋   | 2745/4096 [00:10<00:04, 279.61it/s]
Adding requests:  68%|██████▊   | 2774/4096 [00:10<00:04, 279.74it/s]
Adding requests:  68%|██████▊   | 2805/4096 [00:10<00:04, 287.25it/s]
Adding requests:  69%|██████▉   | 2834/4096 [00:10<00:04, 282.03it/s]
Adding requests:  70%|██████▉   | 2864/4096 [00:10<00:04, 284.40it/s]
Adding requests:  71%|███████   | 2893/4096 [00:10<00:04, 281.76it/s]
Adding requests:  71%|███████▏  | 2922/4096 [00:10<00:04, 281.56it/s]
Adding requests:  72%|███████▏  | 2952/4096 [00:10<00:04, 285.06it/s]
Adding requests:  73%|███████▎  | 2981/4096 [00:10<00:04, 277.84it/s]
Adding requests:  73%|███████▎  | 3009/4096 [00:11<00:03, 276.74it/s]
Adding requests:  74%|███████▍  | 3038/4096 [00:11<00:03, 278.21it/s]
Adding requests:  75%|███████▍  | 3067/4096 [00:11<00:03, 279.33it/s]
Adding requests:  76%|███████▌  | 3096/4096 [00:11<00:03, 280.95it/s]
Adding requests:  76%|███████▋  | 3126/4096 [00:11<00:03, 284.65it/s]
Adding requests:  77%|███████▋  | 3155/4096 [00:11<00:03, 280.90it/s]
Adding requests:  78%|███████▊  | 3184/4096 [00:11<00:03, 277.19it/s]
Adding requests:  78%|███████▊  | 3212/4096 [00:11<00:03, 272.03it/s]
Adding requests:  79%|███████▉  | 3241/4096 [00:11<00:03, 273.90it/s]
Adding requests:  80%|███████▉  | 3269/4096 [00:11<00:03, 269.38it/s]
Adding requests:  80%|████████  | 3296/4096 [00:12<00:03, 266.27it/s]
Adding requests:  81%|████████  | 3324/4096 [00:12<00:02, 269.67it/s]
Adding requests:  82%|████████▏ | 3352/4096 [00:12<00:02, 272.05it/s]
Adding requests:  83%|████████▎ | 3381/4096 [00:12<00:02, 274.79it/s]
Adding requests:  83%|████████▎ | 3410/4096 [00:12<00:02, 277.81it/s]
Adding requests:  84%|████████▍ | 3438/4096 [00:12<00:02, 277.55it/s]
Adding requests:  85%|████████▍ | 3467/4096 [00:12<00:02, 278.17it/s]
Adding requests:  85%|████████▌ | 3495/4096 [00:12<00:02, 273.53it/s]
Adding requests:  86%|████████▌ | 3525/4096 [00:12<00:02, 281.13it/s]
Adding requests:  87%|████████▋ | 3554/4096 [00:12<00:01, 283.66it/s]
Adding requests:  87%|████████▋ | 3583/4096 [00:13<00:01, 281.31it/s]
Adding requests:  88%|████████▊ | 3612/4096 [00:13<00:01, 283.53it/s]
Adding requests:  89%|████████▉ | 3641/4096 [00:13<00:01, 283.32it/s]
Adding requests:  90%|████████▉ | 3670/4096 [00:13<00:01, 275.96it/s]
Adding requests:  90%|█████████ | 3698/4096 [00:13<00:01, 263.68it/s]
Adding requests:  91%|█████████ | 3727/4096 [00:13<00:01, 269.99it/s]
Adding requests:  92%|█████████▏| 3755/4096 [00:13<00:01, 267.20it/s]
Adding requests:  92%|█████████▏| 3782/4096 [00:13<00:01, 265.46it/s]
Adding requests:  93%|█████████▎| 3809/4096 [00:13<00:01, 255.72it/s]
Adding requests:  94%|█████████▎| 3836/4096 [00:14<00:01, 259.04it/s]
Adding requests:  94%|█████████▍| 3863/4096 [00:14<00:00, 260.93it/s]
Adding requests:  95%|█████████▍| 3890/4096 [00:14<00:00, 261.20it/s]
Adding requests:  96%|█████████▌| 3917/4096 [00:14<00:00, 259.82it/s]
Adding requests:  96%|█████████▋| 3944/4096 [00:14<00:00, 257.85it/s]
Adding requests:  97%|█████████▋| 3971/4096 [00:14<00:00, 260.62it/s]
Adding requests:  98%|█████████▊| 3998/4096 [00:14<00:00, 262.12it/s]
Adding requests:  98%|█████████▊| 4025/4096 [00:14<00:00, 264.26it/s]
Adding requests:  99%|█████████▉| 4052/4096 [00:14<00:00, 264.54it/s]
Adding requests: 100%|█████████▉| 4080/4096 [00:14<00:00, 267.02it/s]
Adding requests: 100%|██████████| 4096/4096 [00:15<00:00, 272.33it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:00<00:06, 599.04it/s, est. speed input: 613449.20 toks/s, output: 599.05 toks/s]
Processed prompts:   9%|▊         | 350/4096 [00:02<00:26, 141.36it/s, est. speed input: 178690.68 toks/s, output: 174.50 toks/s]
Processed prompts:   9%|▉         | 377/4096 [00:03<00:49, 74.74it/s, est. speed input: 109428.04 toks/s, output: 106.86 toks/s] 
Processed prompts:  10%|▉         | 393/4096 [00:05<01:19, 46.77it/s, est. speed input: 79655.38 toks/s, output: 77.79 toks/s]  
Processed prompts:  10%|█         | 418/4096 [00:05<01:14, 49.38it/s, est. speed input: 78845.27 toks/s, output: 77.00 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:06<01:38, 37.01it/s, est. speed input: 66256.79 toks/s, output: 64.70 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:08<01:57, 30.81it/s, est. speed input: 58153.19 toks/s, output: 56.79 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:10<02:11, 27.31it/s, est. speed input: 52548.48 toks/s, output: 51.32 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:11<02:21, 25.17it/s, est. speed input: 48427.80 toks/s, output: 47.29 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:13<02:27, 23.79it/s, est. speed input: 45270.53 toks/s, output: 44.21 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:14<02:32, 22.89it/s, est. speed input: 42776.88 toks/s, output: 41.77 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [00:16<02:34, 22.29it/s, est. speed input: 40758.51 toks/s, output: 39.80 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [00:17<02:36, 21.88it/s, est. speed input: 39087.60 toks/s, output: 38.17 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:19<02:37, 21.59it/s, est. speed input: 37681.68 toks/s, output: 36.80 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [00:20<02:36, 21.39it/s, est. speed input: 36484.58 toks/s, output: 35.63 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:22<02:35, 21.43it/s, est. speed input: 35515.35 toks/s, output: 34.68 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:23<02:34, 21.28it/s, est. speed input: 34609.86 toks/s, output: 33.80 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:25<02:33, 21.19it/s, est. speed input: 33815.75 toks/s, output: 33.02 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:26<02:32, 21.12it/s, est. speed input: 33111.98 toks/s, output: 32.34 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [00:28<02:31, 21.07it/s, est. speed input: 32484.25 toks/s, output: 31.72 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [00:29<02:30, 21.05it/s, est. speed input: 31921.82 toks/s, output: 31.17 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:31<02:29, 21.02it/s, est. speed input: 31412.83 toks/s, output: 30.68 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:32<02:27, 21.01it/s, est. speed input: 30952.16 toks/s, output: 30.23 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [00:34<02:26, 20.99it/s, est. speed input: 30530.95 toks/s, output: 29.82 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [00:35<02:24, 20.98it/s, est. speed input: 30145.69 toks/s, output: 29.44 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:37<02:23, 20.98it/s, est. speed input: 29791.85 toks/s, output: 29.09 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:37<01:49, 27.19it/s, est. speed input: 30372.22 toks/s, output: 29.66 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:39<01:57, 24.97it/s, est. speed input: 30026.84 toks/s, output: 29.32 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:40<02:03, 23.62it/s, est. speed input: 29707.43 toks/s, output: 29.01 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:42<02:06, 22.75it/s, est. speed input: 29410.61 toks/s, output: 28.72 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:43<02:08, 22.19it/s, est. speed input: 29135.93 toks/s, output: 28.45 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:45<02:09, 21.79it/s, est. speed input: 28876.21 toks/s, output: 28.20 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:46<02:09, 21.53it/s, est. speed input: 28634.75 toks/s, output: 27.96 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:48<02:08, 21.35it/s, est. speed input: 28408.34 toks/s, output: 27.74 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:50<02:08, 21.23it/s, est. speed input: 28196.49 toks/s, output: 27.54 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:51<02:07, 21.14it/s, est. speed input: 27996.42 toks/s, output: 27.34 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:53<02:05, 21.09it/s, est. speed input: 27808.16 toks/s, output: 27.16 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [00:54<02:04, 21.04it/s, est. speed input: 27630.22 toks/s, output: 26.98 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [00:56<02:03, 21.01it/s, est. speed input: 27461.55 toks/s, output: 26.82 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:57<02:01, 20.99it/s, est. speed input: 27302.28 toks/s, output: 26.66 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:59<02:00, 20.98it/s, est. speed input: 27151.04 toks/s, output: 26.51 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [01:00<01:58, 21.13it/s, est. speed input: 27024.82 toks/s, output: 26.39 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [01:02<01:56, 21.07it/s, est. speed input: 26887.61 toks/s, output: 26.26 toks/s]
Processed prompts:  41%|████      | 1666/4096 [01:03<01:55, 21.03it/s, est. speed input: 26757.26 toks/s, output: 26.13 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [01:05<01:54, 21.00it/s, est. speed input: 26632.52 toks/s, output: 26.01 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [01:06<01:52, 20.98it/s, est. speed input: 26513.23 toks/s, output: 25.89 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [01:08<01:51, 20.96it/s, est. speed input: 26399.68 toks/s, output: 25.78 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [01:08<01:24, 27.16it/s, est. speed input: 26736.12 toks/s, output: 26.11 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [01:10<01:31, 24.94it/s, est. speed input: 26620.83 toks/s, output: 26.00 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [01:11<01:34, 23.59it/s, est. speed input: 26510.53 toks/s, output: 25.89 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [01:13<01:37, 22.72it/s, est. speed input: 26404.89 toks/s, output: 25.79 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [01:14<01:38, 22.16it/s, est. speed input: 26303.35 toks/s, output: 25.69 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [01:16<01:38, 21.77it/s, est. speed input: 26205.68 toks/s, output: 25.59 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [01:17<01:38, 21.51it/s, est. speed input: 26111.97 toks/s, output: 25.50 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [01:19<01:37, 21.34it/s, est. speed input: 26022.25 toks/s, output: 25.41 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [01:20<01:36, 21.21it/s, est. speed input: 25935.44 toks/s, output: 25.33 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [01:22<01:35, 21.13it/s, est. speed input: 25851.98 toks/s, output: 25.25 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [01:23<01:34, 21.07it/s, est. speed input: 25771.49 toks/s, output: 25.17 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [01:25<01:32, 21.02it/s, est. speed input: 25693.70 toks/s, output: 25.09 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [01:27<01:31, 20.99it/s, est. speed input: 25618.38 toks/s, output: 25.02 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [01:28<01:29, 20.96it/s, est. speed input: 25545.60 toks/s, output: 24.95 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [01:30<01:28, 20.93it/s, est. speed input: 25474.14 toks/s, output: 24.88 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [01:31<01:27, 20.93it/s, est. speed input: 25406.56 toks/s, output: 24.81 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [01:33<01:25, 20.93it/s, est. speed input: 25341.42 toks/s, output: 24.75 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [01:34<01:23, 20.93it/s, est. speed input: 25278.30 toks/s, output: 24.69 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [01:36<01:22, 20.92it/s, est. speed input: 25216.61 toks/s, output: 24.63 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [01:37<01:20, 20.93it/s, est. speed input: 25157.58 toks/s, output: 24.57 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [01:39<01:19, 20.92it/s, est. speed input: 25099.94 toks/s, output: 24.51 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [01:39<00:59, 27.20it/s, est. speed input: 25339.84 toks/s, output: 24.75 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [01:41<01:04, 24.96it/s, est. speed input: 25280.79 toks/s, output: 24.69 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [01:42<01:06, 23.60it/s, est. speed input: 25223.71 toks/s, output: 24.63 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [01:44<01:07, 22.74it/s, est. speed input: 25168.42 toks/s, output: 24.58 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [01:45<01:07, 22.17it/s, est. speed input: 25114.71 toks/s, output: 24.53 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [01:47<01:07, 21.79it/s, est. speed input: 25062.55 toks/s, output: 24.48 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [01:48<01:06, 21.51it/s, est. speed input: 25011.08 toks/s, output: 24.42 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [01:50<01:05, 21.33it/s, est. speed input: 24961.14 toks/s, output: 24.38 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [01:51<01:04, 21.20it/s, est. speed input: 24912.42 toks/s, output: 24.33 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [01:53<01:03, 21.11it/s, est. speed input: 24865.37 toks/s, output: 24.28 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [01:54<01:02, 21.05it/s, est. speed input: 24819.07 toks/s, output: 24.24 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [01:56<01:00, 21.00it/s, est. speed input: 24774.10 toks/s, output: 24.19 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [01:58<00:59, 20.96it/s, est. speed input: 24729.54 toks/s, output: 24.15 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [01:59<00:58, 20.92it/s, est. speed input: 24686.10 toks/s, output: 24.11 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [02:01<00:56, 20.90it/s, est. speed input: 24643.83 toks/s, output: 24.07 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [02:02<00:55, 20.89it/s, est. speed input: 24602.64 toks/s, output: 24.03 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [02:04<00:53, 20.88it/s, est. speed input: 24562.47 toks/s, output: 23.99 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [02:05<00:51, 20.89it/s, est. speed input: 24524.30 toks/s, output: 23.95 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [02:07<00:50, 20.90it/s, est. speed input: 24486.94 toks/s, output: 23.91 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [02:08<00:48, 20.90it/s, est. speed input: 24450.54 toks/s, output: 23.88 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [02:10<00:47, 20.90it/s, est. speed input: 24414.70 toks/s, output: 23.84 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [02:10<00:34, 27.40it/s, est. speed input: 24605.49 toks/s, output: 24.03 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [02:12<00:37, 25.00it/s, est. speed input: 24566.47 toks/s, output: 23.99 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [02:13<00:37, 23.62it/s, est. speed input: 24530.65 toks/s, output: 23.96 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [02:15<00:37, 22.74it/s, est. speed input: 24495.51 toks/s, output: 23.92 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [02:16<00:37, 22.17it/s, est. speed input: 24461.41 toks/s, output: 23.89 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [02:18<00:36, 21.78it/s, est. speed input: 24427.78 toks/s, output: 23.86 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [02:19<00:35, 21.52it/s, est. speed input: 24395.03 toks/s, output: 23.82 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [02:21<00:34, 21.32it/s, est. speed input: 24362.19 toks/s, output: 23.79 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [02:22<00:33, 21.17it/s, est. speed input: 24329.57 toks/s, output: 23.76 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [02:24<00:31, 21.04it/s, est. speed input: 24296.50 toks/s, output: 23.73 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [02:25<00:30, 20.97it/s, est. speed input: 24265.13 toks/s, output: 23.70 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [02:27<00:28, 20.92it/s, est. speed input: 24234.04 toks/s, output: 23.67 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [02:29<00:27, 20.85it/s, est. speed input: 24202.66 toks/s, output: 23.64 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [02:30<00:25, 20.85it/s, est. speed input: 24173.36 toks/s, output: 23.61 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [02:32<00:24, 20.84it/s, est. speed input: 24144.70 toks/s, output: 23.58 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [02:33<00:22, 20.84it/s, est. speed input: 24116.54 toks/s, output: 23.55 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [02:35<00:21, 20.84it/s, est. speed input: 24088.93 toks/s, output: 23.52 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [02:36<00:19, 20.99it/s, est. speed input: 24067.81 toks/s, output: 23.50 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [02:38<00:18, 20.93it/s, est. speed input: 24040.74 toks/s, output: 23.48 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [02:39<00:16, 20.89it/s, est. speed input: 24014.20 toks/s, output: 23.45 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [02:41<00:15, 20.86it/s, est. speed input: 23988.18 toks/s, output: 23.43 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [02:42<00:13, 20.83it/s, est. speed input: 23962.34 toks/s, output: 23.40 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [02:43<00:09, 27.77it/s, est. speed input: 24125.68 toks/s, output: 23.56 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [02:44<00:08, 25.24it/s, est. speed input: 24099.45 toks/s, output: 23.53 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [02:46<00:07, 24.06it/s, est. speed input: 24082.65 toks/s, output: 23.52 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [02:47<00:06, 23.08it/s, est. speed input: 24059.96 toks/s, output: 23.50 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [02:49<00:05, 22.41it/s, est. speed input: 24036.83 toks/s, output: 23.47 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [02:50<00:04, 22.01it/s, est. speed input: 24015.49 toks/s, output: 23.45 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [02:52<00:02, 21.74it/s, est. speed input: 23994.58 toks/s, output: 23.43 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [02:53<00:01, 21.58it/s, est. speed input: 23974.85 toks/s, output: 23.41 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:53<00:00, 21.58it/s, est. speed input: 24151.67 toks/s, output: 23.59 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [02:53<00:00, 23.59it/s, est. speed input: 24151.67 toks/s, output: 23.59 toks/s]
[rank0]:[W126 01:43:55.749003336 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 261.1s

测试结果:
  Requests/s:   20.91
  Tokens/s:     21436.81
  Total Reqs:   4096
  Elapsed:      195.85s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     21415.90

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:45:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:45:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=22268) WARNING 01-26 01:45:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=22268) WARNING 01-26 01:45:35 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=22268) ERROR 01-26 01:46:04 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.


─── STDERR ───
[2026-01-26 01:45:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:45:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:45:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:45:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:45:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:45:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:45:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:45:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:45:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:45:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:45:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:45:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:45:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:45:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:45:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:45:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:45:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 01:45:23.423685109 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:24] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:24] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:24] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:24] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:24] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=22268) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=22268) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.23it/s]
(EngineCore_DP0 pid=22268) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.07it/s]
(EngineCore_DP0 pid=22268) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.09it/s]
(EngineCore_DP0 pid=22268) 
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:42] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:42] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:42] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:43] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:44] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:44] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:44] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:44] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:46] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:46] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:46] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:46] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:47] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:48] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:49] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:50] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:51] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:52] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:53] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:54] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:55] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:56] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:57] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:58] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:59] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:59] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:59] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:45:59] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:46:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:46:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
(EngineCore_DP0 pid=22268) [2026-01-26 01:46:00] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=18944), falling back to default heuristic
(EngineCore_DP0 pid=22268) Process EngineCore_DP0:
(EngineCore_DP0 pid=22268) Traceback (most recent call last):
(EngineCore_DP0 pid=22268)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=22268)     self.run()
(EngineCore_DP0 pid=22268)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=22268)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=22268)     raise e
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=22268)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=22268)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=22268)     super().__init__(
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=22268)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=22268)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=22268)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=22268)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=22268)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=22268)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=22268)     raise ValueError(
(EngineCore_DP0 pid=22268) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 01:46:05.746296134 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,16.1250,8272.1446,7.9380
1024,1024,1,128,128,15.9178,16315.7321,8.0413
2048,1024,2,256,128,19.8028,20297.8735,12.9275
4096,1024,4,512,128,20.1703,20674.6042,25.3838
8192,1024,8,1024,128,20.6782,21195.1892,49.5207
16384,1024,16,2048,128,20.7577,21276.6078,98.6623
32768,1024,32,4096,128,20.9140,21436.8110,195.8500
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:46:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:46:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=23460) WARNING 01-26 01:46:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=23460) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=23460) WARNING 01-26 01:46:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.12 requests/s, 8780.66 total tokens/s, 17.12 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 01:46:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:46:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:46:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:46:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:46:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:46:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:46:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:46:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:46:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:46:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:46:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:46:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:46:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:46:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:46:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:46:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:46:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=23460) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=23460) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.26s/it]
(EngineCore_DP0 pid=23460) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.36s/it]
(EngineCore_DP0 pid=23460) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.20s/it]
(EngineCore_DP0 pid=23460) 
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=23460) [2026-01-26 01:46:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=23460) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  7.78it/s]
(EngineCore_DP0 pid=23460) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.25it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 434.58it/s]
Adding requests:  72%|███████▏  | 92/128 [00:00<00:00, 455.22it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 460.35it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:03, 39.64it/s, est. speed input: 20296.97 toks/s, output: 39.64 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:04, 24.25it/s, est. speed input: 13347.77 toks/s, output: 26.07 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 20.80it/s, est. speed input: 11739.79 toks/s, output: 22.93 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 19.38it/s, est. speed input: 11021.31 toks/s, output: 21.53 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:05, 18.81it/s, est. speed input: 10721.53 toks/s, output: 20.94 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:05, 18.40it/s, est. speed input: 10500.51 toks/s, output: 20.51 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 18.10it/s, est. speed input: 10326.83 toks/s, output: 20.17 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 17.87it/s, est. speed input: 10186.07 toks/s, output: 19.89 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.71it/s, est. speed input: 10070.60 toks/s, output: 19.67 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 17.60it/s, est. speed input: 9975.07 toks/s, output: 19.48 toks/s] 
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 17.41it/s, est. speed input: 9877.38 toks/s, output: 19.29 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 17.36it/s, est. speed input: 9803.93 toks/s, output: 19.15 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 17.39it/s, est. speed input: 9748.17 toks/s, output: 19.04 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 17.32it/s, est. speed input: 9689.33 toks/s, output: 18.92 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 17.28it/s, est. speed input: 9638.21 toks/s, output: 18.82 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 17.34it/s, est. speed input: 9600.90 toks/s, output: 18.75 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 17.33it/s, est. speed input: 9563.00 toks/s, output: 18.68 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.36it/s, est. speed input: 9531.68 toks/s, output: 18.62 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.35it/s, est. speed input: 9501.17 toks/s, output: 18.56 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 17.29it/s, est. speed input: 9469.26 toks/s, output: 18.49 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 17.17it/s, est. speed input: 9433.50 toks/s, output: 18.42 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 17.08it/s, est. speed input: 9400.30 toks/s, output: 18.36 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:04, 17.07it/s, est. speed input: 9373.31 toks/s, output: 18.31 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 17.14it/s, est. speed input: 9353.85 toks/s, output: 18.27 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 17.22it/s, est. speed input: 9338.12 toks/s, output: 18.24 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.21it/s, est. speed input: 9318.88 toks/s, output: 18.20 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.24it/s, est. speed input: 9303.72 toks/s, output: 18.17 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.28it/s, est. speed input: 9290.08 toks/s, output: 18.14 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.28it/s, est. speed input: 9276.14 toks/s, output: 18.12 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 17.29it/s, est. speed input: 9263.32 toks/s, output: 18.09 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.29it/s, est. speed input: 9251.10 toks/s, output: 18.07 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 17.17it/s, est. speed input: 9233.34 toks/s, output: 18.03 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 16.89it/s, est. speed input: 9206.25 toks/s, output: 17.98 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 17.02it/s, est. speed input: 9197.04 toks/s, output: 17.96 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.06it/s, est. speed input: 9186.30 toks/s, output: 17.94 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.12it/s, est. speed input: 9177.07 toks/s, output: 17.92 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.19it/s, est. speed input: 9169.81 toks/s, output: 17.91 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 16.81it/s, est. speed input: 9143.62 toks/s, output: 17.86 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 16.93it/s, est. speed input: 9135.60 toks/s, output: 17.84 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 17.10it/s, est. speed input: 9131.51 toks/s, output: 17.83 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 17.23it/s, est. speed input: 9128.17 toks/s, output: 17.83 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.36it/s, est. speed input: 9126.27 toks/s, output: 17.82 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.48it/s, est. speed input: 9125.64 toks/s, output: 17.82 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.58it/s, est. speed input: 9125.75 toks/s, output: 17.82 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.63it/s, est. speed input: 9124.95 toks/s, output: 17.82 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.66it/s, est. speed input: 9124.07 toks/s, output: 17.82 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.70it/s, est. speed input: 9123.58 toks/s, output: 17.82 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 17.65it/s, est. speed input: 9120.86 toks/s, output: 17.81 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 17.68it/s, est. speed input: 9120.26 toks/s, output: 17.81 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.60it/s, est. speed input: 9116.35 toks/s, output: 17.81 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.64it/s, est. speed input: 9115.82 toks/s, output: 17.80 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.67it/s, est. speed input: 9115.03 toks/s, output: 17.80 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.69it/s, est. speed input: 9114.40 toks/s, output: 17.80 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.71it/s, est. speed input: 9113.99 toks/s, output: 17.80 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.77it/s, est. speed input: 9114.89 toks/s, output: 17.80 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.76it/s, est. speed input: 9114.54 toks/s, output: 17.80 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 17.71it/s, est. speed input: 9112.58 toks/s, output: 17.80 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 17.70it/s, est. speed input: 9111.75 toks/s, output: 17.80 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.56it/s, est. speed input: 9107.05 toks/s, output: 17.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.52it/s, est. speed input: 9104.21 toks/s, output: 17.78 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.52it/s, est. speed input: 9104.21 toks/s, output: 17.78 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.78it/s, est. speed input: 9104.21 toks/s, output: 17.78 toks/s]
[rank0]:[W126 01:47:02.520053182 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 56.5s

测试结果:
  Requests/s:   17.12
  Tokens/s:     8780.66
  Total Reqs:   128
  Elapsed:      7.48s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     8763.55

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:47:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:47:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=24480) WARNING 01-26 01:47:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=24480) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=24480) WARNING 01-26 01:47:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.08 requests/s, 17502.20 total tokens/s, 17.08 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 01:47:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:47:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:47:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:47:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:47:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:47:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:47:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:47:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:47:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:47:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:47:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:47:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:47:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:47:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:47:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:47:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:47:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=24480) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=24480) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.41it/s]
(EngineCore_DP0 pid=24480) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.05it/s]
(EngineCore_DP0 pid=24480) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.09it/s]
(EngineCore_DP0 pid=24480) 
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=24480) [2026-01-26 01:47:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=24480) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.63it/s]
(EngineCore_DP0 pid=24480) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 238.75it/s]
Adding requests:  39%|███▉      | 50/128 [00:00<00:00, 250.99it/s]
Adding requests:  61%|██████    | 78/128 [00:00<00:00, 262.12it/s]
Adding requests:  82%|████████▏ | 105/128 [00:00<00:00, 259.67it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 258.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:01, 71.33it/s, est. speed input: 73060.44 toks/s, output: 71.34 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:04, 25.49it/s, est. speed input: 28885.83 toks/s, output: 28.21 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:04, 22.64it/s, est. speed input: 25892.55 toks/s, output: 25.29 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:00<00:04, 21.29it/s, est. speed input: 24579.99 toks/s, output: 24.00 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 20.26it/s, est. speed input: 23620.12 toks/s, output: 23.07 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 19.44it/s, est. speed input: 22868.36 toks/s, output: 22.33 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 18.96it/s, est. speed input: 22335.59 toks/s, output: 21.81 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 18.62it/s, est. speed input: 22011.75 toks/s, output: 21.50 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:04, 18.45it/s, est. speed input: 21767.17 toks/s, output: 21.26 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:04, 18.33it/s, est. speed input: 21559.28 toks/s, output: 21.05 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:01<00:04, 18.17it/s, est. speed input: 21361.26 toks/s, output: 20.86 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 18.07it/s, est. speed input: 21187.12 toks/s, output: 20.69 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.99it/s, est. speed input: 21031.83 toks/s, output: 20.54 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.81it/s, est. speed input: 20866.33 toks/s, output: 20.38 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 17.71it/s, est. speed input: 20722.91 toks/s, output: 20.24 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 17.74it/s, est. speed input: 20610.07 toks/s, output: 20.13 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 17.73it/s, est. speed input: 20502.34 toks/s, output: 20.02 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:04, 17.64it/s, est. speed input: 20390.61 toks/s, output: 19.91 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:04, 17.61it/s, est. speed input: 20291.75 toks/s, output: 19.82 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:03, 17.59it/s, est. speed input: 20202.02 toks/s, output: 19.73 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.56it/s, est. speed input: 20115.92 toks/s, output: 19.64 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.53it/s, est. speed input: 20034.63 toks/s, output: 19.56 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.49it/s, est. speed input: 19957.89 toks/s, output: 19.49 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.35it/s, est. speed input: 19870.73 toks/s, output: 19.40 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 17.36it/s, est. speed input: 19802.71 toks/s, output: 19.34 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.27it/s, est. speed input: 19727.82 toks/s, output: 19.27 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 17.29it/s, est. speed input: 19667.41 toks/s, output: 19.21 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:03, 17.26it/s, est. speed input: 19604.85 toks/s, output: 19.15 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:02, 17.35it/s, est. speed input: 19558.75 toks/s, output: 19.10 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.36it/s, est. speed input: 19508.72 toks/s, output: 19.05 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.32it/s, est. speed input: 19457.94 toks/s, output: 19.00 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.28it/s, est. speed input: 19407.81 toks/s, output: 18.95 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 17.23it/s, est. speed input: 19358.44 toks/s, output: 18.90 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 17.07it/s, est. speed input: 19299.40 toks/s, output: 18.85 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 17.11it/s, est. speed input: 19257.52 toks/s, output: 18.81 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:02, 17.17it/s, est. speed input: 19220.77 toks/s, output: 18.77 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:04<00:02, 17.26it/s, est. speed input: 19190.10 toks/s, output: 18.74 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.33it/s, est. speed input: 19160.53 toks/s, output: 18.71 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.27it/s, est. speed input: 19124.05 toks/s, output: 18.68 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.29it/s, est. speed input: 19094.17 toks/s, output: 18.65 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.36it/s, est. speed input: 19069.52 toks/s, output: 18.62 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.32it/s, est. speed input: 19039.51 toks/s, output: 18.59 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 17.27it/s, est. speed input: 19008.64 toks/s, output: 18.56 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 17.24it/s, est. speed input: 18980.01 toks/s, output: 18.54 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:01, 17.23it/s, est. speed input: 18952.33 toks/s, output: 18.51 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:05<00:01, 17.22it/s, est. speed input: 18926.05 toks/s, output: 18.48 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.18it/s, est. speed input: 18898.84 toks/s, output: 18.46 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.09it/s, est. speed input: 18867.80 toks/s, output: 18.43 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.19it/s, est. speed input: 18849.26 toks/s, output: 18.41 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.23it/s, est. speed input: 18828.98 toks/s, output: 18.39 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.23it/s, est. speed input: 18808.15 toks/s, output: 18.37 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 17.25it/s, est. speed input: 18789.21 toks/s, output: 18.35 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 17.20it/s, est. speed input: 18766.80 toks/s, output: 18.33 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 17.22it/s, est. speed input: 18748.63 toks/s, output: 18.31 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 17.20it/s, est. speed input: 18728.84 toks/s, output: 18.29 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 17.20it/s, est. speed input: 18728.84 toks/s, output: 18.29 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.29it/s, est. speed input: 18728.84 toks/s, output: 18.29 toks/s]
[rank0]:[W126 01:47:52.586390439 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 48.5s

测试结果:
  Requests/s:   17.08
  Tokens/s:     17502.20
  Total Reqs:   128
  Elapsed:      7.50s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     17485.12

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:48:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:48:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=25382) WARNING 01-26 01:48:11 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=25382) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=25382) WARNING 01-26 01:48:23 [backends.py:609] Failed to read file <frozen os>
Throughput: 26.89 requests/s, 27559.61 total tokens/s, 26.89 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 01:48:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:48:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:48:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:48:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:48:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:48:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:48:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:48:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:48:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:48:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:48:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:48:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=25382) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=25382) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.42it/s]
(EngineCore_DP0 pid=25382) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.14it/s]
(EngineCore_DP0 pid=25382) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
(EngineCore_DP0 pid=25382) 
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=25382) [2026-01-26 01:48:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=25382) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.25it/s]
(EngineCore_DP0 pid=25382) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.32it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 24/256 [00:00<00:00, 238.30it/s]
Adding requests:  20%|█▉        | 50/256 [00:00<00:00, 250.06it/s]
Adding requests:  31%|███       | 79/256 [00:00<00:00, 264.61it/s]
Adding requests:  41%|████▏     | 106/256 [00:00<00:00, 265.97it/s]
Adding requests:  52%|█████▏    | 133/256 [00:00<00:00, 260.46it/s]
Adding requests:  63%|██████▎   | 162/256 [00:00<00:00, 267.82it/s]
Adding requests:  75%|███████▌  | 192/256 [00:00<00:00, 276.81it/s]
Adding requests:  86%|████████▌ | 220/256 [00:00<00:00, 275.20it/s]
Adding requests:  97%|█████████▋| 248/256 [00:00<00:00, 272.55it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 267.83it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:00<00:01, 169.67it/s, est. speed input: 173793.55 toks/s, output: 169.68 toks/s]
Processed prompts:  16%|█▌        | 41/256 [00:00<00:04, 49.44it/s, est. speed input: 57818.89 toks/s, output: 56.46 toks/s]   
Processed prompts:  20%|█▉        | 50/256 [00:01<00:05, 38.68it/s, est. speed input: 46887.35 toks/s, output: 45.79 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:01<00:05, 35.63it/s, est. speed input: 43740.18 toks/s, output: 42.71 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:01<00:05, 35.36it/s, est. speed input: 42879.98 toks/s, output: 41.87 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:01<00:06, 31.55it/s, est. speed input: 40340.07 toks/s, output: 39.39 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:06, 30.65it/s, est. speed input: 39370.44 toks/s, output: 38.45 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:01<00:06, 29.88it/s, est. speed input: 38536.62 toks/s, output: 37.63 toks/s]
Processed prompts:  30%|███       | 78/256 [00:02<00:06, 29.26it/s, est. speed input: 37819.55 toks/s, output: 36.93 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:02<00:06, 28.73it/s, est. speed input: 37180.83 toks/s, output: 36.31 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:02<00:06, 28.33it/s, est. speed input: 36618.31 toks/s, output: 35.76 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:05, 28.08it/s, est. speed input: 36131.93 toks/s, output: 35.28 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:05, 27.89it/s, est. speed input: 35695.41 toks/s, output: 34.86 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:05, 27.76it/s, est. speed input: 35308.87 toks/s, output: 34.48 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:02<00:05, 27.67it/s, est. speed input: 34956.73 toks/s, output: 34.14 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:03<00:05, 27.61it/s, est. speed input: 34641.16 toks/s, output: 33.83 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:03<00:05, 27.57it/s, est. speed input: 34350.92 toks/s, output: 33.55 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:03<00:05, 27.53it/s, est. speed input: 34083.33 toks/s, output: 33.28 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:03<00:05, 27.50it/s, est. speed input: 33839.04 toks/s, output: 33.05 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:03<00:04, 27.44it/s, est. speed input: 33606.38 toks/s, output: 32.82 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:03<00:04, 27.35it/s, est. speed input: 33385.05 toks/s, output: 32.60 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:04<00:04, 27.35it/s, est. speed input: 33188.55 toks/s, output: 32.41 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:04<00:04, 27.35it/s, est. speed input: 33006.79 toks/s, output: 32.23 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:04<00:04, 27.38it/s, est. speed input: 32840.77 toks/s, output: 32.07 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:04<00:04, 27.39it/s, est. speed input: 32684.19 toks/s, output: 31.92 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:04<00:04, 27.42it/s, est. speed input: 32540.53 toks/s, output: 31.78 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:04<00:03, 27.44it/s, est. speed input: 32406.31 toks/s, output: 31.65 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:04<00:03, 27.42it/s, est. speed input: 32274.59 toks/s, output: 31.52 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:05<00:03, 27.44it/s, est. speed input: 32155.80 toks/s, output: 31.40 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:05<00:03, 27.46it/s, est. speed input: 32043.20 toks/s, output: 31.29 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:05<00:03, 27.43it/s, est. speed input: 31933.24 toks/s, output: 31.18 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:05<00:03, 27.43it/s, est. speed input: 31830.31 toks/s, output: 31.08 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:05<00:02, 27.45it/s, est. speed input: 31734.90 toks/s, output: 30.99 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:05<00:02, 27.43it/s, est. speed input: 31641.31 toks/s, output: 30.90 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:05<00:02, 27.43it/s, est. speed input: 31554.00 toks/s, output: 30.81 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:06<00:02, 27.47it/s, est. speed input: 31473.74 toks/s, output: 30.74 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:06<00:02, 27.49it/s, est. speed input: 31397.32 toks/s, output: 30.66 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:06<00:02, 27.49it/s, est. speed input: 31322.66 toks/s, output: 30.59 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:06<00:02, 27.49it/s, est. speed input: 31251.53 toks/s, output: 30.52 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:06<00:01, 28.10it/s, est. speed input: 31233.13 toks/s, output: 30.50 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:06<00:01, 27.91it/s, est. speed input: 31166.39 toks/s, output: 30.44 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:06<00:01, 27.75it/s, est. speed input: 31100.21 toks/s, output: 30.37 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:07<00:01, 27.62it/s, est. speed input: 31035.91 toks/s, output: 30.31 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:07<00:01, 27.56it/s, est. speed input: 30975.55 toks/s, output: 30.25 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:07<00:01, 27.47it/s, est. speed input: 30914.37 toks/s, output: 30.19 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:07<00:01, 27.44it/s, est. speed input: 30858.03 toks/s, output: 30.13 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:07<00:00, 27.41it/s, est. speed input: 30803.15 toks/s, output: 30.08 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:07<00:00, 27.48it/s, est. speed input: 30756.88 toks/s, output: 30.04 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:07<00:00, 27.62it/s, est. speed input: 30718.43 toks/s, output: 30.00 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:08<00:00, 27.72it/s, est. speed input: 30681.46 toks/s, output: 29.96 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:08<00:00, 27.78it/s, est. speed input: 30645.26 toks/s, output: 29.93 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:08<00:00, 27.82it/s, est. speed input: 30609.52 toks/s, output: 29.89 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:08<00:00, 27.80it/s, est. speed input: 30573.02 toks/s, output: 29.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 27.80it/s, est. speed input: 30611.06 toks/s, output: 29.89 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 29.89it/s, est. speed input: 30611.06 toks/s, output: 29.89 toks/s]
[rank0]:[W126 01:48:43.123471315 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 52.2s

测试结果:
  Requests/s:   26.89
  Tokens/s:     27559.61
  Total Reqs:   256
  Elapsed:      9.52s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     27532.72

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:48:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:48:56 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=26373) WARNING 01-26 01:49:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=26373) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=26373) WARNING 01-26 01:49:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.68 requests/s, 29398.51 total tokens/s, 28.68 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 01:48:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:48:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:48:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:48:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:48:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:48:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:49:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:49:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:49:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:49:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:49:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:49:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:49:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:49:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:49:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=26373) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=26373) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.48it/s]
(EngineCore_DP0 pid=26373) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
(EngineCore_DP0 pid=26373) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.23it/s]
(EngineCore_DP0 pid=26373) 
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=26373) [2026-01-26 01:49:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=26373) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  9.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.54it/s]
(EngineCore_DP0 pid=26373) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.28it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.20it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.54it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 25/512 [00:00<00:01, 243.70it/s]
Adding requests:  73%|███████▎  | 374/512 [00:00<00:00, 2117.20it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 744.16it/s] 

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:00<00:01, 415.87it/s, est. speed input: 425956.18 toks/s, output: 415.90 toks/s]
Processed prompts:  18%|█▊        | 92/512 [00:01<00:07, 52.50it/s, est. speed input: 62693.22 toks/s, output: 61.22 toks/s]   
Processed prompts:  22%|██▏       | 111/512 [00:02<00:09, 42.49it/s, est. speed input: 51862.57 toks/s, output: 50.65 toks/s]
Processed prompts:  24%|██▍       | 123/512 [00:02<00:09, 39.01it/s, est. speed input: 48325.26 toks/s, output: 47.19 toks/s]
Processed prompts:  26%|██▌       | 132/512 [00:02<00:10, 37.77it/s, est. speed input: 46902.80 toks/s, output: 45.80 toks/s]
Processed prompts:  27%|██▋       | 139/512 [00:03<00:10, 35.05it/s, est. speed input: 45071.85 toks/s, output: 44.02 toks/s]
Processed prompts:  28%|██▊       | 145/512 [00:03<00:10, 36.17it/s, est. speed input: 45040.84 toks/s, output: 43.99 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:03<00:11, 31.11it/s, est. speed input: 42984.56 toks/s, output: 41.98 toks/s]
Processed prompts:  30%|███       | 154/512 [00:03<00:11, 30.74it/s, est. speed input: 42483.16 toks/s, output: 41.49 toks/s]
Processed prompts:  31%|███       | 158/512 [00:03<00:11, 30.39it/s, est. speed input: 42021.93 toks/s, output: 41.04 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:03<00:11, 30.07it/s, est. speed input: 41589.56 toks/s, output: 40.61 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:04<00:11, 29.80it/s, est. speed input: 41188.90 toks/s, output: 40.22 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:04<00:11, 29.60it/s, est. speed input: 40817.55 toks/s, output: 39.86 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:04<00:11, 29.42it/s, est. speed input: 40465.50 toks/s, output: 39.52 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:04<00:11, 29.32it/s, est. speed input: 40140.39 toks/s, output: 39.20 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:04<00:11, 29.19it/s, est. speed input: 39826.65 toks/s, output: 38.89 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:04<00:11, 29.14it/s, est. speed input: 39536.97 toks/s, output: 38.61 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:04<00:11, 29.08it/s, est. speed input: 39260.45 toks/s, output: 38.34 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:05<00:10, 29.03it/s, est. speed input: 38998.23 toks/s, output: 38.08 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:05<00:10, 29.01it/s, est. speed input: 38751.66 toks/s, output: 37.84 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:05<00:10, 30.61it/s, est. speed input: 38695.28 toks/s, output: 37.79 toks/s]
Processed prompts:  40%|████      | 206/512 [00:05<00:10, 30.11it/s, est. speed input: 38468.48 toks/s, output: 37.57 toks/s]
Processed prompts:  41%|████      | 210/512 [00:05<00:10, 29.74it/s, est. speed input: 38250.20 toks/s, output: 37.35 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:05<00:10, 29.48it/s, est. speed input: 38041.48 toks/s, output: 37.15 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:05<00:10, 29.27it/s, est. speed input: 37840.20 toks/s, output: 36.95 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:09, 29.15it/s, est. speed input: 37650.39 toks/s, output: 36.77 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:06<00:09, 29.08it/s, est. speed input: 37470.60 toks/s, output: 36.59 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:06<00:09, 29.01it/s, est. speed input: 37296.39 toks/s, output: 36.42 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:06<00:09, 28.94it/s, est. speed input: 37127.75 toks/s, output: 36.26 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:06<00:09, 28.94it/s, est. speed input: 36970.85 toks/s, output: 36.10 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:06<00:09, 28.86it/s, est. speed input: 36813.29 toks/s, output: 35.95 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:06<00:09, 28.87it/s, est. speed input: 36667.36 toks/s, output: 35.81 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:07<00:09, 28.86it/s, est. speed input: 36525.88 toks/s, output: 35.67 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:07<00:08, 28.85it/s, est. speed input: 36389.93 toks/s, output: 35.54 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:07<00:08, 28.90it/s, est. speed input: 36263.41 toks/s, output: 35.41 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:07<00:08, 28.91it/s, est. speed input: 36140.23 toks/s, output: 35.29 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:07<00:08, 28.89it/s, est. speed input: 36019.10 toks/s, output: 35.17 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:07<00:08, 28.88it/s, est. speed input: 35902.88 toks/s, output: 35.06 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:07<00:08, 28.89it/s, est. speed input: 35791.90 toks/s, output: 34.95 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:07<00:08, 28.91it/s, est. speed input: 35685.14 toks/s, output: 34.85 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:08<00:07, 28.91it/s, est. speed input: 35581.73 toks/s, output: 34.75 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:08<00:07, 28.93it/s, est. speed input: 35482.46 toks/s, output: 34.65 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:08<00:07, 28.94it/s, est. speed input: 35387.09 toks/s, output: 34.56 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:08<00:07, 28.94it/s, est. speed input: 35293.54 toks/s, output: 34.47 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:08<00:07, 28.91it/s, est. speed input: 35201.57 toks/s, output: 34.38 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:08<00:07, 28.89it/s, est. speed input: 35112.36 toks/s, output: 34.29 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:08<00:07, 28.91it/s, est. speed input: 35027.82 toks/s, output: 34.21 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:09<00:06, 28.89it/s, est. speed input: 34944.25 toks/s, output: 34.13 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:09<00:06, 28.89it/s, est. speed input: 34863.91 toks/s, output: 34.05 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:09<00:06, 28.91it/s, est. speed input: 34787.01 toks/s, output: 33.97 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:09<00:06, 28.91it/s, est. speed input: 34711.39 toks/s, output: 33.90 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:09<00:06, 28.88it/s, est. speed input: 34636.48 toks/s, output: 33.82 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:09<00:06, 28.86it/s, est. speed input: 34563.79 toks/s, output: 33.75 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:09<00:06, 28.87it/s, est. speed input: 34494.32 toks/s, output: 33.69 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:10<00:06, 28.84it/s, est. speed input: 34424.81 toks/s, output: 33.62 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:10<00:05, 28.84it/s, est. speed input: 34357.99 toks/s, output: 33.55 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:10<00:05, 28.84it/s, est. speed input: 34293.18 toks/s, output: 33.49 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:10<00:05, 28.87it/s, est. speed input: 34231.67 toks/s, output: 33.43 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:10<00:05, 28.90it/s, est. speed input: 34172.18 toks/s, output: 33.37 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:10<00:05, 28.87it/s, est. speed input: 34111.69 toks/s, output: 33.31 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:10<00:05, 28.83it/s, est. speed input: 34052.09 toks/s, output: 33.25 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:11<00:05, 28.84it/s, est. speed input: 33995.60 toks/s, output: 33.20 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:11<00:04, 28.87it/s, est. speed input: 33941.22 toks/s, output: 33.15 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:11<00:04, 28.87it/s, est. speed input: 33887.86 toks/s, output: 33.09 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:11<00:04, 28.90it/s, est. speed input: 33836.92 toks/s, output: 33.04 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:11<00:04, 28.94it/s, est. speed input: 33788.07 toks/s, output: 33.00 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:11<00:04, 28.92it/s, est. speed input: 33738.18 toks/s, output: 32.95 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:11<00:04, 28.92it/s, est. speed input: 33689.81 toks/s, output: 32.90 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:11<00:04, 28.90it/s, est. speed input: 33642.18 toks/s, output: 32.85 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:12<00:03, 28.88it/s, est. speed input: 33594.77 toks/s, output: 32.81 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:12<00:03, 28.89it/s, est. speed input: 33549.94 toks/s, output: 32.76 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:12<00:03, 28.89it/s, est. speed input: 33505.72 toks/s, output: 32.72 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:12<00:03, 28.91it/s, est. speed input: 33463.40 toks/s, output: 32.68 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:12<00:03, 28.92it/s, est. speed input: 33421.51 toks/s, output: 32.64 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:12<00:03, 28.87it/s, est. speed input: 33378.48 toks/s, output: 32.60 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:12<00:03, 28.85it/s, est. speed input: 33336.88 toks/s, output: 32.56 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:13<00:02, 28.82it/s, est. speed input: 33295.68 toks/s, output: 32.52 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:13<00:02, 28.80it/s, est. speed input: 33255.05 toks/s, output: 32.48 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:13<00:02, 28.79it/s, est. speed input: 33215.44 toks/s, output: 32.44 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:13<00:02, 28.82it/s, est. speed input: 33178.40 toks/s, output: 32.40 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:13<00:02, 28.85it/s, est. speed input: 33142.44 toks/s, output: 32.37 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:13<00:02, 28.87it/s, est. speed input: 33106.86 toks/s, output: 32.33 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:13<00:02, 28.82it/s, est. speed input: 33069.88 toks/s, output: 32.29 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:14<00:02, 28.79it/s, est. speed input: 33033.69 toks/s, output: 32.26 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:14<00:01, 28.84it/s, est. speed input: 33000.63 toks/s, output: 32.23 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:14<00:01, 28.84it/s, est. speed input: 32967.22 toks/s, output: 32.19 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:14<00:01, 28.86it/s, est. speed input: 32935.08 toks/s, output: 32.16 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:14<00:01, 28.87it/s, est. speed input: 32903.43 toks/s, output: 32.13 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:14<00:01, 28.89it/s, est. speed input: 32872.79 toks/s, output: 32.10 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:14<00:01, 28.87it/s, est. speed input: 32841.55 toks/s, output: 32.07 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:15<00:01, 28.85it/s, est. speed input: 32810.68 toks/s, output: 32.04 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:15<00:00, 28.85it/s, est. speed input: 32780.86 toks/s, output: 32.01 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:15<00:00, 28.86it/s, est. speed input: 32751.93 toks/s, output: 31.98 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:15<00:00, 28.87it/s, est. speed input: 32723.64 toks/s, output: 31.96 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:15<00:00, 28.88it/s, est. speed input: 32695.97 toks/s, output: 31.93 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:15<00:00, 28.89it/s, est. speed input: 32668.76 toks/s, output: 31.90 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:15<00:00, 28.90it/s, est. speed input: 32642.27 toks/s, output: 31.88 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:15<00:00, 30.94it/s, est. speed input: 32678.05 toks/s, output: 31.91 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:15<00:00, 30.94it/s, est. speed input: 32805.74 toks/s, output: 32.04 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:15<00:00, 32.04it/s, est. speed input: 32805.74 toks/s, output: 32.04 toks/s]
[rank0]:[W126 01:49:44.862262072 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 61.3s

测试结果:
  Requests/s:   28.68
  Tokens/s:     29398.51
  Total Reqs:   512
  Elapsed:      17.85s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     29369.83

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:50:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:50:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=27509) WARNING 01-26 01:50:09 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=27509) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=27509) WARNING 01-26 01:50:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.70 requests/s, 29412.48 total tokens/s, 28.70 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 01:50:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:50:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:50:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:50:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:50:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:50:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:50:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:50:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:50:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:50:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:50:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:50:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=27509) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=27509) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.46it/s]
(EngineCore_DP0 pid=27509) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.14it/s]
(EngineCore_DP0 pid=27509) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.18it/s]
(EngineCore_DP0 pid=27509) 
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=27509) [2026-01-26 01:50:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=27509) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.37it/s]
(EngineCore_DP0 pid=27509) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.34it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  8.94it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.89it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 24/1024 [00:00<00:04, 233.60it/s]
Adding requests:   5%|▍         | 50/1024 [00:00<00:03, 245.12it/s]
Adding requests:   8%|▊         | 79/1024 [00:00<00:03, 262.07it/s]
Adding requests:  11%|█         | 108/1024 [00:00<00:03, 268.09it/s]
Adding requests:  13%|█▎        | 135/1024 [00:00<00:03, 268.75it/s]
Adding requests:  16%|█▌        | 163/1024 [00:00<00:03, 270.81it/s]
Adding requests:  19%|█▉        | 192/1024 [00:00<00:03, 275.83it/s]
Adding requests:  22%|██▏       | 221/1024 [00:00<00:02, 277.78it/s]
Adding requests:  24%|██▍       | 249/1024 [00:00<00:02, 273.57it/s]
Adding requests:  27%|██▋       | 277/1024 [00:01<00:02, 274.14it/s]
Adding requests:  30%|██▉       | 306/1024 [00:01<00:02, 277.41it/s]
Adding requests:  33%|███▎      | 336/1024 [00:01<00:02, 283.21it/s]
Adding requests:  36%|███▌      | 365/1024 [00:01<00:02, 284.61it/s]
Adding requests:  38%|███▊      | 394/1024 [00:01<00:02, 286.18it/s]
Adding requests:  42%|████▏     | 425/1024 [00:01<00:02, 290.22it/s]
Adding requests:  44%|████▍     | 455/1024 [00:01<00:01, 287.04it/s]
Adding requests:  47%|████▋     | 485/1024 [00:01<00:01, 290.65it/s]
Adding requests:  50%|█████     | 515/1024 [00:01<00:01, 289.69it/s]
Adding requests:  53%|█████▎    | 545/1024 [00:01<00:01, 291.30it/s]
Adding requests:  56%|█████▌    | 575/1024 [00:02<00:01, 289.47it/s]
Adding requests:  59%|█████▉    | 604/1024 [00:02<00:01, 282.43it/s]
Adding requests:  62%|██████▏   | 633/1024 [00:02<00:01, 277.07it/s]
Adding requests:  65%|██████▍   | 661/1024 [00:02<00:01, 274.26it/s]
Adding requests:  67%|██████▋   | 691/1024 [00:02<00:01, 280.54it/s]
Adding requests:  70%|███████   | 720/1024 [00:02<00:01, 276.26it/s]
Adding requests:  73%|███████▎  | 748/1024 [00:02<00:01, 273.10it/s]
Adding requests:  76%|███████▌  | 776/1024 [00:02<00:00, 273.14it/s]
Adding requests:  79%|███████▊  | 804/1024 [00:02<00:00, 266.99it/s]
Adding requests:  81%|████████▏ | 834/1024 [00:03<00:00, 275.94it/s]
Adding requests:  84%|████████▍ | 862/1024 [00:03<00:00, 272.88it/s]
Adding requests:  87%|████████▋ | 891/1024 [00:03<00:00, 275.34it/s]
Adding requests:  90%|████████▉ | 919/1024 [00:03<00:00, 272.06it/s]
Adding requests:  92%|█████████▏| 947/1024 [00:03<00:00, 271.36it/s]
Adding requests:  95%|█████████▌| 976/1024 [00:03<00:00, 276.09it/s]
Adding requests:  98%|█████████▊| 1004/1024 [00:03<00:00, 272.51it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 276.65it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:00<00:01, 644.23it/s, est. speed input: 659822.63 toks/s, output: 644.27 toks/s]
Processed prompts:  16%|█▌        | 163/1024 [00:02<00:14, 57.70it/s, est. speed input: 70698.10 toks/s, output: 69.04 toks/s]  
Processed prompts:  19%|█▉        | 192/1024 [00:03<00:16, 50.01it/s, est. speed input: 61634.12 toks/s, output: 60.19 toks/s]
Processed prompts:  20%|██        | 209/1024 [00:03<00:17, 45.86it/s, est. speed input: 57593.38 toks/s, output: 56.24 toks/s]
Processed prompts:  22%|██▏       | 221/1024 [00:04<00:20, 39.56it/s, est. speed input: 53010.61 toks/s, output: 51.77 toks/s]
Processed prompts:  22%|██▏       | 230/1024 [00:04<00:20, 38.46it/s, est. speed input: 51811.23 toks/s, output: 50.60 toks/s]
Processed prompts:  23%|██▎       | 237/1024 [00:04<00:21, 36.05it/s, est. speed input: 50327.18 toks/s, output: 49.15 toks/s]
Processed prompts:  24%|██▎       | 243/1024 [00:05<00:23, 33.06it/s, est. speed input: 48795.97 toks/s, output: 47.65 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:05<00:24, 31.28it/s, est. speed input: 47618.12 toks/s, output: 46.50 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:05<00:24, 30.71it/s, est. speed input: 46738.49 toks/s, output: 45.64 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:05<00:25, 30.25it/s, est. speed input: 45941.44 toks/s, output: 44.86 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:06<00:25, 29.87it/s, est. speed input: 45208.95 toks/s, output: 44.15 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:06<00:25, 29.61it/s, est. speed input: 44545.19 toks/s, output: 43.50 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:06<00:24, 29.41it/s, est. speed input: 43933.90 toks/s, output: 42.90 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:07<00:24, 29.26it/s, est. speed input: 43368.79 toks/s, output: 42.35 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:07<00:24, 29.14it/s, est. speed input: 42845.42 toks/s, output: 41.84 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:07<00:24, 29.07it/s, est. speed input: 42361.98 toks/s, output: 41.37 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:07<00:24, 29.02it/s, est. speed input: 41913.06 toks/s, output: 40.93 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:08<00:23, 28.97it/s, est. speed input: 41491.35 toks/s, output: 40.52 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:08<00:23, 28.96it/s, est. speed input: 41102.25 toks/s, output: 40.14 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:08<00:23, 28.92it/s, est. speed input: 40733.07 toks/s, output: 39.78 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:08<00:23, 28.92it/s, est. speed input: 40389.75 toks/s, output: 39.44 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:09<00:22, 28.91it/s, est. speed input: 40066.38 toks/s, output: 39.13 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:09<00:22, 28.90it/s, est. speed input: 39761.49 toks/s, output: 38.83 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:09<00:22, 28.89it/s, est. speed input: 39473.27 toks/s, output: 38.55 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:10<00:22, 28.88it/s, est. speed input: 39200.09 toks/s, output: 38.28 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:10<00:21, 28.88it/s, est. speed input: 38942.82 toks/s, output: 38.03 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:10<00:21, 28.87it/s, est. speed input: 38697.73 toks/s, output: 37.79 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:10<00:21, 28.86it/s, est. speed input: 38465.03 toks/s, output: 37.56 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:11<00:20, 28.87it/s, est. speed input: 38244.62 toks/s, output: 37.35 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:11<00:20, 28.86it/s, est. speed input: 38034.57 toks/s, output: 37.14 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:11<00:20, 28.85it/s, est. speed input: 37833.56 toks/s, output: 36.95 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:12<00:20, 28.85it/s, est. speed input: 37642.16 toks/s, output: 36.76 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:12<00:19, 28.85it/s, est. speed input: 37459.61 toks/s, output: 36.58 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:12<00:19, 28.85it/s, est. speed input: 37284.98 toks/s, output: 36.41 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:12<00:19, 28.85it/s, est. speed input: 37117.61 toks/s, output: 36.25 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:13<00:19, 28.85it/s, est. speed input: 36958.03 toks/s, output: 36.09 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:13<00:18, 28.85it/s, est. speed input: 36804.93 toks/s, output: 35.94 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:13<00:18, 28.84it/s, est. speed input: 36656.83 toks/s, output: 35.80 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:13<00:18, 28.85it/s, est. speed input: 36515.76 toks/s, output: 35.66 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:14<00:17, 28.84it/s, est. speed input: 36378.98 toks/s, output: 35.53 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:14<00:17, 28.83it/s, est. speed input: 36247.73 toks/s, output: 35.40 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:14<00:17, 28.83it/s, est. speed input: 36121.65 toks/s, output: 35.27 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:15<00:17, 28.83it/s, est. speed input: 35999.73 toks/s, output: 35.16 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:15<00:16, 28.82it/s, est. speed input: 35882.19 toks/s, output: 35.04 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:15<00:16, 28.82it/s, est. speed input: 35769.29 toks/s, output: 34.93 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:15<00:16, 28.82it/s, est. speed input: 35659.62 toks/s, output: 34.82 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:16<00:16, 28.82it/s, est. speed input: 35554.17 toks/s, output: 34.72 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:16<00:15, 28.82it/s, est. speed input: 35452.09 toks/s, output: 34.62 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:16<00:15, 28.81it/s, est. speed input: 35353.48 toks/s, output: 34.52 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:17<00:15, 28.81it/s, est. speed input: 35257.64 toks/s, output: 34.43 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:17<00:14, 28.80it/s, est. speed input: 35164.75 toks/s, output: 34.34 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:17<00:14, 28.79it/s, est. speed input: 35074.13 toks/s, output: 34.25 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:17<00:14, 28.78it/s, est. speed input: 34986.81 toks/s, output: 34.17 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:18<00:14, 28.78it/s, est. speed input: 34901.97 toks/s, output: 34.08 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:18<00:13, 28.77it/s, est. speed input: 34819.47 toks/s, output: 34.00 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:18<00:13, 28.77it/s, est. speed input: 34739.76 toks/s, output: 33.93 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:18<00:13, 28.76it/s, est. speed input: 34661.85 toks/s, output: 33.85 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:19<00:13, 28.75it/s, est. speed input: 34586.11 toks/s, output: 33.78 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:19<00:12, 28.76it/s, est. speed input: 34513.06 toks/s, output: 33.70 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:19<00:12, 28.75it/s, est. speed input: 34441.43 toks/s, output: 33.63 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:20<00:12, 28.75it/s, est. speed input: 34372.29 toks/s, output: 33.57 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:20<00:11, 28.77it/s, est. speed input: 34305.58 toks/s, output: 33.50 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:20<00:11, 28.75it/s, est. speed input: 34239.45 toks/s, output: 33.44 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:20<00:11, 28.75it/s, est. speed input: 34175.51 toks/s, output: 33.37 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:21<00:11, 28.75it/s, est. speed input: 34113.13 toks/s, output: 33.31 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:21<00:10, 28.75it/s, est. speed input: 34052.73 toks/s, output: 33.25 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:21<00:10, 28.75it/s, est. speed input: 33993.48 toks/s, output: 33.20 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:22<00:10, 28.73it/s, est. speed input: 33935.23 toks/s, output: 33.14 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:22<00:09, 28.73it/s, est. speed input: 33879.00 toks/s, output: 33.08 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:22<00:09, 28.73it/s, est. speed input: 33823.96 toks/s, output: 33.03 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:22<00:09, 28.74it/s, est. speed input: 33770.83 toks/s, output: 32.98 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:23<00:09, 28.74it/s, est. speed input: 33718.68 toks/s, output: 32.93 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:23<00:08, 28.75it/s, est. speed input: 33668.19 toks/s, output: 32.88 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:23<00:08, 28.76it/s, est. speed input: 33619.03 toks/s, output: 32.83 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:23<00:08, 29.71it/s, est. speed input: 33612.02 toks/s, output: 32.82 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:24<00:07, 29.41it/s, est. speed input: 33563.88 toks/s, output: 32.78 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:24<00:07, 29.21it/s, est. speed input: 33517.35 toks/s, output: 32.73 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:24<00:07, 29.06it/s, est. speed input: 33470.80 toks/s, output: 32.69 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:25<00:07, 28.97it/s, est. speed input: 33426.23 toks/s, output: 32.64 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:25<00:06, 28.90it/s, est. speed input: 33382.54 toks/s, output: 32.60 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:25<00:06, 28.86it/s, est. speed input: 33339.65 toks/s, output: 32.56 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:25<00:06, 28.82it/s, est. speed input: 33297.44 toks/s, output: 32.52 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:26<00:02, 70.83it/s, est. speed input: 34637.88 toks/s, output: 33.83 toks/s]
Processed prompts:  87%|████████▋ | 891/1024 [00:26<00:02, 58.35it/s, est. speed input: 34621.76 toks/s, output: 33.81 toks/s]
Processed prompts:  88%|████████▊ | 899/1024 [00:26<00:02, 48.99it/s, est. speed input: 34567.81 toks/s, output: 33.76 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:26<00:02, 41.57it/s, est. speed input: 34476.86 toks/s, output: 33.67 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:27<00:02, 37.61it/s, est. speed input: 34424.98 toks/s, output: 33.62 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:27<00:02, 34.91it/s, est. speed input: 34374.67 toks/s, output: 33.57 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:27<00:02, 33.03it/s, est. speed input: 34325.06 toks/s, output: 33.52 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:28<00:02, 31.74it/s, est. speed input: 34276.60 toks/s, output: 33.47 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:28<00:02, 30.83it/s, est. speed input: 34228.79 toks/s, output: 33.43 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:28<00:02, 30.22it/s, est. speed input: 34182.79 toks/s, output: 33.38 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:28<00:02, 29.79it/s, est. speed input: 34137.45 toks/s, output: 33.34 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:29<00:01, 29.48it/s, est. speed input: 34092.79 toks/s, output: 33.29 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:29<00:01, 29.27it/s, est. speed input: 34048.92 toks/s, output: 33.25 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:29<00:01, 29.12it/s, est. speed input: 34005.93 toks/s, output: 33.21 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:29<00:01, 29.01it/s, est. speed input: 33963.57 toks/s, output: 33.17 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:30<00:00, 28.94it/s, est. speed input: 33922.32 toks/s, output: 33.13 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:30<00:00, 28.90it/s, est. speed input: 33882.00 toks/s, output: 33.09 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:30<00:00, 29.92it/s, est. speed input: 33878.07 toks/s, output: 33.08 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:30<00:00, 29.92it/s, est. speed input: 34077.29 toks/s, output: 33.28 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:30<00:00, 33.28it/s, est. speed input: 34077.29 toks/s, output: 33.28 toks/s]
[rank0]:[W126 01:51:07.703331486 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 82.2s

测试结果:
  Requests/s:   28.70
  Tokens/s:     29412.48
  Total Reqs:   1024
  Elapsed:      35.69s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     29383.78

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:51:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:51:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=28993) WARNING 01-26 01:51:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=28993) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=28993) WARNING 01-26 01:51:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 28.75 requests/s, 29471.33 total tokens/s, 28.75 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 01:51:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:51:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:51:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:51:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:51:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:51:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:51:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:51:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:51:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:51:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:51:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:51:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:51:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:51:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:51:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:51:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:51:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=28993) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=28993) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.49it/s]
(EngineCore_DP0 pid=28993) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.19it/s]
(EngineCore_DP0 pid=28993) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.22it/s]
(EngineCore_DP0 pid=28993) 
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=28993) [2026-01-26 01:51:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=28993) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  9.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.57it/s]
(EngineCore_DP0 pid=28993) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.41it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.72it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  9.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.05it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.81it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 240.75it/s]
Adding requests:   2%|▏         | 50/2048 [00:00<00:08, 239.91it/s]
Adding requests:   4%|▍         | 78/2048 [00:00<00:07, 253.14it/s]
Adding requests:   5%|▌         | 106/2048 [00:00<00:07, 261.54it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:07, 262.52it/s]
Adding requests:   8%|▊         | 162/2048 [00:00<00:07, 269.00it/s]
Adding requests:   9%|▉         | 191/2048 [00:00<00:06, 275.18it/s]
Adding requests:  11%|█         | 221/2048 [00:00<00:06, 279.67it/s]
Adding requests:  12%|█▏        | 249/2048 [00:00<00:06, 274.43it/s]
Adding requests:  14%|█▎        | 277/2048 [00:01<00:06, 273.65it/s]
Adding requests:  15%|█▍        | 306/2048 [00:01<00:06, 278.16it/s]
Adding requests:  16%|█▋        | 336/2048 [00:01<00:06, 282.97it/s]
Adding requests:  35%|███▍      | 710/2048 [00:01<00:01, 1303.86it/s]
Adding requests:  41%|████      | 841/2048 [00:01<00:01, 614.61it/s] 
Adding requests:  46%|████▌     | 941/2048 [00:02<00:02, 466.43it/s]
Adding requests:  50%|████▉     | 1019/2048 [00:02<00:02, 401.57it/s]
Adding requests:  53%|█████▎    | 1082/2048 [00:02<00:02, 368.82it/s]
Adding requests:  55%|█████▌    | 1134/2048 [00:02<00:02, 348.81it/s]
Adding requests:  58%|█████▊    | 1179/2048 [00:03<00:02, 330.47it/s]
Adding requests:  60%|█████▉    | 1219/2048 [00:03<00:02, 321.12it/s]
Adding requests:  61%|██████▏   | 1256/2048 [00:03<00:02, 311.52it/s]
Adding requests:  63%|██████▎   | 1290/2048 [00:03<00:02, 300.85it/s]
Adding requests:  65%|██████▍   | 1322/2048 [00:03<00:02, 294.49it/s]
Adding requests:  66%|██████▌   | 1353/2048 [00:03<00:02, 292.18it/s]
Adding requests:  68%|██████▊   | 1383/2048 [00:03<00:02, 291.10it/s]
Adding requests:  69%|██████▉   | 1413/2048 [00:03<00:02, 286.06it/s]
Adding requests:  70%|███████   | 1442/2048 [00:04<00:02, 284.35it/s]
Adding requests:  72%|███████▏  | 1471/2048 [00:04<00:02, 283.87it/s]
Adding requests:  73%|███████▎  | 1501/2048 [00:04<00:01, 286.73it/s]
Adding requests:  75%|███████▍  | 1530/2048 [00:04<00:01, 283.30it/s]
Adding requests:  76%|███████▌  | 1559/2048 [00:04<00:01, 278.96it/s]
Adding requests:  77%|███████▋  | 1587/2048 [00:04<00:01, 273.20it/s]
Adding requests:  79%|███████▉  | 1615/2048 [00:04<00:01, 269.95it/s]
Adding requests:  80%|████████  | 1643/2048 [00:04<00:01, 265.58it/s]
Adding requests:  82%|████████▏ | 1670/2048 [00:04<00:01, 262.05it/s]
Adding requests:  83%|████████▎ | 1698/2048 [00:04<00:01, 266.16it/s]
Adding requests:  84%|████████▍ | 1727/2048 [00:05<00:01, 269.99it/s]
Adding requests:  86%|████████▌ | 1755/2048 [00:05<00:01, 268.04it/s]
Adding requests:  87%|████████▋ | 1783/2048 [00:05<00:00, 271.32it/s]
Adding requests:  88%|████████▊ | 1811/2048 [00:05<00:00, 272.80it/s]
Adding requests:  90%|████████▉ | 1840/2048 [00:05<00:00, 276.06it/s]
Adding requests:  91%|█████████ | 1868/2048 [00:05<00:00, 274.70it/s]
Adding requests:  93%|█████████▎| 1897/2048 [00:05<00:00, 276.08it/s]
Adding requests:  94%|█████████▍| 1926/2048 [00:05<00:00, 279.64it/s]
Adding requests:  96%|█████████▌| 1957/2048 [00:05<00:00, 286.09it/s]
Adding requests:  97%|█████████▋| 1986/2048 [00:05<00:00, 282.21it/s]
Adding requests:  98%|█████████▊| 2015/2048 [00:06<00:00, 269.17it/s]
Adding requests: 100%|█████████▉| 2043/2048 [00:06<00:00, 268.02it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 328.83it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:00<00:04, 399.42it/s, est. speed input: 409025.77 toks/s, output: 399.43 toks/s]
Processed prompts:  12%|█▏        | 250/2048 [00:01<00:14, 127.03it/s, est. speed input: 157068.69 toks/s, output: 153.39 toks/s]
Processed prompts:  13%|█▎        | 269/2048 [00:02<00:18, 94.71it/s, est. speed input: 126236.79 toks/s, output: 123.28 toks/s] 
Processed prompts:  14%|█▎        | 281/2048 [00:02<00:25, 70.45it/s, est. speed input: 105246.55 toks/s, output: 102.78 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:03<00:33, 53.00it/s, est. speed input: 90364.99 toks/s, output: 88.25 toks/s]  
Processed prompts:  15%|█▍        | 306/2048 [00:03<00:38, 45.42it/s, est. speed input: 81626.12 toks/s, output: 79.71 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:04<00:42, 40.31it/s, est. speed input: 75089.16 toks/s, output: 73.33 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:04<00:46, 36.81it/s, est. speed input: 70005.91 toks/s, output: 68.36 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:05<00:49, 34.41it/s, est. speed input: 65943.98 toks/s, output: 64.40 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:06<00:51, 32.75it/s, est. speed input: 62626.74 toks/s, output: 61.16 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:06<00:52, 31.59it/s, est. speed input: 59861.32 toks/s, output: 58.46 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:07<00:53, 30.79it/s, est. speed input: 57524.70 toks/s, output: 56.18 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:07<00:53, 30.23it/s, est. speed input: 55521.59 toks/s, output: 54.22 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:08<00:54, 29.83it/s, est. speed input: 53785.13 toks/s, output: 52.52 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:08<00:54, 29.44it/s, est. speed input: 52225.34 toks/s, output: 51.00 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:09<00:54, 29.29it/s, est. speed input: 50891.73 toks/s, output: 49.70 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:09<00:53, 29.17it/s, est. speed input: 49705.06 toks/s, output: 48.54 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:10<00:53, 29.09it/s, est. speed input: 48643.86 toks/s, output: 47.50 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:11<00:52, 29.05it/s, est. speed input: 47693.36 toks/s, output: 46.58 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:11<00:52, 29.02it/s, est. speed input: 46832.28 toks/s, output: 45.73 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:12<00:51, 29.00it/s, est. speed input: 46050.16 toks/s, output: 44.97 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:12<00:51, 28.98it/s, est. speed input: 45334.15 toks/s, output: 44.27 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:13<00:50, 28.96it/s, est. speed input: 44677.58 toks/s, output: 43.63 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:13<00:50, 28.96it/s, est. speed input: 44075.45 toks/s, output: 43.04 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:14<00:49, 28.95it/s, est. speed input: 43518.27 toks/s, output: 42.50 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:14<00:49, 28.95it/s, est. speed input: 43003.47 toks/s, output: 42.00 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:15<00:48, 28.94it/s, est. speed input: 42524.98 toks/s, output: 41.53 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:16<00:48, 28.94it/s, est. speed input: 42079.34 toks/s, output: 41.09 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:16<00:47, 28.93it/s, est. speed input: 41663.26 toks/s, output: 40.69 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:17<00:46, 28.94it/s, est. speed input: 41274.69 toks/s, output: 40.31 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:17<00:46, 28.93it/s, est. speed input: 40910.18 toks/s, output: 39.95 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:18<00:45, 28.93it/s, est. speed input: 40567.47 toks/s, output: 39.62 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:18<00:45, 28.83it/s, est. speed input: 40230.74 toks/s, output: 39.29 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:19<00:45, 28.73it/s, est. speed input: 39910.02 toks/s, output: 38.97 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:19<00:44, 28.66it/s, est. speed input: 39608.13 toks/s, output: 38.68 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:20<00:43, 29.08it/s, est. speed input: 39379.71 toks/s, output: 38.46 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:21<00:43, 28.90it/s, est. speed input: 39107.00 toks/s, output: 38.19 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:21<00:42, 28.78it/s, est. speed input: 38848.05 toks/s, output: 37.94 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:22<00:42, 28.71it/s, est. speed input: 38604.45 toks/s, output: 37.70 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:22<00:41, 28.63it/s, est. speed input: 38369.84 toks/s, output: 37.47 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:23<00:41, 28.60it/s, est. speed input: 38148.99 toks/s, output: 37.25 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:23<00:40, 28.58it/s, est. speed input: 37938.34 toks/s, output: 37.05 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:24<00:40, 28.56it/s, est. speed input: 37737.64 toks/s, output: 36.85 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:24<00:39, 28.55it/s, est. speed input: 37545.99 toks/s, output: 36.67 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:25<00:39, 28.54it/s, est. speed input: 37362.29 toks/s, output: 36.49 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:26<00:38, 28.54it/s, est. speed input: 37186.78 toks/s, output: 36.32 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:26<00:20, 50.41it/s, est. speed input: 38505.14 toks/s, output: 37.60 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:26<00:23, 43.57it/s, est. speed input: 38322.78 toks/s, output: 37.42 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:27<00:26, 39.00it/s, est. speed input: 38148.19 toks/s, output: 37.25 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:28<00:28, 35.88it/s, est. speed input: 37979.85 toks/s, output: 37.09 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:28<00:29, 33.75it/s, est. speed input: 37818.47 toks/s, output: 36.93 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:29<00:30, 32.30it/s, est. speed input: 37664.16 toks/s, output: 36.78 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:29<00:30, 31.26it/s, est. speed input: 37513.40 toks/s, output: 36.63 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:30<00:30, 30.56it/s, est. speed input: 37369.32 toks/s, output: 36.49 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:30<00:30, 30.06it/s, est. speed input: 37230.49 toks/s, output: 36.36 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:31<00:30, 29.73it/s, est. speed input: 37096.89 toks/s, output: 36.23 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:31<00:30, 29.49it/s, est. speed input: 36967.69 toks/s, output: 36.10 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:32<00:29, 29.32it/s, est. speed input: 36842.88 toks/s, output: 35.98 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:33<00:29, 29.21it/s, est. speed input: 36722.30 toks/s, output: 35.86 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:33<00:29, 29.12it/s, est. speed input: 36605.44 toks/s, output: 35.75 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:34<00:28, 29.06it/s, est. speed input: 36492.47 toks/s, output: 35.64 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:34<00:28, 28.94it/s, est. speed input: 36377.54 toks/s, output: 35.52 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:35<00:27, 28.83it/s, est. speed input: 36264.32 toks/s, output: 35.41 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:35<00:27, 28.72it/s, est. speed input: 36153.30 toks/s, output: 35.31 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:36<00:26, 28.66it/s, est. speed input: 36046.39 toks/s, output: 35.20 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:36<00:26, 28.62it/s, est. speed input: 35942.72 toks/s, output: 35.10 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:37<00:25, 28.60it/s, est. speed input: 35842.21 toks/s, output: 35.00 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:38<00:25, 28.57it/s, est. speed input: 35744.46 toks/s, output: 34.91 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:38<00:24, 28.56it/s, est. speed input: 35649.60 toks/s, output: 34.81 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:39<00:24, 28.55it/s, est. speed input: 35557.79 toks/s, output: 34.72 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:39<00:23, 28.54it/s, est. speed input: 35468.10 toks/s, output: 34.64 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:40<00:22, 28.54it/s, est. speed input: 35381.04 toks/s, output: 34.55 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:40<00:22, 28.53it/s, est. speed input: 35296.50 toks/s, output: 34.47 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:41<00:21, 28.53it/s, est. speed input: 35214.25 toks/s, output: 34.39 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:42<00:21, 28.54it/s, est. speed input: 35134.39 toks/s, output: 34.31 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:42<00:20, 28.55it/s, est. speed input: 35057.34 toks/s, output: 34.24 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:43<00:20, 28.60it/s, est. speed input: 34984.25 toks/s, output: 34.16 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:43<00:19, 28.63it/s, est. speed input: 34913.16 toks/s, output: 34.09 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:44<00:18, 28.67it/s, est. speed input: 34844.16 toks/s, output: 34.03 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:44<00:18, 28.67it/s, est. speed input: 34776.24 toks/s, output: 33.96 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:45<00:17, 28.68it/s, est. speed input: 34710.06 toks/s, output: 33.90 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:45<00:17, 28.70it/s, est. speed input: 34645.92 toks/s, output: 33.83 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:46<00:16, 28.70it/s, est. speed input: 34582.99 toks/s, output: 33.77 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:47<00:16, 28.71it/s, est. speed input: 34521.81 toks/s, output: 33.71 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:47<00:15, 28.71it/s, est. speed input: 34461.75 toks/s, output: 33.65 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:48<00:14, 29.17it/s, est. speed input: 34424.10 toks/s, output: 33.62 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:48<00:14, 29.03it/s, est. speed input: 34366.60 toks/s, output: 33.56 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:49<00:13, 28.93it/s, est. speed input: 34310.14 toks/s, output: 33.51 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:49<00:13, 28.86it/s, est. speed input: 34255.28 toks/s, output: 33.45 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:50<00:12, 28.81it/s, est. speed input: 34201.42 toks/s, output: 33.40 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:50<00:12, 28.83it/s, est. speed input: 34150.69 toks/s, output: 33.35 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:51<00:11, 28.84it/s, est. speed input: 34101.25 toks/s, output: 33.30 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:52<00:11, 28.85it/s, est. speed input: 34052.83 toks/s, output: 33.25 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:52<00:10, 28.85it/s, est. speed input: 34005.37 toks/s, output: 33.21 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:53<00:09, 28.85it/s, est. speed input: 33958.98 toks/s, output: 33.16 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:53<00:09, 28.86it/s, est. speed input: 33913.59 toks/s, output: 33.12 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:54<00:08, 28.86it/s, est. speed input: 33869.08 toks/s, output: 33.08 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:54<00:08, 28.86it/s, est. speed input: 33825.44 toks/s, output: 33.03 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:55<00:07, 28.85it/s, est. speed input: 33782.32 toks/s, output: 32.99 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:55<00:07, 28.85it/s, est. speed input: 33740.31 toks/s, output: 32.95 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:56<00:06, 28.86it/s, est. speed input: 33699.24 toks/s, output: 32.91 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:57<00:06, 28.86it/s, est. speed input: 33658.92 toks/s, output: 32.87 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:57<00:02, 52.62it/s, est. speed input: 34323.59 toks/s, output: 33.52 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:57<00:02, 44.83it/s, est. speed input: 34277.93 toks/s, output: 33.47 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:58<00:02, 39.73it/s, est. speed input: 34233.24 toks/s, output: 33.43 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:58<00:02, 36.47it/s, est. speed input: 34193.34 toks/s, output: 33.39 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:59<00:01, 34.25it/s, est. speed input: 34154.09 toks/s, output: 33.35 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:00<00:01, 32.73it/s, est. speed input: 34116.14 toks/s, output: 33.32 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:00<00:00, 31.65it/s, est. speed input: 34077.86 toks/s, output: 33.28 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:01<00:00, 31.54it/s, est. speed input: 34060.59 toks/s, output: 33.26 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:01<00:00, 31.54it/s, est. speed input: 34294.81 toks/s, output: 33.49 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:01<00:00, 33.49it/s, est. speed input: 34294.81 toks/s, output: 33.49 toks/s]
[rank0]:[W126 01:53:11.748234338 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 124.0s

测试结果:
  Requests/s:   28.75
  Tokens/s:     29471.33
  Total Reqs:   2048
  Elapsed:      71.23s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     29442.58

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:53:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 01:53:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=31165) WARNING 01-26 01:53:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=31165) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=31165) WARNING 01-26 01:54:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.54 requests/s, 8753.07 total tokens/s, 8.54 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 01:53:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:53:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:53:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:53:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:53:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:53:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:53:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:53:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:53:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:53:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:53:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:53:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:53:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:53:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:53:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:53:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:53:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=31165) [2026-01-26 01:53:58] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=31165) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=31165) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.42it/s]
(EngineCore_DP0 pid=31165) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.14it/s]
(EngineCore_DP0 pid=31165) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.17it/s]
(EngineCore_DP0 pid=31165) 
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=31165) [2026-01-26 01:54:00] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=31165) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  7.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  8.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  8.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.64it/s]
(EngineCore_DP0 pid=31165) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.45it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.40it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  8.92it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.83it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 243.43it/s]
Adding requests:   1%|▏         | 52/4096 [00:00<00:15, 253.06it/s]
Adding requests:   2%|▏         | 80/4096 [00:00<00:15, 262.17it/s]
Adding requests:   3%|▎         | 108/4096 [00:00<00:15, 264.23it/s]
Adding requests:   3%|▎         | 135/4096 [00:00<00:15, 261.32it/s]
Adding requests:   4%|▍         | 162/4096 [00:00<00:15, 248.34it/s]
Adding requests:   5%|▍         | 191/4096 [00:00<00:15, 258.30it/s]
Adding requests:   5%|▌         | 217/4096 [00:00<00:15, 257.34it/s]
Adding requests:   6%|▌         | 243/4096 [00:00<00:15, 252.84it/s]
Adding requests:   7%|▋         | 270/4096 [00:01<00:14, 257.43it/s]
Adding requests:   7%|▋         | 296/4096 [00:01<00:15, 248.12it/s]
Adding requests:   8%|▊         | 324/4096 [00:01<00:14, 255.40it/s]
Adding requests:   9%|▊         | 351/4096 [00:01<00:14, 258.55it/s]
Adding requests:   9%|▉         | 377/4096 [00:01<00:14, 255.35it/s]
Adding requests:  10%|▉         | 405/4096 [00:01<00:14, 262.16it/s]
Adding requests:  11%|█         | 432/4096 [00:01<00:14, 250.69it/s]
Adding requests:  11%|█         | 458/4096 [00:01<00:14, 251.99it/s]
Adding requests:  12%|█▏        | 487/4096 [00:01<00:13, 260.73it/s]
Adding requests:  13%|█▎        | 514/4096 [00:02<00:14, 254.76it/s]
Adding requests:  13%|█▎        | 544/4096 [00:02<00:13, 267.00it/s]
Adding requests:  14%|█▍        | 571/4096 [00:02<00:13, 260.86it/s]
Adding requests:  15%|█▍        | 598/4096 [00:02<00:13, 260.48it/s]
Adding requests:  15%|█▌        | 625/4096 [00:02<00:13, 260.42it/s]
Adding requests:  16%|█▌        | 652/4096 [00:02<00:13, 249.19it/s]
Adding requests:  17%|█▋        | 681/4096 [00:02<00:13, 257.61it/s]
Adding requests:  17%|█▋        | 707/4096 [00:02<00:13, 251.26it/s]
Adding requests:  18%|█▊        | 733/4096 [00:02<00:13, 250.51it/s]
Adding requests:  19%|█▊        | 759/4096 [00:02<00:13, 251.58it/s]
Adding requests:  19%|█▉        | 785/4096 [00:03<00:13, 249.40it/s]
Adding requests:  20%|█▉        | 812/4096 [00:03<00:12, 254.33it/s]
Adding requests:  20%|██        | 838/4096 [00:03<00:13, 250.49it/s]
Adding requests:  21%|██        | 865/4096 [00:03<00:12, 254.53it/s]
Adding requests:  22%|██▏       | 893/4096 [00:03<00:12, 260.19it/s]
Adding requests:  22%|██▏       | 920/4096 [00:03<00:12, 246.90it/s]
Adding requests:  23%|██▎       | 947/4096 [00:03<00:12, 251.60it/s]
Adding requests:  24%|██▍       | 973/4096 [00:03<00:12, 247.83it/s]
Adding requests:  24%|██▍       | 998/4096 [00:03<00:12, 246.87it/s]
Adding requests:  25%|██▌       | 1024/4096 [00:04<00:12, 249.90it/s]
Adding requests:  26%|██▌       | 1050/4096 [00:04<00:12, 245.74it/s]
Adding requests:  26%|██▋       | 1077/4096 [00:04<00:12, 251.22it/s]
Adding requests:  27%|██▋       | 1103/4096 [00:04<00:12, 245.78it/s]
Adding requests:  28%|██▊       | 1130/4096 [00:04<00:11, 251.54it/s]
Adding requests:  28%|██▊       | 1156/4096 [00:04<00:11, 253.55it/s]
Adding requests:  29%|██▉       | 1182/4096 [00:04<00:11, 246.46it/s]
Adding requests:  29%|██▉       | 1207/4096 [00:04<00:11, 242.86it/s]
Adding requests:  30%|███       | 1232/4096 [00:04<00:11, 244.06it/s]
Adding requests:  31%|███       | 1257/4096 [00:04<00:11, 244.00it/s]
Adding requests:  31%|███▏      | 1283/4096 [00:05<00:11, 246.91it/s]
Adding requests:  32%|███▏      | 1308/4096 [00:05<00:11, 238.04it/s]
Adding requests:  33%|███▎      | 1336/4096 [00:05<00:11, 247.09it/s]
Adding requests:  33%|███▎      | 1364/4096 [00:05<00:10, 253.80it/s]
Adding requests:  34%|███▍      | 1390/4096 [00:05<00:10, 253.28it/s]
Adding requests:  35%|███▍      | 1416/4096 [00:05<00:10, 255.20it/s]
Adding requests:  35%|███▌      | 1442/4096 [00:05<00:10, 247.93it/s]
Adding requests:  36%|███▌      | 1470/4096 [00:05<00:10, 256.87it/s]
Adding requests:  37%|███▋      | 1498/4096 [00:05<00:09, 260.49it/s]
Adding requests:  37%|███▋      | 1525/4096 [00:06<00:10, 255.56it/s]
Adding requests:  38%|███▊      | 1553/4096 [00:06<00:09, 259.99it/s]
Adding requests:  39%|███▊      | 1580/4096 [00:06<00:10, 245.54it/s]
Adding requests:  39%|███▉      | 1607/4096 [00:06<00:09, 252.00it/s]
Adding requests:  40%|███▉      | 1633/4096 [00:06<00:09, 248.53it/s]
Adding requests:  40%|████      | 1658/4096 [00:06<00:10, 242.78it/s]
Adding requests:  41%|████      | 1686/4096 [00:06<00:09, 252.56it/s]
Adding requests:  42%|████▏     | 1712/4096 [00:06<00:09, 247.42it/s]
Adding requests:  42%|████▏     | 1739/4096 [00:06<00:09, 252.12it/s]
Adding requests:  43%|████▎     | 1768/4096 [00:06<00:08, 260.68it/s]
Adding requests:  44%|████▍     | 1795/4096 [00:07<00:09, 250.68it/s]
Adding requests:  45%|████▍     | 1823/4096 [00:07<00:08, 256.17it/s]
Adding requests:  45%|████▌     | 1849/4096 [00:07<00:09, 247.65it/s]
Adding requests:  46%|████▌     | 1876/4096 [00:07<00:08, 253.76it/s]
Adding requests:  46%|████▋     | 1902/4096 [00:07<00:08, 253.00it/s]
Adding requests:  47%|████▋     | 1929/4096 [00:07<00:08, 255.49it/s]
Adding requests:  48%|████▊     | 1958/4096 [00:07<00:08, 264.12it/s]
Adding requests:  48%|████▊     | 1985/4096 [00:07<00:08, 249.55it/s]
Adding requests:  49%|████▉     | 2011/4096 [00:07<00:08, 250.91it/s]
Adding requests:  50%|████▉     | 2037/4096 [00:08<00:08, 243.86it/s]
Adding requests:  50%|█████     | 2062/4096 [00:08<00:08, 238.13it/s]
Adding requests:  51%|█████     | 2087/4096 [00:08<00:08, 239.47it/s]
Adding requests:  52%|█████▏    | 2113/4096 [00:08<00:08, 241.78it/s]
Adding requests:  52%|█████▏    | 2140/4096 [00:08<00:07, 247.25it/s]
Adding requests:  53%|█████▎    | 2165/4096 [00:08<00:07, 247.97it/s]
Adding requests:  53%|█████▎    | 2190/4096 [00:08<00:07, 242.91it/s]
Adding requests:  54%|█████▍    | 2217/4096 [00:08<00:07, 250.40it/s]
Adding requests:  55%|█████▍    | 2243/4096 [00:08<00:07, 244.92it/s]
Adding requests:  55%|█████▌    | 2272/4096 [00:09<00:07, 257.43it/s]
Adding requests:  56%|█████▌    | 2301/4096 [00:09<00:06, 265.01it/s]
Adding requests:  57%|█████▋    | 2328/4096 [00:09<00:06, 255.29it/s]
Adding requests:  58%|█████▊    | 2356/4096 [00:09<00:06, 261.73it/s]
Adding requests:  58%|█████▊    | 2383/4096 [00:09<00:06, 257.23it/s]
Adding requests:  59%|█████▉    | 2410/4096 [00:09<00:06, 259.63it/s]
Adding requests:  60%|█████▉    | 2439/4096 [00:09<00:06, 265.05it/s]
Adding requests:  60%|██████    | 2466/4096 [00:09<00:06, 245.31it/s]
Adding requests:  61%|██████    | 2495/4096 [00:09<00:06, 257.07it/s]
Adding requests:  62%|██████▏   | 2522/4096 [00:09<00:06, 253.08it/s]
Adding requests:  62%|██████▏   | 2552/4096 [00:10<00:05, 265.82it/s]
Adding requests:  63%|██████▎   | 2582/4096 [00:10<00:05, 271.93it/s]
Adding requests:  64%|██████▎   | 2610/4096 [00:10<00:05, 263.85it/s]
Adding requests:  64%|██████▍   | 2637/4096 [00:10<00:05, 260.78it/s]
Adding requests:  65%|██████▌   | 2664/4096 [00:10<00:05, 252.42it/s]
Adding requests:  66%|██████▌   | 2691/4096 [00:10<00:05, 256.02it/s]
Adding requests:  66%|██████▋   | 2717/4096 [00:10<00:05, 255.63it/s]
Adding requests:  67%|██████▋   | 2743/4096 [00:10<00:05, 252.03it/s]
Adding requests:  68%|██████▊   | 2772/4096 [00:10<00:05, 262.79it/s]
Adding requests:  68%|██████▊   | 2799/4096 [00:11<00:05, 259.06it/s]
Adding requests:  69%|██████▉   | 2826/4096 [00:11<00:04, 259.56it/s]
Adding requests:  70%|██████▉   | 2854/4096 [00:11<00:04, 263.31it/s]
Adding requests:  70%|███████   | 2881/4096 [00:11<00:04, 251.65it/s]
Adding requests:  71%|███████   | 2908/4096 [00:11<00:04, 255.97it/s]
Adding requests:  72%|███████▏  | 2934/4096 [00:11<00:04, 251.98it/s]
Adding requests:  72%|███████▏  | 2962/4096 [00:11<00:04, 259.28it/s]
Adding requests:  73%|███████▎  | 2989/4096 [00:11<00:04, 260.93it/s]
Adding requests:  74%|███████▎  | 3016/4096 [00:11<00:04, 251.55it/s]
Adding requests:  74%|███████▍  | 3045/4096 [00:12<00:04, 262.48it/s]
Adding requests:  75%|███████▌  | 3073/4096 [00:12<00:03, 266.02it/s]
Adding requests:  76%|███████▌  | 3100/4096 [00:12<00:03, 262.93it/s]
Adding requests:  76%|███████▋  | 3129/4096 [00:12<00:03, 270.22it/s]
Adding requests:  77%|███████▋  | 3157/4096 [00:12<00:03, 258.29it/s]
Adding requests:  78%|███████▊  | 3184/4096 [00:12<00:03, 260.50it/s]
Adding requests:  78%|███████▊  | 3211/4096 [00:12<00:03, 254.47it/s]
Adding requests:  79%|███████▉  | 3238/4096 [00:12<00:03, 258.83it/s]
Adding requests:  80%|███████▉  | 3265/4096 [00:12<00:03, 260.47it/s]
Adding requests:  80%|████████  | 3292/4096 [00:12<00:03, 245.01it/s]
Adding requests:  81%|████████  | 3319/4096 [00:13<00:03, 250.99it/s]
Adding requests:  82%|████████▏ | 3345/4096 [00:13<00:02, 251.31it/s]
Adding requests:  82%|████████▏ | 3371/4096 [00:13<00:02, 253.36it/s]
Adding requests:  83%|████████▎ | 3399/4096 [00:13<00:02, 261.07it/s]
Adding requests:  84%|████████▎ | 3426/4096 [00:13<00:02, 248.55it/s]
Adding requests:  84%|████████▍ | 3454/4096 [00:13<00:02, 254.62it/s]
Adding requests:  85%|████████▍ | 3480/4096 [00:13<00:02, 256.06it/s]
Adding requests:  86%|████████▌ | 3506/4096 [00:13<00:02, 253.16it/s]
Adding requests:  86%|████████▋ | 3536/4096 [00:13<00:02, 265.05it/s]
Adding requests:  87%|████████▋ | 3563/4096 [00:14<00:02, 261.26it/s]
Adding requests:  88%|████████▊ | 3590/4096 [00:14<00:01, 257.17it/s]
Adding requests:  88%|████████▊ | 3617/4096 [00:14<00:01, 260.24it/s]
Adding requests:  89%|████████▉ | 3644/4096 [00:14<00:01, 256.03it/s]
Adding requests:  90%|████████▉ | 3670/4096 [00:14<00:01, 253.39it/s]
Adding requests:  90%|█████████ | 3696/4096 [00:14<00:01, 243.33it/s]
Adding requests:  91%|█████████ | 3724/4096 [00:14<00:01, 253.52it/s]
Adding requests:  92%|█████████▏| 3750/4096 [00:14<00:01, 250.20it/s]
Adding requests:  92%|█████████▏| 3776/4096 [00:14<00:01, 245.57it/s]
Adding requests:  93%|█████████▎| 3801/4096 [00:14<00:01, 246.44it/s]
Adding requests:  93%|█████████▎| 3826/4096 [00:15<00:01, 229.85it/s]
Adding requests:  94%|█████████▍| 3854/4096 [00:15<00:00, 242.11it/s]
Adding requests:  95%|█████████▍| 3881/4096 [00:15<00:00, 248.20it/s]
Adding requests:  95%|█████████▌| 3907/4096 [00:15<00:00, 245.51it/s]
Adding requests:  96%|█████████▌| 3934/4096 [00:15<00:00, 250.41it/s]
Adding requests:  97%|█████████▋| 3960/4096 [00:15<00:00, 243.24it/s]
Adding requests:  97%|█████████▋| 3986/4096 [00:15<00:00, 246.87it/s]
Adding requests:  98%|█████████▊| 4012/4096 [00:15<00:00, 250.47it/s]
Adding requests:  99%|█████████▊| 4038/4096 [00:15<00:00, 244.78it/s]
Adding requests:  99%|█████████▉| 4065/4096 [00:16<00:00, 250.79it/s]
Adding requests: 100%|█████████▉| 4091/4096 [00:16<00:00, 242.68it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 253.11it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:01<00:55, 71.49it/s, est. speed input: 73210.61 toks/s, output: 71.49 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:05<02:40, 24.50it/s, est. speed input: 29808.40 toks/s, output: 29.11 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:09<03:59, 16.27it/s, est. speed input: 21333.59 toks/s, output: 20.83 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:13<04:57, 12.99it/s, est. speed input: 17721.94 toks/s, output: 17.31 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:16<05:39, 11.31it/s, est. speed input: 15719.78 toks/s, output: 15.35 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:20<06:08, 10.34it/s, est. speed input: 14447.42 toks/s, output: 14.11 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:24<06:27,  9.74it/s, est. speed input: 13567.65 toks/s, output: 13.25 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:28<06:40,  9.35it/s, est. speed input: 12922.89 toks/s, output: 12.62 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:31<06:47,  9.09it/s, est. speed input: 12430.56 toks/s, output: 12.14 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:34<06:10,  9.94it/s, est. speed input: 12474.46 toks/s, output: 12.18 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:38<06:24,  9.48it/s, est. speed input: 12107.26 toks/s, output: 11.82 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [00:41<06:33,  9.18it/s, est. speed input: 11805.99 toks/s, output: 11.53 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [00:45<06:39,  8.98it/s, est. speed input: 11554.21 toks/s, output: 11.28 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:49<06:41,  8.84it/s, est. speed input: 11339.98 toks/s, output: 11.07 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [00:53<06:42,  8.74it/s, est. speed input: 11155.47 toks/s, output: 10.89 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [00:56<06:41,  8.68it/s, est. speed input: 10995.60 toks/s, output: 10.74 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:00<06:40,  8.63it/s, est. speed input: 10855.44 toks/s, output: 10.60 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:04<06:37,  8.60it/s, est. speed input: 10731.73 toks/s, output: 10.48 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:06<05:55,  9.54it/s, est. speed input: 10819.72 toks/s, output: 10.57 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:10<06:04,  9.21it/s, est. speed input: 10708.88 toks/s, output: 10.46 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [01:14<06:03,  9.15it/s, est. speed input: 10637.81 toks/s, output: 10.39 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [01:17<06:07,  8.95it/s, est. speed input: 10546.30 toks/s, output: 10.30 toks/s]
Processed prompts:  20%|██        | 834/4096 [01:21<06:09,  8.82it/s, est. speed input: 10463.09 toks/s, output: 10.22 toks/s]
Processed prompts:  21%|██        | 866/4096 [01:25<06:09,  8.73it/s, est. speed input: 10387.16 toks/s, output: 10.14 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [01:29<06:08,  8.67it/s, est. speed input: 10317.58 toks/s, output: 10.08 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [01:32<06:06,  8.63it/s, est. speed input: 10253.69 toks/s, output: 10.01 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [01:35<05:27,  9.56it/s, est. speed input: 10327.55 toks/s, output: 10.09 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [01:39<05:36,  9.22it/s, est. speed input: 10267.28 toks/s, output: 10.03 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [01:42<05:40,  9.00it/s, est. speed input: 10211.43 toks/s, output: 9.97 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [01:46<05:42,  8.86it/s, est. speed input: 10159.58 toks/s, output: 9.92 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [01:50<05:43,  8.76it/s, est. speed input: 10111.23 toks/s, output: 9.87 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [01:54<05:42,  8.69it/s, est. speed input: 10066.14 toks/s, output: 9.83 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [01:57<05:40,  8.64it/s, est. speed input: 10023.89 toks/s, output: 9.79 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [02:01<05:38,  8.61it/s, est. speed input: 9984.13 toks/s, output: 9.75 toks/s] 
Processed prompts:  30%|██▉       | 1218/4096 [02:05<05:35,  8.58it/s, est. speed input: 9946.80 toks/s, output: 9.71 toks/s]
Processed prompts:  31%|███       | 1250/4096 [02:07<04:59,  9.52it/s, est. speed input: 10007.76 toks/s, output: 9.77 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [02:11<05:05,  9.20it/s, est. speed input: 9971.46 toks/s, output: 9.74 toks/s] 
Processed prompts:  32%|███▏      | 1314/4096 [02:15<05:09,  8.99it/s, est. speed input: 9937.20 toks/s, output: 9.70 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [02:19<05:10,  8.85it/s, est. speed input: 9904.87 toks/s, output: 9.67 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [02:22<05:10,  8.75it/s, est. speed input: 9874.20 toks/s, output: 9.64 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [02:26<05:09,  8.69it/s, est. speed input: 9845.70 toks/s, output: 9.61 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [02:30<05:06,  8.65it/s, est. speed input: 9818.62 toks/s, output: 9.59 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [02:34<05:04,  8.60it/s, est. speed input: 9791.58 toks/s, output: 9.56 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [02:37<05:02,  8.57it/s, est. speed input: 9765.72 toks/s, output: 9.54 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [02:40<04:28,  9.51it/s, est. speed input: 9817.58 toks/s, output: 9.59 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [02:44<04:34,  9.20it/s, est. speed input: 9792.87 toks/s, output: 9.56 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [02:47<04:32,  9.14it/s, est. speed input: 9780.65 toks/s, output: 9.55 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [02:51<04:35,  8.93it/s, est. speed input: 9756.40 toks/s, output: 9.53 toks/s]
Processed prompts:  41%|████      | 1666/4096 [02:55<04:36,  8.79it/s, est. speed input: 9733.24 toks/s, output: 9.51 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [02:59<04:35,  8.69it/s, est. speed input: 9710.95 toks/s, output: 9.48 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [03:02<04:34,  8.62it/s, est. speed input: 9689.60 toks/s, output: 9.46 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [03:06<04:31,  8.60it/s, est. speed input: 9670.41 toks/s, output: 9.44 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [03:08<03:59,  9.61it/s, est. speed input: 9720.58 toks/s, output: 9.49 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [03:12<04:04,  9.27it/s, est. speed input: 9701.94 toks/s, output: 9.47 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [03:16<04:07,  9.05it/s, est. speed input: 9684.50 toks/s, output: 9.46 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [03:20<04:08,  8.89it/s, est. speed input: 9666.78 toks/s, output: 9.44 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [03:23<04:08,  8.75it/s, est. speed input: 9648.00 toks/s, output: 9.42 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [03:27<04:07,  8.66it/s, est. speed input: 9630.05 toks/s, output: 9.40 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [03:31<04:05,  8.61it/s, est. speed input: 9613.08 toks/s, output: 9.39 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [03:35<04:02,  8.57it/s, est. speed input: 9596.85 toks/s, output: 9.37 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [03:39<03:59,  8.56it/s, est. speed input: 9582.16 toks/s, output: 9.36 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [03:41<03:30,  9.56it/s, est. speed input: 9624.89 toks/s, output: 9.40 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [03:45<03:34,  9.23it/s, est. speed input: 9610.21 toks/s, output: 9.38 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [03:49<03:36,  9.01it/s, est. speed input: 9595.88 toks/s, output: 9.37 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [03:52<03:32,  9.01it/s, est. speed input: 9590.35 toks/s, output: 9.37 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [03:56<03:32,  8.86it/s, est. speed input: 9576.79 toks/s, output: 9.35 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [04:00<03:31,  8.76it/s, est. speed input: 9563.67 toks/s, output: 9.34 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [04:03<03:29,  8.69it/s, est. speed input: 9550.94 toks/s, output: 9.33 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [04:07<03:27,  8.64it/s, est. speed input: 9538.60 toks/s, output: 9.32 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [04:11<03:24,  8.61it/s, est. speed input: 9526.62 toks/s, output: 9.30 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [04:13<03:01,  9.53it/s, est. speed input: 9561.36 toks/s, output: 9.34 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [04:17<03:03,  9.21it/s, est. speed input: 9549.34 toks/s, output: 9.33 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [04:21<03:04,  9.00it/s, est. speed input: 9537.68 toks/s, output: 9.31 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [04:25<03:04,  8.85it/s, est. speed input: 9526.33 toks/s, output: 9.30 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [04:28<03:02,  8.75it/s, est. speed input: 9515.25 toks/s, output: 9.29 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [04:32<03:00,  8.68it/s, est. speed input: 9504.51 toks/s, output: 9.28 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [04:36<02:57,  8.64it/s, est. speed input: 9494.06 toks/s, output: 9.27 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [04:40<02:54,  8.60it/s, est. speed input: 9483.86 toks/s, output: 9.26 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [04:42<02:34,  9.54it/s, est. speed input: 9515.69 toks/s, output: 9.29 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [04:46<02:36,  9.21it/s, est. speed input: 9505.48 toks/s, output: 9.28 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [04:50<02:36,  9.00it/s, est. speed input: 9495.50 toks/s, output: 9.27 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [04:53<02:35,  8.85it/s, est. speed input: 9485.80 toks/s, output: 9.26 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [04:57<02:33,  8.75it/s, est. speed input: 9476.31 toks/s, output: 9.25 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [05:01<02:30,  8.68it/s, est. speed input: 9467.03 toks/s, output: 9.25 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [05:05<02:27,  8.64it/s, est. speed input: 9457.99 toks/s, output: 9.24 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [05:08<02:24,  8.60it/s, est. speed input: 9449.17 toks/s, output: 9.23 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [05:12<02:21,  8.58it/s, est. speed input: 9440.56 toks/s, output: 9.22 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [05:15<02:04,  9.52it/s, est. speed input: 9469.75 toks/s, output: 9.25 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [05:18<02:04,  9.20it/s, est. speed input: 9461.08 toks/s, output: 9.24 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [05:22<02:04,  8.99it/s, est. speed input: 9452.63 toks/s, output: 9.23 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [05:26<02:02,  8.85it/s, est. speed input: 9444.36 toks/s, output: 9.22 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [05:30<02:00,  8.75it/s, est. speed input: 9436.24 toks/s, output: 9.22 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [05:33<01:57,  8.68it/s, est. speed input: 9428.30 toks/s, output: 9.21 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [05:37<01:54,  8.63it/s, est. speed input: 9420.53 toks/s, output: 9.20 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [05:41<01:51,  8.60it/s, est. speed input: 9412.94 toks/s, output: 9.19 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [05:45<01:47,  8.58it/s, est. speed input: 9405.54 toks/s, output: 9.19 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [05:47<01:33,  9.52it/s, est. speed input: 9432.25 toks/s, output: 9.21 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [05:51<01:33,  9.20it/s, est. speed input: 9424.80 toks/s, output: 9.20 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [05:55<01:32,  8.99it/s, est. speed input: 9417.49 toks/s, output: 9.20 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [05:58<01:30,  8.85it/s, est. speed input: 9410.34 toks/s, output: 9.19 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [06:02<01:27,  8.75it/s, est. speed input: 9403.33 toks/s, output: 9.18 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [06:06<01:24,  8.68it/s, est. speed input: 9396.49 toks/s, output: 9.18 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [06:10<01:21,  8.63it/s, est. speed input: 9389.72 toks/s, output: 9.17 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [06:13<01:17,  8.60it/s, est. speed input: 9383.09 toks/s, output: 9.16 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [06:16<01:06,  9.54it/s, est. speed input: 9407.87 toks/s, output: 9.19 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [06:20<01:05,  9.21it/s, est. speed input: 9401.22 toks/s, output: 9.18 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [06:23<01:03,  9.00it/s, est. speed input: 9394.70 toks/s, output: 9.17 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [06:27<01:01,  8.85it/s, est. speed input: 9388.32 toks/s, output: 9.17 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [06:31<00:58,  8.75it/s, est. speed input: 9382.08 toks/s, output: 9.16 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [06:35<00:55,  8.69it/s, est. speed input: 9375.97 toks/s, output: 9.16 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [06:38<00:51,  8.64it/s, est. speed input: 9369.96 toks/s, output: 9.15 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [06:42<00:47,  8.75it/s, est. speed input: 9368.66 toks/s, output: 9.15 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [06:46<00:44,  8.68it/s, est. speed input: 9362.71 toks/s, output: 9.14 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [06:48<00:36,  9.61it/s, est. speed input: 9385.68 toks/s, output: 9.17 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [06:52<00:34,  9.25it/s, est. speed input: 9379.64 toks/s, output: 9.16 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [06:56<00:31,  9.02it/s, est. speed input: 9373.73 toks/s, output: 9.15 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [06:59<00:28,  8.87it/s, est. speed input: 9367.98 toks/s, output: 9.15 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [07:03<00:25,  8.76it/s, est. speed input: 9362.32 toks/s, output: 9.14 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [07:07<00:21,  8.84it/s, est. speed input: 9361.50 toks/s, output: 9.14 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [07:10<00:18,  8.76it/s, est. speed input: 9356.33 toks/s, output: 9.14 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [07:14<00:14,  8.67it/s, est. speed input: 9350.36 toks/s, output: 9.13 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [07:18<00:10,  8.60it/s, est. speed input: 9344.31 toks/s, output: 9.13 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [07:21<00:06,  9.58it/s, est. speed input: 9366.72 toks/s, output: 9.15 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [07:24<00:03,  9.42it/s, est. speed input: 9365.89 toks/s, output: 9.15 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [07:24<00:00,  9.42it/s, est. speed input: 9434.98 toks/s, output: 9.21 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [07:24<00:00,  9.21it/s, est. speed input: 9434.98 toks/s, output: 9.21 toks/s]
[rank0]:[W126 02:02:03.195720019 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 532.3s

测试结果:
  Requests/s:   8.54
  Tokens/s:     8753.07
  Total Reqs:   4096
  Elapsed:      479.65s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     8744.53

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:03:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:03:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=39355) WARNING 01-26 02:03:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=39355) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=39355) WARNING 01-26 02:03:37 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     def forward(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     raise e
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/tmp/torchinductor_root/kp/ckpniwar6bwhyukpv5i62ryj47uysbdhjhadgl4x6iqsrkxzxjji.py", line 1093, in call
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 4)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) ERROR 01-26 02:03:44 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-26 02:03:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:03:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:03:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:03:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:03:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:03:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:03:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:03:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:03:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:03:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:03:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:03:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 02:03:26.789094858 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=39355) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=39355) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.28it/s]
(EngineCore_DP0 pid=39355) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.12it/s]
(EngineCore_DP0 pid=39355) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.14it/s]
(EngineCore_DP0 pid=39355) 
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=39355) [2026-01-26 02:03:29] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=39355) Process EngineCore_DP0:
(EngineCore_DP0 pid=39355) Traceback (most recent call last):
(EngineCore_DP0 pid=39355)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=39355)     self.run()
(EngineCore_DP0 pid=39355)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=39355)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=39355)     raise e
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=39355)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=39355)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=39355)     super().__init__(
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=39355)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=39355)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=39355)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=39355)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=39355)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=39355)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=39355)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=39355)     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=39355)     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=39355)     self.model_runner.profile_run()
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=39355)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=39355)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=39355)     return func(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=39355)     outputs = self.model(
(EngineCore_DP0 pid=39355)               ^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=39355)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=39355)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=39355)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=39355)     hidden_states = self.model(
(EngineCore_DP0 pid=39355)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=39355)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=39355)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=39355)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=39355)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=39355)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=39355)     def forward(
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=39355)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=39355)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=39355)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=39355)     raise e
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=39355)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=39355)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=39355)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=39355)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=39355)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=39355)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=39355)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=39355)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=39355)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=39355)     return compiled_fn(full_args)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=39355)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=39355)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=39355)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=39355)                             ^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=39355)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=39355)     return self.current_callable(inputs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=39355)     out = model(new_inputs)
(EngineCore_DP0 pid=39355)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/tmp/torchinductor_root/kp/ckpniwar6bwhyukpv5i62ryj47uysbdhjhadgl4x6iqsrkxzxjji.py", line 1093, in call
(EngineCore_DP0 pid=39355)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 4)
(EngineCore_DP0 pid=39355)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=39355)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=39355)     return fn(input, L)
(EngineCore_DP0 pid=39355)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=39355)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=39355)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=39355)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=39355)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=39355)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=39355)     self._init_handles()
(EngineCore_DP0 pid=39355)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=39355)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=39355)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=39355) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 02:03:45.394962712 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,17.1163,8780.6649,7.4782
1024,1024,1,128,128,17.0753,17502.1961,7.4962
2048,1024,2,256,128,26.8874,27559.6092,9.5212
4096,1024,4,512,128,28.6815,29398.5067,17.8512
8192,1024,8,1024,128,28.6951,29412.4766,35.6855
16384,1024,16,2048,128,28.7525,29471.3339,71.2285
32768,1024,32,4096,128,8.5396,8753.0656,479.6491
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:03:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:03:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=40203) WARNING 01-26 02:04:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=40203) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=40203) WARNING 01-26 02:04:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.15 requests/s, 8800.03 total tokens/s, 17.15 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:03:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:03:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:03:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:03:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:03:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:03:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:03:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:03:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:04:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:04:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:04:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:04:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:04:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:04:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:04:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:04:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=40203) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=40203) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:03<00:03,  3.98s/it]
(EngineCore_DP0 pid=40203) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.80s/it]
(EngineCore_DP0 pid=40203) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:09<00:00,  4.68s/it]
(EngineCore_DP0 pid=40203) 
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:15] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=40203) [2026-01-26 02:04:15] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=40203) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  7.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.07it/s]
(EngineCore_DP0 pid=40203) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  36%|███▌      | 46/128 [00:00<00:00, 453.90it/s]
Adding requests:  73%|███████▎  | 94/128 [00:00<00:00, 464.73it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 472.38it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:03, 38.32it/s, est. speed input: 19623.64 toks/s, output: 38.32 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:04, 24.12it/s, est. speed input: 13234.59 toks/s, output: 25.85 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 21.21it/s, est. speed input: 11862.97 toks/s, output: 23.17 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:05, 19.67it/s, est. speed input: 11128.21 toks/s, output: 21.73 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:05, 18.77it/s, est. speed input: 10674.02 toks/s, output: 20.85 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:05, 18.29it/s, est. speed input: 10439.00 toks/s, output: 20.39 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 18.00it/s, est. speed input: 10271.94 toks/s, output: 20.06 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 17.88it/s, est. speed input: 10155.80 toks/s, output: 19.84 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 17.78it/s, est. speed input: 10056.72 toks/s, output: 19.64 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 17.70it/s, est. speed input: 9973.55 toks/s, output: 19.48 toks/s] 
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 17.63it/s, est. speed input: 9899.53 toks/s, output: 19.33 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 17.60it/s, est. speed input: 9838.40 toks/s, output: 19.22 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 17.54it/s, est. speed input: 9780.01 toks/s, output: 19.10 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:05, 17.54it/s, est. speed input: 9733.06 toks/s, output: 19.01 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 17.44it/s, est. speed input: 9680.78 toks/s, output: 18.91 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 17.33it/s, est. speed input: 9631.01 toks/s, output: 18.81 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 17.28it/s, est. speed input: 9587.64 toks/s, output: 18.73 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 17.33it/s, est. speed input: 9556.97 toks/s, output: 18.67 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 17.38it/s, est. speed input: 9529.99 toks/s, output: 18.61 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 17.31it/s, est. speed input: 9496.53 toks/s, output: 18.55 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 17.34it/s, est. speed input: 9472.53 toks/s, output: 18.50 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:04, 17.43it/s, est. speed input: 9455.32 toks/s, output: 18.47 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:04, 17.53it/s, est. speed input: 9441.94 toks/s, output: 18.44 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 17.50it/s, est. speed input: 9422.89 toks/s, output: 18.40 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:03, 17.47it/s, est. speed input: 9404.04 toks/s, output: 18.37 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 17.45it/s, est. speed input: 9387.00 toks/s, output: 18.33 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 17.40it/s, est. speed input: 9369.10 toks/s, output: 18.30 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 17.42it/s, est. speed input: 9355.56 toks/s, output: 18.27 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 17.44it/s, est. speed input: 9342.95 toks/s, output: 18.25 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:03, 17.41it/s, est. speed input: 9328.64 toks/s, output: 18.22 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:03, 17.41it/s, est. speed input: 9316.72 toks/s, output: 18.20 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 17.39it/s, est. speed input: 9304.04 toks/s, output: 18.17 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 17.33it/s, est. speed input: 9289.96 toks/s, output: 18.14 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:02, 17.33it/s, est. speed input: 9278.57 toks/s, output: 18.12 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 17.26it/s, est. speed input: 9264.41 toks/s, output: 18.09 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 17.31it/s, est. speed input: 9255.59 toks/s, output: 18.08 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 17.32it/s, est. speed input: 9246.37 toks/s, output: 18.06 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 17.27it/s, est. speed input: 9234.90 toks/s, output: 18.04 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 17.32it/s, est. speed input: 9227.52 toks/s, output: 18.02 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:02, 17.34it/s, est. speed input: 9219.79 toks/s, output: 18.01 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 17.39it/s, est. speed input: 9214.17 toks/s, output: 18.00 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 17.50it/s, est. speed input: 9211.42 toks/s, output: 17.99 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.41it/s, est. speed input: 9202.49 toks/s, output: 17.97 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.42it/s, est. speed input: 9196.63 toks/s, output: 17.96 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 17.35it/s, est. speed input: 9188.34 toks/s, output: 17.95 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 17.38it/s, est. speed input: 9183.21 toks/s, output: 17.94 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 17.37it/s, est. speed input: 9177.01 toks/s, output: 17.92 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 17.40it/s, est. speed input: 9172.66 toks/s, output: 17.92 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 17.42it/s, est. speed input: 9168.10 toks/s, output: 17.91 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 17.46it/s, est. speed input: 9164.84 toks/s, output: 17.90 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:00, 17.44it/s, est. speed input: 9160.06 toks/s, output: 17.89 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.31it/s, est. speed input: 9151.61 toks/s, output: 17.87 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.24it/s, est. speed input: 9144.19 toks/s, output: 17.86 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 17.28it/s, est. speed input: 9139.95 toks/s, output: 17.85 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 17.30it/s, est. speed input: 9135.54 toks/s, output: 17.84 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 17.26it/s, est. speed input: 9129.59 toks/s, output: 17.83 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 17.27it/s, est. speed input: 9125.03 toks/s, output: 17.82 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 17.30it/s, est. speed input: 9121.05 toks/s, output: 17.81 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:07<00:00, 17.32it/s, est. speed input: 9117.41 toks/s, output: 17.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.32it/s, est. speed input: 9115.94 toks/s, output: 17.80 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.80it/s, est. speed input: 9115.94 toks/s, output: 17.80 toks/s]
[rank0]:[W126 02:04:41.408011098 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 55.6s

测试结果:
  Requests/s:   17.15
  Tokens/s:     8800.03
  Total Reqs:   128
  Elapsed:      7.46s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     8782.87

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:04:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:04:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=41235) WARNING 01-26 02:05:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=41235) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=41235) WARNING 01-26 02:05:12 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.31 requests/s, 17740.05 total tokens/s, 17.31 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:04:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:04:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:04:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:04:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:04:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:04:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:04:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:04:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:04:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:05:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:05:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:05:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:05:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:05:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:05:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=41235) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=41235) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.21it/s]
(EngineCore_DP0 pid=41235) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.16s/it]
(EngineCore_DP0 pid=41235) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]
(EngineCore_DP0 pid=41235) 
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=41235) [2026-01-26 02:05:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=41235) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.56it/s]
(EngineCore_DP0 pid=41235) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|█▉        | 25/128 [00:00<00:00, 244.46it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 252.36it/s]
Adding requests:  62%|██████▎   | 80/128 [00:00<00:00, 261.49it/s]
Adding requests:  84%|████████▎ | 107/128 [00:00<00:00, 264.33it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 260.35it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:02, 55.97it/s, est. speed input: 57321.26 toks/s, output: 55.97 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:04, 26.31it/s, est. speed input: 29635.56 toks/s, output: 28.94 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:04, 22.73it/s, est. speed input: 26019.74 toks/s, output: 25.41 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:05, 21.19it/s, est. speed input: 24520.61 toks/s, output: 23.95 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 20.18it/s, est. speed input: 23527.79 toks/s, output: 22.98 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 19.41it/s, est. speed input: 22768.49 toks/s, output: 22.23 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 19.04it/s, est. speed input: 22380.14 toks/s, output: 21.86 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 18.71it/s, est. speed input: 22043.41 toks/s, output: 21.53 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 18.45it/s, est. speed input: 21758.11 toks/s, output: 21.25 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 18.25it/s, est. speed input: 21513.11 toks/s, output: 21.01 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:05, 18.11it/s, est. speed input: 21301.83 toks/s, output: 20.80 toks/s]
Processed prompts:  30%|███       | 39/128 [00:01<00:04, 18.07it/s, est. speed input: 21130.85 toks/s, output: 20.64 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:04, 18.01it/s, est. speed input: 20972.57 toks/s, output: 20.48 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 18.02it/s, est. speed input: 20841.23 toks/s, output: 20.35 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 18.02it/s, est. speed input: 20721.32 toks/s, output: 20.24 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 17.90it/s, est. speed input: 20590.90 toks/s, output: 20.11 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 17.84it/s, est. speed input: 20477.31 toks/s, output: 20.00 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 17.70it/s, est. speed input: 20358.01 toks/s, output: 19.88 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:04, 17.66it/s, est. speed input: 20257.21 toks/s, output: 19.78 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:04, 17.76it/s, est. speed input: 20184.63 toks/s, output: 19.71 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:02<00:03, 17.78it/s, est. speed input: 20110.23 toks/s, output: 19.64 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:03, 17.79it/s, est. speed input: 20039.65 toks/s, output: 19.57 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 17.80it/s, est. speed input: 19975.66 toks/s, output: 19.51 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 17.71it/s, est. speed input: 19903.80 toks/s, output: 19.44 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 17.73it/s, est. speed input: 19846.90 toks/s, output: 19.38 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 17.77it/s, est. speed input: 19796.54 toks/s, output: 19.33 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:03, 17.78it/s, est. speed input: 19746.74 toks/s, output: 19.28 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:03, 17.72it/s, est. speed input: 19693.33 toks/s, output: 19.23 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:03<00:03, 17.77it/s, est. speed input: 19652.54 toks/s, output: 19.19 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:02, 17.80it/s, est. speed input: 19614.11 toks/s, output: 19.15 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:02, 17.81it/s, est. speed input: 19576.43 toks/s, output: 19.12 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 17.83it/s, est. speed input: 19542.02 toks/s, output: 19.08 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 17.73it/s, est. speed input: 19498.14 toks/s, output: 19.04 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 17.75it/s, est. speed input: 19465.47 toks/s, output: 19.01 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 17.78it/s, est. speed input: 19435.42 toks/s, output: 18.98 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 17.81it/s, est. speed input: 19408.62 toks/s, output: 18.95 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:02, 17.72it/s, est. speed input: 19372.77 toks/s, output: 18.92 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:02, 17.71it/s, est. speed input: 19343.42 toks/s, output: 18.89 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 17.83it/s, est. speed input: 19325.86 toks/s, output: 18.87 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.86it/s, est. speed input: 19303.77 toks/s, output: 18.85 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.92it/s, est. speed input: 19286.62 toks/s, output: 18.83 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 17.83it/s, est. speed input: 19260.23 toks/s, output: 18.81 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 17.73it/s, est. speed input: 19231.86 toks/s, output: 18.78 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 17.67it/s, est. speed input: 19205.21 toks/s, output: 18.76 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 17.66it/s, est. speed input: 19182.22 toks/s, output: 18.73 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 17.61it/s, est. speed input: 19156.84 toks/s, output: 18.71 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:01, 17.45it/s, est. speed input: 19123.40 toks/s, output: 18.68 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:00, 17.60it/s, est. speed input: 19109.91 toks/s, output: 18.66 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.57it/s, est. speed input: 19087.15 toks/s, output: 18.64 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.69it/s, est. speed input: 19074.99 toks/s, output: 18.63 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 17.76it/s, est. speed input: 19062.49 toks/s, output: 18.62 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 17.79it/s, est. speed input: 19048.87 toks/s, output: 18.60 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 17.87it/s, est. speed input: 19039.08 toks/s, output: 18.59 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 17.88it/s, est. speed input: 19027.59 toks/s, output: 18.58 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 17.80it/s, est. speed input: 19010.80 toks/s, output: 18.57 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 17.77it/s, est. speed input: 18995.99 toks/s, output: 18.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 17.77it/s, est. speed input: 18989.61 toks/s, output: 18.54 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.54it/s, est. speed input: 18989.61 toks/s, output: 18.54 toks/s]
[rank0]:[W126 02:05:31.616812399 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 50.0s

测试结果:
  Requests/s:   17.31
  Tokens/s:     17740.05
  Total Reqs:   128
  Elapsed:      7.40s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     17722.75

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:05:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:05:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=42160) WARNING 01-26 02:05:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=42160) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=42160) WARNING 01-26 02:06:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.35 requests/s, 23931.29 total tokens/s, 23.35 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 02:05:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:05:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:05:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:05:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:05:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:05:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:05:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:05:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:05:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:05:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:05:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:05:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:05:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:05:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=42160) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=42160) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.18it/s]
(EngineCore_DP0 pid=42160) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.08s/it]
(EngineCore_DP0 pid=42160) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.05s/it]
(EngineCore_DP0 pid=42160) 
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=42160) [2026-01-26 02:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=42160) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.19it/s]
(EngineCore_DP0 pid=42160) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.36it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.28it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 245.64it/s]
Adding requests:  20%|██        | 52/256 [00:00<00:00, 256.87it/s]
Adding requests:  31%|███▏      | 80/256 [00:00<00:00, 266.49it/s]
Adding requests:  42%|████▏     | 107/256 [00:00<00:00, 266.98it/s]
Adding requests:  52%|█████▏    | 134/256 [00:00<00:00, 260.15it/s]
Adding requests:  63%|██████▎   | 161/256 [00:00<00:00, 259.38it/s]
Adding requests:  73%|███████▎  | 188/256 [00:00<00:00, 262.22it/s]
Adding requests:  84%|████████▍ | 216/256 [00:00<00:00, 264.63it/s]
Adding requests:  95%|█████████▍| 243/256 [00:00<00:00, 262.32it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 261.12it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 183.03it/s, est. speed input: 187476.61 toks/s, output: 183.05 toks/s]
Processed prompts:  15%|█▌        | 39/256 [00:00<00:05, 39.66it/s, est. speed input: 46173.21 toks/s, output: 45.09 toks/s]   
Processed prompts:  19%|█▉        | 49/256 [00:01<00:06, 33.02it/s, est. speed input: 39054.69 toks/s, output: 38.14 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:01<00:06, 30.60it/s, est. speed input: 36657.66 toks/s, output: 35.80 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:01<00:07, 27.63it/s, est. speed input: 34341.14 toks/s, output: 33.54 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:01<00:07, 26.82it/s, est. speed input: 33479.09 toks/s, output: 32.69 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:07, 26.14it/s, est. speed input: 32760.44 toks/s, output: 31.99 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:07, 25.56it/s, est. speed input: 32144.93 toks/s, output: 31.39 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:02<00:07, 25.11it/s, est. speed input: 31616.00 toks/s, output: 30.87 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:02<00:07, 24.74it/s, est. speed input: 31147.99 toks/s, output: 30.42 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:02<00:07, 24.43it/s, est. speed input: 30729.03 toks/s, output: 30.01 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:02<00:06, 24.22it/s, est. speed input: 30359.92 toks/s, output: 29.65 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:06, 24.08it/s, est. speed input: 30034.56 toks/s, output: 29.33 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:03<00:06, 24.01it/s, est. speed input: 29750.04 toks/s, output: 29.05 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:03<00:06, 23.94it/s, est. speed input: 29487.91 toks/s, output: 28.80 toks/s]
Processed prompts:  41%|████      | 104/256 [00:03<00:06, 23.93it/s, est. speed input: 29258.03 toks/s, output: 28.57 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:03<00:06, 23.91it/s, est. speed input: 29046.20 toks/s, output: 28.37 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:03<00:06, 23.86it/s, est. speed input: 28844.90 toks/s, output: 28.17 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:04<00:05, 23.87it/s, est. speed input: 28668.21 toks/s, output: 28.00 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:04<00:05, 23.86it/s, est. speed input: 28503.15 toks/s, output: 27.83 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:04<00:05, 23.85it/s, est. speed input: 28348.02 toks/s, output: 27.68 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:04<00:05, 23.82it/s, est. speed input: 28202.44 toks/s, output: 27.54 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:04<00:05, 23.84it/s, est. speed input: 28072.60 toks/s, output: 27.41 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:04<00:05, 23.82it/s, est. speed input: 27946.60 toks/s, output: 27.29 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:05<00:04, 23.77it/s, est. speed input: 27824.88 toks/s, output: 27.17 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:05<00:04, 23.80it/s, est. speed input: 27717.48 toks/s, output: 27.07 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:05<00:04, 23.82it/s, est. speed input: 27617.34 toks/s, output: 26.97 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:05<00:04, 23.83it/s, est. speed input: 27523.45 toks/s, output: 26.88 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:05<00:04, 23.79it/s, est. speed input: 27429.09 toks/s, output: 26.79 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:05<00:04, 23.75it/s, est. speed input: 27338.65 toks/s, output: 26.70 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:06<00:03, 23.74it/s, est. speed input: 27254.97 toks/s, output: 26.62 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:06<00:03, 23.73it/s, est. speed input: 27175.80 toks/s, output: 26.54 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:06<00:03, 23.76it/s, est. speed input: 27103.84 toks/s, output: 26.47 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:06<00:03, 23.77it/s, est. speed input: 27034.41 toks/s, output: 26.40 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:06<00:03, 23.80it/s, est. speed input: 26971.50 toks/s, output: 26.34 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:07<00:03, 23.82it/s, est. speed input: 26911.00 toks/s, output: 26.28 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:07<00:02, 23.83it/s, est. speed input: 26852.24 toks/s, output: 26.22 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:07<00:02, 23.83it/s, est. speed input: 26796.32 toks/s, output: 26.17 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:07<00:02, 23.80it/s, est. speed input: 26739.99 toks/s, output: 26.11 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:07<00:02, 23.79it/s, est. speed input: 26687.48 toks/s, output: 26.06 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:07<00:02, 24.75it/s, est. speed input: 26711.80 toks/s, output: 26.09 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:07<00:01, 24.45it/s, est. speed input: 26662.07 toks/s, output: 26.04 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:08<00:01, 24.28it/s, est. speed input: 26617.11 toks/s, output: 25.99 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:08<00:01, 24.12it/s, est. speed input: 26570.76 toks/s, output: 25.95 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:08<00:01, 24.03it/s, est. speed input: 26527.86 toks/s, output: 25.91 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:08<00:01, 23.93it/s, est. speed input: 26483.98 toks/s, output: 25.86 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:08<00:01, 23.91it/s, est. speed input: 26444.97 toks/s, output: 25.83 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:08<00:01, 23.87it/s, est. speed input: 26405.46 toks/s, output: 25.79 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:09<00:00, 23.83it/s, est. speed input: 26366.74 toks/s, output: 25.75 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:09<00:00, 23.74it/s, est. speed input: 26325.69 toks/s, output: 25.71 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:09<00:00, 23.76it/s, est. speed input: 26291.05 toks/s, output: 25.67 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:09<00:00, 23.78it/s, est. speed input: 26258.54 toks/s, output: 25.64 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:09<00:00, 23.79it/s, est. speed input: 26226.13 toks/s, output: 25.61 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 24.90it/s, est. speed input: 26260.30 toks/s, output: 25.64 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 24.90it/s, est. speed input: 26260.30 toks/s, output: 25.64 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:09<00:00, 25.64it/s, est. speed input: 26260.30 toks/s, output: 25.64 toks/s]
[rank0]:[W126 02:06:25.416678458 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 53.2s

测试结果:
  Requests/s:   23.35
  Tokens/s:     23931.29
  Total Reqs:   256
  Elapsed:      10.96s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     23907.94

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:06:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:06:38 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=43145) WARNING 01-26 02:06:46 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=43145) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=43145) WARNING 01-26 02:06:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.42 requests/s, 25032.74 total tokens/s, 24.42 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 02:06:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:06:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:06:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:06:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:06:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:06:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:06:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:06:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:06:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:06:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:06:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:06:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:06:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:06:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:06:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:06:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:06:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=43145) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=43145) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.15it/s]
(EngineCore_DP0 pid=43145) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.10s/it]
(EngineCore_DP0 pid=43145) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07s/it]
(EngineCore_DP0 pid=43145) 
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=43145) [2026-01-26 02:06:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=43145) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.50it/s]
(EngineCore_DP0 pid=43145) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.40it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.62it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 236.01it/s]
Adding requests:  10%|▉         | 50/512 [00:00<00:01, 247.89it/s]
Adding requests:  15%|█▌        | 77/512 [00:00<00:01, 256.14it/s]
Adding requests:  20%|██        | 103/512 [00:00<00:01, 256.75it/s]
Adding requests:  25%|██▌       | 130/512 [00:00<00:01, 259.69it/s]
Adding requests:  31%|███       | 158/512 [00:00<00:01, 264.80it/s]
Adding requests:  37%|███▋      | 187/512 [00:00<00:01, 270.81it/s]
Adding requests:  42%|████▏     | 215/512 [00:00<00:01, 265.88it/s]
Adding requests:  47%|████▋     | 242/512 [00:00<00:01, 264.53it/s]
Adding requests:  53%|█████▎    | 269/512 [00:01<00:00, 266.12it/s]
Adding requests:  58%|█████▊    | 296/512 [00:01<00:00, 266.89it/s]
Adding requests:  63%|██████▎   | 324/512 [00:01<00:00, 268.94it/s]
Adding requests:  69%|██████▉   | 353/512 [00:01<00:00, 273.18it/s]
Adding requests:  74%|███████▍  | 381/512 [00:01<00:00, 271.73it/s]
Adding requests:  80%|████████  | 410/512 [00:01<00:00, 274.64it/s]
Adding requests:  86%|████████▌ | 438/512 [00:01<00:00, 271.53it/s]
Adding requests:  91%|█████████ | 466/512 [00:01<00:00, 268.46it/s]
Adding requests:  97%|█████████▋| 495/512 [00:01<00:00, 274.41it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 267.57it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:00<00:02, 193.03it/s, est. speed input: 197680.78 toks/s, output: 193.03 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:01<00:08, 54.26it/s, est. speed input: 65388.21 toks/s, output: 63.85 toks/s]   
Processed prompts:  15%|█▍        | 76/512 [00:01<00:09, 46.94it/s, est. speed input: 57580.82 toks/s, output: 56.23 toks/s]
Processed prompts:  16%|█▌        | 83/512 [00:01<00:10, 39.10it/s, est. speed input: 50898.55 toks/s, output: 49.71 toks/s]
Processed prompts:  17%|█▋        | 88/512 [00:01<00:11, 37.70it/s, est. speed input: 49273.53 toks/s, output: 48.12 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:01<00:11, 36.39it/s, est. speed input: 47903.97 toks/s, output: 46.78 toks/s]
Processed prompts:  19%|█▉        | 97/512 [00:02<00:12, 33.81it/s, est. speed input: 46258.06 toks/s, output: 45.17 toks/s]
Processed prompts:  20%|█▉        | 101/512 [00:02<00:12, 31.68it/s, est. speed input: 44845.54 toks/s, output: 43.79 toks/s]
Processed prompts:  21%|██        | 105/512 [00:02<00:13, 29.98it/s, est. speed input: 43611.56 toks/s, output: 42.59 toks/s]
Processed prompts:  21%|██        | 108/512 [00:02<00:15, 26.84it/s, est. speed input: 42095.89 toks/s, output: 41.11 toks/s]
Processed prompts:  22%|██▏       | 111/512 [00:02<00:16, 24.62it/s, est. speed input: 40793.47 toks/s, output: 39.84 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:02<00:17, 22.97it/s, est. speed input: 39629.91 toks/s, output: 38.70 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:16, 23.59it/s, est. speed input: 38916.75 toks/s, output: 38.00 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:03<00:16, 24.05it/s, est. speed input: 38275.53 toks/s, output: 37.38 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:03<00:15, 24.39it/s, est. speed input: 37697.21 toks/s, output: 36.81 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:03<00:15, 24.61it/s, est. speed input: 37166.49 toks/s, output: 36.30 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:03<00:15, 24.77it/s, est. speed input: 36681.61 toks/s, output: 35.82 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:03<00:15, 24.87it/s, est. speed input: 36232.27 toks/s, output: 35.38 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:14, 24.94it/s, est. speed input: 35819.21 toks/s, output: 34.98 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:04<00:14, 24.98it/s, est. speed input: 35435.71 toks/s, output: 34.60 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:04<00:14, 25.03it/s, est. speed input: 35083.75 toks/s, output: 34.26 toks/s]
Processed prompts:  30%|███       | 154/512 [00:04<00:14, 25.06it/s, est. speed input: 34755.94 toks/s, output: 33.94 toks/s]
Processed prompts:  31%|███       | 158/512 [00:04<00:14, 25.09it/s, est. speed input: 34451.00 toks/s, output: 33.64 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:04<00:13, 25.11it/s, est. speed input: 34166.76 toks/s, output: 33.37 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:05<00:13, 25.12it/s, est. speed input: 33898.98 toks/s, output: 33.10 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:05<00:13, 25.13it/s, est. speed input: 33649.55 toks/s, output: 32.86 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:05<00:13, 25.15it/s, est. speed input: 33415.93 toks/s, output: 32.63 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:05<00:13, 25.16it/s, est. speed input: 33194.60 toks/s, output: 32.42 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:05<00:13, 25.13it/s, est. speed input: 32981.57 toks/s, output: 32.21 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:05<00:12, 25.10it/s, est. speed input: 32780.32 toks/s, output: 32.01 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:05<00:12, 25.09it/s, est. speed input: 32589.35 toks/s, output: 31.83 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:06<00:12, 25.10it/s, est. speed input: 32411.69 toks/s, output: 31.65 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:06<00:12, 25.11it/s, est. speed input: 32242.18 toks/s, output: 31.49 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:06<00:11, 26.54it/s, est. speed input: 32224.27 toks/s, output: 31.47 toks/s]
Processed prompts:  40%|████      | 206/512 [00:06<00:11, 25.93it/s, est. speed input: 32050.56 toks/s, output: 31.30 toks/s]
Processed prompts:  41%|████      | 210/512 [00:06<00:11, 25.48it/s, est. speed input: 31881.83 toks/s, output: 31.13 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:11, 25.19it/s, est. speed input: 31721.93 toks/s, output: 30.98 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:07<00:11, 25.00it/s, est. speed input: 31571.23 toks/s, output: 30.83 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:07<00:11, 24.87it/s, est. speed input: 31427.10 toks/s, output: 30.69 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:07<00:11, 24.77it/s, est. speed input: 31288.42 toks/s, output: 30.55 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:11, 24.71it/s, est. speed input: 31156.10 toks/s, output: 30.43 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:11, 24.64it/s, est. speed input: 31027.30 toks/s, output: 30.30 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:11, 24.59it/s, est. speed input: 30903.88 toks/s, output: 30.18 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:10, 24.57it/s, est. speed input: 30786.52 toks/s, output: 30.06 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:08<00:10, 24.56it/s, est. speed input: 30674.02 toks/s, output: 29.95 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:08<00:10, 24.53it/s, est. speed input: 30564.34 toks/s, output: 29.85 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:10, 24.51it/s, est. speed input: 30458.91 toks/s, output: 29.74 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:10, 24.52it/s, est. speed input: 30358.78 toks/s, output: 29.65 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:08<00:10, 24.49it/s, est. speed input: 30260.05 toks/s, output: 29.55 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:09<00:10, 24.47it/s, est. speed input: 30164.87 toks/s, output: 29.46 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:09<00:09, 24.45it/s, est. speed input: 30072.24 toks/s, output: 29.37 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:09<00:09, 24.45it/s, est. speed input: 29984.11 toks/s, output: 29.28 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:09, 24.46it/s, est. speed input: 29900.28 toks/s, output: 29.20 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:09, 24.47it/s, est. speed input: 29819.06 toks/s, output: 29.12 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:09, 24.48it/s, est. speed input: 29740.27 toks/s, output: 29.04 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:10<00:09, 24.45it/s, est. speed input: 29662.34 toks/s, output: 28.97 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:10<00:08, 24.47it/s, est. speed input: 29589.43 toks/s, output: 28.90 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:10<00:08, 24.47it/s, est. speed input: 29517.40 toks/s, output: 28.83 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:08, 24.46it/s, est. speed input: 29447.36 toks/s, output: 28.76 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:08, 24.45it/s, est. speed input: 29379.37 toks/s, output: 28.69 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:08, 24.43it/s, est. speed input: 29312.73 toks/s, output: 28.63 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:10<00:08, 24.43it/s, est. speed input: 29248.85 toks/s, output: 28.56 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:11<00:07, 24.45it/s, est. speed input: 29187.58 toks/s, output: 28.50 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:07, 24.44it/s, est. speed input: 29127.23 toks/s, output: 28.44 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:07, 24.44it/s, est. speed input: 29068.86 toks/s, output: 28.39 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:07, 24.46it/s, est. speed input: 29013.16 toks/s, output: 28.33 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:11<00:07, 24.44it/s, est. speed input: 28957.07 toks/s, output: 28.28 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:11<00:07, 24.42it/s, est. speed input: 28902.51 toks/s, output: 28.23 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:12<00:06, 24.42it/s, est. speed input: 28849.94 toks/s, output: 28.17 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:06, 24.41it/s, est. speed input: 28797.87 toks/s, output: 28.12 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:06, 24.41it/s, est. speed input: 28747.96 toks/s, output: 28.07 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:12<00:06, 24.44it/s, est. speed input: 28700.79 toks/s, output: 28.03 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:12<00:06, 24.44it/s, est. speed input: 28653.63 toks/s, output: 27.98 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:12<00:06, 24.42it/s, est. speed input: 28606.81 toks/s, output: 27.94 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:13<00:05, 24.41it/s, est. speed input: 28561.37 toks/s, output: 27.89 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:05, 24.41it/s, est. speed input: 28517.42 toks/s, output: 27.85 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:05, 24.42it/s, est. speed input: 28475.06 toks/s, output: 27.81 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:13<00:05, 24.43it/s, est. speed input: 28433.60 toks/s, output: 27.77 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:13<00:05, 24.44it/s, est. speed input: 28393.75 toks/s, output: 27.73 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:13<00:05, 24.43it/s, est. speed input: 28353.53 toks/s, output: 27.69 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:14<00:04, 24.41it/s, est. speed input: 28314.10 toks/s, output: 27.65 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:04, 24.41it/s, est. speed input: 28276.04 toks/s, output: 27.61 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:04, 24.42it/s, est. speed input: 28239.24 toks/s, output: 27.58 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:14<00:04, 24.42it/s, est. speed input: 28202.69 toks/s, output: 27.54 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:14<00:04, 24.43it/s, est. speed input: 28167.81 toks/s, output: 27.51 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:14<00:04, 24.42it/s, est. speed input: 28132.92 toks/s, output: 27.47 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:04, 24.41it/s, est. speed input: 28098.40 toks/s, output: 27.44 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:03, 24.38it/s, est. speed input: 28063.98 toks/s, output: 27.41 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:15<00:03, 24.38it/s, est. speed input: 28030.80 toks/s, output: 27.37 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:15<00:03, 24.38it/s, est. speed input: 27998.77 toks/s, output: 27.34 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:15<00:03, 24.40it/s, est. speed input: 27967.69 toks/s, output: 27.31 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:15<00:03, 24.27it/s, est. speed input: 27931.91 toks/s, output: 27.28 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:03, 24.17it/s, est. speed input: 27896.50 toks/s, output: 27.24 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:16<00:02, 24.09it/s, est. speed input: 27861.05 toks/s, output: 27.21 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:16<00:02, 24.03it/s, est. speed input: 27826.63 toks/s, output: 27.17 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:16<00:02, 24.01it/s, est. speed input: 27793.38 toks/s, output: 27.14 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:16<00:02, 23.99it/s, est. speed input: 27760.79 toks/s, output: 27.11 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:16<00:02, 23.97it/s, est. speed input: 27728.58 toks/s, output: 27.08 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:17<00:02, 23.96it/s, est. speed input: 27697.12 toks/s, output: 27.05 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:17<00:01, 23.96it/s, est. speed input: 27666.51 toks/s, output: 27.02 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:17<00:01, 23.94it/s, est. speed input: 27635.55 toks/s, output: 26.99 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:17<00:01, 23.95it/s, est. speed input: 27606.54 toks/s, output: 26.96 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:17<00:01, 23.97it/s, est. speed input: 27578.16 toks/s, output: 26.93 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:17<00:01, 23.95it/s, est. speed input: 27549.34 toks/s, output: 26.90 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:18<00:01, 23.93it/s, est. speed input: 27520.60 toks/s, output: 26.88 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:18<00:00, 23.94it/s, est. speed input: 27493.21 toks/s, output: 26.85 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:18<00:00, 23.91it/s, est. speed input: 27465.16 toks/s, output: 26.82 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:18<00:00, 23.89it/s, est. speed input: 27437.67 toks/s, output: 26.79 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:18<00:00, 23.88it/s, est. speed input: 27410.93 toks/s, output: 26.77 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:18<00:00, 23.90it/s, est. speed input: 27385.34 toks/s, output: 26.74 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:19<00:00, 25.70it/s, est. speed input: 27415.82 toks/s, output: 26.77 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 25.70it/s, est. speed input: 27523.01 toks/s, output: 26.88 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 26.88it/s, est. speed input: 27523.01 toks/s, output: 26.88 toks/s]
[rank0]:[W126 02:07:30.907805903 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 65.9s

测试结果:
  Requests/s:   24.42
  Tokens/s:     25032.74
  Total Reqs:   512
  Elapsed:      20.96s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     25008.32

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:07:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:07:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=44360) WARNING 01-26 02:07:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=44360) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=44360) WARNING 01-26 02:08:08 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.47 requests/s, 25082.33 total tokens/s, 24.47 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 02:07:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:07:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:07:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:07:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:07:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:07:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:07:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:07:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:07:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:07:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:07:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:07:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:07:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:07:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:07:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:07:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:07:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:56] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=44360) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=44360) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.17it/s]
(EngineCore_DP0 pid=44360) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=44360) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]
(EngineCore_DP0 pid=44360) 
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=44360) [2026-01-26 02:07:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=44360) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  9.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.49it/s]
(EngineCore_DP0 pid=44360) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.32it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.58it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 24/1024 [00:00<00:04, 233.62it/s]
Adding requests:   5%|▍         | 50/1024 [00:00<00:03, 245.78it/s]
Adding requests:   8%|▊         | 78/1024 [00:00<00:03, 260.48it/s]
Adding requests:  10%|█         | 105/1024 [00:00<00:03, 262.56it/s]
Adding requests:  13%|█▎        | 132/1024 [00:00<00:03, 261.66it/s]
Adding requests:  16%|█▌        | 160/1024 [00:00<00:03, 265.43it/s]
Adding requests:  18%|█▊        | 189/1024 [00:00<00:03, 269.97it/s]
Adding requests:  21%|██        | 217/1024 [00:00<00:02, 271.64it/s]
Adding requests:  24%|██▍       | 245/1024 [00:00<00:02, 271.41it/s]
Adding requests:  27%|██▋       | 273/1024 [00:01<00:02, 268.63it/s]
Adding requests:  29%|██▉       | 302/1024 [00:01<00:02, 273.37it/s]
Adding requests:  32%|███▏      | 330/1024 [00:01<00:02, 271.34it/s]
Adding requests:  35%|███▍      | 358/1024 [00:01<00:02, 271.35it/s]
Adding requests:  38%|███▊      | 386/1024 [00:01<00:02, 273.76it/s]
Adding requests:  41%|████      | 416/1024 [00:01<00:02, 279.75it/s]
Adding requests:  43%|████▎     | 444/1024 [00:01<00:02, 268.16it/s]
Adding requests:  46%|████▋     | 474/1024 [00:01<00:01, 275.04it/s]
Adding requests:  49%|████▉     | 505/1024 [00:01<00:01, 284.63it/s]
Adding requests:  52%|█████▏    | 536/1024 [00:01<00:01, 290.01it/s]
Adding requests:  55%|█████▌    | 566/1024 [00:02<00:01, 289.68it/s]
Adding requests:  58%|█████▊    | 596/1024 [00:02<00:01, 278.37it/s]
Adding requests:  61%|██████    | 624/1024 [00:02<00:01, 270.36it/s]
Adding requests:  64%|██████▎   | 652/1024 [00:02<00:01, 269.38it/s]
Adding requests:  67%|██████▋   | 681/1024 [00:02<00:01, 274.03it/s]
Adding requests:  69%|██████▉   | 710/1024 [00:02<00:01, 278.02it/s]
Adding requests:  72%|███████▏  | 738/1024 [00:02<00:01, 272.35it/s]
Adding requests:  75%|███████▍  | 766/1024 [00:02<00:00, 272.35it/s]
Adding requests:  78%|███████▊  | 794/1024 [00:02<00:00, 272.78it/s]
Adding requests:  80%|████████  | 822/1024 [00:03<00:00, 271.02it/s]
Adding requests:  83%|████████▎ | 851/1024 [00:03<00:00, 276.33it/s]
Adding requests:  86%|████████▌ | 879/1024 [00:03<00:00, 275.29it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:03<00:00, 276.36it/s]
Adding requests:  91%|█████████▏| 936/1024 [00:03<00:00, 271.00it/s]
Adding requests:  94%|█████████▍| 966/1024 [00:03<00:00, 277.57it/s]
Adding requests:  97%|█████████▋| 994/1024 [00:03<00:00, 271.37it/s]
Adding requests: 100%|█████████▉| 1022/1024 [00:03<00:00, 268.52it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 272.27it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:00<00:04, 222.72it/s, est. speed input: 228108.56 toks/s, output: 222.74 toks/s]
Processed prompts:  11%|█         | 113/1024 [00:01<00:09, 92.45it/s, est. speed input: 110048.51 toks/s, output: 107.47 toks/s]
Processed prompts:  12%|█▏        | 125/1024 [00:01<00:16, 55.61it/s, est. speed input: 75359.51 toks/s, output: 73.59 toks/s]  
Processed prompts:  13%|█▎        | 132/1024 [00:02<00:19, 46.69it/s, est. speed input: 66846.73 toks/s, output: 65.28 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:02<00:22, 39.01it/s, est. speed input: 60240.79 toks/s, output: 58.83 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:02<00:25, 34.99it/s, est. speed input: 55997.50 toks/s, output: 54.68 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:02<00:27, 32.03it/s, est. speed input: 52666.22 toks/s, output: 51.43 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:03<00:28, 29.91it/s, est. speed input: 49994.84 toks/s, output: 48.82 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:03<00:30, 28.37it/s, est. speed input: 47795.11 toks/s, output: 46.67 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:03<00:30, 27.29it/s, est. speed input: 45958.67 toks/s, output: 44.88 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:04<00:31, 26.51it/s, est. speed input: 44394.42 toks/s, output: 43.35 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:04<00:31, 25.97it/s, est. speed input: 43052.54 toks/s, output: 42.04 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:04<00:31, 26.34it/s, est. speed input: 42149.97 toks/s, output: 41.16 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:31, 25.83it/s, est. speed input: 41101.91 toks/s, output: 40.14 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:05<00:31, 25.47it/s, est. speed input: 40177.10 toks/s, output: 39.24 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:05<00:31, 25.22it/s, est. speed input: 39352.27 toks/s, output: 38.43 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:31, 25.04it/s, est. speed input: 38611.38 toks/s, output: 37.71 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:06<00:31, 24.93it/s, est. speed input: 37949.40 toks/s, output: 37.06 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:06<00:31, 24.84it/s, est. speed input: 37347.69 toks/s, output: 36.47 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:30, 24.78it/s, est. speed input: 36798.99 toks/s, output: 35.94 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:07<00:30, 24.73it/s, est. speed input: 36295.85 toks/s, output: 35.45 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:07<00:30, 24.71it/s, est. speed input: 35838.06 toks/s, output: 35.00 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:30, 24.68it/s, est. speed input: 35415.30 toks/s, output: 34.59 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:29, 24.66it/s, est. speed input: 35023.71 toks/s, output: 34.20 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:29, 24.65it/s, est. speed input: 34661.56 toks/s, output: 33.85 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:29, 24.65it/s, est. speed input: 34326.79 toks/s, output: 33.52 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:28, 24.63it/s, est. speed input: 34011.91 toks/s, output: 33.21 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:28, 24.62it/s, est. speed input: 33718.92 toks/s, output: 32.93 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:10<00:28, 24.61it/s, est. speed input: 33443.26 toks/s, output: 32.66 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:10<00:27, 24.60it/s, est. speed input: 33185.33 toks/s, output: 32.41 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:10<00:27, 24.60it/s, est. speed input: 32942.52 toks/s, output: 32.17 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:27, 24.60it/s, est. speed input: 32715.42 toks/s, output: 31.95 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:11<00:26, 24.58it/s, est. speed input: 32499.00 toks/s, output: 31.74 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:11<00:26, 24.59it/s, est. speed input: 32296.00 toks/s, output: 31.54 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:12<00:26, 24.59it/s, est. speed input: 32104.07 toks/s, output: 31.35 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:12<00:25, 24.58it/s, est. speed input: 31921.07 toks/s, output: 31.17 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:12<00:25, 24.59it/s, est. speed input: 31748.93 toks/s, output: 31.00 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:13<00:25, 24.58it/s, est. speed input: 31584.39 toks/s, output: 30.84 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:13<00:24, 24.57it/s, est. speed input: 31426.70 toks/s, output: 30.69 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:13<00:24, 24.56it/s, est. speed input: 31277.35 toks/s, output: 30.54 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:14<00:24, 24.56it/s, est. speed input: 31134.08 toks/s, output: 30.40 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:14<00:24, 24.56it/s, est. speed input: 30998.50 toks/s, output: 30.27 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:14<00:23, 24.55it/s, est. speed input: 30867.52 toks/s, output: 30.14 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:14<00:23, 24.54it/s, est. speed input: 30742.37 toks/s, output: 30.02 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:15<00:23, 24.55it/s, est. speed input: 30623.14 toks/s, output: 29.91 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:15<00:22, 24.55it/s, est. speed input: 30509.28 toks/s, output: 29.79 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:15<00:22, 24.54it/s, est. speed input: 30398.93 toks/s, output: 29.69 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:16<00:22, 24.54it/s, est. speed input: 30293.93 toks/s, output: 29.58 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:16<00:21, 24.54it/s, est. speed input: 30192.31 toks/s, output: 29.48 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:16<00:21, 24.53it/s, est. speed input: 30094.33 toks/s, output: 29.39 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:17<00:21, 24.53it/s, est. speed input: 30000.32 toks/s, output: 29.30 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:17<00:20, 24.53it/s, est. speed input: 29910.08 toks/s, output: 29.21 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:17<00:20, 24.53it/s, est. speed input: 29822.68 toks/s, output: 29.12 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:18<00:20, 24.53it/s, est. speed input: 29738.19 toks/s, output: 29.04 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:18<00:19, 24.51it/s, est. speed input: 29656.06 toks/s, output: 28.96 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:18<00:19, 24.53it/s, est. speed input: 29578.33 toks/s, output: 28.89 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:19<00:19, 24.52it/s, est. speed input: 29502.44 toks/s, output: 28.81 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:19<00:18, 24.52it/s, est. speed input: 29429.09 toks/s, output: 28.74 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:19<00:18, 24.51it/s, est. speed input: 29357.52 toks/s, output: 28.67 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:20<00:18, 24.51it/s, est. speed input: 29288.62 toks/s, output: 28.60 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:20<00:17, 24.51it/s, est. speed input: 29222.31 toks/s, output: 28.54 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:20<00:17, 24.52it/s, est. speed input: 29157.90 toks/s, output: 28.47 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:21<00:07, 52.81it/s, est. speed input: 30608.60 toks/s, output: 29.89 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:21<00:08, 44.44it/s, est. speed input: 30524.96 toks/s, output: 29.81 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:21<00:09, 38.53it/s, est. speed input: 30444.28 toks/s, output: 29.73 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:22<00:10, 34.35it/s, est. speed input: 30365.33 toks/s, output: 29.65 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:22<00:11, 31.41it/s, est. speed input: 30289.21 toks/s, output: 29.58 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:22<00:11, 29.36it/s, est. speed input: 30215.30 toks/s, output: 29.51 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:23<00:12, 27.90it/s, est. speed input: 30142.81 toks/s, output: 29.44 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:23<00:12, 26.89it/s, est. speed input: 30073.23 toks/s, output: 29.37 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:23<00:12, 26.18it/s, est. speed input: 30005.17 toks/s, output: 29.30 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:24<00:12, 25.69it/s, est. speed input: 29939.28 toks/s, output: 29.24 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:24<00:12, 25.33it/s, est. speed input: 29874.52 toks/s, output: 29.17 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:24<00:12, 25.08it/s, est. speed input: 29811.21 toks/s, output: 29.11 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:25<00:11, 24.91it/s, est. speed input: 29750.01 toks/s, output: 29.05 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:25<00:11, 24.78it/s, est. speed input: 29690.11 toks/s, output: 28.99 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:25<00:11, 24.71it/s, est. speed input: 29632.40 toks/s, output: 28.94 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:26<00:10, 24.66it/s, est. speed input: 29576.10 toks/s, output: 28.88 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:26<00:10, 24.61it/s, est. speed input: 29520.86 toks/s, output: 28.83 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:26<00:10, 24.58it/s, est. speed input: 29466.89 toks/s, output: 28.78 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:27<00:10, 24.57it/s, est. speed input: 29414.64 toks/s, output: 28.73 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:27<00:09, 25.33it/s, est. speed input: 29399.29 toks/s, output: 28.71 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:27<00:09, 25.08it/s, est. speed input: 29348.48 toks/s, output: 28.66 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:28<00:08, 24.90it/s, est. speed input: 29298.72 toks/s, output: 28.61 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:28<00:08, 24.79it/s, est. speed input: 29250.71 toks/s, output: 28.56 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:28<00:08, 24.71it/s, est. speed input: 29203.57 toks/s, output: 28.52 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:29<00:08, 24.66it/s, est. speed input: 29157.97 toks/s, output: 28.47 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:29<00:07, 24.62it/s, est. speed input: 29113.11 toks/s, output: 28.43 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:29<00:07, 24.57it/s, est. speed input: 29068.19 toks/s, output: 28.39 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:29<00:07, 24.56it/s, est. speed input: 29025.24 toks/s, output: 28.34 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:30<00:06, 24.55it/s, est. speed input: 28983.18 toks/s, output: 28.30 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:30<00:06, 24.54it/s, est. speed input: 28941.87 toks/s, output: 28.26 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:30<00:06, 24.54it/s, est. speed input: 28901.60 toks/s, output: 28.22 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:31<00:05, 24.53it/s, est. speed input: 28861.89 toks/s, output: 28.19 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:31<00:05, 24.54it/s, est. speed input: 28823.52 toks/s, output: 28.15 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:31<00:05, 24.53it/s, est. speed input: 28785.36 toks/s, output: 28.11 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:32<00:04, 24.52it/s, est. speed input: 28747.96 toks/s, output: 28.07 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:32<00:04, 24.51it/s, est. speed input: 28711.22 toks/s, output: 28.04 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:32<00:04, 24.52it/s, est. speed input: 28675.73 toks/s, output: 28.00 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:33<00:03, 24.52it/s, est. speed input: 28640.66 toks/s, output: 27.97 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:33<00:03, 24.51it/s, est. speed input: 28606.12 toks/s, output: 27.94 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:33<00:03, 24.51it/s, est. speed input: 28572.29 toks/s, output: 27.90 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:34<00:02, 24.51it/s, est. speed input: 28539.27 toks/s, output: 27.87 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:34<00:02, 24.50it/s, est. speed input: 28506.49 toks/s, output: 27.84 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:34<00:02, 24.51it/s, est. speed input: 28474.72 toks/s, output: 27.81 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:35<00:01, 24.50it/s, est. speed input: 28443.17 toks/s, output: 27.78 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:35<00:01, 24.50it/s, est. speed input: 28412.31 toks/s, output: 27.75 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:35<00:01, 24.50it/s, est. speed input: 28382.14 toks/s, output: 27.72 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:36<00:00, 24.50it/s, est. speed input: 28352.43 toks/s, output: 27.69 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:36<00:00, 24.51it/s, est. speed input: 28323.59 toks/s, output: 27.66 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:36<00:00, 25.44it/s, est. speed input: 28325.38 toks/s, output: 27.66 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 25.44it/s, est. speed input: 28492.11 toks/s, output: 27.82 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:36<00:00, 27.82it/s, est. speed input: 28492.11 toks/s, output: 27.82 toks/s]
[rank0]:[W126 02:09:00.867207997 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 89.1s

测试结果:
  Requests/s:   24.47
  Tokens/s:     25082.33
  Total Reqs:   1024
  Elapsed:      41.85s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     25057.86

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:09:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:09:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=45941) WARNING 01-26 02:09:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=45941) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=45941) WARNING 01-26 02:09:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.47 requests/s, 25085.41 total tokens/s, 24.47 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 02:09:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:09:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:09:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:09:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:09:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:09:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:09:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:09:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:09:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:09:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:09:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:09:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:09:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:09:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:09:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:09:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:09:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=45941) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=45941) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.19it/s]
(EngineCore_DP0 pid=45941) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07s/it]
(EngineCore_DP0 pid=45941) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.04s/it]
(EngineCore_DP0 pid=45941) 
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=45941) [2026-01-26 02:09:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=45941) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  8.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.35it/s]
(EngineCore_DP0 pid=45941) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.13it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.28it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.71it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.06it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.77it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 241.35it/s]
Adding requests:   2%|▏         | 51/2048 [00:00<00:07, 251.64it/s]
Adding requests:   4%|▍         | 78/2048 [00:00<00:07, 256.97it/s]
Adding requests:   5%|▌         | 104/2048 [00:00<00:07, 254.09it/s]
Adding requests:   6%|▋         | 131/2048 [00:00<00:07, 256.70it/s]
Adding requests:   8%|▊         | 158/2048 [00:00<00:07, 260.51it/s]
Adding requests:   9%|▉         | 186/2048 [00:00<00:06, 266.66it/s]
Adding requests:  10%|█         | 213/2048 [00:00<00:06, 266.26it/s]
Adding requests:  12%|█▏        | 240/2048 [00:00<00:06, 265.23it/s]
Adding requests:  13%|█▎        | 267/2048 [00:01<00:06, 262.30it/s]
Adding requests:  14%|█▍        | 295/2048 [00:01<00:06, 265.96it/s]
Adding requests:  16%|█▌        | 324/2048 [00:01<00:06, 272.21it/s]
Adding requests:  17%|█▋        | 353/2048 [00:01<00:06, 277.24it/s]
Adding requests:  19%|█▊        | 381/2048 [00:01<00:06, 276.05it/s]
Adding requests:  20%|██        | 410/2048 [00:01<00:05, 278.38it/s]
Adding requests:  21%|██▏       | 438/2048 [00:01<00:05, 276.96it/s]
Adding requests:  23%|██▎       | 466/2048 [00:01<00:05, 275.49it/s]
Adding requests:  24%|██▍       | 497/2048 [00:01<00:05, 282.91it/s]
Adding requests:  26%|██▌       | 529/2048 [00:01<00:05, 290.45it/s]
Adding requests:  27%|██▋       | 559/2048 [00:02<00:05, 287.94it/s]
Adding requests:  29%|██▊       | 588/2048 [00:02<00:05, 281.16it/s]
Adding requests:  30%|███       | 617/2048 [00:02<00:05, 277.05it/s]
Adding requests:  31%|███▏      | 645/2048 [00:02<00:05, 272.83it/s]
Adding requests:  33%|███▎      | 673/2048 [00:02<00:05, 266.42it/s]
Adding requests:  34%|███▍      | 702/2048 [00:02<00:04, 271.94it/s]
Adding requests:  36%|███▌      | 730/2048 [00:02<00:04, 268.91it/s]
Adding requests:  37%|███▋      | 758/2048 [00:02<00:04, 270.05it/s]
Adding requests:  38%|███▊      | 786/2048 [00:02<00:04, 272.67it/s]
Adding requests:  40%|███▉      | 814/2048 [00:03<00:04, 267.72it/s]
Adding requests:  41%|████      | 843/2048 [00:03<00:04, 273.99it/s]
Adding requests:  43%|████▎     | 871/2048 [00:03<00:04, 271.08it/s]
Adding requests:  44%|████▍     | 899/2048 [00:03<00:04, 272.70it/s]
Adding requests:  45%|████▌     | 927/2048 [00:03<00:04, 268.20it/s]
Adding requests:  47%|████▋     | 955/2048 [00:03<00:04, 270.37it/s]
Adding requests:  48%|████▊     | 983/2048 [00:03<00:03, 266.38it/s]
Adding requests:  49%|████▉     | 1010/2048 [00:03<00:03, 261.60it/s]
Adding requests:  51%|█████     | 1037/2048 [00:03<00:03, 261.88it/s]
Adding requests:  52%|█████▏    | 1064/2048 [00:03<00:03, 261.15it/s]
Adding requests:  53%|█████▎    | 1091/2048 [00:04<00:03, 259.89it/s]
Adding requests:  55%|█████▍    | 1119/2048 [00:04<00:03, 262.65it/s]
Adding requests:  56%|█████▌    | 1148/2048 [00:04<00:03, 267.43it/s]
Adding requests:  57%|█████▋    | 1176/2048 [00:04<00:03, 269.37it/s]
Adding requests:  59%|█████▉    | 1204/2048 [00:04<00:03, 270.44it/s]
Adding requests:  60%|██████    | 1232/2048 [00:04<00:02, 272.81it/s]
Adding requests:  62%|██████▏   | 1260/2048 [00:04<00:02, 271.39it/s]
Adding requests:  63%|██████▎   | 1288/2048 [00:04<00:02, 266.78it/s]
Adding requests:  64%|██████▍   | 1316/2048 [00:04<00:02, 269.49it/s]
Adding requests:  66%|██████▌   | 1344/2048 [00:04<00:02, 269.88it/s]
Adding requests:  67%|██████▋   | 1374/2048 [00:05<00:02, 276.44it/s]
Adding requests:  68%|██████▊   | 1402/2048 [00:05<00:02, 274.23it/s]
Adding requests:  70%|██████▉   | 1430/2048 [00:05<00:02, 274.09it/s]
Adding requests:  71%|███████   | 1458/2048 [00:05<00:02, 273.62it/s]
Adding requests:  73%|███████▎  | 1487/2048 [00:05<00:02, 276.30it/s]
Adding requests:  74%|███████▍  | 1515/2048 [00:05<00:01, 275.25it/s]
Adding requests:  75%|███████▌  | 1543/2048 [00:05<00:01, 270.63it/s]
Adding requests:  77%|███████▋  | 1571/2048 [00:05<00:01, 263.08it/s]
Adding requests:  78%|███████▊  | 1598/2048 [00:05<00:01, 264.58it/s]
Adding requests:  79%|███████▉  | 1625/2048 [00:06<00:01, 263.31it/s]
Adding requests:  81%|████████  | 1652/2048 [00:06<00:01, 261.64it/s]
Adding requests:  82%|████████▏ | 1679/2048 [00:06<00:01, 261.78it/s]
Adding requests:  83%|████████▎ | 1708/2048 [00:06<00:01, 269.12it/s]
Adding requests:  85%|████████▍ | 1735/2048 [00:06<00:01, 267.06it/s]
Adding requests:  86%|████████▌ | 1764/2048 [00:06<00:01, 273.78it/s]
Adding requests:  88%|████████▊ | 1792/2048 [00:06<00:00, 272.97it/s]
Adding requests:  89%|████████▉ | 1820/2048 [00:06<00:00, 270.12it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:06<00:00, 265.58it/s]
Adding requests:  92%|█████████▏| 1876/2048 [00:06<00:00, 268.84it/s]
Adding requests:  93%|█████████▎| 1904/2048 [00:07<00:00, 270.05it/s]
Adding requests:  94%|█████████▍| 1933/2048 [00:07<00:00, 275.18it/s]
Adding requests:  96%|█████████▌| 1961/2048 [00:07<00:00, 274.64it/s]
Adding requests:  97%|█████████▋| 1989/2048 [00:07<00:00, 274.45it/s]
Adding requests:  98%|█████████▊| 2017/2048 [00:07<00:00, 266.31it/s]
Adding requests: 100%|█████████▉| 2044/2048 [00:07<00:00, 258.80it/s]
Adding requests: 100%|██████████| 2048/2048 [00:07<00:00, 269.25it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:00<00:04, 400.50it/s, est. speed input: 410146.79 toks/s, output: 400.51 toks/s]
Processed prompts:  11%|█         | 219/2048 [00:01<00:17, 103.00it/s, est. speed input: 128797.22 toks/s, output: 125.78 toks/s]
Processed prompts:  12%|█▏        | 238/2048 [00:02<00:23, 76.04it/s, est. speed input: 101971.12 toks/s, output: 99.58 toks/s]  
Processed prompts:  12%|█▏        | 250/2048 [00:03<00:31, 56.30it/s, est. speed input: 84248.49 toks/s, output: 82.27 toks/s] 
Processed prompts:  13%|█▎        | 258/2048 [00:03<00:42, 41.83it/s, est. speed input: 71644.70 toks/s, output: 69.97 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:04<00:48, 36.34it/s, est. speed input: 64701.05 toks/s, output: 63.18 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:04<00:53, 32.67it/s, est. speed input: 59558.74 toks/s, output: 58.16 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:05<00:57, 30.18it/s, est. speed input: 55599.91 toks/s, output: 54.30 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:06<01:00, 28.48it/s, est. speed input: 52459.38 toks/s, output: 51.23 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:06<01:02, 27.30it/s, est. speed input: 49904.44 toks/s, output: 48.73 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:07<01:03, 26.48it/s, est. speed input: 47787.41 toks/s, output: 46.67 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:08<01:04, 25.91it/s, est. speed input: 46002.97 toks/s, output: 44.92 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:08<01:05, 25.51it/s, est. speed input: 44478.49 toks/s, output: 43.44 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:09<01:05, 25.24it/s, est. speed input: 43164.77 toks/s, output: 42.15 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:10<01:05, 25.03it/s, est. speed input: 42011.58 toks/s, output: 41.03 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:10<01:05, 24.82it/s, est. speed input: 40975.02 toks/s, output: 40.01 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:11<01:04, 24.75it/s, est. speed input: 40078.92 toks/s, output: 39.14 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:12<01:04, 24.69it/s, est. speed input: 39279.40 toks/s, output: 38.36 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:12<01:03, 24.65it/s, est. speed input: 38560.30 toks/s, output: 37.66 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:13<01:02, 24.63it/s, est. speed input: 37910.83 toks/s, output: 37.02 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:14<00:38, 38.99it/s, est. speed input: 39589.18 toks/s, output: 38.66 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:14<00:42, 34.68it/s, est. speed input: 38951.22 toks/s, output: 38.04 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:15<00:46, 31.65it/s, est. speed input: 38367.30 toks/s, output: 37.47 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:16<00:49, 29.52it/s, est. speed input: 37830.15 toks/s, output: 36.94 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:16<00:51, 28.03it/s, est. speed input: 37334.81 toks/s, output: 36.46 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:17<00:52, 26.98it/s, est. speed input: 36877.03 toks/s, output: 36.01 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:18<00:53, 26.24it/s, est. speed input: 36451.22 toks/s, output: 35.60 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:18<00:54, 25.73it/s, est. speed input: 36054.87 toks/s, output: 35.21 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:19<00:54, 25.37it/s, est. speed input: 35686.47 toks/s, output: 34.85 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:19<00:54, 25.11it/s, est. speed input: 35341.05 toks/s, output: 34.51 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:20<00:53, 24.94it/s, est. speed input: 35017.54 toks/s, output: 34.20 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:21<00:53, 24.81it/s, est. speed input: 34713.52 toks/s, output: 33.90 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:21<00:52, 24.72it/s, est. speed input: 34427.60 toks/s, output: 33.62 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:22<00:52, 24.66it/s, est. speed input: 34158.59 toks/s, output: 33.36 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:23<00:51, 24.62it/s, est. speed input: 33904.67 toks/s, output: 33.11 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:23<00:50, 24.98it/s, est. speed input: 33712.16 toks/s, output: 32.92 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:24<00:50, 24.83it/s, est. speed input: 33482.78 toks/s, output: 32.70 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:25<00:49, 24.73it/s, est. speed input: 33264.45 toks/s, output: 32.48 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:25<00:49, 24.66it/s, est. speed input: 33057.59 toks/s, output: 32.28 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:26<00:48, 24.61it/s, est. speed input: 32860.83 toks/s, output: 32.09 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:27<00:48, 24.58it/s, est. speed input: 32674.10 toks/s, output: 31.91 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:27<00:47, 24.55it/s, est. speed input: 32495.65 toks/s, output: 31.73 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:28<00:46, 24.54it/s, est. speed input: 32325.45 toks/s, output: 31.57 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:29<00:46, 24.52it/s, est. speed input: 32162.97 toks/s, output: 31.41 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:29<00:45, 24.52it/s, est. speed input: 32007.91 toks/s, output: 31.26 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:30<00:44, 24.53it/s, est. speed input: 31860.39 toks/s, output: 31.11 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:31<00:44, 24.51it/s, est. speed input: 31717.03 toks/s, output: 30.97 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:31<00:43, 24.51it/s, est. speed input: 31580.96 toks/s, output: 30.84 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:32<00:43, 24.50it/s, est. speed input: 31449.54 toks/s, output: 30.71 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:33<00:42, 24.50it/s, est. speed input: 31323.72 toks/s, output: 30.59 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:33<00:41, 24.50it/s, est. speed input: 31203.00 toks/s, output: 30.47 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:34<00:41, 24.50it/s, est. speed input: 31086.75 toks/s, output: 30.36 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:34<00:40, 24.51it/s, est. speed input: 30975.17 toks/s, output: 30.25 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:35<00:39, 24.51it/s, est. speed input: 30867.30 toks/s, output: 30.14 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:36<00:39, 24.51it/s, est. speed input: 30763.42 toks/s, output: 30.04 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:36<00:38, 24.50it/s, est. speed input: 30663.05 toks/s, output: 29.94 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:37<00:37, 24.50it/s, est. speed input: 30566.00 toks/s, output: 29.85 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:38<00:37, 24.49it/s, est. speed input: 30472.02 toks/s, output: 29.76 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:38<00:36, 24.49it/s, est. speed input: 30381.16 toks/s, output: 29.67 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:39<00:35, 24.49it/s, est. speed input: 30293.31 toks/s, output: 29.58 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:40<00:35, 24.49it/s, est. speed input: 30208.50 toks/s, output: 29.50 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:40<00:34, 24.49it/s, est. speed input: 30126.60 toks/s, output: 29.42 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:41<00:33, 24.49it/s, est. speed input: 30046.91 toks/s, output: 29.34 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:42<00:33, 24.49it/s, est. speed input: 29969.89 toks/s, output: 29.27 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:42<00:32, 24.49it/s, est. speed input: 29895.42 toks/s, output: 29.19 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:43<00:31, 24.49it/s, est. speed input: 29822.95 toks/s, output: 29.12 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:44<00:31, 24.49it/s, est. speed input: 29752.41 toks/s, output: 29.06 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:44<00:30, 24.49it/s, est. speed input: 29684.33 toks/s, output: 28.99 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:45<00:17, 39.02it/s, est. speed input: 30333.38 toks/s, output: 29.62 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:46<00:19, 34.69it/s, est. speed input: 30259.68 toks/s, output: 29.55 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:46<00:21, 31.63it/s, est. speed input: 30186.73 toks/s, output: 29.48 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:47<00:22, 29.49it/s, est. speed input: 30116.30 toks/s, output: 29.41 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:48<00:22, 27.99it/s, est. speed input: 30047.94 toks/s, output: 29.34 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:48<00:23, 26.95it/s, est. speed input: 29981.45 toks/s, output: 29.28 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:49<00:23, 26.21it/s, est. speed input: 29916.74 toks/s, output: 29.22 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:50<00:22, 25.70it/s, est. speed input: 29853.66 toks/s, output: 29.15 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:50<00:22, 25.34it/s, est. speed input: 29792.04 toks/s, output: 29.09 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:51<00:22, 25.08it/s, est. speed input: 29732.16 toks/s, output: 29.04 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:51<00:21, 24.91it/s, est. speed input: 29673.59 toks/s, output: 28.98 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:52<00:21, 24.78it/s, est. speed input: 29616.51 toks/s, output: 28.92 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:53<00:20, 24.68it/s, est. speed input: 29560.15 toks/s, output: 28.87 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:53<00:20, 24.61it/s, est. speed input: 29505.13 toks/s, output: 28.81 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:54<00:19, 24.56it/s, est. speed input: 29451.57 toks/s, output: 28.76 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:55<00:18, 24.53it/s, est. speed input: 29399.20 toks/s, output: 28.71 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:55<00:18, 24.50it/s, est. speed input: 29348.08 toks/s, output: 28.66 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:56<00:17, 24.88it/s, est. speed input: 29316.28 toks/s, output: 28.63 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:57<00:16, 24.75it/s, est. speed input: 29267.07 toks/s, output: 28.58 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:57<00:16, 24.66it/s, est. speed input: 29219.33 toks/s, output: 28.53 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:58<00:15, 24.60it/s, est. speed input: 29172.49 toks/s, output: 28.49 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:59<00:14, 24.55it/s, est. speed input: 29126.67 toks/s, output: 28.44 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:59<00:14, 24.52it/s, est. speed input: 29081.91 toks/s, output: 28.40 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:00<00:13, 24.50it/s, est. speed input: 29038.15 toks/s, output: 28.36 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:01<00:12, 24.50it/s, est. speed input: 28995.82 toks/s, output: 28.32 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:01<00:12, 24.49it/s, est. speed input: 28954.24 toks/s, output: 28.28 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:02<00:11, 24.49it/s, est. speed input: 28913.72 toks/s, output: 28.24 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:03<00:11, 24.50it/s, est. speed input: 28874.47 toks/s, output: 28.20 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:03<00:10, 24.49it/s, est. speed input: 28834.98 toks/s, output: 28.16 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:04<00:09, 24.49it/s, est. speed input: 28796.95 toks/s, output: 28.12 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:05<00:09, 24.49it/s, est. speed input: 28759.57 toks/s, output: 28.09 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:05<00:08, 24.49it/s, est. speed input: 28722.89 toks/s, output: 28.05 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:06<00:07, 24.49it/s, est. speed input: 28686.88 toks/s, output: 28.01 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:06<00:07, 24.49it/s, est. speed input: 28651.80 toks/s, output: 27.98 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:07<00:06, 24.49it/s, est. speed input: 28617.24 toks/s, output: 27.95 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:08<00:05, 24.49it/s, est. speed input: 28583.40 toks/s, output: 27.91 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:08<00:05, 24.47it/s, est. speed input: 28549.41 toks/s, output: 27.88 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:09<00:04, 24.43it/s, est. speed input: 28515.32 toks/s, output: 27.85 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:10<00:03, 24.41it/s, est. speed input: 28481.92 toks/s, output: 27.81 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:10<00:03, 24.40it/s, est. speed input: 28449.19 toks/s, output: 27.78 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:11<00:02, 24.38it/s, est. speed input: 28416.97 toks/s, output: 27.75 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:12<00:01, 24.38it/s, est. speed input: 28385.37 toks/s, output: 27.72 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:12<00:01, 24.37it/s, est. speed input: 28354.44 toks/s, output: 27.69 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:13<00:00, 24.85it/s, est. speed input: 28340.32 toks/s, output: 27.68 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:13<00:00, 24.85it/s, est. speed input: 28535.24 toks/s, output: 27.87 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:13<00:00, 27.87it/s, est. speed input: 28535.24 toks/s, output: 27.87 toks/s]
[rank0]:[W126 02:11:17.330381101 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 137.4s

测试结果:
  Requests/s:   24.47
  Tokens/s:     25085.41
  Total Reqs:   2048
  Elapsed:      83.68s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     25060.94

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:11:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:11:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=48331) WARNING 01-26 02:12:02 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=48331) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=48331) WARNING 01-26 02:12:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 6.39 requests/s, 6544.83 total tokens/s, 6.39 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 02:11:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:11:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:11:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:11:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:11:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:11:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:11:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:11:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:11:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:12:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:12:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:12:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:12:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:12:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:12:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:12:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:12:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:12:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=48331) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=48331) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.17it/s]
(EngineCore_DP0 pid=48331) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.10s/it]
(EngineCore_DP0 pid=48331) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=48331) 
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=48331) [2026-01-26 02:12:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=48331) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  8.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  9.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  8.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.67it/s]
(EngineCore_DP0 pid=48331) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.36it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.87it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  9.07it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  9.14it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.97it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 239.97it/s]
Adding requests:   1%|▏         | 52/4096 [00:00<00:16, 252.67it/s]
Adding requests:   2%|▏         | 80/4096 [00:00<00:15, 262.06it/s]
Adding requests:   3%|▎         | 107/4096 [00:00<00:15, 263.34it/s]
Adding requests:   3%|▎         | 134/4096 [00:00<00:15, 259.49it/s]
Adding requests:   4%|▍         | 160/4096 [00:00<00:15, 255.67it/s]
Adding requests:   5%|▍         | 186/4096 [00:00<00:15, 250.21it/s]
Adding requests:   5%|▌         | 213/4096 [00:00<00:15, 256.22it/s]
Adding requests:   6%|▌         | 240/4096 [00:00<00:14, 258.67it/s]
Adding requests:   6%|▋         | 266/4096 [00:01<00:15, 249.52it/s]
Adding requests:   7%|▋         | 292/4096 [00:01<00:15, 251.60it/s]
Adding requests:   8%|▊         | 321/4096 [00:01<00:14, 261.46it/s]
Adding requests:   8%|▊         | 348/4096 [00:01<00:15, 246.71it/s]
Adding requests:   9%|▉         | 373/4096 [00:01<00:16, 222.88it/s]
Adding requests:  10%|▉         | 396/4096 [00:01<00:17, 210.18it/s]
Adding requests:  10%|█         | 418/4096 [00:01<00:18, 196.60it/s]
Adding requests:  11%|█         | 439/4096 [00:01<00:19, 186.28it/s]
Adding requests:  11%|█         | 458/4096 [00:02<00:19, 185.96it/s]
Adding requests:  12%|█▏        | 477/4096 [00:02<00:19, 182.73it/s]
Adding requests:  12%|█▏        | 497/4096 [00:02<00:19, 186.02it/s]
Adding requests:  13%|█▎        | 517/4096 [00:02<00:18, 188.55it/s]
Adding requests:  13%|█▎        | 537/4096 [00:02<00:18, 188.41it/s]
Adding requests:  14%|█▎        | 556/4096 [00:02<00:19, 182.69it/s]
Adding requests:  14%|█▍        | 576/4096 [00:02<00:18, 185.92it/s]
Adding requests:  15%|█▍        | 595/4096 [00:02<00:19, 179.91it/s]
Adding requests:  15%|█▍        | 614/4096 [00:02<00:20, 170.76it/s]
Adding requests:  15%|█▌        | 633/4096 [00:02<00:19, 174.82it/s]
Adding requests:  16%|█▌        | 651/4096 [00:03<00:19, 172.26it/s]
Adding requests:  16%|█▋        | 671/4096 [00:03<00:19, 177.88it/s]
Adding requests:  17%|█▋        | 691/4096 [00:03<00:18, 184.08it/s]
Adding requests:  17%|█▋        | 710/4096 [00:03<00:18, 184.78it/s]
Adding requests:  18%|█▊        | 729/4096 [00:03<00:19, 174.56it/s]
Adding requests:  18%|█▊        | 747/4096 [00:03<00:19, 172.97it/s]
Adding requests:  19%|█▊        | 765/4096 [00:03<00:19, 173.73it/s]
Adding requests:  19%|█▉        | 786/4096 [00:03<00:18, 182.69it/s]
Adding requests:  20%|█▉        | 808/4096 [00:03<00:17, 193.33it/s]
Adding requests:  20%|██        | 837/4096 [00:04<00:14, 220.22it/s]
Adding requests:  21%|██        | 864/4096 [00:04<00:13, 234.02it/s]
Adding requests:  22%|██▏       | 890/4096 [00:04<00:13, 240.08it/s]
Adding requests:  22%|██▏       | 915/4096 [00:04<00:13, 240.51it/s]
Adding requests:  23%|██▎       | 943/4096 [00:04<00:12, 249.17it/s]
Adding requests:  24%|██▎       | 969/4096 [00:04<00:12, 251.64it/s]
Adding requests:  24%|██▍       | 995/4096 [00:04<00:13, 238.30it/s]
Adding requests:  25%|██▍       | 1021/4096 [00:04<00:12, 241.77it/s]
Adding requests:  26%|██▌       | 1047/4096 [00:04<00:12, 246.70it/s]
Adding requests:  26%|██▌       | 1072/4096 [00:04<00:12, 236.12it/s]
Adding requests:  27%|██▋       | 1098/4096 [00:05<00:12, 240.68it/s]
Adding requests:  27%|██▋       | 1125/4096 [00:05<00:11, 248.00it/s]
Adding requests:  28%|██▊       | 1150/4096 [00:05<00:12, 242.74it/s]
Adding requests:  29%|██▊       | 1175/4096 [00:05<00:12, 243.11it/s]
Adding requests:  29%|██▉       | 1203/4096 [00:05<00:11, 251.54it/s]
Adding requests:  30%|███       | 1229/4096 [00:05<00:11, 248.03it/s]
Adding requests:  31%|███       | 1254/4096 [00:05<00:11, 241.54it/s]
Adding requests:  31%|███▏      | 1280/4096 [00:05<00:11, 244.76it/s]
Adding requests:  32%|███▏      | 1308/4096 [00:05<00:11, 252.10it/s]
Adding requests:  33%|███▎      | 1334/4096 [00:06<00:11, 246.74it/s]
Adding requests:  33%|███▎      | 1362/4096 [00:06<00:10, 254.55it/s]
Adding requests:  34%|███▍      | 1388/4096 [00:06<00:10, 255.42it/s]
Adding requests:  35%|███▍      | 1414/4096 [00:06<00:10, 251.83it/s]
Adding requests:  35%|███▌      | 1440/4096 [00:06<00:10, 249.97it/s]
Adding requests:  36%|███▌      | 1468/4096 [00:06<00:10, 256.46it/s]
Adding requests:  37%|███▋      | 1497/4096 [00:06<00:09, 264.57it/s]
Adding requests:  37%|███▋      | 1524/4096 [00:06<00:10, 252.52it/s]
Adding requests:  38%|███▊      | 1551/4096 [00:06<00:09, 255.80it/s]
Adding requests:  39%|███▊      | 1577/4096 [00:06<00:09, 256.77it/s]
Adding requests:  39%|███▉      | 1603/4096 [00:07<00:09, 251.76it/s]
Adding requests:  40%|███▉      | 1629/4096 [00:07<00:10, 245.43it/s]
Adding requests:  40%|████      | 1654/4096 [00:07<00:09, 245.35it/s]
Adding requests:  41%|████      | 1679/4096 [00:07<00:09, 246.51it/s]
Adding requests:  42%|████▏     | 1704/4096 [00:07<00:09, 242.29it/s]
Adding requests:  42%|████▏     | 1732/4096 [00:07<00:09, 251.41it/s]
Adding requests:  43%|████▎     | 1759/4096 [00:07<00:09, 256.41it/s]
Adding requests:  44%|████▎     | 1785/4096 [00:07<00:09, 249.02it/s]
Adding requests:  44%|████▍     | 1810/4096 [00:07<00:09, 244.83it/s]
Adding requests:  45%|████▍     | 1836/4096 [00:08<00:09, 248.11it/s]
Adding requests:  45%|████▌     | 1861/4096 [00:08<00:08, 248.61it/s]
Adding requests:  46%|████▌     | 1886/4096 [00:08<00:09, 242.79it/s]
Adding requests:  47%|████▋     | 1914/4096 [00:08<00:08, 251.79it/s]
Adding requests:  47%|████▋     | 1943/4096 [00:08<00:08, 261.25it/s]
Adding requests:  48%|████▊     | 1970/4096 [00:08<00:08, 250.98it/s]
Adding requests:  49%|████▊     | 1996/4096 [00:08<00:08, 253.44it/s]
Adding requests:  49%|████▉     | 2022/4096 [00:08<00:08, 255.28it/s]
Adding requests:  50%|█████     | 2048/4096 [00:08<00:08, 248.09it/s]
Adding requests:  51%|█████     | 2073/4096 [00:08<00:08, 239.64it/s]
Adding requests:  51%|█████▏    | 2101/4096 [00:09<00:07, 250.46it/s]
Adding requests:  52%|█████▏    | 2127/4096 [00:09<00:07, 252.84it/s]
Adding requests:  53%|█████▎    | 2153/4096 [00:09<00:07, 244.02it/s]
Adding requests:  53%|█████▎    | 2178/4096 [00:09<00:07, 244.92it/s]
Adding requests:  54%|█████▍    | 2205/4096 [00:09<00:07, 249.59it/s]
Adding requests:  54%|█████▍    | 2231/4096 [00:09<00:07, 243.92it/s]
Adding requests:  55%|█████▌    | 2259/4096 [00:09<00:07, 250.87it/s]
Adding requests:  56%|█████▌    | 2287/4096 [00:09<00:07, 257.94it/s]
Adding requests:  56%|█████▋    | 2313/4096 [00:09<00:06, 255.32it/s]
Adding requests:  57%|█████▋    | 2339/4096 [00:10<00:06, 255.01it/s]
Adding requests:  58%|█████▊    | 2367/4096 [00:10<00:06, 261.18it/s]
Adding requests:  59%|█████▊    | 2397/4096 [00:10<00:06, 271.69it/s]
Adding requests:  59%|█████▉    | 2425/4096 [00:10<00:06, 259.71it/s]
Adding requests:  60%|█████▉    | 2452/4096 [00:10<00:06, 252.26it/s]
Adding requests:  61%|██████    | 2479/4096 [00:10<00:06, 255.79it/s]
Adding requests:  61%|██████    | 2505/4096 [00:10<00:06, 252.36it/s]
Adding requests:  62%|██████▏   | 2531/4096 [00:10<00:06, 253.23it/s]
Adding requests:  62%|██████▏   | 2559/4096 [00:10<00:05, 260.37it/s]
Adding requests:  63%|██████▎   | 2587/4096 [00:10<00:05, 266.04it/s]
Adding requests:  64%|██████▍   | 2614/4096 [00:11<00:05, 252.85it/s]
Adding requests:  64%|██████▍   | 2640/4096 [00:11<00:05, 251.69it/s]
Adding requests:  65%|██████▌   | 2667/4096 [00:11<00:05, 256.21it/s]
Adding requests:  66%|██████▌   | 2693/4096 [00:11<00:05, 245.42it/s]
Adding requests:  66%|██████▋   | 2720/4096 [00:11<00:05, 250.39it/s]
Adding requests:  67%|██████▋   | 2747/4096 [00:11<00:05, 255.53it/s]
Adding requests:  68%|██████▊   | 2774/4096 [00:11<00:05, 258.49it/s]
Adding requests:  68%|██████▊   | 2801/4096 [00:11<00:04, 260.64it/s]
Adding requests:  69%|██████▉   | 2828/4096 [00:11<00:04, 261.93it/s]
Adding requests:  70%|██████▉   | 2857/4096 [00:12<00:04, 267.06it/s]
Adding requests:  70%|███████   | 2884/4096 [00:12<00:04, 256.60it/s]
Adding requests:  71%|███████   | 2912/4096 [00:12<00:04, 261.55it/s]
Adding requests:  72%|███████▏  | 2941/4096 [00:12<00:04, 269.25it/s]
Adding requests:  72%|███████▏  | 2969/4096 [00:12<00:04, 265.13it/s]
Adding requests:  73%|███████▎  | 2996/4096 [00:12<00:04, 261.99it/s]
Adding requests:  74%|███████▍  | 3024/4096 [00:12<00:04, 265.80it/s]
Adding requests:  75%|███████▍  | 3053/4096 [00:12<00:03, 271.11it/s]
Adding requests:  75%|███████▌  | 3081/4096 [00:12<00:03, 259.14it/s]
Adding requests:  76%|███████▌  | 3109/4096 [00:12<00:03, 262.72it/s]
Adding requests:  77%|███████▋  | 3139/4096 [00:13<00:03, 271.35it/s]
Adding requests:  77%|███████▋  | 3167/4096 [00:13<00:03, 254.70it/s]
Adding requests:  78%|███████▊  | 3193/4096 [00:13<00:03, 255.87it/s]
Adding requests:  79%|███████▊  | 3222/4096 [00:13<00:03, 262.87it/s]
Adding requests:  79%|███████▉  | 3249/4096 [00:13<00:03, 261.15it/s]
Adding requests:  80%|███████▉  | 3276/4096 [00:13<00:03, 252.52it/s]
Adding requests:  81%|████████  | 3302/4096 [00:13<00:03, 250.90it/s]
Adding requests:  81%|████████▏ | 3328/4096 [00:13<00:03, 251.73it/s]
Adding requests:  82%|████████▏ | 3354/4096 [00:13<00:03, 244.05it/s]
Adding requests:  83%|████████▎ | 3382/4096 [00:14<00:02, 252.80it/s]
Adding requests:  83%|████████▎ | 3410/4096 [00:14<00:02, 260.01it/s]
Adding requests:  84%|████████▍ | 3437/4096 [00:14<00:02, 247.61it/s]
Adding requests:  85%|████████▍ | 3465/4096 [00:14<00:02, 255.96it/s]
Adding requests:  85%|████████▌ | 3492/4096 [00:14<00:02, 258.27it/s]
Adding requests:  86%|████████▌ | 3520/4096 [00:14<00:02, 262.61it/s]
Adding requests:  87%|████████▋ | 3547/4096 [00:14<00:02, 262.43it/s]
Adding requests:  87%|████████▋ | 3574/4096 [00:14<00:01, 263.63it/s]
Adding requests:  88%|████████▊ | 3602/4096 [00:14<00:01, 267.82it/s]
Adding requests:  89%|████████▊ | 3629/4096 [00:15<00:01, 256.23it/s]
Adding requests:  89%|████████▉ | 3656/4096 [00:15<00:01, 259.78it/s]
Adding requests:  90%|████████▉ | 3683/4096 [00:15<00:01, 262.16it/s]
Adding requests:  91%|█████████ | 3710/4096 [00:15<00:01, 257.32it/s]
Adding requests:  91%|█████████ | 3737/4096 [00:15<00:01, 258.53it/s]
Adding requests:  92%|█████████▏| 3764/4096 [00:15<00:01, 258.78it/s]
Adding requests:  93%|█████████▎| 3790/4096 [00:15<00:01, 251.73it/s]
Adding requests:  93%|█████████▎| 3816/4096 [00:15<00:01, 231.14it/s]
Adding requests:  94%|█████████▍| 3843/4096 [00:15<00:01, 241.57it/s]
Adding requests:  95%|█████████▍| 3871/4096 [00:15<00:00, 250.24it/s]
Adding requests:  95%|█████████▌| 3897/4096 [00:16<00:00, 239.91it/s]
Adding requests:  96%|█████████▌| 3923/4096 [00:16<00:00, 244.83it/s]
Adding requests:  96%|█████████▋| 3951/4096 [00:16<00:00, 253.42it/s]
Adding requests:  97%|█████████▋| 3977/4096 [00:16<00:00, 248.09it/s]
Adding requests:  98%|█████████▊| 4003/4096 [00:16<00:00, 251.23it/s]
Adding requests:  98%|█████████▊| 4031/4096 [00:16<00:00, 258.27it/s]
Adding requests:  99%|█████████▉| 4057/4096 [00:16<00:00, 257.37it/s]
Adding requests: 100%|█████████▉| 4083/4096 [00:16<00:00, 248.22it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 242.50it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:03<02:29, 26.72it/s, est. speed input: 27362.86 toks/s, output: 26.72 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:07<04:08, 15.95it/s, est. speed input: 17971.61 toks/s, output: 17.55 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:12<06:01, 10.87it/s, est. speed input: 13360.47 toks/s, output: 13.05 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:17<07:16,  8.93it/s, est. speed input: 11400.11 toks/s, output: 11.13 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:22<08:06,  7.96it/s, est. speed input: 10314.81 toks/s, output: 10.07 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:27<08:38,  7.41it/s, est. speed input: 9625.54 toks/s, output: 9.40 toks/s]  
Processed prompts:   7%|▋         | 290/4096 [00:32<08:58,  7.06it/s, est. speed input: 9148.75 toks/s, output: 8.93 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:37<09:11,  6.84it/s, est. speed input: 8799.89 toks/s, output: 8.59 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:41<08:33,  7.29it/s, est. speed input: 8799.64 toks/s, output: 8.59 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:46<08:50,  6.99it/s, est. speed input: 8554.51 toks/s, output: 8.35 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:51<09:01,  6.80it/s, est. speed input: 8356.52 toks/s, output: 8.16 toks/s]
Processed prompts:  11%|█         | 450/4096 [00:56<09:06,  6.67it/s, est. speed input: 8193.86 toks/s, output: 8.00 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:01<09:09,  6.58it/s, est. speed input: 8058.17 toks/s, output: 7.87 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:06<09:09,  6.52it/s, est. speed input: 7942.83 toks/s, output: 7.76 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:09<08:24,  7.03it/s, est. speed input: 7989.25 toks/s, output: 7.80 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:14<08:35,  6.82it/s, est. speed input: 7891.86 toks/s, output: 7.71 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:20<08:41,  6.68it/s, est. speed input: 7806.75 toks/s, output: 7.62 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:25<08:44,  6.59it/s, est. speed input: 7731.61 toks/s, output: 7.55 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:30<08:44,  6.52it/s, est. speed input: 7664.79 toks/s, output: 7.49 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:35<08:43,  6.48it/s, est. speed input: 7605.02 toks/s, output: 7.43 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:40<08:40,  6.45it/s, est. speed input: 7551.13 toks/s, output: 7.37 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [01:43<07:50,  7.07it/s, est. speed input: 7611.69 toks/s, output: 7.43 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [01:48<08:01,  6.85it/s, est. speed input: 7561.79 toks/s, output: 7.38 toks/s]
Processed prompts:  20%|██        | 834/4096 [01:53<08:06,  6.70it/s, est. speed input: 7516.34 toks/s, output: 7.34 toks/s]
Processed prompts:  21%|██        | 866/4096 [01:58<08:09,  6.60it/s, est. speed input: 7474.79 toks/s, output: 7.30 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:03<08:09,  6.53it/s, est. speed input: 7436.58 toks/s, output: 7.26 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:08<08:08,  6.49it/s, est. speed input: 7401.21 toks/s, output: 7.23 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:12<07:27,  7.01it/s, est. speed input: 7441.15 toks/s, output: 7.27 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:17<07:35,  6.80it/s, est. speed input: 7407.70 toks/s, output: 7.23 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:22<07:40,  6.67it/s, est. speed input: 7376.77 toks/s, output: 7.20 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [02:27<07:41,  6.58it/s, est. speed input: 7348.01 toks/s, output: 7.18 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [02:32<07:41,  6.52it/s, est. speed input: 7321.32 toks/s, output: 7.15 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [02:37<07:39,  6.48it/s, est. speed input: 7296.07 toks/s, output: 7.13 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [02:42<07:36,  6.44it/s, est. speed input: 7271.80 toks/s, output: 7.10 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [02:46<06:57,  6.98it/s, est. speed input: 7307.34 toks/s, output: 7.14 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [02:51<07:04,  6.79it/s, est. speed input: 7284.71 toks/s, output: 7.11 toks/s]
Processed prompts:  31%|███       | 1250/4096 [02:56<07:07,  6.66it/s, est. speed input: 7263.20 toks/s, output: 7.09 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:01<07:08,  6.57it/s, est. speed input: 7242.96 toks/s, output: 7.07 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:06<07:06,  6.52it/s, est. speed input: 7224.28 toks/s, output: 7.05 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:11<07:04,  6.48it/s, est. speed input: 7206.42 toks/s, output: 7.04 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:14<06:28,  6.99it/s, est. speed input: 7236.59 toks/s, output: 7.07 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [03:20<06:35,  6.80it/s, est. speed input: 7219.00 toks/s, output: 7.05 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [03:25<06:38,  6.66it/s, est. speed input: 7201.96 toks/s, output: 7.03 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [03:30<06:40,  6.55it/s, est. speed input: 7183.92 toks/s, output: 7.02 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [03:35<06:39,  6.49it/s, est. speed input: 7167.63 toks/s, output: 7.00 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [03:40<06:36,  6.45it/s, est. speed input: 7152.75 toks/s, output: 6.99 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [03:45<06:32,  6.43it/s, est. speed input: 7139.18 toks/s, output: 6.97 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [03:48<05:50,  7.11it/s, est. speed input: 7176.37 toks/s, output: 7.01 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [03:53<05:56,  6.91it/s, est. speed input: 7165.51 toks/s, output: 7.00 toks/s]
Processed prompts:  41%|████      | 1666/4096 [03:58<06:00,  6.74it/s, est. speed input: 7151.66 toks/s, output: 6.98 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:03<06:04,  6.58it/s, est. speed input: 7135.49 toks/s, output: 6.97 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [04:08<06:02,  6.52it/s, est. speed input: 7123.39 toks/s, output: 6.96 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [04:13<06:00,  6.48it/s, est. speed input: 7111.87 toks/s, output: 6.95 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [04:17<05:28,  7.01it/s, est. speed input: 7137.20 toks/s, output: 6.97 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [04:22<05:33,  6.81it/s, est. speed input: 7125.95 toks/s, output: 6.96 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [04:27<05:35,  6.68it/s, est. speed input: 7114.96 toks/s, output: 6.95 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [04:32<05:34,  6.59it/s, est. speed input: 7104.34 toks/s, output: 6.94 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [04:37<05:33,  6.53it/s, est. speed input: 7094.12 toks/s, output: 6.93 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [04:42<05:30,  6.48it/s, est. speed input: 7084.22 toks/s, output: 6.92 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [04:47<05:26,  6.45it/s, est. speed input: 7074.71 toks/s, output: 6.91 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [04:51<04:58,  6.97it/s, est. speed input: 7096.30 toks/s, output: 6.93 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [04:56<05:01,  6.78it/s, est. speed input: 7086.83 toks/s, output: 6.92 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [05:01<05:02,  6.66it/s, est. speed input: 7077.69 toks/s, output: 6.91 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [05:06<05:01,  6.57it/s, est. speed input: 7068.78 toks/s, output: 6.90 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [05:11<04:59,  6.51it/s, est. speed input: 7060.16 toks/s, output: 6.89 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [05:16<04:52,  6.55it/s, est. speed input: 7056.41 toks/s, output: 6.89 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [05:19<04:27,  7.06it/s, est. speed input: 7076.79 toks/s, output: 6.91 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [05:24<04:31,  6.84it/s, est. speed input: 7068.40 toks/s, output: 6.90 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [05:29<04:32,  6.70it/s, est. speed input: 7060.28 toks/s, output: 6.89 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [05:34<04:31,  6.60it/s, est. speed input: 7052.38 toks/s, output: 6.89 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [05:39<04:29,  6.53it/s, est. speed input: 7044.69 toks/s, output: 6.88 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [05:44<04:26,  6.48it/s, est. speed input: 7037.24 toks/s, output: 6.87 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [05:49<04:22,  6.45it/s, est. speed input: 7030.01 toks/s, output: 6.87 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [05:53<03:58,  6.98it/s, est. speed input: 7048.93 toks/s, output: 6.88 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [05:58<04:00,  6.79it/s, est. speed input: 7041.72 toks/s, output: 6.88 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [06:03<03:59,  6.66it/s, est. speed input: 7034.69 toks/s, output: 6.87 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [06:08<03:58,  6.57it/s, est. speed input: 7027.87 toks/s, output: 6.86 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [06:13<03:55,  6.51it/s, est. speed input: 7021.22 toks/s, output: 6.86 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [06:18<03:52,  6.47it/s, est. speed input: 7014.73 toks/s, output: 6.85 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [06:22<03:30,  7.00it/s, est. speed input: 7032.37 toks/s, output: 6.87 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [06:27<03:31,  6.80it/s, est. speed input: 7025.89 toks/s, output: 6.86 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [06:32<03:30,  6.67it/s, est. speed input: 7019.61 toks/s, output: 6.86 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [06:37<03:28,  6.58it/s, est. speed input: 7013.47 toks/s, output: 6.85 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [06:42<03:25,  6.52it/s, est. speed input: 7007.47 toks/s, output: 6.84 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [06:47<03:22,  6.48it/s, est. speed input: 7001.62 toks/s, output: 6.84 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [06:52<03:18,  6.45it/s, est. speed input: 6995.89 toks/s, output: 6.83 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [06:56<02:58,  6.97it/s, est. speed input: 7012.25 toks/s, output: 6.85 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [07:01<02:58,  6.78it/s, est. speed input: 7006.52 toks/s, output: 6.84 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [07:06<02:57,  6.66it/s, est. speed input: 7000.94 toks/s, output: 6.84 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [07:11<02:54,  6.57it/s, est. speed input: 6995.50 toks/s, output: 6.83 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [07:16<02:51,  6.51it/s, est. speed input: 6990.20 toks/s, output: 6.83 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [07:21<02:47,  6.47it/s, est. speed input: 6984.90 toks/s, output: 6.82 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [07:24<02:30,  7.00it/s, est. speed input: 7000.39 toks/s, output: 6.84 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [07:29<02:30,  6.80it/s, est. speed input: 6995.13 toks/s, output: 6.83 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [07:35<02:28,  6.67it/s, est. speed input: 6989.99 toks/s, output: 6.83 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [07:40<02:25,  6.58it/s, est. speed input: 6984.95 toks/s, output: 6.82 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [07:45<02:22,  6.52it/s, est. speed input: 6980.13 toks/s, output: 6.82 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [07:50<02:18,  6.47it/s, est. speed input: 6975.30 toks/s, output: 6.81 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [07:55<02:14,  6.43it/s, est. speed input: 6970.05 toks/s, output: 6.81 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [07:58<01:58,  6.98it/s, est. speed input: 6984.92 toks/s, output: 6.82 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [08:03<01:57,  6.78it/s, est. speed input: 6980.22 toks/s, output: 6.82 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [08:08<01:55,  6.65it/s, est. speed input: 6975.52 toks/s, output: 6.81 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [08:13<01:51,  6.56it/s, est. speed input: 6970.85 toks/s, output: 6.81 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [08:18<01:48,  6.50it/s, est. speed input: 6966.08 toks/s, output: 6.80 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [08:23<01:43,  6.46it/s, est. speed input: 6961.63 toks/s, output: 6.80 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [08:27<01:30,  7.02it/s, est. speed input: 6976.28 toks/s, output: 6.81 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [08:32<01:28,  6.81it/s, est. speed input: 6971.97 toks/s, output: 6.81 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [08:37<01:25,  6.68it/s, est. speed input: 6967.72 toks/s, output: 6.80 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [08:42<01:22,  6.59it/s, est. speed input: 6963.55 toks/s, output: 6.80 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [08:47<01:18,  6.52it/s, est. speed input: 6959.45 toks/s, output: 6.80 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [08:52<01:13,  6.48it/s, est. speed input: 6955.41 toks/s, output: 6.79 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [08:57<01:09,  6.45it/s, est. speed input: 6951.46 toks/s, output: 6.79 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [09:01<00:58,  7.07it/s, est. speed input: 6966.96 toks/s, output: 6.80 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [09:06<00:55,  6.85it/s, est. speed input: 6962.95 toks/s, output: 6.80 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [09:11<00:52,  6.70it/s, est. speed input: 6959.02 toks/s, output: 6.80 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [09:16<00:48,  6.60it/s, est. speed input: 6955.15 toks/s, output: 6.79 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [09:21<00:43,  6.53it/s, est. speed input: 6951.34 toks/s, output: 6.79 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [09:26<00:39,  6.48it/s, est. speed input: 6947.62 toks/s, output: 6.78 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [09:29<00:31,  7.01it/s, est. speed input: 6959.98 toks/s, output: 6.80 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [09:34<00:27,  6.90it/s, est. speed input: 6958.75 toks/s, output: 6.80 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [09:39<00:23,  6.73it/s, est. speed input: 6955.04 toks/s, output: 6.79 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [09:44<00:19,  6.62it/s, est. speed input: 6951.40 toks/s, output: 6.79 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [09:49<00:14,  6.55it/s, est. speed input: 6947.82 toks/s, output: 6.78 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [09:54<00:09,  6.49it/s, est. speed input: 6944.29 toks/s, output: 6.78 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [09:59<00:04,  6.55it/s, est. speed input: 6943.36 toks/s, output: 6.78 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [09:59<00:00,  6.55it/s, est. speed input: 6994.58 toks/s, output: 6.83 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [09:59<00:00,  6.83it/s, est. speed input: 6994.58 toks/s, output: 6.83 toks/s]
[rank0]:[W126 02:22:44.860713431 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 686.8s

测试结果:
  Requests/s:   6.39
  Tokens/s:     6544.83
  Total Reqs:   4096
  Elapsed:      641.48s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     6538.44

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:23:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:23:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=58798) WARNING 01-26 02:24:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=58798) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=58798) WARNING 01-26 02:24:17 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     def forward(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     raise e
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/tmp/torchinductor_root/ax/caxhtv4z7pvejo2kecicfp7dovq5qwcbf7pbrxlmuivaiaz6ety5.py", line 1093, in call
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) ERROR 01-26 02:24:23 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


─── STDERR ───
[2026-01-26 02:23:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:23:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:23:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:23:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:23:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:23:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:23:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:23:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:23:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:23:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:23:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:23:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:23:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:23:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:23:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:23:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:23:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=58798) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=58798) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.17it/s]
(EngineCore_DP0 pid=58798) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.09s/it]
(EngineCore_DP0 pid=58798) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.05s/it]
(EngineCore_DP0 pid=58798) 
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 16662528 bytes
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12959744 bytes
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 137003008 bytes
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=58798) [2026-01-26 02:24:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 68009984 bytes
(EngineCore_DP0 pid=58798) Process EngineCore_DP0:
(EngineCore_DP0 pid=58798) Traceback (most recent call last):
(EngineCore_DP0 pid=58798)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=58798)     self.run()
(EngineCore_DP0 pid=58798)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=58798)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=58798)     raise e
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=58798)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=58798)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=58798)     super().__init__(
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=58798)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=58798)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=58798)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=58798)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=58798)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=58798)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=58798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=58798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=58798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=58798)     self.model_runner.profile_run()
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=58798)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=58798)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=58798)     return func(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=58798)     outputs = self.model(
(EngineCore_DP0 pid=58798)               ^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=58798)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=58798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=58798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=58798)     hidden_states = self.model(
(EngineCore_DP0 pid=58798)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=58798)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=58798)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=58798)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=58798)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=58798)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=58798)     def forward(
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=58798)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=58798)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=58798)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=58798)     raise e
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=58798)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=58798)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=58798)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=58798)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=58798)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=58798)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=58798)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=58798)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=58798)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=58798)     return compiled_fn(full_args)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=58798)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=58798)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=58798)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=58798)                             ^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=58798)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=58798)     return self.current_callable(inputs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=58798)     out = model(new_inputs)
(EngineCore_DP0 pid=58798)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/tmp/torchinductor_root/ax/caxhtv4z7pvejo2kecicfp7dovq5qwcbf7pbrxlmuivaiaz6ety5.py", line 1093, in call
(EngineCore_DP0 pid=58798)     buf17 = torch.ops.slidesparse.quant_slide_int8.default(buf16, 'Qwen2.5-7B-INT8', 6)
(EngineCore_DP0 pid=58798)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=58798)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/slidesparse/core/kernels.py", line 564, in _quant_slide_int8_impl
(EngineCore_DP0 pid=58798)     return fn(input, L)
(EngineCore_DP0 pid=58798)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 369, in quant_slide_int8_triton
(EngineCore_DP0 pid=58798)     _quant_slide_int8_kernel[(M,)](
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=58798)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=58798)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=58798)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=58798)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=58798)     self._init_handles()
(EngineCore_DP0 pid=58798)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=58798)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=58798)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=58798) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 02:24:24.218424741 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,17.1540,8800.0258,7.4618
1024,1024,1,128,128,17.3074,17740.0544,7.3957
2048,1024,2,256,128,23.3476,23931.2871,10.9647
4096,1024,4,512,128,24.4222,25032.7427,20.9645
8192,1024,8,1024,128,24.4706,25082.3283,41.8462
16384,1024,16,2048,128,24.4736,25085.4131,83.6821
32768,1024,32,4096,128,6.3852,6544.8279,641.4836
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:24:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:24:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=59619) WARNING 01-26 02:24:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=59619) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=59619) WARNING 01-26 02:25:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.21 requests/s, 8828.67 total tokens/s, 17.21 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:24:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:24:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:24:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:24:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:24:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:24:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:24:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:24:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:24:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:24:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:24:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:24:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:24:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:24:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:24:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:24:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:24:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=59619) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=59619) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.22s/it]
(EngineCore_DP0 pid=59619) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.43s/it]
(EngineCore_DP0 pid=59619) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:08<00:00,  4.40s/it]
(EngineCore_DP0 pid=59619) 
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:53] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:53] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=59619) [2026-01-26 02:24:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=59619) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.22it/s]
(EngineCore_DP0 pid=59619) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.57it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▍      | 44/128 [00:00<00:00, 438.60it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 465.30it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 469.37it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:02, 49.80it/s, est. speed input: 25501.77 toks/s, output: 49.80 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 23.17it/s, est. speed input: 12898.44 toks/s, output: 25.19 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 20.23it/s, est. speed input: 11342.02 toks/s, output: 22.15 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:05, 19.36it/s, est. speed input: 10848.71 toks/s, output: 21.19 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:05, 18.72it/s, est. speed input: 10501.97 toks/s, output: 20.51 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 18.33it/s, est. speed input: 10270.54 toks/s, output: 20.06 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 18.14it/s, est. speed input: 10151.13 toks/s, output: 19.83 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 17.99it/s, est. speed input: 10054.89 toks/s, output: 19.64 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 17.91it/s, est. speed input: 9977.61 toks/s, output: 19.49 toks/s] 
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 17.77it/s, est. speed input: 9900.77 toks/s, output: 19.34 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 17.55it/s, est. speed input: 9819.31 toks/s, output: 19.18 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 17.45it/s, est. speed input: 9755.54 toks/s, output: 19.05 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:05, 17.32it/s, est. speed input: 9692.61 toks/s, output: 18.93 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 17.34it/s, est. speed input: 9648.86 toks/s, output: 18.85 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 17.37it/s, est. speed input: 9610.52 toks/s, output: 18.77 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 17.37it/s, est. speed input: 9574.45 toks/s, output: 18.70 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 17.32it/s, est. speed input: 9537.61 toks/s, output: 18.63 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 17.34it/s, est. speed input: 9508.93 toks/s, output: 18.57 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 17.38it/s, est. speed input: 9484.21 toks/s, output: 18.52 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 17.22it/s, est. speed input: 9447.91 toks/s, output: 18.45 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:04, 17.24it/s, est. speed input: 9423.68 toks/s, output: 18.41 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:02<00:04, 17.24it/s, est. speed input: 9400.73 toks/s, output: 18.36 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 17.31it/s, est. speed input: 9383.95 toks/s, output: 18.33 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:03, 17.29it/s, est. speed input: 9363.88 toks/s, output: 18.29 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 17.28it/s, est. speed input: 9345.34 toks/s, output: 18.25 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 17.28it/s, est. speed input: 9328.93 toks/s, output: 18.22 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 17.27it/s, est. speed input: 9312.86 toks/s, output: 18.19 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 17.22it/s, est. speed input: 9295.24 toks/s, output: 18.15 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:03, 17.14it/s, est. speed input: 9276.33 toks/s, output: 18.12 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:03, 17.13it/s, est. speed input: 9260.73 toks/s, output: 18.09 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 17.14it/s, est. speed input: 9246.95 toks/s, output: 18.06 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 17.22it/s, est. speed input: 9237.74 toks/s, output: 18.04 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:02, 17.31it/s, est. speed input: 9230.60 toks/s, output: 18.03 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 17.26it/s, est. speed input: 9218.69 toks/s, output: 18.01 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 17.39it/s, est. speed input: 9214.93 toks/s, output: 18.00 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 17.50it/s, est. speed input: 9211.99 toks/s, output: 17.99 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 17.56it/s, est. speed input: 9208.38 toks/s, output: 17.99 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 17.61it/s, est. speed input: 9205.39 toks/s, output: 17.98 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:02, 17.62it/s, est. speed input: 9201.33 toks/s, output: 17.97 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 17.70it/s, est. speed input: 9200.32 toks/s, output: 17.97 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:01, 17.81it/s, est. speed input: 9201.45 toks/s, output: 17.97 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.85it/s, est. speed input: 9201.29 toks/s, output: 17.97 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.66it/s, est. speed input: 9193.15 toks/s, output: 17.96 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 17.61it/s, est. speed input: 9188.08 toks/s, output: 17.95 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 17.64it/s, est. speed input: 9185.77 toks/s, output: 17.94 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 17.71it/s, est. speed input: 9184.97 toks/s, output: 17.94 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 17.60it/s, est. speed input: 9179.04 toks/s, output: 17.93 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 17.56it/s, est. speed input: 9174.54 toks/s, output: 17.92 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 17.55it/s, est. speed input: 9170.64 toks/s, output: 17.91 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:00, 17.67it/s, est. speed input: 9171.01 toks/s, output: 17.91 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.70it/s, est. speed input: 9169.74 toks/s, output: 17.91 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.64it/s, est. speed input: 9166.17 toks/s, output: 17.90 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 17.66it/s, est. speed input: 9164.31 toks/s, output: 17.90 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 17.62it/s, est. speed input: 9161.06 toks/s, output: 17.89 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 17.59it/s, est. speed input: 9157.87 toks/s, output: 17.89 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 17.59it/s, est. speed input: 11292.54 toks/s, output: 22.06 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 22.05it/s, est. speed input: 11292.54 toks/s, output: 22.06 toks/s]
[rank0]:[W126 02:25:21.028836229 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 56.2s

测试结果:
  Requests/s:   17.21
  Tokens/s:     8828.67
  Total Reqs:   128
  Elapsed:      7.44s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     8811.46

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:25:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:25:33 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=60624) WARNING 01-26 02:25:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=60624) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=60624) WARNING 01-26 02:25:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.74 requests/s, 17156.25 total tokens/s, 16.74 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:25:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:25:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:25:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:25:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:25:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:25:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:25:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:25:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:25:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:25:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:25:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:25:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:25:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:25:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:25:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:25:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:25:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=60624) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=60624) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.08it/s]
(EngineCore_DP0 pid=60624) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.27s/it]
(EngineCore_DP0 pid=60624) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]
(EngineCore_DP0 pid=60624) 
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=60624) [2026-01-26 02:25:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=60624) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.08it/s]
(EngineCore_DP0 pid=60624) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 237.66it/s]
Adding requests:  40%|███▉      | 51/128 [00:00<00:00, 255.53it/s]
Adding requests:  62%|██████▏   | 79/128 [00:00<00:00, 264.42it/s]
Adding requests:  83%|████████▎ | 106/128 [00:00<00:00, 256.87it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 255.92it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:02, 52.73it/s, est. speed input: 54003.88 toks/s, output: 52.73 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 25.04it/s, est. speed input: 28020.32 toks/s, output: 27.36 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:05, 21.87it/s, est. speed input: 24791.45 toks/s, output: 24.21 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:05, 20.49it/s, est. speed input: 23443.45 toks/s, output: 22.89 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 19.52it/s, est. speed input: 22510.40 toks/s, output: 21.98 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 18.99it/s, est. speed input: 21912.06 toks/s, output: 21.40 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 18.59it/s, est. speed input: 21543.13 toks/s, output: 21.04 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 18.28it/s, est. speed input: 21240.61 toks/s, output: 20.74 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 18.07it/s, est. speed input: 20994.56 toks/s, output: 20.50 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 17.93it/s, est. speed input: 20787.69 toks/s, output: 20.30 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 17.75it/s, est. speed input: 20588.05 toks/s, output: 20.11 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:01<00:05, 17.66it/s, est. speed input: 20422.80 toks/s, output: 19.94 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 17.43it/s, est. speed input: 20239.92 toks/s, output: 19.77 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:04, 17.46it/s, est. speed input: 20117.30 toks/s, output: 19.65 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 17.54it/s, est. speed input: 20020.08 toks/s, output: 19.55 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.52it/s, est. speed input: 19916.39 toks/s, output: 19.45 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 17.39it/s, est. speed input: 19803.44 toks/s, output: 19.34 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 17.42it/s, est. speed input: 19719.15 toks/s, output: 19.26 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 17.39it/s, est. speed input: 19634.72 toks/s, output: 19.17 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:02<00:04, 17.42it/s, est. speed input: 19565.20 toks/s, output: 19.11 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:02<00:04, 17.43it/s, est. speed input: 19499.79 toks/s, output: 19.04 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 17.32it/s, est. speed input: 19423.18 toks/s, output: 18.97 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:03, 17.24it/s, est. speed input: 19349.07 toks/s, output: 18.90 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:03, 17.26it/s, est. speed input: 19292.83 toks/s, output: 18.84 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 17.29it/s, est. speed input: 19240.97 toks/s, output: 18.79 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 17.26it/s, est. speed input: 19187.86 toks/s, output: 18.74 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 17.30it/s, est. speed input: 19143.29 toks/s, output: 18.69 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:03<00:03, 17.34it/s, est. speed input: 19103.67 toks/s, output: 18.66 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 17.38it/s, est. speed input: 19068.40 toks/s, output: 18.62 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:03<00:03, 17.41it/s, est. speed input: 19034.96 toks/s, output: 18.59 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 17.14it/s, est. speed input: 18973.95 toks/s, output: 18.53 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:02, 17.11it/s, est. speed input: 18930.28 toks/s, output: 18.49 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 17.10it/s, est. speed input: 18891.78 toks/s, output: 18.45 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 17.13it/s, est. speed input: 18858.29 toks/s, output: 18.42 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 17.07it/s, est. speed input: 18819.17 toks/s, output: 18.38 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:04<00:02, 17.03it/s, est. speed input: 18781.89 toks/s, output: 18.34 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:02, 17.02it/s, est. speed input: 18748.31 toks/s, output: 18.31 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:04<00:02, 16.96it/s, est. speed input: 18711.40 toks/s, output: 18.27 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.02it/s, est. speed input: 18684.79 toks/s, output: 18.25 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:02, 16.97it/s, est. speed input: 18652.66 toks/s, output: 18.22 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 16.95it/s, est. speed input: 18622.10 toks/s, output: 18.19 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 16.97it/s, est. speed input: 18596.00 toks/s, output: 18.16 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.08it/s, est. speed input: 18578.40 toks/s, output: 18.14 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.14it/s, est. speed input: 18561.17 toks/s, output: 18.13 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 17.20it/s, est. speed input: 18544.45 toks/s, output: 18.11 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:05<00:01, 17.25it/s, est. speed input: 18529.66 toks/s, output: 18.10 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:05<00:01, 17.27it/s, est. speed input: 18514.42 toks/s, output: 18.08 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.23it/s, est. speed input: 18495.91 toks/s, output: 18.06 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.04it/s, est. speed input: 18467.17 toks/s, output: 18.03 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 16.97it/s, est. speed input: 18443.62 toks/s, output: 18.01 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 16.97it/s, est. speed input: 18424.25 toks/s, output: 17.99 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 16.95it/s, est. speed input: 18403.93 toks/s, output: 17.97 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.02it/s, est. speed input: 18390.26 toks/s, output: 17.96 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 17.10it/s, est. speed input: 18378.10 toks/s, output: 17.95 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 17.13it/s, est. speed input: 18365.06 toks/s, output: 17.93 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.15it/s, est. speed input: 18352.66 toks/s, output: 17.92 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.21it/s, est. speed input: 18343.33 toks/s, output: 17.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.21it/s, est. speed input: 18343.33 toks/s, output: 17.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.91it/s, est. speed input: 18343.33 toks/s, output: 17.91 toks/s]
[rank0]:[W126 02:26:11.899735785 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 50.6s

测试结果:
  Requests/s:   16.74
  Tokens/s:     17156.25
  Total Reqs:   128
  Elapsed:      7.65s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     17139.51

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:26:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:26:23 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=61555) WARNING 01-26 02:26:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=61555) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=61555) WARNING 01-26 02:26:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.77 requests/s, 22311.26 total tokens/s, 21.77 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 02:26:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:26:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:26:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:26:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:26:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:26:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:26:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:26:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:26:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:26:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:26:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:26:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:26:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:26:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:26:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:26:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:26:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=61555) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=61555) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.10it/s]
(EngineCore_DP0 pid=61555) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.18s/it]
(EngineCore_DP0 pid=61555) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.14s/it]
(EngineCore_DP0 pid=61555) 
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=61555) [2026-01-26 02:26:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=61555) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.03it/s]
(EngineCore_DP0 pid=61555) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.33it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 243.05it/s]
Adding requests:  20%|██        | 52/256 [00:00<00:00, 253.55it/s]
Adding requests:  31%|███       | 79/256 [00:00<00:00, 260.83it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, -722.72it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:01, 159.13it/s, est. speed input: 162989.13 toks/s, output: 159.14 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:00<00:06, 34.67it/s, est. speed input: 40219.32 toks/s, output: 39.28 toks/s]   
Processed prompts:  16%|█▌        | 40/256 [00:01<00:07, 29.80it/s, est. speed input: 34920.20 toks/s, output: 34.10 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:01<00:07, 27.58it/s, est. speed input: 32678.38 toks/s, output: 31.91 toks/s]
Processed prompts:  20%|█▉        | 51/256 [00:01<00:07, 27.63it/s, est. speed input: 32208.56 toks/s, output: 31.45 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:01<00:07, 26.36it/s, est. speed input: 31279.12 toks/s, output: 30.55 toks/s]
Processed prompts:  23%|██▎       | 59/256 [00:01<00:07, 25.31it/s, est. speed input: 30506.74 toks/s, output: 29.79 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:02<00:08, 23.03it/s, est. speed input: 29400.53 toks/s, output: 28.71 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:02<00:08, 22.86it/s, est. speed input: 28908.54 toks/s, output: 28.23 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:02<00:08, 22.71it/s, est. speed input: 28479.67 toks/s, output: 27.81 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:02<00:08, 22.62it/s, est. speed input: 28110.47 toks/s, output: 27.45 toks/s]
Processed prompts:  30%|███       | 78/256 [00:02<00:07, 22.56it/s, est. speed input: 27790.19 toks/s, output: 27.14 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:07, 22.49it/s, est. speed input: 27502.41 toks/s, output: 26.86 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:03<00:07, 22.42it/s, est. speed input: 27240.03 toks/s, output: 26.60 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:03<00:07, 22.40it/s, est. speed input: 27010.68 toks/s, output: 26.38 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:03<00:07, 22.38it/s, est. speed input: 26805.37 toks/s, output: 26.18 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:07, 22.37it/s, est. speed input: 26618.06 toks/s, output: 25.99 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:03<00:06, 22.38it/s, est. speed input: 26451.41 toks/s, output: 25.83 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:04<00:06, 22.34it/s, est. speed input: 26291.39 toks/s, output: 25.68 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:04<00:06, 22.31it/s, est. speed input: 26144.91 toks/s, output: 25.53 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:04<00:06, 22.32it/s, est. speed input: 26015.42 toks/s, output: 25.41 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:04<00:06, 22.31it/s, est. speed input: 25891.60 toks/s, output: 25.28 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:04<00:06, 22.30it/s, est. speed input: 25777.26 toks/s, output: 25.17 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:05<00:05, 22.28it/s, est. speed input: 25670.53 toks/s, output: 25.07 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:05<00:05, 22.26it/s, est. speed input: 25568.55 toks/s, output: 24.97 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:05<00:05, 22.26it/s, est. speed input: 25476.42 toks/s, output: 24.88 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:05<00:05, 22.29it/s, est. speed input: 25393.08 toks/s, output: 24.80 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:05<00:05, 22.31it/s, est. speed input: 25315.21 toks/s, output: 24.72 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:05<00:04, 22.33it/s, est. speed input: 25243.06 toks/s, output: 24.65 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:06<00:04, 22.34it/s, est. speed input: 25174.42 toks/s, output: 24.58 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:06<00:04, 22.36it/s, est. speed input: 25110.40 toks/s, output: 24.52 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:06<00:04, 22.34it/s, est. speed input: 25047.61 toks/s, output: 24.46 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:06<00:04, 22.35it/s, est. speed input: 24989.82 toks/s, output: 24.40 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:06<00:04, 22.36it/s, est. speed input: 24935.46 toks/s, output: 24.35 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:06<00:03, 22.36it/s, est. speed input: 24883.56 toks/s, output: 24.30 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:07<00:03, 22.37it/s, est. speed input: 24834.65 toks/s, output: 24.25 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:07<00:03, 22.32it/s, est. speed input: 24783.64 toks/s, output: 24.20 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:07<00:03, 22.32it/s, est. speed input: 24737.65 toks/s, output: 24.16 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:07<00:03, 22.32it/s, est. speed input: 24694.24 toks/s, output: 24.12 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:07<00:02, 22.30it/s, est. speed input: 24650.60 toks/s, output: 24.07 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:08<00:02, 22.28it/s, est. speed input: 24608.86 toks/s, output: 24.03 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:08<00:02, 22.27it/s, est. speed input: 24568.84 toks/s, output: 23.99 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:08<00:02, 23.37it/s, est. speed input: 24613.25 toks/s, output: 24.04 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:08<00:02, 23.05it/s, est. speed input: 24577.03 toks/s, output: 24.00 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:08<00:02, 22.82it/s, est. speed input: 24541.66 toks/s, output: 23.97 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:08<00:01, 22.65it/s, est. speed input: 24506.78 toks/s, output: 23.93 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:09<00:01, 22.56it/s, est. speed input: 24475.10 toks/s, output: 23.90 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:09<00:01, 22.46it/s, est. speed input: 24441.47 toks/s, output: 23.87 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:09<00:01, 22.40it/s, est. speed input: 24410.29 toks/s, output: 23.84 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:09<00:01, 22.35it/s, est. speed input: 24380.16 toks/s, output: 23.81 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:09<00:00, 22.34it/s, est. speed input: 24352.10 toks/s, output: 23.78 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:10<00:00, 22.34it/s, est. speed input: 24325.78 toks/s, output: 23.76 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:10<00:00, 22.34it/s, est. speed input: 24300.19 toks/s, output: 23.73 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:10<00:00, 22.32it/s, est. speed input: 24274.57 toks/s, output: 23.71 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:10<00:00, 22.31it/s, est. speed input: 24249.88 toks/s, output: 23.68 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:10<00:00, 22.31it/s, est. speed input: 24226.39 toks/s, output: 23.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 22.31it/s, est. speed input: 24288.89 toks/s, output: 23.72 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 23.72it/s, est. speed input: 24288.89 toks/s, output: 23.72 toks/s]
[rank0]:[W126 02:27:05.624914274 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 54.1s

测试结果:
  Requests/s:   21.77
  Tokens/s:     22311.26
  Total Reqs:   256
  Elapsed:      11.76s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     22289.50

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:27:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:27:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=62571) WARNING 01-26 02:27:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=62571) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=62571) WARNING 01-26 02:27:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.87 requests/s, 23438.43 total tokens/s, 22.87 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 02:27:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:27:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:27:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:27:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:27:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:27:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:27:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:27:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:27:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:27:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:27:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:27] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=62571) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=62571) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.09it/s]
(EngineCore_DP0 pid=62571) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.15s/it]
(EngineCore_DP0 pid=62571) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.12s/it]
(EngineCore_DP0 pid=62571) 
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=62571) [2026-01-26 02:27:30] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=62571) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  9.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.49it/s]
(EngineCore_DP0 pid=62571) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.27it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.64it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 236.10it/s]
Adding requests:  10%|▉         | 50/512 [00:00<00:01, 243.74it/s]
Adding requests:  15%|█▌        | 78/512 [00:00<00:01, 256.17it/s]
Adding requests:  20%|██        | 104/512 [00:00<00:01, 256.84it/s]
Adding requests:  25%|██▌       | 130/512 [00:00<00:01, 256.38it/s]
Adding requests:  31%|███       | 158/512 [00:00<00:01, 263.63it/s]
Adding requests:  37%|███▋      | 187/512 [00:00<00:01, 270.78it/s]
Adding requests:  42%|████▏     | 215/512 [00:00<00:01, 272.42it/s]
Adding requests:  47%|████▋     | 243/512 [00:00<00:00, 273.47it/s]
Adding requests:  53%|█████▎    | 271/512 [00:01<00:00, 270.96it/s]
Adding requests:  58%|█████▊    | 299/512 [00:01<00:00, 273.54it/s]
Adding requests:  64%|██████▍   | 327/512 [00:01<00:00, 271.23it/s]
Adding requests:  70%|██████▉   | 356/512 [00:01<00:00, 275.09it/s]
Adding requests:  75%|███████▌  | 384/512 [00:01<00:00, 274.31it/s]
Adding requests:  80%|████████  | 412/512 [00:01<00:00, 273.54it/s]
Adding requests:  86%|████████▌ | 440/512 [00:01<00:00, 274.55it/s]
Adding requests:  92%|█████████▏| 469/512 [00:01<00:00, 277.27it/s]
Adding requests:  97%|█████████▋| 499/512 [00:01<00:00, 282.70it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 271.35it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:00<00:02, 177.88it/s, est. speed input: 182165.10 toks/s, output: 177.88 toks/s]
Processed prompts:  12%|█▏        | 60/512 [00:00<00:08, 55.34it/s, est. speed input: 66253.71 toks/s, output: 64.70 toks/s]   
Processed prompts:  13%|█▎        | 69/512 [00:01<00:09, 44.62it/s, est. speed input: 55497.97 toks/s, output: 54.20 toks/s]
Processed prompts:  15%|█▍        | 76/512 [00:01<00:12, 36.23it/s, est. speed input: 48052.39 toks/s, output: 46.93 toks/s]
Processed prompts:  16%|█▌        | 81/512 [00:01<00:12, 34.78it/s, est. speed input: 46265.41 toks/s, output: 45.18 toks/s]
Processed prompts:  17%|█▋        | 85/512 [00:01<00:13, 32.18it/s, est. speed input: 44255.23 toks/s, output: 43.22 toks/s]
Processed prompts:  17%|█▋        | 89/512 [00:02<00:14, 30.03it/s, est. speed input: 42596.77 toks/s, output: 41.60 toks/s]
Processed prompts:  18%|█▊        | 93/512 [00:02<00:14, 28.28it/s, est. speed input: 41184.31 toks/s, output: 40.22 toks/s]
Processed prompts:  19%|█▉        | 96/512 [00:02<00:16, 25.38it/s, est. speed input: 39559.16 toks/s, output: 38.63 toks/s]
Processed prompts:  19%|█▉        | 99/512 [00:02<00:17, 23.16it/s, est. speed input: 38139.26 toks/s, output: 37.25 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:02<00:19, 21.53it/s, est. speed input: 36898.34 toks/s, output: 36.03 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:18, 21.99it/s, est. speed input: 36139.23 toks/s, output: 35.29 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:18, 22.31it/s, est. speed input: 35457.07 toks/s, output: 34.63 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:03<00:17, 22.56it/s, est. speed input: 34850.94 toks/s, output: 34.03 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:03<00:17, 22.73it/s, est. speed input: 34303.87 toks/s, output: 33.50 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:03<00:17, 22.84it/s, est. speed input: 33804.23 toks/s, output: 33.01 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:03<00:16, 22.92it/s, est. speed input: 33351.05 toks/s, output: 32.57 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:16, 22.98it/s, est. speed input: 32936.75 toks/s, output: 32.16 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:16, 23.03it/s, est. speed input: 32558.11 toks/s, output: 31.79 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:04<00:16, 23.04it/s, est. speed input: 32204.37 toks/s, output: 31.45 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:04<00:04, 70.41it/s, est. speed input: 38509.57 toks/s, output: 37.61 toks/s]
Processed prompts:  35%|███▌      | 181/512 [00:04<00:05, 62.04it/s, est. speed input: 38609.50 toks/s, output: 37.70 toks/s]
Processed prompts:  37%|███▋      | 187/512 [00:05<00:07, 42.24it/s, est. speed input: 37200.83 toks/s, output: 36.33 toks/s]
Processed prompts:  38%|███▊      | 192/512 [00:05<00:08, 39.05it/s, est. speed input: 36954.26 toks/s, output: 36.09 toks/s]
Processed prompts:  38%|███▊      | 196/512 [00:05<00:09, 34.95it/s, est. speed input: 36531.83 toks/s, output: 35.68 toks/s]
Processed prompts:  39%|███▉      | 200/512 [00:05<00:09, 31.75it/s, est. speed input: 36134.13 toks/s, output: 35.29 toks/s]
Processed prompts:  40%|███▉      | 204/512 [00:05<00:09, 30.92it/s, est. speed input: 35958.76 toks/s, output: 35.12 toks/s]
Processed prompts:  41%|████      | 208/512 [00:05<00:10, 28.61it/s, est. speed input: 35600.22 toks/s, output: 34.77 toks/s]
Processed prompts:  41%|████      | 211/512 [00:06<00:11, 25.25it/s, est. speed input: 35094.19 toks/s, output: 34.27 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:06<00:13, 22.87it/s, est. speed input: 34615.44 toks/s, output: 33.80 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:06<00:12, 22.92it/s, est. speed input: 34320.80 toks/s, output: 33.52 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:06<00:12, 22.95it/s, est. speed input: 34041.77 toks/s, output: 33.24 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:06<00:12, 22.97it/s, est. speed input: 33776.23 toks/s, output: 32.98 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:07<00:12, 22.97it/s, est. speed input: 33522.31 toks/s, output: 32.74 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:07<00:12, 22.98it/s, est. speed input: 33281.79 toks/s, output: 32.50 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:07<00:11, 23.00it/s, est. speed input: 33053.50 toks/s, output: 32.28 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:07<00:11, 22.99it/s, est. speed input: 32833.90 toks/s, output: 32.06 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:07<00:11, 23.01it/s, est. speed input: 32626.31 toks/s, output: 31.86 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:07<00:11, 23.01it/s, est. speed input: 32426.67 toks/s, output: 31.67 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:08<00:11, 23.00it/s, est. speed input: 32235.03 toks/s, output: 31.48 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:08<00:11, 23.02it/s, est. speed input: 32053.83 toks/s, output: 31.30 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:08<00:10, 23.01it/s, est. speed input: 31877.81 toks/s, output: 31.13 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:08<00:10, 23.00it/s, est. speed input: 31708.58 toks/s, output: 30.97 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:08<00:10, 23.01it/s, est. speed input: 31547.47 toks/s, output: 30.81 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:08<00:10, 23.02it/s, est. speed input: 31392.86 toks/s, output: 30.66 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:09<00:10, 23.01it/s, est. speed input: 31243.34 toks/s, output: 30.51 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:09<00:09, 23.00it/s, est. speed input: 31098.49 toks/s, output: 30.37 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:09<00:09, 22.99it/s, est. speed input: 30958.81 toks/s, output: 30.23 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:09<00:09, 22.99it/s, est. speed input: 30825.24 toks/s, output: 30.10 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:09<00:09, 22.99it/s, est. speed input: 30695.70 toks/s, output: 29.98 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:09<00:09, 22.99it/s, est. speed input: 30571.20 toks/s, output: 29.85 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:10<00:09, 22.99it/s, est. speed input: 30450.60 toks/s, output: 29.74 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:10<00:08, 22.99it/s, est. speed input: 30334.50 toks/s, output: 29.62 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:10<00:08, 22.99it/s, est. speed input: 30221.73 toks/s, output: 29.51 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:10<00:08, 22.99it/s, est. speed input: 30112.85 toks/s, output: 29.41 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:10<00:08, 23.00it/s, est. speed input: 30008.03 toks/s, output: 29.30 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:11<00:08, 23.01it/s, est. speed input: 29906.89 toks/s, output: 29.21 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:11<00:08, 22.99it/s, est. speed input: 29806.87 toks/s, output: 29.11 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:11<00:07, 22.98it/s, est. speed input: 29710.72 toks/s, output: 29.01 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:11<00:07, 22.98it/s, est. speed input: 29617.48 toks/s, output: 28.92 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:11<00:07, 22.99it/s, est. speed input: 29527.95 toks/s, output: 28.84 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:11<00:07, 23.01it/s, est. speed input: 29441.22 toks/s, output: 28.75 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:12<00:07, 22.99it/s, est. speed input: 29355.61 toks/s, output: 28.67 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:12<00:07, 22.97it/s, est. speed input: 29271.80 toks/s, output: 28.59 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:12<00:06, 22.97it/s, est. speed input: 29191.10 toks/s, output: 28.51 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:12<00:06, 22.95it/s, est. speed input: 29111.51 toks/s, output: 28.43 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:12<00:06, 22.95it/s, est. speed input: 29034.83 toks/s, output: 28.35 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:12<00:06, 22.94it/s, est. speed input: 28959.93 toks/s, output: 28.28 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:13<00:06, 22.96it/s, est. speed input: 28888.40 toks/s, output: 28.21 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:13<00:06, 22.95it/s, est. speed input: 28817.44 toks/s, output: 28.14 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:13<00:05, 22.95it/s, est. speed input: 28748.37 toks/s, output: 28.07 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:13<00:05, 22.96it/s, est. speed input: 28681.80 toks/s, output: 28.01 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:13<00:05, 22.96it/s, est. speed input: 28616.86 toks/s, output: 27.95 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:13<00:05, 22.97it/s, est. speed input: 28553.69 toks/s, output: 27.88 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:14<00:05, 22.96it/s, est. speed input: 28491.47 toks/s, output: 27.82 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:14<00:04, 22.97it/s, est. speed input: 28431.55 toks/s, output: 27.77 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:14<00:04, 22.97it/s, est. speed input: 28372.59 toks/s, output: 27.71 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:14<00:04, 22.96it/s, est. speed input: 28314.35 toks/s, output: 27.65 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:14<00:04, 22.95it/s, est. speed input: 28257.64 toks/s, output: 27.60 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:15<00:04, 22.96it/s, est. speed input: 28203.05 toks/s, output: 27.54 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:15<00:04, 22.96it/s, est. speed input: 28149.35 toks/s, output: 27.49 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:15<00:03, 22.96it/s, est. speed input: 28096.58 toks/s, output: 27.44 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:15<00:03, 22.94it/s, est. speed input: 28044.51 toks/s, output: 27.39 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:15<00:03, 22.92it/s, est. speed input: 27993.10 toks/s, output: 27.34 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:15<00:03, 22.90it/s, est. speed input: 27942.40 toks/s, output: 27.29 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:03, 22.89it/s, est. speed input: 27893.27 toks/s, output: 27.24 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:16<00:03, 22.91it/s, est. speed input: 27846.21 toks/s, output: 27.19 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:16<00:02, 22.92it/s, est. speed input: 27799.89 toks/s, output: 27.15 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:16<00:02, 22.93it/s, est. speed input: 27754.69 toks/s, output: 27.10 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:16<00:02, 22.91it/s, est. speed input: 27709.48 toks/s, output: 27.06 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:16<00:02, 22.92it/s, est. speed input: 27666.13 toks/s, output: 27.02 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:17<00:02, 22.93it/s, est. speed input: 27623.90 toks/s, output: 26.98 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:17<00:02, 22.94it/s, est. speed input: 27582.66 toks/s, output: 26.94 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:17<00:01, 22.94it/s, est. speed input: 27541.85 toks/s, output: 26.90 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:17<00:01, 22.93it/s, est. speed input: 27501.51 toks/s, output: 26.86 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:17<00:01, 22.93it/s, est. speed input: 27462.16 toks/s, output: 26.82 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:17<00:01, 22.93it/s, est. speed input: 27423.57 toks/s, output: 26.78 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:18<00:01, 22.94it/s, est. speed input: 27385.88 toks/s, output: 26.74 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:18<00:00, 22.94it/s, est. speed input: 27348.85 toks/s, output: 26.71 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:18<00:00, 22.93it/s, est. speed input: 27312.26 toks/s, output: 26.67 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:18<00:00, 22.90it/s, est. speed input: 27275.25 toks/s, output: 26.64 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:18<00:00, 22.89it/s, est. speed input: 27239.71 toks/s, output: 26.60 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:19<00:00, 22.89it/s, est. speed input: 27204.91 toks/s, output: 26.57 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:19<00:00, 24.64it/s, est. speed input: 27229.27 toks/s, output: 26.59 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 24.64it/s, est. speed input: 27335.74 toks/s, output: 26.70 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:19<00:00, 26.69it/s, est. speed input: 27335.74 toks/s, output: 26.70 toks/s]
[rank0]:[W126 02:28:12.156706917 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 66.9s

测试结果:
  Requests/s:   22.87
  Tokens/s:     23438.43
  Total Reqs:   512
  Elapsed:      22.39s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     23415.56

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:28:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:28:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=63759) WARNING 01-26 02:28:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=63759) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=63759) WARNING 01-26 02:28:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.05 requests/s, 23625.93 total tokens/s, 23.05 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 02:28:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:28:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:28:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:28:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:28:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:28:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:28:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:28:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:28:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:28:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:28:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:28:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:28:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:28:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:28:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:28:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:28:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=63759) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=63759) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.08it/s]
(EngineCore_DP0 pid=63759) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.15s/it]
(EngineCore_DP0 pid=63759) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.11s/it]
(EngineCore_DP0 pid=63759) 
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=63759) [2026-01-26 02:28:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=63759) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  9.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.53it/s]
(EngineCore_DP0 pid=63759) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00, -4.36it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 24/1024 [00:00<00:04, 239.76it/s]
Adding requests:   5%|▍         | 50/1024 [00:00<00:03, 250.57it/s]
Adding requests:   8%|▊         | 77/1024 [00:00<00:03, 257.67it/s]
Adding requests:  10%|█         | 103/1024 [00:00<00:03, 255.22it/s]
Adding requests:  13%|█▎        | 129/1024 [00:00<00:03, 255.96it/s]
Adding requests:  15%|█▌        | 156/1024 [00:00<00:03, 259.29it/s]
Adding requests:  18%|█▊        | 185/1024 [00:00<00:03, 268.80it/s]
Adding requests:  21%|██        | 214/1024 [00:00<00:02, 272.17it/s]
Adding requests:  24%|██▎       | 242/1024 [00:00<00:02, 269.26it/s]
Adding requests:  26%|██▋       | 269/1024 [00:01<00:02, 268.15it/s]
Adding requests:  29%|██▉       | 298/1024 [00:01<00:02, 271.57it/s]
Adding requests:  32%|███▏      | 326/1024 [00:01<00:02, 273.36it/s]
Adding requests:  35%|███▍      | 355/1024 [00:01<00:02, 275.47it/s]
Adding requests:  37%|███▋      | 383/1024 [00:01<00:02, 275.87it/s]
Adding requests:  40%|████      | 412/1024 [00:01<00:02, 278.52it/s]
Adding requests:  43%|████▎     | 440/1024 [00:01<00:02, 275.90it/s]
Adding requests:  46%|████▌     | 469/1024 [00:01<00:02, 276.94it/s]
Adding requests:  49%|████▊     | 499/1024 [00:01<00:01, 280.43it/s]
Adding requests:  52%|█████▏    | 530/1024 [00:01<00:01, 285.78it/s]
Adding requests:  55%|█████▍    | 559/1024 [00:02<00:01, 283.15it/s]
Adding requests:  57%|█████▋    | 588/1024 [00:02<00:01, 266.62it/s]
Adding requests:  60%|██████    | 616/1024 [00:02<00:01, 268.69it/s]
Adding requests:  63%|██████▎   | 644/1024 [00:02<00:01, 259.85it/s]
Adding requests:  66%|██████▌   | 671/1024 [00:02<00:01, 256.19it/s]
Adding requests:  68%|██████▊   | 700/1024 [00:02<00:01, 264.91it/s]
Adding requests:  71%|███████   | 727/1024 [00:02<00:01, 261.12it/s]
Adding requests:  74%|███████▎  | 754/1024 [00:02<00:01, 262.53it/s]
Adding requests:  76%|███████▋  | 782/1024 [00:02<00:00, 267.08it/s]
Adding requests:  79%|███████▉  | 809/1024 [00:03<00:00, 267.22it/s]
Adding requests:  82%|████████▏ | 838/1024 [00:03<00:00, 272.25it/s]
Adding requests:  85%|████████▍ | 866/1024 [00:03<00:00, 270.27it/s]
Adding requests:  87%|████████▋ | 895/1024 [00:03<00:00, 275.43it/s]
Adding requests:  90%|█████████ | 923/1024 [00:03<00:00, 266.05it/s]
Adding requests:  93%|█████████▎| 951/1024 [00:03<00:00, 268.05it/s]
Adding requests:  96%|█████████▌| 980/1024 [00:03<00:00, 272.54it/s]
Adding requests:  98%|█████████▊| 1008/1024 [00:03<00:00, 269.88it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 268.87it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:00<00:02, 331.48it/s, est. speed input: 339482.85 toks/s, output: 331.49 toks/s]
Processed prompts:  11%|█▏        | 116/1024 [00:01<00:15, 59.18it/s, est. speed input: 73385.50 toks/s, output: 71.67 toks/s]  
Processed prompts:  13%|█▎        | 132/1024 [00:02<00:19, 45.28it/s, est. speed input: 58668.40 toks/s, output: 57.29 toks/s]
Processed prompts:  14%|█▍        | 142/1024 [00:02<00:21, 41.78it/s, est. speed input: 54937.34 toks/s, output: 53.65 toks/s]
Processed prompts:  15%|█▍        | 149/1024 [00:02<00:23, 36.73it/s, est. speed input: 51036.91 toks/s, output: 49.84 toks/s]
Processed prompts:  15%|█▌        | 155/1024 [00:03<00:27, 31.86it/s, est. speed input: 47627.39 toks/s, output: 46.51 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:03<00:29, 28.82it/s, est. speed input: 45132.03 toks/s, output: 44.07 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:04<00:31, 27.31it/s, est. speed input: 43316.61 toks/s, output: 42.30 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:04<00:32, 26.16it/s, est. speed input: 41776.33 toks/s, output: 40.80 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:04<00:33, 25.31it/s, est. speed input: 40459.01 toks/s, output: 39.51 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:05<00:33, 24.70it/s, est. speed input: 39318.77 toks/s, output: 38.40 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:05<00:33, 24.74it/s, est. speed input: 38488.02 toks/s, output: 37.59 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:05<00:33, 24.27it/s, est. speed input: 37598.91 toks/s, output: 36.72 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:06<00:33, 23.94it/s, est. speed input: 36808.78 toks/s, output: 35.95 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:06<00:33, 23.72it/s, est. speed input: 36105.80 toks/s, output: 35.26 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:06<00:33, 23.55it/s, est. speed input: 35473.30 toks/s, output: 34.64 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:07<00:33, 23.44it/s, est. speed input: 34903.34 toks/s, output: 34.09 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:07<00:33, 23.35it/s, est. speed input: 34383.32 toks/s, output: 33.58 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:07<00:32, 23.30it/s, est. speed input: 33910.76 toks/s, output: 33.12 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:08<00:32, 23.26it/s, est. speed input: 33477.80 toks/s, output: 32.69 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:08<00:32, 23.23it/s, est. speed input: 33079.94 toks/s, output: 32.30 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:08<00:31, 23.20it/s, est. speed input: 32713.19 toks/s, output: 31.95 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:09<00:31, 23.19it/s, est. speed input: 32373.83 toks/s, output: 31.61 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:09<00:31, 23.17it/s, est. speed input: 32057.55 toks/s, output: 31.31 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:09<00:31, 23.15it/s, est. speed input: 31763.35 toks/s, output: 31.02 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:10<00:30, 23.14it/s, est. speed input: 31489.48 toks/s, output: 30.75 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:10<00:30, 23.13it/s, est. speed input: 31232.65 toks/s, output: 30.50 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:10<00:30, 23.12it/s, est. speed input: 30992.06 toks/s, output: 30.27 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:11<00:29, 23.12it/s, est. speed input: 30766.94 toks/s, output: 30.05 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:11<00:29, 23.11it/s, est. speed input: 30553.93 toks/s, output: 29.84 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:28, 23.11it/s, est. speed input: 30353.73 toks/s, output: 29.64 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:12<00:28, 23.11it/s, est. speed input: 30165.82 toks/s, output: 29.46 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:12<00:28, 23.12it/s, est. speed input: 29989.21 toks/s, output: 29.29 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:12<00:27, 23.13it/s, est. speed input: 29821.63 toks/s, output: 29.12 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:13<00:27, 23.12it/s, est. speed input: 29661.55 toks/s, output: 28.97 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:13<00:27, 23.13it/s, est. speed input: 29510.43 toks/s, output: 28.82 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:14<00:26, 23.12it/s, est. speed input: 29365.91 toks/s, output: 28.68 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:14<00:26, 23.12it/s, est. speed input: 29228.82 toks/s, output: 28.54 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:14<00:26, 23.12it/s, est. speed input: 29097.73 toks/s, output: 28.42 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:15<00:25, 23.12it/s, est. speed input: 28973.22 toks/s, output: 28.29 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:15<00:25, 23.11it/s, est. speed input: 28853.32 toks/s, output: 28.18 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:15<00:25, 23.11it/s, est. speed input: 28739.01 toks/s, output: 28.07 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:16<00:24, 23.10it/s, est. speed input: 28629.19 toks/s, output: 27.96 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:16<00:24, 23.10it/s, est. speed input: 28524.21 toks/s, output: 27.86 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:16<00:24, 23.09it/s, est. speed input: 28423.27 toks/s, output: 27.76 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:17<00:23, 23.10it/s, est. speed input: 28327.06 toks/s, output: 27.66 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:17<00:23, 23.09it/s, est. speed input: 28234.23 toks/s, output: 27.57 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:17<00:23, 23.09it/s, est. speed input: 28144.81 toks/s, output: 27.49 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:18<00:22, 23.08it/s, est. speed input: 28058.54 toks/s, output: 27.40 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:18<00:22, 23.09it/s, est. speed input: 27976.00 toks/s, output: 27.32 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:18<00:22, 23.09it/s, est. speed input: 27896.35 toks/s, output: 27.24 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:19<00:21, 23.09it/s, est. speed input: 27819.57 toks/s, output: 27.17 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:19<00:21, 23.08it/s, est. speed input: 27745.30 toks/s, output: 27.09 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:19<00:21, 23.08it/s, est. speed input: 27673.83 toks/s, output: 27.03 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:20<00:20, 23.08it/s, est. speed input: 27604.49 toks/s, output: 26.96 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:20<00:20, 23.08it/s, est. speed input: 27537.67 toks/s, output: 26.89 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:20<00:20, 23.08it/s, est. speed input: 27472.99 toks/s, output: 26.83 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:21<00:19, 23.07it/s, est. speed input: 27410.23 toks/s, output: 26.77 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:21<00:19, 23.08it/s, est. speed input: 27349.90 toks/s, output: 26.71 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:21<00:18, 23.08it/s, est. speed input: 27291.51 toks/s, output: 26.65 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:22<00:18, 23.08it/s, est. speed input: 27234.77 toks/s, output: 26.60 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:22<00:18, 23.09it/s, est. speed input: 27180.01 toks/s, output: 26.54 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:23<00:17, 23.09it/s, est. speed input: 27126.98 toks/s, output: 26.49 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:23<00:17, 23.09it/s, est. speed input: 27075.43 toks/s, output: 26.44 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:23<00:17, 23.10it/s, est. speed input: 27025.56 toks/s, output: 26.39 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:24<00:16, 23.10it/s, est. speed input: 26977.00 toks/s, output: 26.34 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:24<00:16, 23.09it/s, est. speed input: 26929.59 toks/s, output: 26.30 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:24<00:16, 23.09it/s, est. speed input: 26883.65 toks/s, output: 26.25 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:25<00:15, 23.09it/s, est. speed input: 26838.96 toks/s, output: 26.21 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:25<00:15, 23.09it/s, est. speed input: 26795.35 toks/s, output: 26.17 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:25<00:15, 23.09it/s, est. speed input: 26753.04 toks/s, output: 26.13 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:26<00:14, 23.09it/s, est. speed input: 26711.77 toks/s, output: 26.09 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:26<00:14, 23.09it/s, est. speed input: 26671.60 toks/s, output: 26.05 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:26<00:06, 48.30it/s, est. speed input: 27791.67 toks/s, output: 27.14 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:27<00:06, 41.00it/s, est. speed input: 27739.01 toks/s, output: 27.09 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:27<00:07, 35.77it/s, est. speed input: 27687.70 toks/s, output: 27.04 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:27<00:08, 32.03it/s, est. speed input: 27637.43 toks/s, output: 26.99 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:28<00:08, 29.39it/s, est. speed input: 27588.83 toks/s, output: 26.94 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:28<00:09, 27.55it/s, est. speed input: 27542.92 toks/s, output: 26.90 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:28<00:09, 26.27it/s, est. speed input: 27497.99 toks/s, output: 26.85 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:29<00:09, 26.09it/s, est. speed input: 27484.76 toks/s, output: 26.84 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:29<00:09, 25.21it/s, est. speed input: 27441.43 toks/s, output: 26.80 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:29<00:09, 24.60it/s, est. speed input: 27399.10 toks/s, output: 26.76 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:30<00:08, 24.17it/s, est. speed input: 27357.47 toks/s, output: 26.72 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:30<00:08, 23.88it/s, est. speed input: 27317.16 toks/s, output: 26.68 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:31<00:08, 23.68it/s, est. speed input: 27277.55 toks/s, output: 26.64 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:31<00:08, 23.53it/s, est. speed input: 27238.84 toks/s, output: 26.60 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:31<00:07, 23.43it/s, est. speed input: 27200.86 toks/s, output: 26.56 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:32<00:07, 23.36it/s, est. speed input: 27163.69 toks/s, output: 26.53 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:32<00:07, 23.31it/s, est. speed input: 27127.41 toks/s, output: 26.49 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:32<00:06, 23.28it/s, est. speed input: 27091.96 toks/s, output: 26.46 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:33<00:06, 23.25it/s, est. speed input: 27056.97 toks/s, output: 26.42 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:33<00:06, 23.23it/s, est. speed input: 27022.80 toks/s, output: 26.39 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:33<00:05, 23.22it/s, est. speed input: 26989.23 toks/s, output: 26.36 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:34<00:05, 23.21it/s, est. speed input: 26956.56 toks/s, output: 26.32 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:34<00:05, 23.21it/s, est. speed input: 26924.72 toks/s, output: 26.29 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:34<00:04, 23.20it/s, est. speed input: 26893.00 toks/s, output: 26.26 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:35<00:04, 23.20it/s, est. speed input: 26862.07 toks/s, output: 26.23 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:35<00:04, 23.20it/s, est. speed input: 26831.92 toks/s, output: 26.20 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:35<00:03, 23.20it/s, est. speed input: 26802.33 toks/s, output: 26.17 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:36<00:03, 23.20it/s, est. speed input: 26773.35 toks/s, output: 26.15 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:36<00:03, 23.11it/s, est. speed input: 26741.62 toks/s, output: 26.11 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:36<00:02, 23.05it/s, est. speed input: 26710.36 toks/s, output: 26.08 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:37<00:02, 22.99it/s, est. speed input: 26679.30 toks/s, output: 26.05 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:37<00:02, 22.94it/s, est. speed input: 26648.56 toks/s, output: 26.02 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:37<00:01, 22.91it/s, est. speed input: 26618.52 toks/s, output: 25.99 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:38<00:01, 22.89it/s, est. speed input: 26589.07 toks/s, output: 25.97 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:38<00:00, 22.88it/s, est. speed input: 26560.27 toks/s, output: 25.94 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:38<00:00, 22.89it/s, est. speed input: 26532.28 toks/s, output: 25.91 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:39<00:00, 23.73it/s, est. speed input: 26532.72 toks/s, output: 25.91 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 23.73it/s, est. speed input: 26688.88 toks/s, output: 26.06 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 26.06it/s, est. speed input: 26688.88 toks/s, output: 26.06 toks/s]
[rank0]:[W126 02:29:44.656140203 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 91.5s

测试结果:
  Requests/s:   23.05
  Tokens/s:     23625.93
  Total Reqs:   1024
  Elapsed:      44.43s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     23602.88

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:30:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:30:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=65384) WARNING 01-26 02:30:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=65384) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=65384) WARNING 01-26 02:30:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 11.99 requests/s, 12287.27 total tokens/s, 11.99 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 02:30:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:30:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:30:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:30:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:30:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:30:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:30:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:30:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:30:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:30:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:30:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:30:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:30:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:16] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=65384) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=65384) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.09it/s]
(EngineCore_DP0 pid=65384) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.18s/it]
(EngineCore_DP0 pid=65384) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.14s/it]
(EngineCore_DP0 pid=65384) 
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=65384) [2026-01-26 02:30:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=65384) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  9.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.61it/s]
(EngineCore_DP0 pid=65384) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.55it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.70it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  9.05it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  9.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.16it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.99it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 244.23it/s]
Adding requests:   3%|▎         | 52/2048 [00:00<00:07, 255.38it/s]
Adding requests:   4%|▍         | 79/2048 [00:00<00:07, 261.30it/s]
Adding requests:   5%|▌         | 106/2048 [00:00<00:07, 256.19it/s]
Adding requests:   6%|▋         | 132/2048 [00:00<00:07, 249.27it/s]
Adding requests:   8%|▊         | 158/2048 [00:00<00:07, 252.55it/s]
Adding requests:   9%|▉         | 184/2048 [00:00<00:07, 254.86it/s]
Adding requests:  10%|█         | 210/2048 [00:00<00:07, 254.46it/s]
Adding requests:  12%|█▏        | 237/2048 [00:00<00:07, 257.07it/s]
Adding requests:  13%|█▎        | 263/2048 [00:01<00:06, 255.95it/s]
Adding requests:  14%|█▍        | 290/2048 [00:01<00:06, 258.43it/s]
Adding requests:  16%|█▌        | 318/2048 [00:01<00:06, 263.53it/s]
Adding requests:  17%|█▋        | 345/2048 [00:01<00:06, 260.56it/s]
Adding requests:  18%|█▊        | 372/2048 [00:01<00:06, 261.00it/s]
Adding requests:  19%|█▉        | 399/2048 [00:01<00:06, 258.07it/s]
Adding requests:  21%|██        | 427/2048 [00:01<00:06, 263.85it/s]
Adding requests:  22%|██▏       | 454/2048 [00:01<00:06, 255.98it/s]
Adding requests:  24%|██▎       | 482/2048 [00:01<00:06, 260.06it/s]
Adding requests:  25%|██▍       | 509/2048 [00:01<00:05, 261.43it/s]
Adding requests:  26%|██▋       | 538/2048 [00:02<00:05, 266.76it/s]
Adding requests:  28%|██▊       | 567/2048 [00:02<00:05, 271.04it/s]
Adding requests:  29%|██▉       | 595/2048 [00:02<00:05, 261.07it/s]
Adding requests:  30%|███       | 622/2048 [00:02<00:05, 260.65it/s]
Adding requests:  32%|███▏      | 649/2048 [00:02<00:05, 254.92it/s]
Adding requests:  33%|███▎      | 675/2048 [00:02<00:05, 252.62it/s]
Adding requests:  34%|███▍      | 703/2048 [00:02<00:05, 258.24it/s]
Adding requests:  36%|███▌      | 729/2048 [00:02<00:05, 245.97it/s]
Adding requests:  37%|███▋      | 755/2048 [00:02<00:05, 249.00it/s]
Adding requests:  38%|███▊      | 782/2048 [00:03<00:04, 254.58it/s]
Adding requests:  39%|███▉      | 808/2048 [00:03<00:04, 255.67it/s]
Adding requests:  41%|████      | 836/2048 [00:03<00:04, 262.72it/s]
Adding requests:  42%|████▏     | 863/2048 [00:03<00:04, 254.09it/s]
Adding requests:  44%|████▎     | 891/2048 [00:03<00:04, 259.98it/s]
Adding requests:  45%|████▍     | 918/2048 [00:03<00:04, 257.16it/s]
Adding requests:  46%|████▌     | 944/2048 [00:03<00:04, 255.12it/s]
Adding requests:  47%|████▋     | 971/2048 [00:03<00:04, 256.82it/s]
Adding requests:  49%|████▊     | 997/2048 [00:03<00:04, 253.76it/s]
Adding requests:  50%|████▉     | 1023/2048 [00:03<00:04, 254.86it/s]
Adding requests:  51%|█████     | 1049/2048 [00:04<00:03, 254.68it/s]
Adding requests:  52%|█████▏    | 1075/2048 [00:04<00:03, 255.74it/s]
Adding requests:  54%|█████▍    | 1101/2048 [00:04<00:03, 256.01it/s]
Adding requests:  55%|█████▌    | 1129/2048 [00:04<00:03, 261.83it/s]
Adding requests:  56%|█████▋    | 1156/2048 [00:04<00:03, 251.70it/s]
Adding requests:  58%|█████▊    | 1182/2048 [00:04<00:03, 253.64it/s]
Adding requests:  59%|█████▉    | 1208/2048 [00:04<00:03, 252.34it/s]
Adding requests:  60%|██████    | 1234/2048 [00:04<00:03, 252.37it/s]
Adding requests:  62%|██████▏   | 1260/2048 [00:04<00:03, 245.85it/s]
Adding requests:  63%|██████▎   | 1285/2048 [00:05<00:03, 242.75it/s]
Adding requests:  64%|██████▍   | 1310/2048 [00:05<00:03, 243.60it/s]
Adding requests:  65%|██████▌   | 1336/2048 [00:05<00:02, 247.35it/s]
Adding requests:  67%|██████▋   | 1364/2048 [00:05<00:02, 255.36it/s]
Adding requests:  68%|██████▊   | 1391/2048 [00:05<00:02, 257.59it/s]
Adding requests:  69%|██████▉   | 1417/2048 [00:05<00:02, 253.64it/s]
Adding requests:  71%|███████   | 1444/2048 [00:05<00:02, 258.15it/s]
Adding requests:  72%|███████▏  | 1470/2048 [00:05<00:02, 257.08it/s]
Adding requests:  73%|███████▎  | 1497/2048 [00:05<00:02, 257.94it/s]
Adding requests:  74%|███████▍  | 1524/2048 [00:05<00:02, 260.71it/s]
Adding requests:  76%|███████▌  | 1551/2048 [00:06<00:01, 259.11it/s]
Adding requests:  77%|███████▋  | 1577/2048 [00:06<00:01, 254.47it/s]
Adding requests:  78%|███████▊  | 1603/2048 [00:06<00:01, 255.71it/s]
Adding requests:  80%|███████▉  | 1629/2048 [00:06<00:01, 250.93it/s]
Adding requests:  81%|████████  | 1655/2048 [00:06<00:01, 246.89it/s]
Adding requests:  82%|████████▏ | 1681/2048 [00:06<00:01, 249.32it/s]
Adding requests:  83%|████████▎ | 1708/2048 [00:06<00:01, 254.45it/s]
Adding requests:  85%|████████▍ | 1734/2048 [00:06<00:01, 253.55it/s]
Adding requests:  86%|████████▌ | 1760/2048 [00:06<00:01, 253.17it/s]
Adding requests:  87%|████████▋ | 1786/2048 [00:06<00:01, 254.91it/s]
Adding requests:  88%|████████▊ | 1812/2048 [00:07<00:00, 254.94it/s]
Adding requests:  90%|████████▉ | 1838/2048 [00:07<00:00, 254.70it/s]
Adding requests:  91%|█████████ | 1865/2048 [00:07<00:00, 257.32it/s]
Adding requests:  92%|█████████▏| 1892/2048 [00:07<00:00, 259.56it/s]
Adding requests:  94%|█████████▎| 1919/2048 [00:07<00:00, 261.94it/s]
Adding requests:  95%|█████████▌| 1946/2048 [00:07<00:00, 263.85it/s]
Adding requests:  96%|█████████▋| 1973/2048 [00:07<00:00, 263.89it/s]
Adding requests:  98%|█████████▊| 2000/2048 [00:07<00:00, 253.45it/s]
Adding requests:  99%|█████████▉| 2026/2048 [00:07<00:00, 246.35it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 255.06it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:00<00:07, 276.17it/s, est. speed input: 282827.77 toks/s, output: 276.18 toks/s]
Processed prompts:   5%|▌         | 110/2048 [00:01<00:35, 55.13it/s, est. speed input: 68755.77 toks/s, output: 67.14 toks/s]  
Processed prompts:   6%|▌         | 123/2048 [00:02<01:04, 30.00it/s, est. speed input: 42263.82 toks/s, output: 41.27 toks/s]
Processed prompts:   6%|▋         | 131/2048 [00:04<01:38, 19.39it/s, est. speed input: 31035.60 toks/s, output: 30.31 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:05<01:57, 16.21it/s, est. speed input: 26394.78 toks/s, output: 25.78 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:07<02:08, 14.69it/s, est. speed input: 23677.00 toks/s, output: 23.12 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:08<02:15, 13.76it/s, est. speed input: 21835.53 toks/s, output: 21.32 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:09<02:20, 13.16it/s, est. speed input: 20502.09 toks/s, output: 20.02 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:11<02:23, 12.77it/s, est. speed input: 19492.51 toks/s, output: 19.04 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:12<02:25, 12.50it/s, est. speed input: 18701.40 toks/s, output: 18.26 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:13<02:26, 12.32it/s, est. speed input: 18065.05 toks/s, output: 17.64 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:15<02:26, 12.20it/s, est. speed input: 17543.29 toks/s, output: 17.13 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:16<02:26, 12.11it/s, est. speed input: 17105.78 toks/s, output: 16.70 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:17<01:51, 15.58it/s, est. speed input: 17634.77 toks/s, output: 17.22 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:19<01:59, 14.48it/s, est. speed input: 17252.86 toks/s, output: 16.85 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:20<02:04, 13.71it/s, est. speed input: 16921.06 toks/s, output: 16.52 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:21<02:08, 13.17it/s, est. speed input: 16629.60 toks/s, output: 16.24 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:23<02:11, 12.79it/s, est. speed input: 16372.64 toks/s, output: 15.99 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:24<02:12, 12.53it/s, est. speed input: 16144.08 toks/s, output: 15.77 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:25<02:13, 12.34it/s, est. speed input: 15938.55 toks/s, output: 15.56 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:27<02:13, 12.21it/s, est. speed input: 15753.45 toks/s, output: 15.38 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:28<02:13, 12.12it/s, est. speed input: 15585.64 toks/s, output: 15.22 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:29<02:12, 12.06it/s, est. speed input: 15432.70 toks/s, output: 15.07 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:31<02:11, 12.01it/s, est. speed input: 15293.23 toks/s, output: 14.93 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:32<02:10, 11.98it/s, est. speed input: 15165.17 toks/s, output: 14.81 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:33<02:09, 11.96it/s, est. speed input: 15047.27 toks/s, output: 14.69 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:35<02:08, 11.94it/s, est. speed input: 14938.75 toks/s, output: 14.59 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:36<02:07, 11.93it/s, est. speed input: 14837.65 toks/s, output: 14.49 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:37<02:05, 11.92it/s, est. speed input: 14743.90 toks/s, output: 14.40 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:39<02:04, 11.92it/s, est. speed input: 14656.38 toks/s, output: 14.31 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:40<02:03, 11.91it/s, est. speed input: 14574.75 toks/s, output: 14.23 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:41<02:02, 11.91it/s, est. speed input: 14498.15 toks/s, output: 14.16 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:43<02:00, 11.91it/s, est. speed input: 14426.69 toks/s, output: 14.09 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:44<01:59, 11.90it/s, est. speed input: 14358.89 toks/s, output: 14.02 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:45<01:58, 11.90it/s, est. speed input: 14295.35 toks/s, output: 13.96 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:47<01:56, 11.90it/s, est. speed input: 14235.46 toks/s, output: 13.90 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:48<01:28, 15.42it/s, est. speed input: 14510.57 toks/s, output: 14.17 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:50<01:33, 14.36it/s, est. speed input: 14448.16 toks/s, output: 14.11 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:51<01:37, 13.63it/s, est. speed input: 14388.83 toks/s, output: 14.05 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:52<01:39, 13.11it/s, est. speed input: 14332.67 toks/s, output: 14.00 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:54<01:41, 12.74it/s, est. speed input: 14279.12 toks/s, output: 13.94 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:55<01:42, 12.49it/s, est. speed input: 14228.43 toks/s, output: 13.89 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:56<01:30, 13.93it/s, est. speed input: 14311.16 toks/s, output: 13.98 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:57<01:33, 13.27it/s, est. speed input: 14261.46 toks/s, output: 13.93 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:58<01:35, 12.83it/s, est. speed input: 14214.02 toks/s, output: 13.88 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:00<01:36, 12.54it/s, est. speed input: 14168.64 toks/s, output: 13.84 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:01<01:37, 12.34it/s, est. speed input: 14125.32 toks/s, output: 13.79 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:02<01:36, 12.20it/s, est. speed input: 14083.75 toks/s, output: 13.75 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [01:04<01:36, 12.11it/s, est. speed input: 14043.87 toks/s, output: 13.71 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:05<01:35, 12.04it/s, est. speed input: 14005.66 toks/s, output: 13.68 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:07<01:34, 12.00it/s, est. speed input: 13969.02 toks/s, output: 13.64 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:08<01:33, 11.97it/s, est. speed input: 13933.90 toks/s, output: 13.61 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:09<01:32, 11.95it/s, est. speed input: 13899.99 toks/s, output: 13.57 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:11<01:31, 11.93it/s, est. speed input: 13867.40 toks/s, output: 13.54 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:12<01:29, 11.92it/s, est. speed input: 13836.06 toks/s, output: 13.51 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:13<01:28, 11.91it/s, est. speed input: 13805.89 toks/s, output: 13.48 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:15<01:27, 11.91it/s, est. speed input: 13776.74 toks/s, output: 13.45 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:16<01:25, 11.90it/s, est. speed input: 13748.62 toks/s, output: 13.43 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:17<01:24, 11.90it/s, est. speed input: 13721.47 toks/s, output: 13.40 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:19<01:03, 15.41it/s, est. speed input: 13899.34 toks/s, output: 13.57 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:20<01:06, 14.36it/s, est. speed input: 13870.58 toks/s, output: 13.55 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:21<01:09, 13.62it/s, est. speed input: 13842.76 toks/s, output: 13.52 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:23<01:10, 13.10it/s, est. speed input: 13815.79 toks/s, output: 13.49 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:24<01:11, 12.74it/s, est. speed input: 13789.67 toks/s, output: 13.47 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:25<01:11, 12.48it/s, est. speed input: 13764.42 toks/s, output: 13.44 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:27<01:11, 12.31it/s, est. speed input: 13739.92 toks/s, output: 13.42 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:28<01:10, 12.18it/s, est. speed input: 13716.20 toks/s, output: 13.39 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:29<01:09, 12.10it/s, est. speed input: 13693.22 toks/s, output: 13.37 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [01:31<01:08, 12.03it/s, est. speed input: 13670.85 toks/s, output: 13.35 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:32<01:07, 11.99it/s, est. speed input: 13649.16 toks/s, output: 13.33 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:33<01:06, 11.96it/s, est. speed input: 13628.11 toks/s, output: 13.31 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:35<01:05, 11.94it/s, est. speed input: 13607.61 toks/s, output: 13.29 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:36<01:04, 11.93it/s, est. speed input: 13587.67 toks/s, output: 13.27 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [01:37<01:02, 11.92it/s, est. speed input: 13568.36 toks/s, output: 13.25 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:39<01:01, 11.91it/s, est. speed input: 13549.50 toks/s, output: 13.23 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:40<01:00, 11.90it/s, est. speed input: 13531.14 toks/s, output: 13.21 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:41<00:58, 11.90it/s, est. speed input: 13513.29 toks/s, output: 13.20 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:43<00:57, 11.90it/s, est. speed input: 13495.84 toks/s, output: 13.18 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:44<00:56, 11.90it/s, est. speed input: 13478.90 toks/s, output: 13.16 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:46<00:54, 11.89it/s, est. speed input: 13462.34 toks/s, output: 13.15 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:47<00:53, 11.89it/s, est. speed input: 13446.28 toks/s, output: 13.13 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:48<00:52, 11.89it/s, est. speed input: 13430.50 toks/s, output: 13.12 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:50<00:50, 11.89it/s, est. speed input: 13415.20 toks/s, output: 13.10 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:51<00:37, 15.40it/s, est. speed input: 13545.38 toks/s, output: 13.23 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:52<00:38, 14.35it/s, est. speed input: 13529.10 toks/s, output: 13.21 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:54<00:39, 13.62it/s, est. speed input: 13513.16 toks/s, output: 13.20 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:55<00:40, 13.10it/s, est. speed input: 13497.56 toks/s, output: 13.18 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:56<00:40, 12.74it/s, est. speed input: 13482.32 toks/s, output: 13.17 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:58<00:39, 12.48it/s, est. speed input: 13467.44 toks/s, output: 13.15 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:59<00:38, 12.30it/s, est. speed input: 13452.81 toks/s, output: 13.14 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:00<00:37, 12.18it/s, est. speed input: 13438.52 toks/s, output: 13.12 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [02:02<00:36, 12.09it/s, est. speed input: 13424.59 toks/s, output: 13.11 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [02:03<00:31, 13.61it/s, est. speed input: 13467.74 toks/s, output: 13.15 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [02:04<00:31, 13.05it/s, est. speed input: 13453.69 toks/s, output: 13.14 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [02:05<00:31, 12.68it/s, est. speed input: 13439.96 toks/s, output: 13.12 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [02:07<00:30, 12.43it/s, est. speed input: 13426.47 toks/s, output: 13.11 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [02:08<00:29, 12.26it/s, est. speed input: 13413.27 toks/s, output: 13.10 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [02:09<00:28, 12.14it/s, est. speed input: 13400.33 toks/s, output: 13.09 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [02:11<00:27, 12.06it/s, est. speed input: 13387.66 toks/s, output: 13.07 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [02:12<00:26, 12.01it/s, est. speed input: 13375.27 toks/s, output: 13.06 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [02:13<00:25, 11.97it/s, est. speed input: 13363.15 toks/s, output: 13.05 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [02:15<00:23, 11.95it/s, est. speed input: 13351.24 toks/s, output: 13.04 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [02:16<00:22, 11.93it/s, est. speed input: 13339.54 toks/s, output: 13.03 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:17<00:21, 11.91it/s, est. speed input: 13328.14 toks/s, output: 13.02 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:19<00:19, 11.91it/s, est. speed input: 13316.95 toks/s, output: 13.00 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:20<00:18, 11.90it/s, est. speed input: 13305.92 toks/s, output: 12.99 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:21<00:12, 15.45it/s, est. speed input: 13410.33 toks/s, output: 13.10 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:23<00:12, 14.38it/s, est. speed input: 13398.77 toks/s, output: 13.08 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [02:24<00:11, 13.64it/s, est. speed input: 13387.44 toks/s, output: 13.07 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [02:25<00:10, 13.12it/s, est. speed input: 13376.31 toks/s, output: 13.06 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [02:27<00:09, 12.75it/s, est. speed input: 13365.36 toks/s, output: 13.05 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:28<00:08, 12.49it/s, est. speed input: 13354.58 toks/s, output: 13.04 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:29<00:07, 12.31it/s, est. speed input: 13343.97 toks/s, output: 13.03 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:31<00:06, 12.18it/s, est. speed input: 13333.31 toks/s, output: 13.02 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [02:32<00:05, 12.08it/s, est. speed input: 13322.88 toks/s, output: 13.01 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:33<00:03, 12.02it/s, est. speed input: 13312.62 toks/s, output: 13.00 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:35<00:02, 11.97it/s, est. speed input: 13302.53 toks/s, output: 12.99 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:36<00:01, 13.55it/s, est. speed input: 13338.11 toks/s, output: 13.03 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:36<00:00, 13.55it/s, est. speed input: 13429.88 toks/s, output: 13.12 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:36<00:00, 13.12it/s, est. speed input: 13429.88 toks/s, output: 13.12 toks/s]
[rank0]:[W126 02:33:24.326476444 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 220.3s

测试结果:
  Requests/s:   11.99
  Tokens/s:     12287.27
  Total Reqs:   2048
  Elapsed:      170.84s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     12275.28

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:34:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:34:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=68931) WARNING 01-26 02:34:11 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=68931) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=68931) WARNING 01-26 02:34:22 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.61 requests/s, 5754.02 total tokens/s, 5.61 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 02:34:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:34:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:34:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:34:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:34:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:34:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:34:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:34:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:34:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:34:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:34:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:34:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:34:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:34:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:34:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:34:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:34:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=68931) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=68931) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.11it/s]
(EngineCore_DP0 pid=68931) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.16s/it]
(EngineCore_DP0 pid=68931) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.12s/it]
(EngineCore_DP0 pid=68931) 
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=68931) [2026-01-26 02:34:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=68931) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  8.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  8.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  9.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.49it/s]
(EngineCore_DP0 pid=68931) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.34it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.29it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.76it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  9.02it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  9.17it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.04it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/4096 [00:00<00:17, 234.78it/s]
Adding requests:   1%|          | 49/4096 [00:00<00:16, 239.47it/s]
Adding requests:   2%|▏         | 76/4096 [00:00<00:16, 250.05it/s]
Adding requests:   2%|▏         | 102/4096 [00:00<00:15, 252.80it/s]
Adding requests:   3%|▎         | 128/4096 [00:00<00:15, 252.26it/s]
Adding requests:   4%|▍         | 154/4096 [00:00<00:15, 249.64it/s]
Adding requests:   4%|▍         | 179/4096 [00:00<00:16, 239.72it/s]
Adding requests:   5%|▌         | 207/4096 [00:00<00:15, 250.63it/s]
Adding requests:   6%|▌         | 235/4096 [00:00<00:14, 257.57it/s]
Adding requests:   6%|▋         | 261/4096 [00:01<00:15, 252.78it/s]
Adding requests:   7%|▋         | 287/4096 [00:01<00:15, 240.97it/s]
Adding requests:   8%|▊         | 316/4096 [00:01<00:14, 254.44it/s]
Adding requests:   8%|▊         | 344/4096 [00:01<00:14, 260.03it/s]
Adding requests:   9%|▉         | 371/4096 [00:01<00:14, 256.99it/s]
Adding requests:  10%|▉         | 397/4096 [00:01<00:14, 252.03it/s]
Adding requests:  10%|█         | 426/4096 [00:01<00:14, 260.21it/s]
Adding requests:  11%|█         | 454/4096 [00:01<00:13, 264.67it/s]
Adding requests:  12%|█▏        | 481/4096 [00:01<00:13, 262.54it/s]
Adding requests:  12%|█▏        | 508/4096 [00:01<00:13, 259.85it/s]
Adding requests:  13%|█▎        | 537/4096 [00:02<00:13, 268.37it/s]
Adding requests:  14%|█▍        | 566/4096 [00:02<00:12, 272.43it/s]
Adding requests:  15%|█▍        | 594/4096 [00:02<00:14, 246.81it/s]
Adding requests:  15%|█▌        | 620/4096 [00:02<00:14, 246.26it/s]
Adding requests:  16%|█▌        | 647/4096 [00:02<00:13, 250.65it/s]
Adding requests:  16%|█▋        | 673/4096 [00:02<00:13, 248.53it/s]
Adding requests:  17%|█▋        | 699/4096 [00:02<00:14, 241.66it/s]
Adding requests:  18%|█▊        | 724/4096 [00:02<00:13, 243.11it/s]
Adding requests:  18%|█▊        | 750/4096 [00:02<00:13, 246.41it/s]
Adding requests:  19%|█▉        | 775/4096 [00:03<00:13, 243.98it/s]
Adding requests:  20%|█▉        | 800/4096 [00:03<00:14, 234.22it/s]
Adding requests:  20%|██        | 827/4096 [00:03<00:13, 242.84it/s]
Adding requests:  21%|██        | 856/4096 [00:03<00:12, 255.02it/s]
Adding requests:  22%|██▏       | 882/4096 [00:03<00:12, 254.98it/s]
Adding requests:  22%|██▏       | 908/4096 [00:03<00:12, 249.22it/s]
Adding requests:  23%|██▎       | 934/4096 [00:03<00:12, 249.09it/s]
Adding requests:  23%|██▎       | 962/4096 [00:03<00:12, 256.48it/s]
Adding requests:  24%|██▍       | 988/4096 [00:03<00:12, 249.15it/s]
Adding requests:  25%|██▍       | 1013/4096 [00:04<00:12, 238.72it/s]
Adding requests:  25%|██▌       | 1041/4096 [00:04<00:12, 248.81it/s]
Adding requests:  26%|██▌       | 1067/4096 [00:04<00:12, 251.86it/s]
Adding requests:  27%|██▋       | 1093/4096 [00:04<00:12, 236.06it/s]
Adding requests:  27%|██▋       | 1117/4096 [00:04<00:12, 232.64it/s]
Adding requests:  28%|██▊       | 1146/4096 [00:04<00:11, 246.13it/s]
Adding requests:  29%|██▊       | 1172/4096 [00:04<00:11, 248.56it/s]
Adding requests:  29%|██▉       | 1197/4096 [00:04<00:11, 241.76it/s]
Adding requests:  30%|██▉       | 1225/4096 [00:04<00:11, 252.55it/s]
Adding requests:  31%|███       | 1253/4096 [00:05<00:10, 258.93it/s]
Adding requests:  31%|███▏      | 1280/4096 [00:05<00:11, 254.20it/s]
Adding requests:  32%|███▏      | 1306/4096 [00:05<00:11, 245.21it/s]
Adding requests:  33%|███▎      | 1333/4096 [00:05<00:11, 249.39it/s]
Adding requests:  33%|███▎      | 1362/4096 [00:05<00:10, 260.15it/s]
Adding requests:  34%|███▍      | 1389/4096 [00:05<00:10, 254.54it/s]
Adding requests:  35%|███▍      | 1415/4096 [00:05<00:10, 246.51it/s]
Adding requests:  35%|███▌      | 1443/4096 [00:05<00:10, 255.06it/s]
Adding requests:  36%|███▌      | 1470/4096 [00:05<00:10, 258.56it/s]
Adding requests:  37%|███▋      | 1496/4096 [00:05<00:10, 254.04it/s]
Adding requests:  37%|███▋      | 1522/4096 [00:06<00:10, 248.54it/s]
Adding requests:  38%|███▊      | 1549/4096 [00:06<00:10, 253.23it/s]
Adding requests:  47%|████▋     | 1906/4096 [00:06<00:01, 1204.56it/s]
Adding requests:  50%|████▉     | 2029/4096 [00:06<00:03, 568.37it/s] 
Adding requests:  52%|█████▏    | 2123/4096 [00:07<00:04, 433.88it/s]
Adding requests:  54%|█████▎    | 2196/4096 [00:07<00:05, 375.92it/s]
Adding requests:  55%|█████▌    | 2255/4096 [00:07<00:05, 341.02it/s]
Adding requests:  56%|█████▋    | 2304/4096 [00:07<00:05, 321.56it/s]
Adding requests:  57%|█████▋    | 2346/4096 [00:08<00:05, 298.34it/s]
Adding requests:  58%|█████▊    | 2382/4096 [00:08<00:05, 293.30it/s]
Adding requests:  59%|█████▉    | 2416/4096 [00:08<00:05, 283.73it/s]
Adding requests:  60%|█████▉    | 2447/4096 [00:08<00:05, 275.67it/s]
Adding requests:  60%|██████    | 2477/4096 [00:08<00:05, 274.79it/s]
Adding requests:  61%|██████    | 2506/4096 [00:08<00:05, 274.92it/s]
Adding requests:  62%|██████▏   | 2535/4096 [00:08<00:05, 265.95it/s]
Adding requests:  63%|██████▎   | 2567/4096 [00:08<00:05, 277.75it/s]
Adding requests:  63%|██████▎   | 2596/4096 [00:08<00:05, 280.91it/s]
Adding requests:  64%|██████▍   | 2625/4096 [00:09<00:05, 268.79it/s]
Adding requests:  65%|██████▍   | 2653/4096 [00:09<00:05, 254.04it/s]
Adding requests:  65%|██████▌   | 2681/4096 [00:09<00:05, 259.02it/s]
Adding requests:  66%|██████▌   | 2708/4096 [00:09<00:05, 258.18it/s]
Adding requests:  67%|██████▋   | 2735/4096 [00:09<00:05, 250.64it/s]
Adding requests:  67%|██████▋   | 2763/4096 [00:09<00:05, 257.45it/s]
Adding requests:  68%|██████▊   | 2793/4096 [00:09<00:04, 267.35it/s]
Adding requests:  69%|██████▉   | 2821/4096 [00:09<00:04, 270.73it/s]
Adding requests:  70%|██████▉   | 2849/4096 [00:09<00:04, 262.39it/s]
Adding requests:  70%|███████   | 2876/4096 [00:10<00:04, 260.81it/s]
Adding requests:  71%|███████   | 2905/4096 [00:10<00:04, 268.45it/s]
Adding requests:  72%|███████▏  | 2932/4096 [00:10<00:04, 266.80it/s]
Adding requests:  72%|███████▏  | 2959/4096 [00:10<00:04, 258.37it/s]
Adding requests:  73%|███████▎  | 2985/4096 [00:10<00:04, 257.18it/s]
Adding requests:  74%|███████▎  | 3015/4096 [00:10<00:04, 267.53it/s]
Adding requests:  74%|███████▍  | 3042/4096 [00:10<00:03, 268.17it/s]
Adding requests:  75%|███████▍  | 3069/4096 [00:10<00:04, 254.58it/s]
Adding requests:  76%|███████▌  | 3097/4096 [00:10<00:03, 259.61it/s]
Adding requests:  76%|███████▋  | 3126/4096 [00:11<00:03, 266.64it/s]
Adding requests:  77%|███████▋  | 3153/4096 [00:11<00:03, 259.88it/s]
Adding requests:  78%|███████▊  | 3180/4096 [00:11<00:03, 242.43it/s]
Adding requests:  78%|███████▊  | 3208/4096 [00:11<00:03, 250.16it/s]
Adding requests:  79%|███████▉  | 3239/4096 [00:11<00:03, 264.85it/s]
Adding requests:  80%|███████▉  | 3266/4096 [00:11<00:03, 252.63it/s]
Adding requests:  80%|████████  | 3292/4096 [00:11<00:03, 244.87it/s]
Adding requests:  81%|████████  | 3319/4096 [00:11<00:03, 249.71it/s]
Adding requests:  82%|████████▏ | 3348/4096 [00:11<00:02, 258.97it/s]
Adding requests:  82%|████████▏ | 3375/4096 [00:12<00:02, 254.39it/s]
Adding requests:  83%|████████▎ | 3402/4096 [00:12<00:02, 257.76it/s]
Adding requests:  84%|████████▎ | 3430/4096 [00:12<00:02, 263.21it/s]
Adding requests:  84%|████████▍ | 3459/4096 [00:12<00:02, 268.91it/s]
Adding requests:  85%|████████▌ | 3486/4096 [00:12<00:02, 254.95it/s]
Adding requests:  86%|████████▌ | 3514/4096 [00:12<00:02, 261.98it/s]
Adding requests:  87%|████████▋ | 3545/4096 [00:12<00:02, 274.01it/s]
Adding requests:  87%|████████▋ | 3573/4096 [00:12<00:01, 266.54it/s]
Adding requests:  88%|████████▊ | 3600/4096 [00:12<00:01, 256.95it/s]
Adding requests:  89%|████████▊ | 3629/4096 [00:12<00:01, 265.60it/s]
Adding requests:  89%|████████▉ | 3658/4096 [00:13<00:01, 269.88it/s]
Adding requests:  90%|████████▉ | 3686/4096 [00:13<00:01, 259.50it/s]
Adding requests:  91%|█████████ | 3713/4096 [00:13<00:01, 242.73it/s]
Adding requests:  91%|█████████▏| 3741/4096 [00:13<00:01, 252.66it/s]
Adding requests:  92%|█████████▏| 3767/4096 [00:13<00:01, 252.51it/s]
Adding requests:  93%|█████████▎| 3793/4096 [00:13<00:01, 236.05it/s]
Adding requests:  93%|█████████▎| 3818/4096 [00:13<00:01, 238.20it/s]
Adding requests:  94%|█████████▍| 3845/4096 [00:13<00:01, 244.50it/s]
Adding requests:  95%|█████████▍| 3871/4096 [00:13<00:00, 247.60it/s]
Adding requests:  95%|█████████▌| 3896/4096 [00:14<00:00, 236.22it/s]
Adding requests:  96%|█████████▌| 3921/4096 [00:14<00:00, 239.51it/s]
Adding requests:  96%|█████████▋| 3948/4096 [00:14<00:00, 246.22it/s]
Adding requests:  97%|█████████▋| 3973/4096 [00:14<00:00, 240.50it/s]
Adding requests:  98%|█████████▊| 3998/4096 [00:14<00:00, 236.86it/s]
Adding requests:  98%|█████████▊| 4026/4096 [00:14<00:00, 247.09it/s]
Adding requests:  99%|█████████▉| 4053/4096 [00:14<00:00, 253.58it/s]
Adding requests: 100%|█████████▉| 4079/4096 [00:14<00:00, 250.02it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 275.14it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 66/4096 [00:01<01:25, 46.93it/s, est. speed input: 48056.25 toks/s, output: 46.93 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:07<05:42, 11.69it/s, est. speed input: 14107.66 toks/s, output: 13.78 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:12<07:54,  8.35it/s, est. speed input: 10387.18 toks/s, output: 10.14 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:18<09:10,  7.15it/s, est. speed input: 8958.73 toks/s, output: 8.75 toks/s]  
Processed prompts:   5%|▍         | 194/4096 [00:22<09:01,  7.21it/s, est. speed input: 8680.98 toks/s, output: 8.48 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:28<09:45,  6.60it/s, est. speed input: 8095.54 toks/s, output: 7.91 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:34<10:13,  6.26it/s, est. speed input: 7704.68 toks/s, output: 7.52 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:39<10:30,  6.04it/s, est. speed input: 7425.22 toks/s, output: 7.25 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:45<10:39,  5.90it/s, est. speed input: 7215.56 toks/s, output: 7.05 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:51<10:44,  5.81it/s, est. speed input: 7051.86 toks/s, output: 6.89 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:55<09:58,  6.20it/s, est. speed input: 7087.19 toks/s, output: 6.92 toks/s]
Processed prompts:  10%|█         | 418/4096 [01:01<10:12,  6.01it/s, est. speed input: 6962.68 toks/s, output: 6.80 toks/s]
Processed prompts:  11%|█         | 450/4096 [01:07<10:19,  5.88it/s, est. speed input: 6859.40 toks/s, output: 6.70 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:12<10:23,  5.80it/s, est. speed input: 6772.03 toks/s, output: 6.61 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:18<10:24,  5.74it/s, est. speed input: 6697.46 toks/s, output: 6.54 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:24<10:22,  5.70it/s, est. speed input: 6632.99 toks/s, output: 6.48 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:28<09:35,  6.11it/s, est. speed input: 6675.93 toks/s, output: 6.52 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:34<09:45,  5.95it/s, est. speed input: 6619.64 toks/s, output: 6.46 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:40<09:51,  5.84it/s, est. speed input: 6569.84 toks/s, output: 6.42 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:45<09:52,  5.77it/s, est. speed input: 6525.21 toks/s, output: 6.37 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:51<09:52,  5.72it/s, est. speed input: 6485.20 toks/s, output: 6.33 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:55<09:08,  6.12it/s, est. speed input: 6523.58 toks/s, output: 6.37 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [02:01<09:11,  6.03it/s, est. speed input: 6498.17 toks/s, output: 6.35 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [02:07<09:18,  5.90it/s, est. speed input: 6464.30 toks/s, output: 6.31 toks/s]
Processed prompts:  20%|██        | 834/4096 [02:12<09:21,  5.81it/s, est. speed input: 6433.37 toks/s, output: 6.28 toks/s]
Processed prompts:  21%|██        | 866/4096 [02:18<09:21,  5.75it/s, est. speed input: 6405.02 toks/s, output: 6.25 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:24<09:20,  5.71it/s, est. speed input: 6378.88 toks/s, output: 6.23 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:28<08:37,  6.11it/s, est. speed input: 6412.06 toks/s, output: 6.26 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:34<08:46,  5.95it/s, est. speed input: 6387.33 toks/s, output: 6.24 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:39<08:50,  5.84it/s, est. speed input: 6364.35 toks/s, output: 6.22 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:45<08:51,  5.77it/s, est. speed input: 6342.93 toks/s, output: 6.19 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [02:51<08:50,  5.72it/s, est. speed input: 6322.94 toks/s, output: 6.17 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [02:57<08:48,  5.69it/s, est. speed input: 6304.16 toks/s, output: 6.16 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [03:01<08:07,  6.10it/s, est. speed input: 6333.18 toks/s, output: 6.18 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [03:07<08:15,  5.94it/s, est. speed input: 6315.25 toks/s, output: 6.17 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [03:12<08:18,  5.84it/s, est. speed input: 6298.12 toks/s, output: 6.15 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [03:18<08:19,  5.76it/s, est. speed input: 6281.99 toks/s, output: 6.13 toks/s]
Processed prompts:  31%|███       | 1250/4096 [03:24<08:17,  5.72it/s, est. speed input: 6266.92 toks/s, output: 6.12 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:28<07:39,  6.13it/s, est. speed input: 6293.25 toks/s, output: 6.15 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:34<07:46,  5.96it/s, est. speed input: 6278.54 toks/s, output: 6.13 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:40<07:50,  5.85it/s, est. speed input: 6264.68 toks/s, output: 6.12 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:45<07:50,  5.78it/s, est. speed input: 6251.49 toks/s, output: 6.10 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [03:51<07:49,  5.72it/s, est. speed input: 6238.96 toks/s, output: 6.09 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [03:57<07:46,  5.69it/s, est. speed input: 6227.02 toks/s, output: 6.08 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [04:01<07:09,  6.10it/s, est. speed input: 6250.38 toks/s, output: 6.10 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [04:07<07:15,  5.94it/s, est. speed input: 6238.66 toks/s, output: 6.09 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [04:12<07:18,  5.84it/s, est. speed input: 6227.47 toks/s, output: 6.08 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [04:18<07:17,  5.77it/s, est. speed input: 6216.79 toks/s, output: 6.07 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [04:24<07:11,  5.78it/s, est. speed input: 6211.45 toks/s, output: 6.07 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [04:29<07:09,  5.73it/s, est. speed input: 6201.56 toks/s, output: 6.06 toks/s]
Processed prompts:  41%|████      | 1666/4096 [04:34<06:36,  6.13it/s, est. speed input: 6222.49 toks/s, output: 6.08 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:39<06:41,  5.97it/s, est. speed input: 6212.72 toks/s, output: 6.07 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [04:45<06:44,  5.86it/s, est. speed input: 6203.40 toks/s, output: 6.06 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [04:51<06:43,  5.78it/s, est. speed input: 6194.36 toks/s, output: 6.05 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [04:56<06:41,  5.73it/s, est. speed input: 6185.68 toks/s, output: 6.04 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [05:02<06:38,  5.69it/s, est. speed input: 6177.33 toks/s, output: 6.03 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [05:07<06:06,  6.10it/s, est. speed input: 6196.32 toks/s, output: 6.05 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [05:12<06:11,  5.94it/s, est. speed input: 6188.05 toks/s, output: 6.04 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [05:18<06:12,  5.84it/s, est. speed input: 6180.09 toks/s, output: 6.04 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [05:24<06:11,  5.77it/s, est. speed input: 6172.41 toks/s, output: 6.03 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [05:29<06:08,  5.72it/s, est. speed input: 6164.98 toks/s, output: 6.02 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [05:34<05:39,  6.13it/s, est. speed input: 6182.63 toks/s, output: 6.04 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [05:39<05:43,  5.96it/s, est. speed input: 6175.22 toks/s, output: 6.03 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [05:45<05:44,  5.85it/s, est. speed input: 6168.10 toks/s, output: 6.02 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [05:51<05:43,  5.78it/s, est. speed input: 6161.18 toks/s, output: 6.02 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [05:57<05:40,  5.72it/s, est. speed input: 6154.49 toks/s, output: 6.01 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [06:02<05:33,  5.75it/s, est. speed input: 6151.57 toks/s, output: 6.01 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [06:06<05:06,  6.15it/s, est. speed input: 6167.76 toks/s, output: 6.02 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [06:12<05:10,  5.98it/s, est. speed input: 6161.28 toks/s, output: 6.02 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [06:18<05:10,  5.86it/s, est. speed input: 6154.98 toks/s, output: 6.01 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [06:24<05:09,  5.78it/s, est. speed input: 6148.87 toks/s, output: 6.00 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [06:29<05:06,  5.73it/s, est. speed input: 6142.93 toks/s, output: 6.00 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [06:35<05:03,  5.69it/s, est. speed input: 6137.15 toks/s, output: 5.99 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [06:39<04:37,  6.10it/s, est. speed input: 6152.22 toks/s, output: 6.01 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [06:45<04:39,  5.95it/s, est. speed input: 6146.45 toks/s, output: 6.00 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [06:51<04:39,  5.84it/s, est. speed input: 6140.79 toks/s, output: 6.00 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [06:56<04:37,  5.77it/s, est. speed input: 6135.28 toks/s, output: 5.99 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [07:02<04:33,  5.72it/s, est. speed input: 6129.94 toks/s, output: 5.99 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [07:06<04:10,  6.13it/s, est. speed input: 6144.24 toks/s, output: 6.00 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [07:12<04:11,  5.96it/s, est. speed input: 6139.01 toks/s, output: 6.00 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [07:18<04:11,  5.85it/s, est. speed input: 6133.81 toks/s, output: 5.99 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [07:24<04:09,  5.77it/s, est. speed input: 6128.56 toks/s, output: 5.98 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [07:29<04:05,  5.72it/s, est. speed input: 6123.61 toks/s, output: 5.98 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [07:35<04:01,  5.69it/s, est. speed input: 6118.80 toks/s, output: 5.98 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [07:39<03:39,  6.11it/s, est. speed input: 6132.37 toks/s, output: 5.99 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [07:45<03:40,  5.95it/s, est. speed input: 6127.59 toks/s, output: 5.98 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [07:51<03:38,  5.84it/s, est. speed input: 6122.92 toks/s, output: 5.98 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [07:56<03:35,  5.77it/s, est. speed input: 6118.35 toks/s, output: 5.97 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [08:02<03:32,  5.72it/s, est. speed input: 6113.90 toks/s, output: 5.97 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [08:08<03:27,  5.69it/s, est. speed input: 6109.57 toks/s, output: 5.97 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [08:12<03:08,  6.10it/s, est. speed input: 6122.08 toks/s, output: 5.98 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [08:18<03:08,  5.94it/s, est. speed input: 6117.73 toks/s, output: 5.97 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [08:24<03:05,  5.84it/s, est. speed input: 6113.49 toks/s, output: 5.97 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [08:29<03:02,  5.77it/s, est. speed input: 6109.34 toks/s, output: 5.97 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [08:35<02:58,  5.72it/s, est. speed input: 6105.28 toks/s, output: 5.96 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [08:39<02:41,  6.13it/s, est. speed input: 6117.16 toks/s, output: 5.97 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [08:45<02:40,  5.96it/s, est. speed input: 6113.07 toks/s, output: 5.97 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [08:51<02:38,  5.85it/s, est. speed input: 6109.08 toks/s, output: 5.97 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [08:57<02:34,  5.77it/s, est. speed input: 6105.18 toks/s, output: 5.96 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [09:02<02:30,  5.72it/s, est. speed input: 6101.37 toks/s, output: 5.96 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [09:08<02:25,  5.69it/s, est. speed input: 6097.63 toks/s, output: 5.95 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [09:12<02:10,  6.10it/s, est. speed input: 6108.85 toks/s, output: 5.97 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [09:18<02:08,  5.94it/s, est. speed input: 6105.10 toks/s, output: 5.96 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [09:24<02:05,  5.84it/s, est. speed input: 6101.41 toks/s, output: 5.96 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [09:29<02:01,  5.77it/s, est. speed input: 6097.80 toks/s, output: 5.95 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [09:35<01:57,  5.72it/s, est. speed input: 6094.27 toks/s, output: 5.95 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [09:41<01:52,  5.68it/s, est. speed input: 6090.82 toks/s, output: 5.95 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [09:45<01:39,  6.10it/s, est. speed input: 6101.48 toks/s, output: 5.96 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [09:51<01:36,  5.94it/s, est. speed input: 6098.01 toks/s, output: 5.96 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [09:57<01:32,  5.84it/s, est. speed input: 6094.61 toks/s, output: 5.95 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [10:02<01:28,  5.77it/s, est. speed input: 6091.26 toks/s, output: 5.95 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [10:08<01:23,  5.72it/s, est. speed input: 6087.98 toks/s, output: 5.95 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [10:14<01:18,  5.68it/s, est. speed input: 6084.77 toks/s, output: 5.94 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [10:18<01:07,  6.17it/s, est. speed input: 6096.94 toks/s, output: 5.95 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [10:24<01:03,  5.99it/s, est. speed input: 6093.70 toks/s, output: 5.95 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [10:29<00:59,  5.87it/s, est. speed input: 6090.51 toks/s, output: 5.95 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [10:35<00:54,  5.79it/s, est. speed input: 6087.37 toks/s, output: 5.94 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [10:41<00:49,  5.73it/s, est. speed input: 6084.28 toks/s, output: 5.94 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [10:45<00:41,  6.14it/s, est. speed input: 6093.99 toks/s, output: 5.95 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [10:51<00:37,  5.97it/s, est. speed input: 6090.93 toks/s, output: 5.95 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [10:56<00:32,  5.92it/s, est. speed input: 6089.79 toks/s, output: 5.95 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [11:02<00:27,  5.82it/s, est. speed input: 6086.73 toks/s, output: 5.94 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [11:08<00:21,  5.75it/s, est. speed input: 6083.69 toks/s, output: 5.94 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [11:13<00:16,  5.71it/s, est. speed input: 6080.76 toks/s, output: 5.94 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [11:18<00:10,  6.12it/s, est. speed input: 6090.23 toks/s, output: 5.95 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [11:23<00:04,  6.04it/s, est. speed input: 6089.43 toks/s, output: 5.95 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [11:23<00:00,  6.04it/s, est. speed input: 6134.35 toks/s, output: 5.99 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [11:23<00:00,  5.99it/s, est. speed input: 6134.35 toks/s, output: 5.99 toks/s]
[rank0]:[W126 02:46:15.252536810 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 771.8s

测试结果:
  Requests/s:   5.61
  Tokens/s:     5754.02
  Total Reqs:   4096
  Elapsed:      729.65s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     5748.40

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:47:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:47:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=80581) WARNING 01-26 02:47:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=80581) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=80581) WARNING 01-26 02:47:53 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     def forward(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     raise e
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "<eval_with_key>.58", line 339, in forward
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     submod_6 = self.submod_6(getitem_13, s72, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_, getitem_14, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_13 = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_ = getitem_14 = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 177, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     self._maybe_compile_for_range_entry(range_entry, args)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 144, in _maybe_compile_for_range_entry
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     range_entry.runnable = self.vllm_backend.compiler_manager.compile(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/backends.py", line 244, in compile
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     compiled_graph, handle = self.compiler.compile(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                              ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 233, in compile
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     compiled_graph = standalone_compile(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                      ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/__init__.py", line 422, in standalone_compile
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return standalone_compile(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 252, in standalone_compile
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     compiled_fn = compile_fx(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                   ^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2413, in compile_fx
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return compile_fx(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2681, in compile_fx
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return aot_autograd(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/backends/common.py", line 117, in __call__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1096, in aot_module_simplified
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     aot_state = create_aot_state(
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                 ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 522, in create_aot_state
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     stack.enter_context(preserve_rng_state())
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/lib/python3.12/contextlib.py", line 526, in enter_context
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     result = _enter(cm)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]              ^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return next(self.gen)
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py", line 2220, in preserve_rng_state
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     cuda_rng_state = torch.clone(torch.cuda.get_rng_state())
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 43, in get_rng_state
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]     return default_generator.get_state()
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=80581) ERROR 01-26 02:48:02 [core.py:866] 


─── STDERR ───
[2026-01-26 02:47:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:47:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:47:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:47:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:47:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:47:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:47:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:47:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:47:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:47:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:47:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:47:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:47:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:47:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:47:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:47:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:47:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 02:47:41.905204310 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=80581) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=80581) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.02s/it]
(EngineCore_DP0 pid=80581) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]
(EngineCore_DP0 pid=80581) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.19s/it]
(EngineCore_DP0 pid=80581) 
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18579456 bytes
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 14450688 bytes
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 152764416 bytes
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=80581) [2026-01-26 02:47:44] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 76382208 bytes
(EngineCore_DP0 pid=80581) Process EngineCore_DP0:
(EngineCore_DP0 pid=80581) Traceback (most recent call last):
(EngineCore_DP0 pid=80581)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=80581)     self.run()
(EngineCore_DP0 pid=80581)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=80581)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=80581)     raise e
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=80581)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=80581)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=80581)     super().__init__(
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=80581)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=80581)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=80581)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=80581)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=80581)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=80581)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=80581)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=80581)     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=80581)     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=80581)     self.model_runner.profile_run()
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=80581)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=80581)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=80581)     return func(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=80581)     outputs = self.model(
(EngineCore_DP0 pid=80581)               ^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=80581)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=80581)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=80581)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=80581)     hidden_states = self.model(
(EngineCore_DP0 pid=80581)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=80581)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=80581)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=80581)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=80581)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=80581)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=80581)     def forward(
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=80581)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=80581)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=80581)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=80581)     raise e
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=80581)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=80581)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=80581)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "<eval_with_key>.58", line 339, in forward
(EngineCore_DP0 pid=80581)     submod_6 = self.submod_6(getitem_13, s72, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_, getitem_14, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_13 = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_ = getitem_14 = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=80581)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=80581)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 177, in __call__
(EngineCore_DP0 pid=80581)     self._maybe_compile_for_range_entry(range_entry, args)
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 144, in _maybe_compile_for_range_entry
(EngineCore_DP0 pid=80581)     range_entry.runnable = self.vllm_backend.compiler_manager.compile(
(EngineCore_DP0 pid=80581)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/backends.py", line 244, in compile
(EngineCore_DP0 pid=80581)     compiled_graph, handle = self.compiler.compile(
(EngineCore_DP0 pid=80581)                              ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 233, in compile
(EngineCore_DP0 pid=80581)     compiled_graph = standalone_compile(
(EngineCore_DP0 pid=80581)                      ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/__init__.py", line 422, in standalone_compile
(EngineCore_DP0 pid=80581)     return standalone_compile(
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 252, in standalone_compile
(EngineCore_DP0 pid=80581)     compiled_fn = compile_fx(
(EngineCore_DP0 pid=80581)                   ^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2413, in compile_fx
(EngineCore_DP0 pid=80581)     return compile_fx(
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2681, in compile_fx
(EngineCore_DP0 pid=80581)     return aot_autograd(
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/backends/common.py", line 117, in __call__
(EngineCore_DP0 pid=80581)     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
(EngineCore_DP0 pid=80581)          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1096, in aot_module_simplified
(EngineCore_DP0 pid=80581)     aot_state = create_aot_state(
(EngineCore_DP0 pid=80581)                 ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 522, in create_aot_state
(EngineCore_DP0 pid=80581)     stack.enter_context(preserve_rng_state())
(EngineCore_DP0 pid=80581)   File "/usr/lib/python3.12/contextlib.py", line 526, in enter_context
(EngineCore_DP0 pid=80581)     result = _enter(cm)
(EngineCore_DP0 pid=80581)              ^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
(EngineCore_DP0 pid=80581)     return next(self.gen)
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py", line 2220, in preserve_rng_state
(EngineCore_DP0 pid=80581)     cuda_rng_state = torch.clone(torch.cuda.get_rng_state())
(EngineCore_DP0 pid=80581)                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 43, in get_rng_state
(EngineCore_DP0 pid=80581)     return default_generator.get_state()
(EngineCore_DP0 pid=80581)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=80581) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=80581) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=80581) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=80581) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=80581) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=80581) 
[rank0]:[W126 02:48:03.776418188 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,17.2099,8828.6710,7.4376
1024,1024,1,128,128,16.7378,17156.2459,7.6474
2048,1024,2,256,128,21.7671,22311.2631,11.7609
4096,1024,4,512,128,22.8668,23438.4272,22.3906
8192,1024,8,1024,128,23.0497,23625.9260,44.4258
16384,1024,16,2048,128,11.9876,12287.2696,170.8435
32768,1024,32,4096,128,5.6137,5754.0186,729.6466
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败

============================================================
  Qwen2.5-7B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/8] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:48:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:48:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=81483) WARNING 01-26 02:48:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=81483) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=81483) WARNING 01-26 02:48:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.04 requests/s, 8740.49 total tokens/s, 17.04 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:48:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:48:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:48:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:48:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:48:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:48:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:48:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:48:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:48:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:48:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:48:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:48:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:48:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:48:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:48:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:48:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:48:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:23] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=81483) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=81483) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:04<00:04,  4.57s/it]
(EngineCore_DP0 pid=81483) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.61s/it]
(EngineCore_DP0 pid=81483) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:10<00:00,  5.45s/it]
(EngineCore_DP0 pid=81483) 
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:34] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:34] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=81483) [2026-01-26 02:48:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=81483) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.13it/s]
(EngineCore_DP0 pid=81483) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.52it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  35%|███▌      | 45/128 [00:00<00:00, 442.48it/s]
Adding requests:  73%|███████▎  | 94/128 [00:00<00:00, 467.44it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 467.80it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:04, 25.58it/s, est. speed input: 13101.26 toks/s, output: 25.59 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:06, 19.99it/s, est. speed input: 10584.88 toks/s, output: 20.67 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 18.77it/s, est. speed input: 9980.47 toks/s, output: 19.49 toks/s] 
Processed prompts:   9%|▊         | 11/128 [00:00<00:06, 18.34it/s, est. speed input: 9768.11 toks/s, output: 19.08 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:06, 18.10it/s, est. speed input: 9640.30 toks/s, output: 18.83 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:00<00:06, 17.95it/s, est. speed input: 9553.35 toks/s, output: 18.66 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:06, 17.84it/s, est. speed input: 9485.33 toks/s, output: 18.53 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 17.85it/s, est. speed input: 9447.97 toks/s, output: 18.45 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:05, 17.89it/s, est. speed input: 9424.65 toks/s, output: 18.41 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:05, 17.91it/s, est. speed input: 9404.09 toks/s, output: 18.37 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 17.94it/s, est. speed input: 9390.01 toks/s, output: 18.34 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 17.93it/s, est. speed input: 9372.23 toks/s, output: 18.30 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 17.88it/s, est. speed input: 9353.26 toks/s, output: 18.27 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 17.88it/s, est. speed input: 9339.74 toks/s, output: 18.24 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:05, 17.91it/s, est. speed input: 9331.68 toks/s, output: 18.23 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:01<00:05, 17.70it/s, est. speed input: 9301.31 toks/s, output: 18.17 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 17.57it/s, est. speed input: 9275.29 toks/s, output: 18.12 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 17.52it/s, est. speed input: 9255.63 toks/s, output: 18.08 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:04, 17.53it/s, est. speed input: 9242.03 toks/s, output: 18.05 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 17.53it/s, est. speed input: 9229.24 toks/s, output: 18.03 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 17.55it/s, est. speed input: 9218.99 toks/s, output: 18.01 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 17.54it/s, est. speed input: 9208.32 toks/s, output: 17.98 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 17.44it/s, est. speed input: 9191.37 toks/s, output: 17.95 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:02<00:04, 17.44it/s, est. speed input: 9181.00 toks/s, output: 17.93 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:02<00:04, 17.36it/s, est. speed input: 9165.84 toks/s, output: 17.90 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 17.37it/s, est. speed input: 9155.79 toks/s, output: 17.88 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 17.40it/s, est. speed input: 9148.51 toks/s, output: 17.87 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:03, 17.47it/s, est. speed input: 9144.37 toks/s, output: 17.86 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 17.51it/s, est. speed input: 9140.03 toks/s, output: 17.85 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 17.52it/s, est. speed input: 9134.76 toks/s, output: 17.84 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 17.51it/s, est. speed input: 9129.19 toks/s, output: 17.83 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:03<00:03, 17.52it/s, est. speed input: 9124.68 toks/s, output: 17.82 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:03<00:03, 17.48it/s, est. speed input: 9117.91 toks/s, output: 17.81 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:03<00:03, 17.33it/s, est. speed input: 9105.85 toks/s, output: 17.78 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 17.25it/s, est. speed input: 9095.43 toks/s, output: 17.76 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 17.23it/s, est. speed input: 9087.04 toks/s, output: 17.75 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:02, 17.23it/s, est. speed input: 9079.94 toks/s, output: 17.73 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 17.43it/s, est. speed input: 9082.22 toks/s, output: 17.74 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 17.53it/s, est. speed input: 9082.64 toks/s, output: 17.74 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 17.57it/s, est. speed input: 9081.74 toks/s, output: 17.74 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:04<00:02, 17.57it/s, est. speed input: 9079.56 toks/s, output: 17.73 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 17.63it/s, est. speed input: 9079.93 toks/s, output: 17.73 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 17.63it/s, est. speed input: 9078.88 toks/s, output: 17.73 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 17.49it/s, est. speed input: 9072.30 toks/s, output: 17.72 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 17.42it/s, est. speed input: 9067.01 toks/s, output: 17.71 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.36it/s, est. speed input: 9061.62 toks/s, output: 17.70 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.38it/s, est. speed input: 9058.74 toks/s, output: 17.69 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 17.42it/s, est. speed input: 9056.80 toks/s, output: 17.69 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 17.42it/s, est. speed input: 9054.12 toks/s, output: 17.68 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 17.43it/s, est. speed input: 9051.75 toks/s, output: 17.68 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 17.51it/s, est. speed input: 9051.88 toks/s, output: 17.68 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 17.56it/s, est. speed input: 9051.80 toks/s, output: 17.68 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 17.51it/s, est. speed input: 9049.18 toks/s, output: 17.67 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:00, 17.53it/s, est. speed input: 9048.12 toks/s, output: 17.67 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.62it/s, est. speed input: 9049.76 toks/s, output: 17.68 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.69it/s, est. speed input: 9051.29 toks/s, output: 17.68 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 17.72it/s, est. speed input: 9052.39 toks/s, output: 17.68 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 17.72it/s, est. speed input: 9052.77 toks/s, output: 17.68 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 17.67it/s, est. speed input: 9051.54 toks/s, output: 17.68 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 17.75it/s, est. speed input: 9053.81 toks/s, output: 17.68 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 17.79it/s, est. speed input: 9055.49 toks/s, output: 17.69 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:07<00:00, 17.78it/s, est. speed input: 9056.03 toks/s, output: 17.69 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.78it/s, est. speed input: 9055.39 toks/s, output: 17.69 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.69it/s, est. speed input: 9055.39 toks/s, output: 17.69 toks/s]
[rank0]:[W126 02:49:02.680598404 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 57.5s

测试结果:
  Requests/s:   17.04
  Tokens/s:     8740.49
  Total Reqs:   128
  Elapsed:      7.51s

  [Prefill 分析]
  Total Prefill Tokens: 65536
  Prefill Tokens/s:     8723.46

============================================================
[2/8] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:49:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:49:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=82534) WARNING 01-26 02:49:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=82534) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=82534) WARNING 01-26 02:49:34 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.60 requests/s, 17014.08 total tokens/s, 16.60 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128


─── STDERR ───
[2026-01-26 02:49:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:49:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:49:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:49:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:49:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:49:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:49:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:49:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:49:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:49:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:49:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:49:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:49:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:49:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:49:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:49:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:49:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=82534) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=82534) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.13s/it]
(EngineCore_DP0 pid=82534) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.42s/it]
(EngineCore_DP0 pid=82534) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.38s/it]
(EngineCore_DP0 pid=82534) 
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=82534) [2026-01-26 02:49:24] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=82534) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.23it/s]
(EngineCore_DP0 pid=82534) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 233.75it/s]
Adding requests:  39%|███▉      | 50/128 [00:00<00:00, 242.70it/s]
Adding requests:  61%|██████    | 78/128 [00:00<00:00, 255.22it/s]
Adding requests:  81%|████████▏ | 104/128 [00:00<00:00, 254.92it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 250.98it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:02, 57.17it/s, est. speed input: 58558.65 toks/s, output: 57.18 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:00, 139.85it/s, est. speed input: 130809.15 toks/s, output: 127.73 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:01<00:02, 36.44it/s, est. speed input: 44468.06 toks/s, output: 43.42 toks/s]   
Processed prompts:  43%|████▎     | 55/128 [00:01<00:02, 27.90it/s, est. speed input: 35479.75 toks/s, output: 34.65 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:02, 24.73it/s, est. speed input: 32241.78 toks/s, output: 31.49 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:02<00:02, 22.90it/s, est. speed input: 30411.80 toks/s, output: 29.70 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:02<00:02, 21.57it/s, est. speed input: 29184.02 toks/s, output: 28.50 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:02, 20.80it/s, est. speed input: 28459.97 toks/s, output: 27.79 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:02, 20.04it/s, est. speed input: 27799.13 toks/s, output: 27.15 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:02<00:02, 19.41it/s, est. speed input: 27217.85 toks/s, output: 26.58 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:02, 18.90it/s, est. speed input: 26702.51 toks/s, output: 26.08 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:03<00:02, 18.63it/s, est. speed input: 26395.53 toks/s, output: 25.78 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:03<00:02, 18.26it/s, est. speed input: 26080.58 toks/s, output: 25.47 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:02, 17.98it/s, est. speed input: 25793.30 toks/s, output: 25.19 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:03<00:02, 17.78it/s, est. speed input: 25528.86 toks/s, output: 24.93 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:02, 17.64it/s, est. speed input: 25283.71 toks/s, output: 24.69 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:03<00:01, 17.47it/s, est. speed input: 25043.92 toks/s, output: 24.46 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:03<00:01, 17.37it/s, est. speed input: 24822.13 toks/s, output: 24.24 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:04<00:01, 17.23it/s, est. speed input: 24603.98 toks/s, output: 24.03 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:04<00:01, 17.13it/s, est. speed input: 24398.21 toks/s, output: 23.83 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:04<00:01, 17.16it/s, est. speed input: 24216.84 toks/s, output: 23.65 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:04<00:01, 16.19it/s, est. speed input: 23913.55 toks/s, output: 23.35 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:04<00:01, 16.50it/s, est. speed input: 23755.61 toks/s, output: 23.20 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:01, 16.71it/s, est. speed input: 23604.14 toks/s, output: 23.05 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:04<00:01, 16.88it/s, est. speed input: 23462.39 toks/s, output: 22.91 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:04<00:00, 16.97it/s, est. speed input: 23323.35 toks/s, output: 22.78 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 17.02it/s, est. speed input: 23190.13 toks/s, output: 22.65 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:05<00:00, 17.12it/s, est. speed input: 23068.92 toks/s, output: 22.53 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:05<00:00, 17.11it/s, est. speed input: 22945.10 toks/s, output: 22.41 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:05<00:00, 17.21it/s, est. speed input: 22836.25 toks/s, output: 22.30 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 17.18it/s, est. speed input: 22723.47 toks/s, output: 22.19 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 17.22it/s, est. speed input: 22621.09 toks/s, output: 22.09 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:05<00:00, 17.32it/s, est. speed input: 22528.12 toks/s, output: 22.00 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 17.35it/s, est. speed input: 22436.14 toks/s, output: 21.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 17.35it/s, est. speed input: 22436.14 toks/s, output: 21.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.91it/s, est. speed input: 22436.14 toks/s, output: 21.91 toks/s]
[rank0]:[W126 02:49:52.157029500 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 49.7s

测试结果:
  Requests/s:   16.60
  Tokens/s:     17014.08
  Total Reqs:   128
  Elapsed:      7.71s

  [Prefill 分析]
  Total Prefill Tokens: 131072
  Prefill Tokens/s:     16997.48

============================================================
[3/8] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:50:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:50:05 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=83448) WARNING 01-26 02:50:12 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=83448) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=83448) WARNING 01-26 02:50:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.00 requests/s, 21525.39 total tokens/s, 21.00 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256


─── STDERR ───
[2026-01-26 02:50:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:50:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:50:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:50:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:50:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:50:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:50:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:50:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:50:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:50:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:50:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:50:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:50:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:50:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:50:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:50:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:50:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:13] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=83448) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=83448) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=83448) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]
(EngineCore_DP0 pid=83448) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.19s/it]
(EngineCore_DP0 pid=83448) 
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=83448) [2026-01-26 02:50:16] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=83448) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.94it/s]
(EngineCore_DP0 pid=83448) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.22it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   9%|▉         | 23/256 [00:00<00:01, 224.66it/s]
Adding requests:  19%|█▉        | 49/256 [00:00<00:00, 243.88it/s]
Adding requests:  30%|██▉       | 76/256 [00:00<00:00, 253.51it/s]
Adding requests:  40%|███▉      | 102/256 [00:00<00:00, 251.26it/s]
Adding requests:  50%|█████     | 128/256 [00:00<00:00, 249.65it/s]
Adding requests:  60%|██████    | 154/256 [00:00<00:00, 251.13it/s]
Adding requests:  71%|███████   | 182/256 [00:00<00:00, 259.07it/s]
Adding requests:  82%|████████▏ | 210/256 [00:00<00:00, 263.78it/s]
Adding requests:  93%|█████████▎| 237/256 [00:00<00:00, 258.18it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 254.16it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 18/256 [00:00<00:01, 136.91it/s, est. speed input: 140227.80 toks/s, output: 136.92 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:00<00:06, 35.69it/s, est. speed input: 41761.43 toks/s, output: 40.78 toks/s]   
Processed prompts:  15%|█▌        | 39/256 [00:01<00:06, 31.94it/s, est. speed input: 37496.15 toks/s, output: 36.62 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:01<00:07, 27.25it/s, est. speed input: 33494.78 toks/s, output: 32.71 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:08, 25.86it/s, est. speed input: 32093.68 toks/s, output: 31.34 toks/s]
Processed prompts:  20%|██        | 52/256 [00:01<00:08, 24.73it/s, est. speed input: 30990.02 toks/s, output: 30.26 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:01<00:08, 23.83it/s, est. speed input: 30096.36 toks/s, output: 29.39 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:02<00:08, 23.15it/s, est. speed input: 29364.94 toks/s, output: 28.68 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:08, 22.65it/s, est. speed input: 28751.73 toks/s, output: 28.08 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:02<00:08, 22.30it/s, est. speed input: 28235.05 toks/s, output: 27.57 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:02<00:08, 22.04it/s, est. speed input: 27790.11 toks/s, output: 27.14 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:02<00:08, 21.84it/s, est. speed input: 27399.91 toks/s, output: 26.76 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:03<00:08, 21.73it/s, est. speed input: 27066.20 toks/s, output: 26.43 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:03<00:07, 21.61it/s, est. speed input: 26761.94 toks/s, output: 26.13 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:07, 21.57it/s, est. speed input: 26501.31 toks/s, output: 25.88 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:03<00:07, 21.56it/s, est. speed input: 26269.95 toks/s, output: 25.65 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:03<00:07, 21.52it/s, est. speed input: 26056.03 toks/s, output: 25.45 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:03<00:07, 21.50it/s, est. speed input: 25862.54 toks/s, output: 25.26 toks/s]
Processed prompts:  41%|████      | 104/256 [00:04<00:07, 21.45it/s, est. speed input: 25680.80 toks/s, output: 25.08 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:04<00:06, 21.44it/s, est. speed input: 25519.56 toks/s, output: 24.92 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:04<00:06, 21.43it/s, est. speed input: 25371.45 toks/s, output: 24.78 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:04<00:06, 21.42it/s, est. speed input: 25234.21 toks/s, output: 24.64 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:04<00:06, 21.41it/s, est. speed input: 25105.77 toks/s, output: 24.52 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:06, 21.42it/s, est. speed input: 24989.99 toks/s, output: 24.40 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:05<00:05, 21.44it/s, est. speed input: 24884.73 toks/s, output: 24.30 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:05<00:05, 21.40it/s, est. speed input: 24778.97 toks/s, output: 24.20 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:05<00:05, 21.40it/s, est. speed input: 24683.74 toks/s, output: 24.11 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:05<00:05, 21.38it/s, est. speed input: 24592.49 toks/s, output: 24.02 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:06<00:05, 21.40it/s, est. speed input: 24510.82 toks/s, output: 23.94 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:06<00:05, 21.41it/s, est. speed input: 24434.36 toks/s, output: 23.86 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:06<00:04, 21.41it/s, est. speed input: 24360.56 toks/s, output: 23.79 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:06<00:04, 21.42it/s, est. speed input: 24292.78 toks/s, output: 23.72 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:06<00:04, 21.45it/s, est. speed input: 24230.08 toks/s, output: 23.66 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:06<00:04, 21.42it/s, est. speed input: 24166.69 toks/s, output: 23.60 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:07<00:04, 21.44it/s, est. speed input: 24109.67 toks/s, output: 23.54 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:07<00:03, 21.46it/s, est. speed input: 24056.91 toks/s, output: 23.49 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:07<00:03, 21.45it/s, est. speed input: 24004.32 toks/s, output: 23.44 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:07<00:03, 21.46it/s, est. speed input: 23955.83 toks/s, output: 23.39 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:07<00:03, 21.45it/s, est. speed input: 23908.23 toks/s, output: 23.35 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:08<00:03, 21.46it/s, est. speed input: 23863.69 toks/s, output: 23.30 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:08<00:02, 21.44it/s, est. speed input: 23819.95 toks/s, output: 23.26 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:08<00:02, 21.46it/s, est. speed input: 23779.95 toks/s, output: 23.22 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:08<00:02, 21.42it/s, est. speed input: 23738.01 toks/s, output: 23.18 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:08<00:02, 22.54it/s, est. speed input: 23783.30 toks/s, output: 23.23 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:08<00:02, 22.15it/s, est. speed input: 23741.58 toks/s, output: 23.19 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:09<00:02, 21.91it/s, est. speed input: 23703.81 toks/s, output: 23.15 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:09<00:01, 21.77it/s, est. speed input: 23668.80 toks/s, output: 23.11 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:09<00:01, 21.65it/s, est. speed input: 23633.90 toks/s, output: 23.08 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:09<00:01, 21.58it/s, est. speed input: 23601.57 toks/s, output: 23.05 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:09<00:01, 21.52it/s, est. speed input: 23568.79 toks/s, output: 23.02 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:10<00:01, 21.49it/s, est. speed input: 23539.05 toks/s, output: 22.99 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:10<00:00, 21.45it/s, est. speed input: 23508.15 toks/s, output: 22.96 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:10<00:00, 21.43it/s, est. speed input: 23479.39 toks/s, output: 22.93 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:10<00:00, 21.41it/s, est. speed input: 23451.07 toks/s, output: 22.90 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:10<00:00, 21.41it/s, est. speed input: 23424.74 toks/s, output: 22.88 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:11<00:00, 21.39it/s, est. speed input: 23398.45 toks/s, output: 22.85 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.64it/s, est. speed input: 23445.39 toks/s, output: 22.90 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.64it/s, est. speed input: 23445.39 toks/s, output: 22.90 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 22.90it/s, est. speed input: 23445.39 toks/s, output: 22.90 toks/s]
[rank0]:[W126 02:50:48.874105024 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 55.0s

测试结果:
  Requests/s:   21.00
  Tokens/s:     21525.39
  Total Reqs:   256
  Elapsed:      12.19s

  [Prefill 分析]
  Total Prefill Tokens: 262144
  Prefill Tokens/s:     21504.39

============================================================
[4/8] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:51:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:51:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=84470) WARNING 01-26 02:51:09 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=84470) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=84470) WARNING 01-26 02:51:20 [backends.py:609] Failed to read file <frozen os>
Throughput: 21.86 requests/s, 22411.25 total tokens/s, 21.86 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512


─── STDERR ───
[2026-01-26 02:51:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:51:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:51:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:51:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:51:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:51:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:51:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:51:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:51:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:51:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:51:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:51:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:51:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:51:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:51:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:51:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:51:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=84470) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=84470) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.01it/s]
(EngineCore_DP0 pid=84470) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.25s/it]
(EngineCore_DP0 pid=84470) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.21s/it]
(EngineCore_DP0 pid=84470) 
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=84470) [2026-01-26 02:51:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=84470) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  7.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.20it/s]
(EngineCore_DP0 pid=84470) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.28it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.83it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.57it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 23/512 [00:00<00:02, 228.84it/s]
Adding requests:  10%|▉         | 49/512 [00:00<00:01, 241.91it/s]
Adding requests:  15%|█▍        | 75/512 [00:00<00:01, 247.15it/s]
Adding requests:  20%|█▉        | 101/512 [00:00<00:01, 248.45it/s]
Adding requests:  25%|██▌       | 129/512 [00:00<00:01, 256.48it/s]
Adding requests:  30%|███       | 156/512 [00:00<00:01, 260.23it/s]
Adding requests:  36%|███▌      | 185/512 [00:00<00:01, 268.36it/s]
Adding requests:  41%|████▏     | 212/512 [00:00<00:01, 268.04it/s]
Adding requests:  47%|████▋     | 239/512 [00:00<00:01, 268.14it/s]
Adding requests:  52%|█████▏    | 266/512 [00:01<00:00, 268.64it/s]
Adding requests:  57%|█████▋    | 293/512 [00:01<00:00, 267.78it/s]
Adding requests:  63%|██████▎   | 322/512 [00:01<00:00, 271.72it/s]
Adding requests:  68%|██████▊   | 350/512 [00:01<00:00, 271.11it/s]
Adding requests:  74%|███████▍  | 378/512 [00:01<00:00, 272.92it/s]
Adding requests:  80%|███████▉  | 408/512 [00:01<00:00, 279.24it/s]
Adding requests:  85%|████████▌ | 436/512 [00:01<00:00, 277.06it/s]
Adding requests:  91%|█████████ | 464/512 [00:01<00:00, 275.36it/s]
Adding requests:  97%|█████████▋| 495/512 [00:01<00:00, 284.54it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 268.94it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:00<00:01, 316.70it/s, est. speed input: 324380.33 toks/s, output: 316.72 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:01<00:12, 36.90it/s, est. speed input: 43757.56 toks/s, output: 42.73 toks/s]   
Processed prompts:  16%|█▌        | 81/512 [00:02<00:12, 33.84it/s, est. speed input: 39815.29 toks/s, output: 38.88 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:02<00:14, 28.86it/s, est. speed input: 35527.91 toks/s, output: 34.70 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:02<00:15, 26.65it/s, est. speed input: 33654.11 toks/s, output: 32.87 toks/s]
Processed prompts:  20%|██        | 103/512 [00:03<00:15, 26.82it/s, est. speed input: 33363.16 toks/s, output: 32.58 toks/s]
Processed prompts:  21%|██        | 108/512 [00:03<00:14, 26.99it/s, est. speed input: 33097.86 toks/s, output: 32.32 toks/s]
Processed prompts:  22%|██▏       | 112/512 [00:03<00:15, 26.06it/s, est. speed input: 32573.21 toks/s, output: 31.81 toks/s]
Processed prompts:  23%|██▎       | 116/512 [00:03<00:15, 25.22it/s, est. speed input: 32096.52 toks/s, output: 31.34 toks/s]
Processed prompts:  23%|██▎       | 119/512 [00:03<00:16, 23.19it/s, est. speed input: 31402.98 toks/s, output: 30.67 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:18, 21.55it/s, est. speed input: 30770.77 toks/s, output: 30.05 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:17, 21.73it/s, est. speed input: 30431.56 toks/s, output: 29.72 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:17, 21.87it/s, est. speed input: 30119.74 toks/s, output: 29.41 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:04<00:17, 21.97it/s, est. speed input: 29830.92 toks/s, output: 29.13 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:04<00:16, 22.04it/s, est. speed input: 29565.14 toks/s, output: 28.87 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:04<00:16, 22.10it/s, est. speed input: 29318.44 toks/s, output: 28.63 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:16, 22.14it/s, est. speed input: 29089.48 toks/s, output: 28.41 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:16, 22.18it/s, est. speed input: 28877.68 toks/s, output: 28.20 toks/s]
Processed prompts:  30%|███       | 154/512 [00:05<00:16, 22.19it/s, est. speed input: 28676.28 toks/s, output: 28.00 toks/s]
Processed prompts:  31%|███       | 158/512 [00:05<00:15, 22.21it/s, est. speed input: 28490.37 toks/s, output: 27.82 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:05<00:15, 22.22it/s, est. speed input: 28314.95 toks/s, output: 27.65 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:06<00:15, 22.23it/s, est. speed input: 28149.85 toks/s, output: 27.49 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:06<00:15, 22.22it/s, est. speed input: 27992.80 toks/s, output: 27.34 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:06<00:15, 22.23it/s, est. speed input: 27846.25 toks/s, output: 27.19 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:06<00:15, 22.22it/s, est. speed input: 27706.61 toks/s, output: 27.06 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:06<00:14, 22.23it/s, est. speed input: 27575.18 toks/s, output: 26.93 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:06<00:14, 22.23it/s, est. speed input: 27450.78 toks/s, output: 26.81 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:07<00:14, 22.23it/s, est. speed input: 27331.86 toks/s, output: 26.69 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:07<00:14, 22.22it/s, est. speed input: 27218.41 toks/s, output: 26.58 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:07<00:14, 22.19it/s, est. speed input: 27108.31 toks/s, output: 26.47 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:07<00:13, 23.49it/s, est. speed input: 27122.46 toks/s, output: 26.49 toks/s]
Processed prompts:  40%|████      | 206/512 [00:07<00:13, 23.08it/s, est. speed input: 27020.37 toks/s, output: 26.39 toks/s]
Processed prompts:  41%|████      | 210/512 [00:07<00:13, 22.80it/s, est. speed input: 26923.20 toks/s, output: 26.29 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:08<00:13, 22.63it/s, est. speed input: 26831.89 toks/s, output: 26.20 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:08<00:13, 22.51it/s, est. speed input: 26743.92 toks/s, output: 26.12 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:08<00:12, 22.40it/s, est. speed input: 26658.42 toks/s, output: 26.03 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:08<00:12, 22.34it/s, est. speed input: 26577.03 toks/s, output: 25.95 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:08<00:12, 22.30it/s, est. speed input: 26499.10 toks/s, output: 25.88 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:09<00:12, 22.28it/s, est. speed input: 26425.35 toks/s, output: 25.81 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:09<00:12, 22.26it/s, est. speed input: 26353.55 toks/s, output: 25.74 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:09<00:12, 22.23it/s, est. speed input: 26283.72 toks/s, output: 25.67 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:09<00:11, 22.22it/s, est. speed input: 26216.94 toks/s, output: 25.60 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:09<00:11, 22.20it/s, est. speed input: 26151.74 toks/s, output: 25.54 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:09<00:11, 22.20it/s, est. speed input: 26089.96 toks/s, output: 25.48 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:10<00:11, 22.22it/s, est. speed input: 26032.04 toks/s, output: 25.42 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:10<00:11, 22.23it/s, est. speed input: 25975.07 toks/s, output: 25.37 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:10<00:11, 22.22it/s, est. speed input: 25919.75 toks/s, output: 25.31 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:10<00:10, 22.20it/s, est. speed input: 25864.69 toks/s, output: 25.26 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:10<00:10, 22.17it/s, est. speed input: 25811.37 toks/s, output: 25.21 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:11<00:10, 22.17it/s, est. speed input: 25760.62 toks/s, output: 25.16 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:11<00:10, 22.18it/s, est. speed input: 25711.93 toks/s, output: 25.11 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:11<00:10, 22.18it/s, est. speed input: 25664.53 toks/s, output: 25.06 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:11<00:10, 22.18it/s, est. speed input: 25618.59 toks/s, output: 25.02 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:11<00:09, 22.18it/s, est. speed input: 25573.86 toks/s, output: 24.97 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:11<00:09, 22.17it/s, est. speed input: 25530.16 toks/s, output: 24.93 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:12<00:09, 22.14it/s, est. speed input: 25486.69 toks/s, output: 24.89 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:12<00:09, 22.13it/s, est. speed input: 25444.76 toks/s, output: 24.85 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:12<00:09, 22.13it/s, est. speed input: 25404.24 toks/s, output: 24.81 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:12<00:08, 22.13it/s, est. speed input: 25365.27 toks/s, output: 24.77 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:12<00:08, 22.12it/s, est. speed input: 25326.52 toks/s, output: 24.73 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:13<00:08, 22.12it/s, est. speed input: 25289.43 toks/s, output: 24.70 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:13<00:08, 22.11it/s, est. speed input: 25252.82 toks/s, output: 24.66 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:13<00:08, 22.10it/s, est. speed input: 25217.23 toks/s, output: 24.63 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:13<00:08, 22.10it/s, est. speed input: 25182.45 toks/s, output: 24.59 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:13<00:07, 22.10it/s, est. speed input: 25149.03 toks/s, output: 24.56 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:13<00:07, 22.07it/s, est. speed input: 25114.98 toks/s, output: 24.53 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:14<00:07, 22.08it/s, est. speed input: 25083.22 toks/s, output: 24.50 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:14<00:07, 22.09it/s, est. speed input: 25052.29 toks/s, output: 24.47 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:14<00:07, 22.09it/s, est. speed input: 25021.76 toks/s, output: 24.44 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:14<00:06, 22.09it/s, est. speed input: 24992.17 toks/s, output: 24.41 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:14<00:06, 22.08it/s, est. speed input: 24962.86 toks/s, output: 24.38 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:15<00:06, 22.07it/s, est. speed input: 24934.01 toks/s, output: 24.35 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:15<00:06, 22.08it/s, est. speed input: 24906.49 toks/s, output: 24.32 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:15<00:06, 22.09it/s, est. speed input: 24879.93 toks/s, output: 24.30 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:15<00:06, 22.09it/s, est. speed input: 24853.87 toks/s, output: 24.27 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:15<00:05, 22.10it/s, est. speed input: 24828.54 toks/s, output: 24.25 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:16<00:01, 66.09it/s, est. speed input: 26721.34 toks/s, output: 26.10 toks/s]
Processed prompts:  83%|████████▎ | 424/512 [00:16<00:01, 57.06it/s, est. speed input: 26801.79 toks/s, output: 26.17 toks/s]
Processed prompts:  84%|████████▍ | 429/512 [00:16<00:01, 48.79it/s, est. speed input: 26818.17 toks/s, output: 26.19 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:16<00:02, 33.21it/s, est. speed input: 26544.37 toks/s, output: 25.92 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:16<00:02, 30.52it/s, est. speed input: 26502.21 toks/s, output: 25.88 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:17<00:02, 28.35it/s, est. speed input: 26460.79 toks/s, output: 25.84 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:17<00:02, 26.66it/s, est. speed input: 26420.11 toks/s, output: 25.80 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:17<00:02, 25.38it/s, est. speed input: 26380.13 toks/s, output: 25.76 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:17<00:02, 24.43it/s, est. speed input: 26340.69 toks/s, output: 25.72 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:17<00:02, 23.77it/s, est. speed input: 26303.38 toks/s, output: 25.69 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:18<00:02, 23.27it/s, est. speed input: 26266.23 toks/s, output: 25.65 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:18<00:02, 22.93it/s, est. speed input: 26229.94 toks/s, output: 25.62 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:18<00:01, 22.67it/s, est. speed input: 26194.13 toks/s, output: 25.58 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:18<00:01, 22.49it/s, est. speed input: 26158.71 toks/s, output: 25.55 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:18<00:01, 22.35it/s, est. speed input: 26123.68 toks/s, output: 25.51 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:18<00:01, 22.25it/s, est. speed input: 26089.54 toks/s, output: 25.48 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:19<00:01, 22.19it/s, est. speed input: 26056.01 toks/s, output: 25.45 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:19<00:00, 22.14it/s, est. speed input: 26023.02 toks/s, output: 25.41 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:19<00:00, 22.12it/s, est. speed input: 25991.11 toks/s, output: 25.38 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:19<00:00, 22.09it/s, est. speed input: 25959.16 toks/s, output: 25.35 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:19<00:00, 22.10it/s, est. speed input: 25929.02 toks/s, output: 25.32 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:20<00:00, 22.10it/s, est. speed input: 25899.36 toks/s, output: 25.29 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:20<00:00, 23.74it/s, est. speed input: 25923.63 toks/s, output: 25.32 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:20<00:00, 23.74it/s, est. speed input: 26025.03 toks/s, output: 25.42 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:20<00:00, 25.41it/s, est. speed input: 26025.03 toks/s, output: 25.42 toks/s]
[rank0]:[W126 02:51:55.883123550 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 68.3s

测试结果:
  Requests/s:   21.86
  Tokens/s:     22411.25
  Total Reqs:   512
  Elapsed:      23.42s

  [Prefill 分析]
  Total Prefill Tokens: 524288
  Prefill Tokens/s:     22389.39

============================================================
[5/8] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:52:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:52:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=85695) WARNING 01-26 02:52:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=85695) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=85695) WARNING 01-26 02:52:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 22.26 requests/s, 22819.14 total tokens/s, 22.26 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024


─── STDERR ───
[2026-01-26 02:52:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:52:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:52:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:52:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:52:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:52:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:52:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:52:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:52:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:52:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:52:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:52:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:52:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:52:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:52:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:52:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:52:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:20] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=85695) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=85695) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.04it/s]
(EngineCore_DP0 pid=85695) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.22s/it]
(EngineCore_DP0 pid=85695) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.18s/it]
(EngineCore_DP0 pid=85695) 
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=85695) [2026-01-26 02:52:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=85695) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  7.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.16it/s]
(EngineCore_DP0 pid=85695) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.26it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.40it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  8.86it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.80it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 215.82it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 236.82it/s]
Adding requests:   7%|▋         | 75/1024 [00:00<00:03, 249.56it/s]
Adding requests:  10%|▉         | 102/1024 [00:00<00:03, 255.99it/s]
Adding requests:  13%|█▎        | 129/1024 [00:00<00:03, 257.24it/s]
Adding requests:  15%|█▌        | 155/1024 [00:00<00:03, 257.53it/s]
Adding requests:  18%|█▊        | 184/1024 [00:00<00:03, 266.85it/s]
Adding requests:  21%|██        | 212/1024 [00:00<00:03, 269.61it/s]
Adding requests:  23%|██▎       | 240/1024 [00:00<00:02, 269.92it/s]
Adding requests:  26%|██▌       | 267/1024 [00:01<00:02, 269.59it/s]
Adding requests:  29%|██▊       | 294/1024 [00:01<00:02, 269.35it/s]
Adding requests:  31%|███▏      | 322/1024 [00:01<00:02, 271.24it/s]
Adding requests:  34%|███▍      | 350/1024 [00:01<00:02, 270.98it/s]
Adding requests:  37%|███▋      | 378/1024 [00:01<00:02, 271.30it/s]
Adding requests:  40%|███▉      | 408/1024 [00:01<00:02, 277.00it/s]
Adding requests:  43%|████▎     | 436/1024 [00:01<00:02, 277.45it/s]
Adding requests:  45%|████▌     | 464/1024 [00:01<00:02, 272.07it/s]
Adding requests:  48%|████▊     | 496/1024 [00:01<00:01, 283.25it/s]
Adding requests:  52%|█████▏    | 528/1024 [00:01<00:01, 289.81it/s]
Adding requests:  54%|█████▍    | 557/1024 [00:02<00:01, 282.92it/s]
Adding requests:  57%|█████▋    | 586/1024 [00:02<00:01, 277.38it/s]
Adding requests:  60%|█████▉    | 614/1024 [00:02<00:01, 274.77it/s]
Adding requests:  63%|██████▎   | 642/1024 [00:02<00:01, 270.26it/s]
Adding requests:  65%|██████▌   | 670/1024 [00:02<00:01, 265.85it/s]
Adding requests:  68%|██████▊   | 699/1024 [00:02<00:01, 271.17it/s]
Adding requests:  71%|███████   | 727/1024 [00:02<00:01, 261.15it/s]
Adding requests:  74%|███████▎  | 754/1024 [00:02<00:01, 260.11it/s]
Adding requests:  76%|███████▋  | 782/1024 [00:02<00:00, 263.55it/s]
Adding requests:  79%|███████▉  | 809/1024 [00:03<00:00, 262.94it/s]
Adding requests:  82%|████████▏ | 837/1024 [00:03<00:00, 267.54it/s]
Adding requests:  84%|████████▍ | 864/1024 [00:03<00:00, 266.21it/s]
Adding requests:  87%|████████▋ | 892/1024 [00:03<00:00, 268.10it/s]
Adding requests:  90%|████████▉ | 919/1024 [00:03<00:00, 263.73it/s]
Adding requests:  92%|█████████▏| 946/1024 [00:03<00:00, 263.65it/s]
Adding requests:  95%|█████████▌| 975/1024 [00:03<00:00, 268.46it/s]
Adding requests:  98%|█████████▊| 1002/1024 [00:03<00:00, 262.86it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 267.21it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 82/1024 [00:00<00:03, 283.64it/s, est. speed input: 290477.90 toks/s, output: 283.65 toks/s]
Processed prompts:  11%|█         | 111/1024 [00:01<00:13, 67.99it/s, est. speed input: 83730.04 toks/s, output: 81.77 toks/s]  
Processed prompts:  12%|█▏        | 125/1024 [00:02<00:19, 46.50it/s, est. speed input: 61848.15 toks/s, output: 60.40 toks/s]
Processed prompts:  13%|█▎        | 134/1024 [00:02<00:21, 41.39it/s, est. speed input: 56568.08 toks/s, output: 55.24 toks/s]
Processed prompts:  14%|█▎        | 140/1024 [00:02<00:25, 35.10it/s, est. speed input: 51536.43 toks/s, output: 50.33 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:03<00:29, 30.21it/s, est. speed input: 47642.68 toks/s, output: 46.53 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:03<00:31, 28.06it/s, est. speed input: 45131.32 toks/s, output: 44.07 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:03<00:16, 49.54it/s, est. speed input: 50794.09 toks/s, output: 49.60 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:04<00:19, 41.97it/s, est. speed input: 48465.24 toks/s, output: 47.33 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:04<00:22, 36.40it/s, est. speed input: 46496.89 toks/s, output: 45.41 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:04<00:24, 32.35it/s, est. speed input: 44809.81 toks/s, output: 43.76 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:05<00:27, 29.45it/s, est. speed input: 43349.10 toks/s, output: 42.33 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:05<00:28, 27.37it/s, est. speed input: 42069.91 toks/s, output: 41.08 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:06<00:30, 25.89it/s, est. speed input: 40939.83 toks/s, output: 39.98 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:06<00:31, 24.85it/s, est. speed input: 39935.34 toks/s, output: 39.00 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:06<00:31, 24.12it/s, est. speed input: 39037.47 toks/s, output: 38.12 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:07<00:32, 23.59it/s, est. speed input: 38226.75 toks/s, output: 37.33 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:07<00:32, 23.22it/s, est. speed input: 37494.30 toks/s, output: 36.62 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:07<00:32, 22.96it/s, est. speed input: 36827.84 toks/s, output: 35.96 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:08<00:32, 22.78it/s, est. speed input: 36219.90 toks/s, output: 35.37 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:08<00:32, 22.65it/s, est. speed input: 35661.71 toks/s, output: 34.83 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:08<00:31, 22.56it/s, est. speed input: 35148.57 toks/s, output: 34.32 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:09<00:31, 22.49it/s, est. speed input: 34674.04 toks/s, output: 33.86 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:09<00:31, 22.45it/s, est. speed input: 34235.89 toks/s, output: 33.43 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:09<00:30, 22.41it/s, est. speed input: 33827.57 toks/s, output: 33.03 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:10<00:30, 22.38it/s, est. speed input: 33447.45 toks/s, output: 32.66 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:10<00:30, 22.36it/s, est. speed input: 33092.14 toks/s, output: 32.32 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:11<00:29, 22.34it/s, est. speed input: 32759.42 toks/s, output: 31.99 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:11<00:29, 22.34it/s, est. speed input: 32448.96 toks/s, output: 31.69 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:11<00:29, 22.33it/s, est. speed input: 32156.74 toks/s, output: 31.40 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:12<00:28, 22.33it/s, est. speed input: 31882.06 toks/s, output: 31.13 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:12<00:28, 22.32it/s, est. speed input: 31622.50 toks/s, output: 30.88 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:12<00:28, 22.31it/s, est. speed input: 31377.58 toks/s, output: 30.64 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:13<00:27, 22.31it/s, est. speed input: 31145.65 toks/s, output: 30.42 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:13<00:27, 22.30it/s, est. speed input: 30925.30 toks/s, output: 30.20 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:13<00:27, 22.29it/s, est. speed input: 30716.05 toks/s, output: 30.00 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:14<00:26, 22.29it/s, est. speed input: 30517.33 toks/s, output: 29.80 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:14<00:26, 22.28it/s, est. speed input: 30327.98 toks/s, output: 29.62 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:15<00:26, 22.27it/s, est. speed input: 30147.79 toks/s, output: 29.44 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:15<00:25, 22.27it/s, est. speed input: 29976.06 toks/s, output: 29.27 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:15<00:25, 22.27it/s, est. speed input: 29812.43 toks/s, output: 29.11 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:16<00:25, 22.27it/s, est. speed input: 29656.13 toks/s, output: 28.96 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:16<00:24, 22.27it/s, est. speed input: 29505.88 toks/s, output: 28.81 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:16<00:24, 22.27it/s, est. speed input: 29362.47 toks/s, output: 28.67 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:17<00:23, 22.26it/s, est. speed input: 29224.78 toks/s, output: 28.54 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:17<00:23, 22.26it/s, est. speed input: 29092.64 toks/s, output: 28.41 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:17<00:23, 22.26it/s, est. speed input: 28966.10 toks/s, output: 28.29 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:18<00:22, 22.27it/s, est. speed input: 28845.19 toks/s, output: 28.17 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:18<00:22, 22.27it/s, est. speed input: 28728.65 toks/s, output: 28.06 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:18<00:22, 22.26it/s, est. speed input: 28616.08 toks/s, output: 27.95 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:19<00:21, 22.26it/s, est. speed input: 28507.50 toks/s, output: 27.84 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:19<00:21, 22.26it/s, est. speed input: 28403.10 toks/s, output: 27.74 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:20<00:21, 22.26it/s, est. speed input: 28302.29 toks/s, output: 27.64 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:20<00:20, 22.26it/s, est. speed input: 28205.32 toks/s, output: 27.54 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:20<00:20, 22.26it/s, est. speed input: 28111.73 toks/s, output: 27.45 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:21<00:20, 22.26it/s, est. speed input: 28021.51 toks/s, output: 27.36 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:21<00:19, 22.27it/s, est. speed input: 27934.58 toks/s, output: 27.28 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:21<00:19, 22.27it/s, est. speed input: 27850.39 toks/s, output: 27.20 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:22<00:18, 22.27it/s, est. speed input: 27768.55 toks/s, output: 27.12 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:22<00:18, 22.27it/s, est. speed input: 27689.87 toks/s, output: 27.04 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:22<00:18, 22.27it/s, est. speed input: 27613.33 toks/s, output: 26.97 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:23<00:17, 22.28it/s, est. speed input: 27539.68 toks/s, output: 26.89 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:23<00:17, 22.28it/s, est. speed input: 27467.83 toks/s, output: 26.82 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:23<00:17, 22.28it/s, est. speed input: 27398.13 toks/s, output: 26.76 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:24<00:16, 22.27it/s, est. speed input: 27330.15 toks/s, output: 26.69 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:24<00:16, 22.27it/s, est. speed input: 27264.41 toks/s, output: 26.63 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:25<00:16, 22.27it/s, est. speed input: 27200.68 toks/s, output: 26.56 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:25<00:15, 22.28it/s, est. speed input: 27138.87 toks/s, output: 26.50 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:25<00:15, 22.28it/s, est. speed input: 27078.69 toks/s, output: 26.44 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:26<00:14, 22.27it/s, est. speed input: 27019.61 toks/s, output: 26.39 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:26<00:14, 22.27it/s, est. speed input: 26962.36 toks/s, output: 26.33 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:26<00:14, 22.27it/s, est. speed input: 26906.77 toks/s, output: 26.28 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:27<00:13, 22.27it/s, est. speed input: 26852.60 toks/s, output: 26.22 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:27<00:13, 22.27it/s, est. speed input: 26799.79 toks/s, output: 26.17 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:27<00:13, 22.27it/s, est. speed input: 26748.54 toks/s, output: 26.12 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:28<00:12, 22.28it/s, est. speed input: 26699.00 toks/s, output: 26.07 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:28<00:12, 22.28it/s, est. speed input: 26650.27 toks/s, output: 26.03 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:29<00:12, 22.28it/s, est. speed input: 26602.94 toks/s, output: 25.98 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:29<00:11, 22.28it/s, est. speed input: 26556.50 toks/s, output: 25.93 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:29<00:11, 22.28it/s, est. speed input: 26511.54 toks/s, output: 25.89 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:30<00:11, 22.28it/s, est. speed input: 26467.54 toks/s, output: 25.85 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:30<00:10, 22.91it/s, est. speed input: 26453.13 toks/s, output: 25.83 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:30<00:10, 22.73it/s, est. speed input: 26410.92 toks/s, output: 25.79 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:31<00:09, 22.59it/s, est. speed input: 26369.42 toks/s, output: 25.75 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:31<00:09, 22.50it/s, est. speed input: 26329.05 toks/s, output: 25.71 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:31<00:09, 22.43it/s, est. speed input: 26289.54 toks/s, output: 25.67 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:32<00:08, 22.39it/s, est. speed input: 26250.92 toks/s, output: 25.64 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:32<00:08, 22.35it/s, est. speed input: 26212.93 toks/s, output: 25.60 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:32<00:08, 22.34it/s, est. speed input: 26176.08 toks/s, output: 25.56 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:33<00:07, 22.32it/s, est. speed input: 26139.76 toks/s, output: 25.53 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:33<00:07, 22.31it/s, est. speed input: 26104.27 toks/s, output: 25.49 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:34<00:07, 22.30it/s, est. speed input: 26069.50 toks/s, output: 25.46 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:34<00:06, 22.30it/s, est. speed input: 26035.70 toks/s, output: 25.43 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:34<00:06, 22.29it/s, est. speed input: 26002.47 toks/s, output: 25.39 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:35<00:02, 46.08it/s, est. speed input: 26844.93 toks/s, output: 26.22 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:35<00:02, 39.25it/s, est. speed input: 26804.32 toks/s, output: 26.18 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:35<00:02, 34.31it/s, est. speed input: 26764.44 toks/s, output: 26.14 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:36<00:02, 30.79it/s, est. speed input: 26725.49 toks/s, output: 26.10 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:36<00:02, 28.27it/s, est. speed input: 26687.03 toks/s, output: 26.06 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:36<00:02, 26.49it/s, est. speed input: 26649.21 toks/s, output: 26.02 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:37<00:02, 25.23it/s, est. speed input: 26612.29 toks/s, output: 25.99 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:37<00:01, 24.35it/s, est. speed input: 26576.05 toks/s, output: 25.95 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:38<00:01, 23.73it/s, est. speed input: 26540.62 toks/s, output: 25.92 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:38<00:01, 23.30it/s, est. speed input: 26505.85 toks/s, output: 25.88 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:38<00:00, 22.99it/s, est. speed input: 26471.40 toks/s, output: 25.85 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:39<00:00, 22.78it/s, est. speed input: 26437.91 toks/s, output: 25.82 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:39<00:00, 23.46it/s, est. speed input: 26433.25 toks/s, output: 25.81 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 23.46it/s, est. speed input: 26588.85 toks/s, output: 25.97 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:39<00:00, 25.97it/s, est. speed input: 26588.85 toks/s, output: 25.97 toks/s]
[rank0]:[W126 02:53:29.750317527 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 93.8s

测试结果:
  Requests/s:   22.26
  Tokens/s:     22819.14
  Total Reqs:   1024
  Elapsed:      46.00s

  [Prefill 分析]
  Total Prefill Tokens: 1048576
  Prefill Tokens/s:     22796.88

============================================================
[6/8] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:53:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:53:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=87342) WARNING 01-26 02:54:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=87342) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=87342) WARNING 01-26 02:54:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 8.23 requests/s, 8438.58 total tokens/s, 8.23 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048


─── STDERR ───
[2026-01-26 02:53:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:53:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:53:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:53:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:53:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:53:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:53:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:53:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:53:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:54:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:54:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:54:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:54:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:54:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:54:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:54:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:54:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:54:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=87342) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=87342) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.04it/s]
(EngineCore_DP0 pid=87342) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.25s/it]
(EngineCore_DP0 pid=87342) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
(EngineCore_DP0 pid=87342) 
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=87342) [2026-01-26 02:54:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=87342) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  7.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  7.76it/s]
(EngineCore_DP0 pid=87342) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  6.65it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  7.85it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.36it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.69it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.43it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 23/2048 [00:00<00:08, 225.44it/s]
Adding requests:   2%|▏         | 49/2048 [00:00<00:08, 241.41it/s]
Adding requests:   4%|▎         | 76/2048 [00:00<00:07, 250.88it/s]
Adding requests:   5%|▍         | 102/2048 [00:00<00:08, 241.31it/s]
Adding requests:   6%|▌         | 127/2048 [00:00<00:07, 240.43it/s]
Adding requests:   7%|▋         | 152/2048 [00:00<00:07, 238.09it/s]
Adding requests:   9%|▊         | 177/2048 [00:00<00:07, 240.90it/s]
Adding requests:  10%|▉         | 203/2048 [00:00<00:07, 244.35it/s]
Adding requests:  11%|█         | 229/2048 [00:00<00:07, 247.35it/s]
Adding requests:  12%|█▏        | 254/2048 [00:01<00:07, 239.85it/s]
Adding requests:  14%|█▎        | 279/2048 [00:01<00:07, 241.47it/s]
Adding requests:  15%|█▍        | 304/2048 [00:01<00:07, 240.98it/s]
Adding requests:  16%|█▌        | 330/2048 [00:01<00:07, 244.98it/s]
Adding requests:  17%|█▋        | 357/2048 [00:01<00:06, 251.34it/s]
Adding requests:  19%|█▊        | 383/2048 [00:01<00:06, 251.27it/s]
Adding requests:  20%|██        | 410/2048 [00:01<00:06, 254.64it/s]
Adding requests:  21%|██▏       | 436/2048 [00:01<00:06, 250.67it/s]
Adding requests:  23%|██▎       | 462/2048 [00:01<00:06, 251.81it/s]
Adding requests:  24%|██▍       | 490/2048 [00:01<00:06, 259.33it/s]
Adding requests:  25%|██▌       | 517/2048 [00:02<00:05, 261.55it/s]
Adding requests:  27%|██▋       | 544/2048 [00:02<00:05, 263.36it/s]
Adding requests:  28%|██▊       | 571/2048 [00:02<00:05, 259.73it/s]
Adding requests:  29%|██▉       | 597/2048 [00:02<00:05, 248.75it/s]
Adding requests:  30%|███       | 623/2048 [00:02<00:05, 248.49it/s]
Adding requests:  32%|███▏      | 648/2048 [00:02<00:05, 245.97it/s]
Adding requests:  33%|███▎      | 673/2048 [00:02<00:05, 244.02it/s]
Adding requests:  34%|███▍      | 701/2048 [00:02<00:05, 252.84it/s]
Adding requests:  35%|███▌      | 727/2048 [00:02<00:05, 249.53it/s]
Adding requests:  37%|███▋      | 752/2048 [00:03<00:05, 248.97it/s]
Adding requests:  38%|███▊      | 777/2048 [00:03<00:05, 245.62it/s]
Adding requests:  39%|███▉      | 802/2048 [00:03<00:05, 244.62it/s]
Adding requests:  40%|████      | 828/2048 [00:03<00:04, 248.80it/s]
Adding requests:  42%|████▏     | 853/2048 [00:03<00:04, 246.43it/s]
Adding requests:  43%|████▎     | 879/2048 [00:03<00:04, 248.56it/s]
Adding requests:  44%|████▍     | 906/2048 [00:03<00:04, 252.70it/s]
Adding requests:  46%|████▌     | 932/2048 [00:03<00:04, 241.72it/s]
Adding requests:  47%|████▋     | 957/2048 [00:03<00:04, 240.74it/s]
Adding requests:  48%|████▊     | 982/2048 [00:03<00:04, 242.05it/s]
Adding requests:  49%|████▉     | 1007/2048 [00:04<00:04, 236.29it/s]
Adding requests:  50%|█████     | 1031/2048 [00:04<00:04, 237.20it/s]
Adding requests:  52%|█████▏    | 1055/2048 [00:04<00:04, 237.79it/s]
Adding requests:  53%|█████▎    | 1079/2048 [00:04<00:04, 237.85it/s]
Adding requests:  54%|█████▍    | 1103/2048 [00:04<00:04, 234.22it/s]
Adding requests:  55%|█████▌    | 1130/2048 [00:04<00:03, 243.97it/s]
Adding requests:  56%|█████▋    | 1155/2048 [00:04<00:03, 240.41it/s]
Adding requests:  58%|█████▊    | 1182/2048 [00:04<00:03, 246.82it/s]
Adding requests:  59%|█████▉    | 1208/2048 [00:04<00:03, 249.14it/s]
Adding requests:  60%|██████    | 1235/2048 [00:05<00:03, 252.36it/s]
Adding requests:  62%|██████▏   | 1261/2048 [00:05<00:03, 248.51it/s]
Adding requests:  63%|██████▎   | 1286/2048 [00:05<00:03, 247.89it/s]
Adding requests:  64%|██████▍   | 1311/2048 [00:05<00:02, 248.43it/s]
Adding requests:  65%|██████▌   | 1336/2048 [00:05<00:02, 245.03it/s]
Adding requests:  67%|██████▋   | 1363/2048 [00:05<00:02, 248.50it/s]
Adding requests:  68%|██████▊   | 1388/2048 [00:05<00:02, 248.28it/s]
Adding requests:  69%|██████▉   | 1414/2048 [00:05<00:02, 248.79it/s]
Adding requests:  70%|███████   | 1440/2048 [00:05<00:02, 249.32it/s]
Adding requests:  72%|███████▏  | 1466/2048 [00:05<00:02, 250.89it/s]
Adding requests:  73%|███████▎  | 1492/2048 [00:06<00:02, 252.47it/s]
Adding requests:  74%|███████▍  | 1518/2048 [00:06<00:02, 254.34it/s]
Adding requests:  75%|███████▌  | 1544/2048 [00:06<00:02, 250.99it/s]
Adding requests:  77%|███████▋  | 1570/2048 [00:06<00:01, 244.26it/s]
Adding requests:  78%|███████▊  | 1596/2048 [00:06<00:01, 246.18it/s]
Adding requests:  79%|███████▉  | 1621/2048 [00:06<00:01, 236.67it/s]
Adding requests:  80%|████████  | 1645/2048 [00:06<00:01, 236.90it/s]
Adding requests:  81%|████████▏ | 1669/2048 [00:06<00:01, 231.29it/s]
Adding requests:  83%|████████▎ | 1695/2048 [00:06<00:01, 236.70it/s]
Adding requests:  84%|████████▍ | 1720/2048 [00:06<00:01, 238.80it/s]
Adding requests:  85%|████████▌ | 1746/2048 [00:07<00:01, 242.71it/s]
Adding requests:  87%|████████▋ | 1772/2048 [00:07<00:01, 245.48it/s]
Adding requests:  88%|████████▊ | 1797/2048 [00:07<00:01, 241.50it/s]
Adding requests:  89%|████████▉ | 1822/2048 [00:07<00:00, 242.28it/s]
Adding requests:  90%|█████████ | 1848/2048 [00:07<00:00, 244.29it/s]
Adding requests:  91%|█████████▏| 1873/2048 [00:07<00:00, 243.11it/s]
Adding requests:  93%|█████████▎| 1898/2048 [00:07<00:00, 244.36it/s]
Adding requests:  94%|█████████▍| 1925/2048 [00:07<00:00, 250.59it/s]
Adding requests:  95%|█████████▌| 1951/2048 [00:07<00:00, 241.76it/s]
Adding requests:  96%|█████████▋| 1976/2048 [00:08<00:00, 243.19it/s]
Adding requests:  98%|█████████▊| 2001/2048 [00:08<00:00, 244.78it/s]
Adding requests:  99%|█████████▉| 2026/2048 [00:08<00:00, 238.74it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 245.55it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 66/2048 [00:01<00:51, 38.53it/s, est. speed input: 39450.68 toks/s, output: 38.53 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:03<01:40, 19.64it/s, est. speed input: 22810.11 toks/s, output: 22.28 toks/s]
Processed prompts:   5%|▍         | 98/2048 [00:05<02:17, 14.23it/s, est. speed input: 17762.67 toks/s, output: 17.35 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:07<02:44, 11.77it/s, est. speed input: 15323.13 toks/s, output: 14.96 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:09<03:03, 10.45it/s, est. speed input: 13888.31 toks/s, output: 13.56 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:11<03:16,  9.67it/s, est. speed input: 12949.16 toks/s, output: 12.65 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:13<03:25,  9.17it/s, est. speed input: 12283.47 toks/s, output: 12.00 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:15<03:31,  8.85it/s, est. speed input: 11786.03 toks/s, output: 11.51 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:17<03:34,  8.64it/s, est. speed input: 11401.02 toks/s, output: 11.13 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:19<03:36,  8.49it/s, est. speed input: 11095.06 toks/s, output: 10.84 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:21<03:36,  8.40it/s, est. speed input: 10845.30 toks/s, output: 10.59 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:23<03:36,  8.33it/s, est. speed input: 10637.30 toks/s, output: 10.39 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:23<02:49, 10.56it/s, est. speed input: 11072.83 toks/s, output: 10.81 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:25<03:02,  9.71it/s, est. speed input: 10867.60 toks/s, output: 10.61 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:27<03:11,  9.19it/s, est. speed input: 10691.23 toks/s, output: 10.44 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:29<03:16,  8.86it/s, est. speed input: 10538.00 toks/s, output: 10.29 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:31<03:19,  8.64it/s, est. speed input: 10403.71 toks/s, output: 10.16 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:33<03:21,  8.49it/s, est. speed input: 10284.95 toks/s, output: 10.04 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:35<03:21,  8.39it/s, est. speed input: 10179.31 toks/s, output: 9.94 toks/s] 
Processed prompts:  18%|█▊        | 370/2048 [00:37<03:21,  8.32it/s, est. speed input: 10084.73 toks/s, output: 9.85 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:39<03:20,  8.28it/s, est. speed input: 9999.37 toks/s, output: 9.77 toks/s] 
Processed prompts:  20%|█▉        | 402/2048 [00:41<03:19,  8.24it/s, est. speed input: 9922.02 toks/s, output: 9.69 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:43<03:18,  8.22it/s, est. speed input: 9851.76 toks/s, output: 9.62 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:45<03:16,  8.20it/s, est. speed input: 9787.39 toks/s, output: 9.56 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:47<03:15,  8.19it/s, est. speed input: 9728.46 toks/s, output: 9.50 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:49<03:13,  8.18it/s, est. speed input: 9674.06 toks/s, output: 9.45 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:51<03:11,  8.18it/s, est. speed input: 9623.77 toks/s, output: 9.40 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:53<03:09,  8.17it/s, est. speed input: 9577.19 toks/s, output: 9.35 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:53<02:28, 10.35it/s, est. speed input: 9777.17 toks/s, output: 9.55 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:55<02:38,  9.58it/s, est. speed input: 9727.36 toks/s, output: 9.50 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:57<02:44,  9.11it/s, est. speed input: 9680.96 toks/s, output: 9.45 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:59<02:48,  8.80it/s, est. speed input: 9637.57 toks/s, output: 9.41 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [01:01<02:50,  8.60it/s, est. speed input: 9596.90 toks/s, output: 9.37 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [01:03<02:51,  8.46it/s, est. speed input: 9558.80 toks/s, output: 9.33 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [01:05<02:51,  8.37it/s, est. speed input: 9522.93 toks/s, output: 9.30 toks/s]
Processed prompts:  31%|███       | 626/2048 [01:07<02:51,  8.31it/s, est. speed input: 9489.14 toks/s, output: 9.27 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [01:09<02:50,  8.26it/s, est. speed input: 9457.22 toks/s, output: 9.24 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [01:11<02:48,  8.23it/s, est. speed input: 9427.11 toks/s, output: 9.21 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [01:13<02:47,  8.21it/s, est. speed input: 9398.45 toks/s, output: 9.18 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [01:15<02:45,  8.20it/s, est. speed input: 9371.45 toks/s, output: 9.15 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [01:17<02:43,  8.19it/s, est. speed input: 9345.77 toks/s, output: 9.13 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [01:19<02:42,  8.18it/s, est. speed input: 9321.31 toks/s, output: 9.10 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [01:21<02:40,  8.17it/s, est. speed input: 9298.05 toks/s, output: 9.08 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [01:23<02:38,  8.17it/s, est. speed input: 9275.86 toks/s, output: 9.06 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [01:25<02:36,  8.17it/s, est. speed input: 9254.74 toks/s, output: 9.04 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [01:26<01:53, 10.98it/s, est. speed input: 9446.05 toks/s, output: 9.22 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [01:28<02:01, 10.11it/s, est. speed input: 9422.01 toks/s, output: 9.20 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:30<02:07,  9.52it/s, est. speed input: 9399.08 toks/s, output: 9.18 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:32<02:11,  9.11it/s, est. speed input: 9377.12 toks/s, output: 9.16 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:34<02:13,  8.82it/s, est. speed input: 9356.02 toks/s, output: 9.14 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [01:36<02:15,  8.62it/s, est. speed input: 9335.82 toks/s, output: 9.12 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:38<02:15,  8.48it/s, est. speed input: 9316.39 toks/s, output: 9.10 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:40<02:15,  8.39it/s, est. speed input: 9297.73 toks/s, output: 9.08 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:42<02:14,  8.32it/s, est. speed input: 9279.78 toks/s, output: 9.06 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [01:44<02:13,  8.27it/s, est. speed input: 9262.54 toks/s, output: 9.05 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:46<02:11,  8.24it/s, est. speed input: 9245.93 toks/s, output: 9.03 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:48<02:10,  8.22it/s, est. speed input: 9229.88 toks/s, output: 9.01 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:50<02:08,  8.20it/s, est. speed input: 9214.36 toks/s, output: 9.00 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:52<02:06,  8.19it/s, est. speed input: 9199.42 toks/s, output: 8.98 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:54<02:04,  8.18it/s, est. speed input: 9184.98 toks/s, output: 8.97 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:56<02:03,  8.17it/s, est. speed input: 9171.05 toks/s, output: 8.96 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:56<01:35, 10.34it/s, est. speed input: 9265.00 toks/s, output: 9.05 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:58<01:41,  9.58it/s, est. speed input: 9250.06 toks/s, output: 9.03 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [02:00<01:45,  9.10it/s, est. speed input: 9235.60 toks/s, output: 9.02 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [02:02<01:47,  8.80it/s, est. speed input: 9221.60 toks/s, output: 9.01 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [02:04<01:47,  8.60it/s, est. speed input: 9208.05 toks/s, output: 8.99 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [02:06<01:47,  8.46it/s, est. speed input: 9194.89 toks/s, output: 8.98 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [02:08<01:46,  8.37it/s, est. speed input: 9182.14 toks/s, output: 8.97 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [02:10<01:45,  8.31it/s, est. speed input: 9169.77 toks/s, output: 8.95 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [02:12<01:44,  8.26it/s, est. speed input: 9157.83 toks/s, output: 8.94 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [02:14<01:42,  8.23it/s, est. speed input: 9146.10 toks/s, output: 8.93 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [02:16<01:41,  8.21it/s, est. speed input: 9134.81 toks/s, output: 8.92 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [02:18<01:39,  8.20it/s, est. speed input: 9123.80 toks/s, output: 8.91 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [02:20<01:37,  8.19it/s, est. speed input: 9113.08 toks/s, output: 8.90 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [02:22<01:35,  8.18it/s, est. speed input: 9102.70 toks/s, output: 8.89 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [02:24<01:33,  8.17it/s, est. speed input: 9092.61 toks/s, output: 8.88 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [02:26<01:31,  8.17it/s, est. speed input: 9082.74 toks/s, output: 8.87 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [02:26<01:10, 10.34it/s, est. speed input: 9157.93 toks/s, output: 8.94 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [02:28<01:14,  9.57it/s, est. speed input: 9147.37 toks/s, output: 8.93 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [02:30<01:17,  9.10it/s, est. speed input: 9137.10 toks/s, output: 8.92 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [02:32<01:17,  8.80it/s, est. speed input: 9127.09 toks/s, output: 8.91 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [02:34<01:17,  8.60it/s, est. speed input: 9117.35 toks/s, output: 8.90 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [02:36<01:17,  8.46it/s, est. speed input: 9107.86 toks/s, output: 8.89 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [02:38<01:16,  8.37it/s, est. speed input: 9098.59 toks/s, output: 8.89 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [02:40<01:14,  8.31it/s, est. speed input: 9089.55 toks/s, output: 8.88 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [02:42<01:13,  8.26it/s, est. speed input: 9080.77 toks/s, output: 8.87 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [02:44<01:11,  8.23it/s, est. speed input: 9072.15 toks/s, output: 8.86 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [02:46<01:09,  8.21it/s, est. speed input: 9063.76 toks/s, output: 8.85 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [02:48<01:08,  8.20it/s, est. speed input: 9055.50 toks/s, output: 8.84 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [02:50<01:06,  8.19it/s, est. speed input: 9047.50 toks/s, output: 8.84 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [02:52<01:04,  8.18it/s, est. speed input: 9039.65 toks/s, output: 8.83 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [02:54<01:02,  8.17it/s, est. speed input: 9032.00 toks/s, output: 8.82 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [02:56<01:00,  8.17it/s, est. speed input: 9024.51 toks/s, output: 8.81 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [02:58<00:58,  8.17it/s, est. speed input: 9017.18 toks/s, output: 8.81 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:58<00:44, 10.33it/s, est. speed input: 9078.91 toks/s, output: 8.87 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [03:00<00:46,  9.57it/s, est. speed input: 9071.10 toks/s, output: 8.86 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [03:01<00:40, 10.55it/s, est. speed input: 9103.59 toks/s, output: 8.89 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [03:03<00:42,  9.70it/s, est. speed input: 9095.66 toks/s, output: 8.88 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [03:05<00:43,  9.18it/s, est. speed input: 9087.90 toks/s, output: 8.87 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [03:07<00:43,  8.85it/s, est. speed input: 9080.25 toks/s, output: 8.87 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [03:09<00:42,  8.63it/s, est. speed input: 9072.78 toks/s, output: 8.86 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [03:11<00:41,  8.48it/s, est. speed input: 9065.46 toks/s, output: 8.85 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [03:13<00:39,  8.38it/s, est. speed input: 9058.30 toks/s, output: 8.85 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [03:15<00:38,  8.32it/s, est. speed input: 9051.25 toks/s, output: 8.84 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [03:17<00:36,  8.27it/s, est. speed input: 9044.35 toks/s, output: 8.83 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [03:19<00:34,  8.24it/s, est. speed input: 9037.62 toks/s, output: 8.83 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [03:21<00:32,  8.21it/s, est. speed input: 9030.99 toks/s, output: 8.82 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [03:23<00:30,  8.20it/s, est. speed input: 9024.48 toks/s, output: 8.81 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [03:25<00:29,  8.19it/s, est. speed input: 9018.11 toks/s, output: 8.81 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [03:27<00:27,  8.18it/s, est. speed input: 9011.87 toks/s, output: 8.80 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [03:29<00:25,  8.17it/s, est. speed input: 9005.74 toks/s, output: 8.79 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [03:30<00:18, 10.34it/s, est. speed input: 9058.52 toks/s, output: 8.85 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [03:31<00:18,  9.58it/s, est. speed input: 9052.08 toks/s, output: 8.84 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [03:33<00:17,  9.11it/s, est. speed input: 9045.77 toks/s, output: 8.83 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [03:35<00:16,  8.80it/s, est. speed input: 9039.56 toks/s, output: 8.83 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [03:37<00:14,  8.60it/s, est. speed input: 9033.47 toks/s, output: 8.82 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [03:39<00:12,  8.46it/s, est. speed input: 9027.39 toks/s, output: 8.82 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [03:41<00:11,  8.37it/s, est. speed input: 9021.38 toks/s, output: 8.81 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [03:43<00:09,  8.30it/s, est. speed input: 9015.50 toks/s, output: 8.80 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [03:45<00:07,  8.26it/s, est. speed input: 9009.73 toks/s, output: 8.80 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [03:47<00:05,  8.22it/s, est. speed input: 9003.98 toks/s, output: 8.79 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [03:49<00:03,  8.20it/s, est. speed input: 8998.33 toks/s, output: 8.79 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [03:50<00:01,  9.36it/s, est. speed input: 9024.72 toks/s, output: 8.81 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [03:50<00:00,  9.36it/s, est. speed input: 9086.82 toks/s, output: 8.87 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [03:50<00:00,  8.87it/s, est. speed input: 9086.82 toks/s, output: 8.87 toks/s]
[rank0]:[W126 02:58:25.197754202 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 296.1s

测试结果:
  Requests/s:   8.23
  Tokens/s:     8438.58
  Total Reqs:   2048
  Elapsed:      248.76s

  [Prefill 分析]
  Total Prefill Tokens: 2097152
  Prefill Tokens/s:     8430.34

============================================================
[7/8] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 02:59:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 02:59:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=91990) WARNING 01-26 02:59:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=91990) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=91990) WARNING 01-26 02:59:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 5.28 requests/s, 5409.50 total tokens/s, 5.28 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 02:59:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:59:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:59:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:59:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:59:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:59:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:59:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:59:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 02:59:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 02:59:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:59:10] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 02:59:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 02:59:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 02:59:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 02:59:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 02:59:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 02:59:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=91990) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=91990) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=91990) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.25s/it]
(EngineCore_DP0 pid=91990) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.21s/it]
(EngineCore_DP0 pid=91990) 
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=91990) [2026-01-26 02:59:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=91990) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  8.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  8.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  8.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  8.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  9.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  9.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.71it/s]
(EngineCore_DP0 pid=91990) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.30it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.80it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  9.10it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  9.24it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  9.02it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/4096 [00:00<00:16, 240.61it/s]
Adding requests:   1%|▏         | 52/4096 [00:00<00:16, 251.39it/s]
Adding requests:   2%|▏         | 79/4096 [00:00<00:15, 259.36it/s]
Adding requests:   3%|▎         | 107/4096 [00:00<00:15, 264.13it/s]
Adding requests:   3%|▎         | 134/4096 [00:00<00:15, 259.58it/s]
Adding requests:   4%|▍         | 160/4096 [00:00<00:15, 250.84it/s]
Adding requests:   5%|▍         | 186/4096 [00:00<00:15, 245.58it/s]
Adding requests:   5%|▌         | 214/4096 [00:00<00:15, 254.78it/s]
Adding requests:   6%|▌         | 242/4096 [00:00<00:14, 260.16it/s]
Adding requests:   7%|▋         | 269/4096 [00:01<00:14, 256.24it/s]
Adding requests:   7%|▋         | 295/4096 [00:01<00:15, 244.13it/s]
Adding requests:   8%|▊         | 323/4096 [00:01<00:14, 252.92it/s]
Adding requests:   9%|▊         | 352/4096 [00:01<00:14, 262.07it/s]
Adding requests:   9%|▉         | 379/4096 [00:01<00:14, 259.70it/s]
Adding requests:  10%|▉         | 406/4096 [00:01<00:14, 250.61it/s]
Adding requests:  11%|█         | 432/4096 [00:01<00:14, 252.38it/s]
Adding requests:  11%|█         | 459/4096 [00:01<00:14, 256.66it/s]
Adding requests:  12%|█▏        | 488/4096 [00:01<00:13, 263.64it/s]
Adding requests:  13%|█▎        | 515/4096 [00:02<00:14, 251.54it/s]
Adding requests:  13%|█▎        | 544/4096 [00:02<00:13, 260.28it/s]
Adding requests:  14%|█▍        | 574/4096 [00:02<00:13, 269.83it/s]
Adding requests:  15%|█▍        | 602/4096 [00:02<00:13, 263.20it/s]
Adding requests:  15%|█▌        | 629/4096 [00:02<00:13, 252.34it/s]
Adding requests:  16%|█▌        | 655/4096 [00:02<00:13, 251.93it/s]
Adding requests:  17%|█▋        | 682/4096 [00:02<00:13, 255.56it/s]
Adding requests:  17%|█▋        | 709/4096 [00:02<00:13, 259.36it/s]
Adding requests:  18%|█▊        | 736/4096 [00:02<00:14, 239.56it/s]
Adding requests:  19%|█▊        | 763/4096 [00:03<00:13, 246.01it/s]
Adding requests:  19%|█▉        | 792/4096 [00:03<00:12, 254.50it/s]
Adding requests:  20%|█▉        | 818/4096 [00:03<00:12, 254.82it/s]
Adding requests:  21%|██        | 844/4096 [00:03<00:13, 249.84it/s]
Adding requests:  21%|██▏       | 872/4096 [00:03<00:12, 257.61it/s]
Adding requests:  22%|██▏       | 900/4096 [00:03<00:12, 261.88it/s]
Adding requests:  23%|██▎       | 927/4096 [00:03<00:12, 255.12it/s]
Adding requests:  23%|██▎       | 953/4096 [00:03<00:12, 247.21it/s]
Adding requests:  24%|██▍       | 979/4096 [00:03<00:12, 250.39it/s]
Adding requests:  25%|██▍       | 1005/4096 [00:03<00:12, 250.60it/s]
Adding requests:  25%|██▌       | 1033/4096 [00:04<00:11, 257.24it/s]
Adding requests:  26%|██▌       | 1059/4096 [00:04<00:12, 243.49it/s]
Adding requests:  26%|██▋       | 1085/4096 [00:04<00:12, 246.21it/s]
Adding requests:  27%|██▋       | 1110/4096 [00:04<00:12, 243.39it/s]
Adding requests:  28%|██▊       | 1139/4096 [00:04<00:11, 256.03it/s]
Adding requests:  28%|██▊       | 1165/4096 [00:04<00:12, 238.84it/s]
Adding requests:  29%|██▉       | 1190/4096 [00:04<00:12, 240.39it/s]
Adding requests:  30%|██▉       | 1219/4096 [00:04<00:11, 253.13it/s]
Adding requests:  30%|███       | 1245/4096 [00:04<00:11, 253.70it/s]
Adding requests:  31%|███       | 1271/4096 [00:05<00:11, 240.85it/s]
Adding requests:  32%|███▏      | 1296/4096 [00:05<00:11, 240.24it/s]
Adding requests:  32%|███▏      | 1322/4096 [00:05<00:11, 244.54it/s]
Adding requests:  33%|███▎      | 1351/4096 [00:05<00:10, 254.52it/s]
Adding requests:  34%|███▎      | 1377/4096 [00:05<00:10, 249.22it/s]
Adding requests:  34%|███▍      | 1403/4096 [00:05<00:10, 248.32it/s]
Adding requests:  35%|███▍      | 1431/4096 [00:05<00:10, 256.31it/s]
Adding requests:  36%|███▌      | 1459/4096 [00:05<00:10, 263.15it/s]
Adding requests:  36%|███▋      | 1486/4096 [00:05<00:10, 257.55it/s]
Adding requests:  37%|███▋      | 1512/4096 [00:05<00:10, 256.42it/s]
Adding requests:  38%|███▊      | 1540/4096 [00:06<00:09, 260.66it/s]
Adding requests:  38%|███▊      | 1567/4096 [00:06<00:09, 261.75it/s]
Adding requests:  39%|███▉      | 1594/4096 [00:06<00:10, 246.84it/s]
Adding requests:  40%|███▉      | 1619/4096 [00:06<00:10, 241.24it/s]
Adding requests:  40%|████      | 1645/4096 [00:06<00:09, 245.37it/s]
Adding requests:  41%|████      | 1671/4096 [00:06<00:09, 247.81it/s]
Adding requests:  41%|████▏     | 1696/4096 [00:06<00:09, 242.24it/s]
Adding requests:  42%|████▏     | 1721/4096 [00:06<00:09, 240.85it/s]
Adding requests:  43%|████▎     | 1750/4096 [00:06<00:09, 254.20it/s]
Adding requests:  43%|████▎     | 1779/4096 [00:07<00:08, 263.29it/s]
Adding requests:  44%|████▍     | 1806/4096 [00:07<00:08, 256.89it/s]
Adding requests:  45%|████▍     | 1832/4096 [00:07<00:09, 249.11it/s]
Adding requests:  45%|████▌     | 1860/4096 [00:07<00:08, 256.43it/s]
Adding requests:  46%|████▌     | 1889/4096 [00:07<00:08, 262.78it/s]
Adding requests:  47%|████▋     | 1916/4096 [00:07<00:08, 259.24it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:07<00:08, 251.56it/s]
Adding requests:  48%|████▊     | 1969/4096 [00:07<00:08, 255.90it/s]
Adding requests:  49%|████▊     | 1996/4096 [00:07<00:08, 258.21it/s]
Adding requests:  49%|████▉     | 2022/4096 [00:08<00:08, 249.81it/s]
Adding requests:  50%|█████     | 2048/4096 [00:08<00:08, 240.04it/s]
Adding requests:  51%|█████     | 2073/4096 [00:08<00:08, 239.39it/s]
Adding requests:  51%|█████▏    | 2100/4096 [00:08<00:08, 247.59it/s]
Adding requests:  52%|█████▏    | 2126/4096 [00:08<00:07, 250.48it/s]
Adding requests:  53%|█████▎    | 2152/4096 [00:08<00:08, 241.70it/s]
Adding requests:  53%|█████▎    | 2177/4096 [00:08<00:07, 242.06it/s]
Adding requests:  54%|█████▍    | 2203/4096 [00:08<00:07, 246.69it/s]
Adding requests:  54%|█████▍    | 2228/4096 [00:08<00:07, 247.36it/s]
Adding requests:  55%|█████▌    | 2253/4096 [00:08<00:07, 243.12it/s]
Adding requests:  56%|█████▌    | 2281/4096 [00:09<00:07, 251.63it/s]
Adding requests:  56%|█████▋    | 2309/4096 [00:09<00:06, 257.81it/s]
Adding requests:  57%|█████▋    | 2335/4096 [00:09<00:06, 254.75it/s]
Adding requests:  58%|█████▊    | 2361/4096 [00:09<00:07, 245.00it/s]
Adding requests:  58%|█████▊    | 2390/4096 [00:09<00:06, 256.16it/s]
Adding requests:  59%|█████▉    | 2418/4096 [00:09<00:06, 260.75it/s]
Adding requests:  60%|█████▉    | 2445/4096 [00:09<00:06, 261.75it/s]
Adding requests:  60%|██████    | 2472/4096 [00:09<00:06, 249.58it/s]
Adding requests:  61%|██████    | 2499/4096 [00:09<00:06, 253.71it/s]
Adding requests:  62%|██████▏   | 2527/4096 [00:10<00:06, 259.94it/s]
Adding requests:  62%|██████▏   | 2559/4096 [00:10<00:05, 273.86it/s]
Adding requests:  63%|██████▎   | 2587/4096 [00:10<00:05, 264.98it/s]
Adding requests:  64%|██████▍   | 2614/4096 [00:10<00:05, 262.01it/s]
Adding requests:  64%|██████▍   | 2641/4096 [00:10<00:05, 262.37it/s]
Adding requests:  65%|██████▌   | 2669/4096 [00:10<00:05, 266.42it/s]
Adding requests:  66%|██████▌   | 2696/4096 [00:10<00:05, 252.12it/s]
Adding requests:  66%|██████▋   | 2722/4096 [00:10<00:05, 251.16it/s]
Adding requests:  67%|██████▋   | 2749/4096 [00:10<00:05, 255.07it/s]
Adding requests:  68%|██████▊   | 2777/4096 [00:10<00:05, 260.20it/s]
Adding requests:  68%|██████▊   | 2804/4096 [00:11<00:05, 256.24it/s]
Adding requests:  69%|██████▉   | 2830/4096 [00:11<00:05, 251.50it/s]
Adding requests:  70%|██████▉   | 2858/4096 [00:11<00:04, 257.89it/s]
Adding requests:  70%|███████   | 2885/4096 [00:11<00:04, 259.50it/s]
Adding requests:  71%|███████   | 2911/4096 [00:11<00:04, 249.40it/s]
Adding requests:  72%|███████▏  | 2937/4096 [00:11<00:04, 251.74it/s]
Adding requests:  72%|███████▏  | 2965/4096 [00:11<00:04, 258.32it/s]
Adding requests:  73%|███████▎  | 2994/4096 [00:11<00:04, 267.30it/s]
Adding requests:  74%|███████▍  | 3021/4096 [00:11<00:04, 262.95it/s]
Adding requests:  74%|███████▍  | 3048/4096 [00:12<00:04, 255.89it/s]
Adding requests:  75%|███████▌  | 3078/4096 [00:12<00:03, 266.88it/s]
Adding requests:  76%|███████▌  | 3106/4096 [00:12<00:03, 268.20it/s]
Adding requests:  76%|███████▋  | 3133/4096 [00:12<00:03, 264.61it/s]
Adding requests:  77%|███████▋  | 3160/4096 [00:12<00:03, 250.35it/s]
Adding requests:  78%|███████▊  | 3189/4096 [00:12<00:03, 259.80it/s]
Adding requests:  79%|███████▊  | 3216/4096 [00:12<00:03, 261.59it/s]
Adding requests:  79%|███████▉  | 3243/4096 [00:12<00:03, 262.90it/s]
Adding requests:  80%|███████▉  | 3270/4096 [00:12<00:03, 249.28it/s]
Adding requests:  80%|████████  | 3296/4096 [00:12<00:03, 247.59it/s]
Adding requests:  81%|████████  | 3324/4096 [00:13<00:03, 254.11it/s]
Adding requests:  82%|████████▏ | 3351/4096 [00:13<00:02, 256.31it/s]
Adding requests:  82%|████████▏ | 3377/4096 [00:13<00:02, 250.49it/s]
Adding requests:  83%|████████▎ | 3404/4096 [00:13<00:02, 253.46it/s]
Adding requests:  84%|████████▍ | 3432/4096 [00:13<00:02, 260.16it/s]
Adding requests:  84%|████████▍ | 3459/4096 [00:13<00:02, 262.50it/s]
Adding requests:  85%|████████▌ | 3486/4096 [00:13<00:02, 248.41it/s]
Adding requests:  86%|████████▌ | 3515/4096 [00:13<00:02, 258.28it/s]
Adding requests:  87%|████████▋ | 3545/4096 [00:13<00:02, 269.64it/s]
Adding requests:  87%|████████▋ | 3573/4096 [00:14<00:01, 265.62it/s]
Adding requests:  88%|████████▊ | 3600/4096 [00:14<00:01, 251.97it/s]
Adding requests:  89%|████████▊ | 3628/4096 [00:14<00:01, 257.73it/s]
Adding requests:  89%|████████▉ | 3655/4096 [00:14<00:01, 260.54it/s]
Adding requests:  90%|████████▉ | 3682/4096 [00:14<00:01, 252.99it/s]
Adding requests:  91%|█████████ | 3708/4096 [00:14<00:01, 233.99it/s]
Adding requests:  91%|█████████ | 3736/4096 [00:14<00:01, 245.77it/s]
Adding requests:  92%|█████████▏| 3762/4096 [00:14<00:01, 248.06it/s]
Adding requests:  92%|█████████▏| 3788/4096 [00:14<00:01, 243.27it/s]
Adding requests:  93%|█████████▎| 3813/4096 [00:15<00:01, 229.51it/s]
Adding requests:  94%|█████████▍| 3841/4096 [00:15<00:01, 242.50it/s]
Adding requests:  94%|█████████▍| 3869/4096 [00:15<00:00, 252.69it/s]
Adding requests:  95%|█████████▌| 3895/4096 [00:15<00:00, 244.86it/s]
Adding requests:  96%|█████████▌| 3920/4096 [00:15<00:00, 232.62it/s]
Adding requests:  96%|█████████▋| 3946/4096 [00:15<00:00, 240.01it/s]
Adding requests:  97%|█████████▋| 3973/4096 [00:15<00:00, 246.05it/s]
Adding requests:  98%|█████████▊| 3998/4096 [00:15<00:00, 245.83it/s]
Adding requests:  98%|█████████▊| 4023/4096 [00:15<00:00, 240.51it/s]
Adding requests:  99%|█████████▉| 4050/4096 [00:16<00:00, 247.21it/s]
Adding requests: 100%|█████████▉| 4078/4096 [00:16<00:00, 254.31it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 253.04it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 66/4096 [00:02<02:33, 26.23it/s, est. speed input: 26859.03 toks/s, output: 26.23 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:08<06:40,  9.99it/s, est. speed input: 11695.17 toks/s, output: 11.42 toks/s]
Processed prompts:   3%|▎         | 130/4096 [00:14<08:47,  7.51it/s, est. speed input: 9089.07 toks/s, output: 8.88 toks/s] 
Processed prompts:   4%|▍         | 162/4096 [00:19<09:01,  7.26it/s, est. speed input: 8580.55 toks/s, output: 8.38 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:25<10:04,  6.46it/s, est. speed input: 7821.51 toks/s, output: 7.64 toks/s]
Processed prompts:   6%|▌         | 226/4096 [00:31<10:42,  6.03it/s, est. speed input: 7355.15 toks/s, output: 7.18 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:37<11:05,  5.77it/s, est. speed input: 7038.56 toks/s, output: 6.87 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:43<11:19,  5.60it/s, est. speed input: 6810.50 toks/s, output: 6.65 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:48<10:36,  5.93it/s, est. speed input: 6827.98 toks/s, output: 6.67 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:54<10:54,  5.71it/s, est. speed input: 6668.96 toks/s, output: 6.51 toks/s]
Processed prompts:   9%|▉         | 386/4096 [01:00<11:05,  5.57it/s, est. speed input: 6541.73 toks/s, output: 6.39 toks/s]
Processed prompts:  10%|█         | 418/4096 [01:06<11:11,  5.48it/s, est. speed input: 6437.74 toks/s, output: 6.29 toks/s]
Processed prompts:  11%|█         | 450/4096 [01:12<11:13,  5.42it/s, est. speed input: 6351.12 toks/s, output: 6.20 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:17<10:25,  5.78it/s, est. speed input: 6389.75 toks/s, output: 6.24 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:23<10:37,  5.62it/s, est. speed input: 6317.90 toks/s, output: 6.17 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:29<10:44,  5.51it/s, est. speed input: 6255.61 toks/s, output: 6.11 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:35<10:47,  5.44it/s, est. speed input: 6201.26 toks/s, output: 6.06 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:41<10:47,  5.39it/s, est. speed input: 6153.38 toks/s, output: 6.01 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:47<10:45,  5.35it/s, est. speed input: 6110.95 toks/s, output: 5.97 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:52<09:58,  5.72it/s, est. speed input: 6147.33 toks/s, output: 6.00 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:58<10:07,  5.58it/s, est. speed input: 6109.09 toks/s, output: 5.97 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [02:04<10:12,  5.48it/s, est. speed input: 6074.45 toks/s, output: 5.93 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [02:10<10:07,  5.48it/s, est. speed input: 6052.77 toks/s, output: 5.91 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [02:16<10:08,  5.41it/s, est. speed input: 6023.71 toks/s, output: 5.88 toks/s]
Processed prompts:  20%|██        | 834/4096 [02:21<09:25,  5.77it/s, est. speed input: 6055.77 toks/s, output: 5.91 toks/s]
Processed prompts:  21%|██        | 866/4096 [02:27<09:35,  5.61it/s, est. speed input: 6028.91 toks/s, output: 5.89 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:33<09:40,  5.51it/s, est. speed input: 6003.89 toks/s, output: 5.86 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:39<09:42,  5.43it/s, est. speed input: 5980.65 toks/s, output: 5.84 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:45<09:42,  5.38it/s, est. speed input: 5959.10 toks/s, output: 5.82 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:49<08:59,  5.75it/s, est. speed input: 5987.76 toks/s, output: 5.85 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:56<09:08,  5.60it/s, est. speed input: 5967.89 toks/s, output: 5.83 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [03:02<09:12,  5.50it/s, est. speed input: 5949.16 toks/s, output: 5.81 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [03:08<09:14,  5.42it/s, est. speed input: 5930.50 toks/s, output: 5.79 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [03:14<09:13,  5.37it/s, est. speed input: 5913.69 toks/s, output: 5.78 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [03:20<09:10,  5.34it/s, est. speed input: 5898.08 toks/s, output: 5.76 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [03:25<08:28,  5.72it/s, est. speed input: 5923.69 toks/s, output: 5.78 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [03:31<08:35,  5.58it/s, est. speed input: 5908.60 toks/s, output: 5.77 toks/s]
Processed prompts:  31%|███       | 1250/4096 [03:37<08:38,  5.48it/s, est. speed input: 5894.41 toks/s, output: 5.76 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:43<08:39,  5.42it/s, est. speed input: 5881.00 toks/s, output: 5.74 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:49<08:37,  5.37it/s, est. speed input: 5868.28 toks/s, output: 5.73 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:53<07:59,  5.74it/s, est. speed input: 5890.72 toks/s, output: 5.75 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [04:00<08:06,  5.59it/s, est. speed input: 5878.30 toks/s, output: 5.74 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [04:06<08:09,  5.49it/s, est. speed input: 5866.53 toks/s, output: 5.73 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [04:12<08:09,  5.42it/s, est. speed input: 5855.28 toks/s, output: 5.72 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [04:18<08:07,  5.38it/s, est. speed input: 5844.59 toks/s, output: 5.71 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [04:24<08:04,  5.35it/s, est. speed input: 5834.39 toks/s, output: 5.70 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [04:29<07:27,  5.72it/s, est. speed input: 5854.53 toks/s, output: 5.72 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [04:35<07:32,  5.58it/s, est. speed input: 5844.50 toks/s, output: 5.71 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [04:40<07:30,  5.54it/s, est. speed input: 5839.25 toks/s, output: 5.70 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [04:47<07:31,  5.46it/s, est. speed input: 5829.95 toks/s, output: 5.69 toks/s]
Processed prompts:  41%|████      | 1666/4096 [04:53<07:29,  5.40it/s, est. speed input: 5821.07 toks/s, output: 5.68 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:57<06:56,  5.76it/s, est. speed input: 5839.43 toks/s, output: 5.70 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [05:03<07:02,  5.61it/s, est. speed input: 5830.66 toks/s, output: 5.69 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [05:09<07:04,  5.50it/s, est. speed input: 5822.16 toks/s, output: 5.69 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [05:15<07:03,  5.43it/s, est. speed input: 5814.06 toks/s, output: 5.68 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [05:22<07:01,  5.38it/s, est. speed input: 5806.28 toks/s, output: 5.67 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [05:26<06:29,  5.75it/s, est. speed input: 5823.22 toks/s, output: 5.69 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [05:32<06:34,  5.60it/s, est. speed input: 5815.53 toks/s, output: 5.68 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [05:38<06:35,  5.50it/s, est. speed input: 5808.08 toks/s, output: 5.67 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [05:44<06:34,  5.43it/s, est. speed input: 5800.88 toks/s, output: 5.66 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [05:50<06:32,  5.38it/s, est. speed input: 5793.93 toks/s, output: 5.66 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [05:57<06:28,  5.35it/s, est. speed input: 5787.23 toks/s, output: 5.65 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [06:01<05:57,  5.72it/s, est. speed input: 5802.91 toks/s, output: 5.67 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [06:07<06:00,  5.58it/s, est. speed input: 5796.31 toks/s, output: 5.66 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [06:13<06:01,  5.48it/s, est. speed input: 5789.81 toks/s, output: 5.65 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [06:19<06:00,  5.42it/s, est. speed input: 5783.41 toks/s, output: 5.65 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [06:25<05:53,  5.43it/s, est. speed input: 5780.45 toks/s, output: 5.64 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [06:30<05:25,  5.79it/s, est. speed input: 5795.16 toks/s, output: 5.66 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [06:36<05:29,  5.63it/s, est. speed input: 5789.44 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [06:42<05:30,  5.51it/s, est. speed input: 5783.26 toks/s, output: 5.65 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [06:48<05:29,  5.43it/s, est. speed input: 5777.19 toks/s, output: 5.64 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [06:54<05:26,  5.38it/s, est. speed input: 5771.45 toks/s, output: 5.64 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [06:59<04:59,  5.76it/s, est. speed input: 5785.57 toks/s, output: 5.65 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [07:05<05:02,  5.60it/s, est. speed input: 5780.09 toks/s, output: 5.64 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [07:11<05:02,  5.50it/s, est. speed input: 5774.75 toks/s, output: 5.64 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [07:17<05:00,  5.43it/s, est. speed input: 5769.55 toks/s, output: 5.63 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [07:23<04:56,  5.38it/s, est. speed input: 5764.60 toks/s, output: 5.63 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [07:29<04:52,  5.35it/s, est. speed input: 5759.71 toks/s, output: 5.62 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [07:34<04:28,  5.72it/s, est. speed input: 5772.23 toks/s, output: 5.64 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [07:40<04:29,  5.57it/s, est. speed input: 5767.22 toks/s, output: 5.63 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [07:46<04:28,  5.48it/s, est. speed input: 5762.39 toks/s, output: 5.63 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [07:52<04:25,  5.42it/s, est. speed input: 5757.72 toks/s, output: 5.62 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [07:58<04:21,  5.37it/s, est. speed input: 5753.16 toks/s, output: 5.62 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [08:03<03:59,  5.74it/s, est. speed input: 5765.33 toks/s, output: 5.63 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [08:09<03:59,  5.59it/s, est. speed input: 5760.79 toks/s, output: 5.63 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [08:15<03:58,  5.49it/s, est. speed input: 5756.36 toks/s, output: 5.62 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [08:21<03:55,  5.43it/s, est. speed input: 5752.04 toks/s, output: 5.62 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [08:27<03:51,  5.38it/s, est. speed input: 5747.82 toks/s, output: 5.61 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [08:32<03:31,  5.75it/s, est. speed input: 5759.25 toks/s, output: 5.62 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [08:38<03:31,  5.60it/s, est. speed input: 5755.04 toks/s, output: 5.62 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [08:44<03:29,  5.49it/s, est. speed input: 5750.92 toks/s, output: 5.62 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [08:50<03:26,  5.43it/s, est. speed input: 5746.89 toks/s, output: 5.61 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [08:56<03:21,  5.38it/s, est. speed input: 5742.95 toks/s, output: 5.61 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [09:02<03:17,  5.35it/s, est. speed input: 5739.13 toks/s, output: 5.60 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [09:07<02:58,  5.72it/s, est. speed input: 5749.88 toks/s, output: 5.62 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [09:13<02:57,  5.58it/s, est. speed input: 5746.04 toks/s, output: 5.61 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [09:19<02:54,  5.48it/s, est. speed input: 5742.27 toks/s, output: 5.61 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [09:25<02:50,  5.42it/s, est. speed input: 5738.59 toks/s, output: 5.60 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [09:31<02:46,  5.37it/s, est. speed input: 5735.01 toks/s, output: 5.60 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [09:36<02:30,  5.74it/s, est. speed input: 5745.23 toks/s, output: 5.61 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [09:42<02:28,  5.59it/s, est. speed input: 5741.63 toks/s, output: 5.61 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [09:48<02:25,  5.49it/s, est. speed input: 5738.09 toks/s, output: 5.60 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [09:54<02:21,  5.42it/s, est. speed input: 5734.61 toks/s, output: 5.60 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [10:00<02:16,  5.38it/s, est. speed input: 5731.21 toks/s, output: 5.60 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [10:06<02:11,  5.34it/s, est. speed input: 5727.87 toks/s, output: 5.59 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [10:11<01:57,  5.72it/s, est. speed input: 5737.67 toks/s, output: 5.60 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [10:17<01:54,  5.58it/s, est. speed input: 5734.34 toks/s, output: 5.60 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [10:23<01:50,  5.48it/s, est. speed input: 5731.02 toks/s, output: 5.60 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [10:29<01:46,  5.41it/s, est. speed input: 5727.70 toks/s, output: 5.59 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [10:35<01:40,  5.37it/s, est. speed input: 5724.53 toks/s, output: 5.59 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [10:40<01:28,  5.74it/s, est. speed input: 5734.02 toks/s, output: 5.60 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [10:46<01:25,  5.60it/s, est. speed input: 5731.13 toks/s, output: 5.60 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [10:52<01:21,  5.49it/s, est. speed input: 5727.72 toks/s, output: 5.59 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [10:58<01:15,  5.47it/s, est. speed input: 5726.30 toks/s, output: 5.59 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [11:04<01:10,  5.41it/s, est. speed input: 5723.21 toks/s, output: 5.59 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [11:09<01:00,  5.78it/s, est. speed input: 5732.45 toks/s, output: 5.60 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [11:15<00:56,  5.62it/s, est. speed input: 5729.47 toks/s, output: 5.60 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [11:21<00:51,  5.51it/s, est. speed input: 5726.53 toks/s, output: 5.59 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [11:27<00:46,  5.44it/s, est. speed input: 5723.65 toks/s, output: 5.59 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [11:33<00:41,  5.39it/s, est. speed input: 5720.88 toks/s, output: 5.59 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [11:39<00:35,  5.41it/s, est. speed input: 5719.80 toks/s, output: 5.59 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [11:43<00:27,  5.77it/s, est. speed input: 5728.19 toks/s, output: 5.59 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [11:50<00:22,  5.61it/s, est. speed input: 5725.33 toks/s, output: 5.59 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [11:56<00:17,  5.50it/s, est. speed input: 5722.54 toks/s, output: 5.59 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [12:02<00:11,  5.43it/s, est. speed input: 5719.80 toks/s, output: 5.59 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [12:08<00:05,  5.44it/s, est. speed input: 5718.87 toks/s, output: 5.58 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [12:08<00:00,  5.44it/s, est. speed input: 5761.06 toks/s, output: 5.63 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [12:08<00:00,  5.63it/s, est. speed input: 5761.06 toks/s, output: 5.63 toks/s]
[rank0]:[W126 03:12:01.548362107 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 816.6s

测试结果:
  Requests/s:   5.28
  Tokens/s:     5409.50
  Total Reqs:   4096
  Elapsed:      776.12s

  [Prefill 分析]
  Total Prefill Tokens: 4194304
  Prefill Tokens/s:     5404.22

============================================================
[8/8] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-7B-INT8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:13:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:13:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=104255) WARNING 01-26 03:13:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=104255) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=104255) WARNING 01-26 03:13:37 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     def forward(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     raise e
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "<eval_with_key>.58", line 339, in forward
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     submod_6 = self.submod_6(getitem_13, s72, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_, getitem_14, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_13 = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_ = getitem_14 = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 177, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     self._maybe_compile_for_range_entry(range_entry, args)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 144, in _maybe_compile_for_range_entry
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     range_entry.runnable = self.vllm_backend.compiler_manager.compile(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/backends.py", line 244, in compile
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     compiled_graph, handle = self.compiler.compile(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                              ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 233, in compile
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     compiled_graph = standalone_compile(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                      ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/__init__.py", line 422, in standalone_compile
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return standalone_compile(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 252, in standalone_compile
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     compiled_fn = compile_fx(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                   ^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2413, in compile_fx
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return compile_fx(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2681, in compile_fx
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return aot_autograd(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/backends/common.py", line 117, in __call__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1096, in aot_module_simplified
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     aot_state = create_aot_state(
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                 ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 522, in create_aot_state
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     stack.enter_context(preserve_rng_state())
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/lib/python3.12/contextlib.py", line 526, in enter_context
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     result = _enter(cm)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]              ^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return next(self.gen)
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py", line 2220, in preserve_rng_state
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     cuda_rng_state = torch.clone(torch.cuda.get_rng_state())
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 43, in get_rng_state
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]     return default_generator.get_state()
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=104255) ERROR 01-26 03:13:44 [core.py:866] 


─── STDERR ───
[2026-01-26 03:13:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:13:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:13:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:13:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:13:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:13:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:13:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:13:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:13:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:13:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:13:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:13:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:13:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 03:13:24.586040678 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=104255) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=104255) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.03it/s]
(EngineCore_DP0 pid=104255) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.26s/it]
(EngineCore_DP0 pid=104255) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.21s/it]
(EngineCore_DP0 pid=104255) 
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=104255) [2026-01-26 03:13:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=104255) Process EngineCore_DP0:
(EngineCore_DP0 pid=104255) Traceback (most recent call last):
(EngineCore_DP0 pid=104255)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=104255)     self.run()
(EngineCore_DP0 pid=104255)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=104255)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=104255)     raise e
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=104255)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=104255)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=104255)     super().__init__(
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=104255)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=104255)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=104255)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=104255)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=104255)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=104255)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=104255)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=104255)     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=104255)     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=104255)     self.model_runner.profile_run()
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=104255)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=104255)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=104255)     return func(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=104255)     outputs = self.model(
(EngineCore_DP0 pid=104255)               ^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=104255)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=104255)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=104255)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=104255)     hidden_states = self.model(
(EngineCore_DP0 pid=104255)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=104255)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=104255)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=104255)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=104255)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=104255)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=104255)     def forward(
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=104255)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=104255)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=104255)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=104255)     raise e
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=104255)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=104255)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=104255)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "<eval_with_key>.58", line 339, in forward
(EngineCore_DP0 pid=104255)     submod_6 = self.submod_6(getitem_13, s72, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_, getitem_14, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_13 = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_post_attention_layernorm_parameters_weight_ = getitem_14 = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_2_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=104255)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=104255)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 177, in __call__
(EngineCore_DP0 pid=104255)     self._maybe_compile_for_range_entry(range_entry, args)
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 144, in _maybe_compile_for_range_entry
(EngineCore_DP0 pid=104255)     range_entry.runnable = self.vllm_backend.compiler_manager.compile(
(EngineCore_DP0 pid=104255)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/backends.py", line 244, in compile
(EngineCore_DP0 pid=104255)     compiled_graph, handle = self.compiler.compile(
(EngineCore_DP0 pid=104255)                              ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 233, in compile
(EngineCore_DP0 pid=104255)     compiled_graph = standalone_compile(
(EngineCore_DP0 pid=104255)                      ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/__init__.py", line 422, in standalone_compile
(EngineCore_DP0 pid=104255)     return standalone_compile(
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 252, in standalone_compile
(EngineCore_DP0 pid=104255)     compiled_fn = compile_fx(
(EngineCore_DP0 pid=104255)                   ^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2413, in compile_fx
(EngineCore_DP0 pid=104255)     return compile_fx(
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 2681, in compile_fx
(EngineCore_DP0 pid=104255)     return aot_autograd(
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/backends/common.py", line 117, in __call__
(EngineCore_DP0 pid=104255)     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
(EngineCore_DP0 pid=104255)          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1096, in aot_module_simplified
(EngineCore_DP0 pid=104255)     aot_state = create_aot_state(
(EngineCore_DP0 pid=104255)                 ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 522, in create_aot_state
(EngineCore_DP0 pid=104255)     stack.enter_context(preserve_rng_state())
(EngineCore_DP0 pid=104255)   File "/usr/lib/python3.12/contextlib.py", line 526, in enter_context
(EngineCore_DP0 pid=104255)     result = _enter(cm)
(EngineCore_DP0 pid=104255)              ^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
(EngineCore_DP0 pid=104255)     return next(self.gen)
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py", line 2220, in preserve_rng_state
(EngineCore_DP0 pid=104255)     cuda_rng_state = torch.clone(torch.cuda.get_rng_state())
(EngineCore_DP0 pid=104255)                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255)   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/random.py", line 43, in get_rng_state
(EngineCore_DP0 pid=104255)     return default_generator.get_state()
(EngineCore_DP0 pid=104255)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=104255) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=104255) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=104255) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=104255) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=104255) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=104255) 
[rank0]:[W126 03:13:45.171259920 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[ERROR] 测试失败: M=65536 (exit code: 1)


------------------------------------------------------------
  生成 CSV: Qwen2.5-7B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10/Qwen2.5-7B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
512,512,1,128,128,17.0380,8740.4940,7.5126
1024,1024,1,128,128,16.5991,17014.0826,7.7113
2048,1024,2,256,128,21.0004,21525.3937,12.1903
4096,1024,4,512,128,21.8646,22411.2535,23.4168
8192,1024,8,1024,128,22.2626,22819.1441,45.9965
16384,1024,16,2048,128,8.2328,8438.5769,248.7623
32768,1024,32,4096,128,5.2776,5409.5021,776.1158
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[INFO] 完成: 7 成功, 1 失败


============================================================
  Benchmark 完成!
============================================================


总计: 35 成功, 5 失败
============================================================
